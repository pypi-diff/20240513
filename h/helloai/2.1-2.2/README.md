# Comparing `tmp/helloai-2.1-py3-none-any.whl.zip` & `tmp/helloai-2.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,54 +1,56 @@
-Zip file size: 66721 bytes, number of entries: 52
--rw-rw-rw-  2.0 fat      559 b- defN 23-Jul-13 02:08 hi.py
--rw-rw-rw-  2.0 fat       84 b- defN 23-Jul-13 02:08 helloai/__init__.py
--rw-rw-rw-  2.0 fat       40 b- defN 23-Jul-13 02:08 helloai/__main__.py
--rw-rw-rw-  2.0 fat       84 b- defN 23-Jul-13 02:08 helloai/builtins.py
--rw-rw-rw-  2.0 fat     3684 b- defN 23-Jul-13 02:08 helloai/runner.py
--rw-rw-rw-  2.0 fat     1144 b- defN 23-Jul-13 02:08 helloai/version.py
--rw-rw-rw-  2.0 fat      676 b- defN 23-Jul-13 02:08 helloai/core/__init__.py
--rw-rw-rw-  2.0 fat     6407 b- defN 23-Jul-13 02:08 helloai/core/api.py
--rw-rw-rw-  2.0 fat     5606 b- defN 23-Jul-13 02:08 helloai/core/camera.py
--rw-rw-rw-  2.0 fat    16195 b- defN 23-Jul-13 02:08 helloai/core/colors.py
--rw-rw-rw-  2.0 fat     1526 b- defN 23-Jul-13 02:08 helloai/core/config.py
--rw-rw-rw-  2.0 fat     8536 b- defN 23-Jul-13 02:08 helloai/core/core.py
--rw-rw-rw-  2.0 fat     1812 b- defN 23-Jul-13 02:08 helloai/core/display.py
--rw-rw-rw-  2.0 fat      720 b- defN 23-Jul-13 02:08 helloai/core/helper.py
--rw-rw-rw-  2.0 fat    52108 b- defN 23-Jul-13 02:08 helloai/core/image.py
--rw-rw-rw-  2.0 fat     2828 b- defN 23-Jul-13 02:08 helloai/core/movie.py
--rw-rw-rw-  2.0 fat      790 b- defN 23-Jul-13 02:08 helloai/core/mytimer.py
--rw-rw-rw-  2.0 fat     2468 b- defN 23-Jul-13 02:08 helloai/core/plotwindow.py
--rw-rw-rw-  2.0 fat      285 b- defN 23-Jul-13 02:08 helloai/core/singlestore.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-13 02:08 helloai/core/sketch.py
--rw-rw-rw-  2.0 fat      489 b- defN 23-Jul-13 02:08 helloai/core/trackbarwin.py
--rw-rw-rw-  2.0 fat    13096 b- defN 23-Jul-13 02:08 helloai/core/vector.py
--rw-rw-rw-  2.0 fat     2834 b- defN 23-Jul-13 02:08 helloai/core/video.py
--rw-rw-rw-  2.0 fat     1800 b- defN 23-Jul-13 02:08 helloai/core/video_writer.py
--rw-rw-rw-  2.0 fat     2683 b- defN 23-Jul-13 02:08 helloai/core/virtualcamera.py
--rw-rw-rw-  2.0 fat     8984 b- defN 23-Jul-13 02:08 helloai/core/window.py
--rw-rw-rw-  2.0 fat      132 b- defN 23-Jul-13 02:08 helloai/ext/__init__.py
--rw-rw-rw-  2.0 fat       20 b- defN 23-Jul-13 02:08 helloai/ext/aruco/__init__.py
--rw-rw-rw-  2.0 fat     4330 b- defN 23-Jul-13 02:08 helloai/ext/aruco/aruco.py
--rw-rw-rw-  2.0 fat     3111 b- defN 23-Jul-13 02:08 helloai/ext/aruco/aruco_test.py
--rw-rw-rw-  2.0 fat       28 b- defN 23-Jul-13 02:08 helloai/ext/face_detector/__init__.py
--rw-rw-rw-  2.0 fat     4379 b- defN 23-Jul-13 02:08 helloai/ext/face_detector/face_detector.py
--rw-rw-rw-  2.0 fat       29 b- defN 23-Jul-13 02:08 helloai/ext/hands_detector/__init__.py
--rw-rw-rw-  2.0 fat     5110 b- defN 23-Jul-13 02:08 helloai/ext/hands_detector/hands_detector.py
--rw-rw-rw-  2.0 fat       30 b- defN 23-Jul-13 02:08 helloai/ext/pose_detector/__init__.py
--rw-rw-rw-  2.0 fat     4053 b- defN 23-Jul-13 02:08 helloai/ext/pose_detector/pose_detector.py
--rw-rw-rw-  2.0 fat       31 b- defN 23-Jul-13 02:08 helloai/ext/tmimage/__init__.py
--rw-rw-rw-  2.0 fat     4986 b- defN 23-Jul-13 02:08 helloai/ext/tmimage/tm_imageproject.py
--rw-rw-rw-  2.0 fat     2241 b- defN 23-Jul-13 02:08 helloai/utils/PID.py
--rw-rw-rw-  2.0 fat      112 b- defN 23-Jul-13 02:08 helloai/utils/__init__.py
--rw-rw-rw-  2.0 fat     6672 b- defN 23-Jul-13 02:08 helloai/utils/cvzone.py
--rw-rw-rw-  2.0 fat     3288 b- defN 23-Jul-13 02:08 helloai/utils/fetcher.py
--rw-rw-rw-  2.0 fat     6915 b- defN 23-Jul-13 02:08 helloai/utils/rand.py
--rw-rw-rw-  2.0 fat     1090 b- defN 23-Jul-13 02:08 helloai/utils/time.py
--rw-rw-rw-  2.0 fat     6878 b- defN 23-Jul-13 02:08 helloai/utils/utils.py
--rw-rw-rw-  2.0 fat     2428 b- defN 23-Jul-13 02:08 helloai/utils/voc.py
--rw-rw-rw-  2.0 fat      849 b- defN 23-Jul-13 02:44 helloai-2.1.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     1225 b- defN 23-Jul-13 02:44 helloai-2.1.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Jul-13 02:44 helloai-2.1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       44 b- defN 23-Jul-13 02:44 helloai-2.1.dist-info/entry_points.txt
--rw-rw-rw-  2.0 fat       11 b- defN 23-Jul-13 02:44 helloai-2.1.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     4220 b- defN 23-Jul-13 02:44 helloai-2.1.dist-info/RECORD
-52 files, 197742 bytes uncompressed, 60065 bytes compressed:  69.6%
+Zip file size: 67735 bytes, number of entries: 54
+-rw-rw-rw-  2.0 fat      559 b- defN 24-May-13 07:14 hi.py
+-rw-rw-rw-  2.0 fat       83 b- defN 24-May-13 07:14 helloai/__init__.py
+-rw-rw-rw-  2.0 fat       40 b- defN 24-May-13 07:14 helloai/__main__.py
+-rw-rw-rw-  2.0 fat       83 b- defN 24-May-13 07:14 helloai/builtins.py
+-rw-rw-rw-  2.0 fat     3688 b- defN 24-May-13 07:14 helloai/runner.py
+-rw-rw-rw-  2.0 fat     1144 b- defN 24-May-13 07:50 helloai/version.py
+-rw-rw-rw-  2.0 fat      675 b- defN 24-May-13 07:14 helloai/core/__init__.py
+-rw-rw-rw-  2.0 fat     6434 b- defN 24-May-13 07:14 helloai/core/api.py
+-rw-rw-rw-  2.0 fat     5675 b- defN 24-May-13 07:14 helloai/core/camera.py
+-rw-rw-rw-  2.0 fat    12976 b- defN 24-May-13 07:14 helloai/core/colors.py
+-rw-rw-rw-  2.0 fat     1531 b- defN 24-May-13 07:14 helloai/core/config.py
+-rw-rw-rw-  2.0 fat     9388 b- defN 24-May-13 07:14 helloai/core/core.py
+-rw-rw-rw-  2.0 fat     1808 b- defN 24-May-13 07:14 helloai/core/display.py
+-rw-rw-rw-  2.0 fat      749 b- defN 24-May-13 07:14 helloai/core/helper.py
+-rw-rw-rw-  2.0 fat    52106 b- defN 24-May-13 07:14 helloai/core/image.py
+-rw-rw-rw-  2.0 fat     2824 b- defN 24-May-13 07:14 helloai/core/movie.py
+-rw-rw-rw-  2.0 fat      790 b- defN 24-May-13 07:14 helloai/core/mytimer.py
+-rw-rw-rw-  2.0 fat     2431 b- defN 24-May-13 07:14 helloai/core/plotwindow.py
+-rw-rw-rw-  2.0 fat      285 b- defN 24-May-13 07:14 helloai/core/singlestore.py
+-rw-rw-rw-  2.0 fat        0 b- defN 24-May-13 07:14 helloai/core/sketch.py
+-rw-rw-rw-  2.0 fat      489 b- defN 24-May-13 07:14 helloai/core/trackbarwin.py
+-rw-rw-rw-  2.0 fat    13056 b- defN 24-May-13 07:14 helloai/core/vector.py
+-rw-rw-rw-  2.0 fat     2831 b- defN 24-May-13 07:14 helloai/core/video.py
+-rw-rw-rw-  2.0 fat     1845 b- defN 24-May-13 07:14 helloai/core/video_writer.py
+-rw-rw-rw-  2.0 fat     2699 b- defN 24-May-13 07:14 helloai/core/virtualcamera.py
+-rw-rw-rw-  2.0 fat     8911 b- defN 24-May-13 07:14 helloai/core/window.py
+-rw-rw-rw-  2.0 fat      157 b- defN 24-May-13 07:14 helloai/ext/__init__.py
+-rw-rw-rw-  2.0 fat       21 b- defN 24-May-13 07:14 helloai/ext/aruco/__init__.py
+-rw-rw-rw-  2.0 fat     4339 b- defN 24-May-13 07:14 helloai/ext/aruco/aruco.py
+-rw-rw-rw-  2.0 fat     3062 b- defN 24-May-13 07:14 helloai/ext/aruco/aruco_test.py
+-rw-rw-rw-  2.0 fat       29 b- defN 24-May-13 07:14 helloai/ext/face_detector/__init__.py
+-rw-rw-rw-  2.0 fat     4523 b- defN 24-May-13 07:14 helloai/ext/face_detector/face_detector.py
+-rw-rw-rw-  2.0 fat       30 b- defN 24-May-13 07:14 helloai/ext/hands_detector/__init__.py
+-rw-rw-rw-  2.0 fat     5432 b- defN 24-May-13 07:14 helloai/ext/hands_detector/hands_detector.py
+-rw-rw-rw-  2.0 fat       30 b- defN 24-May-13 07:14 helloai/ext/pose_detector/__init__.py
+-rw-rw-rw-  2.0 fat     4169 b- defN 24-May-13 07:14 helloai/ext/pose_detector/pose_detector.py
+-rw-rw-rw-  2.0 fat       25 b- defN 24-May-13 07:14 helloai/ext/regressor/__init__.py
+-rw-rw-rw-  2.0 fat     1203 b- defN 24-May-13 07:14 helloai/ext/regressor/regressor.py
+-rw-rw-rw-  2.0 fat       31 b- defN 24-May-13 07:14 helloai/ext/tmimage/__init__.py
+-rw-rw-rw-  2.0 fat     4978 b- defN 24-May-13 07:14 helloai/ext/tmimage/tm_imageproject.py
+-rw-rw-rw-  2.0 fat     2394 b- defN 24-May-13 07:14 helloai/utils/PID.py
+-rw-rw-rw-  2.0 fat      108 b- defN 24-May-13 07:14 helloai/utils/__init__.py
+-rw-rw-rw-  2.0 fat     6790 b- defN 24-May-13 07:14 helloai/utils/cvzone.py
+-rw-rw-rw-  2.0 fat     3225 b- defN 24-May-13 07:14 helloai/utils/fetcher.py
+-rw-rw-rw-  2.0 fat     6939 b- defN 24-May-13 07:14 helloai/utils/rand.py
+-rw-rw-rw-  2.0 fat     1090 b- defN 24-May-13 07:14 helloai/utils/time.py
+-rw-rw-rw-  2.0 fat     7173 b- defN 24-May-13 07:14 helloai/utils/utils.py
+-rw-rw-rw-  2.0 fat     2483 b- defN 24-May-13 07:14 helloai/utils/voc.py
+-rw-rw-rw-  2.0 fat      849 b- defN 24-May-13 08:05 helloai-2.2.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     1371 b- defN 24-May-13 08:05 helloai-2.2.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 24-May-13 08:05 helloai-2.2.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       45 b- defN 24-May-13 08:05 helloai-2.2.dist-info/entry_points.txt
+-rw-rw-rw-  2.0 fat       11 b- defN 24-May-13 08:05 helloai-2.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     4399 b- defN 24-May-13 08:05 helloai-2.2.dist-info/RECORD
+54 files, 198098 bytes uncompressed, 60793 bytes compressed:  69.3%
```

## zipnote {}

```diff
@@ -102,14 +102,20 @@
 
 Filename: helloai/ext/pose_detector/__init__.py
 Comment: 
 
 Filename: helloai/ext/pose_detector/pose_detector.py
 Comment: 
 
+Filename: helloai/ext/regressor/__init__.py
+Comment: 
+
+Filename: helloai/ext/regressor/regressor.py
+Comment: 
+
 Filename: helloai/ext/tmimage/__init__.py
 Comment: 
 
 Filename: helloai/ext/tmimage/tm_imageproject.py
 Comment: 
 
 Filename: helloai/utils/PID.py
@@ -132,26 +138,26 @@
 
 Filename: helloai/utils/utils.py
 Comment: 
 
 Filename: helloai/utils/voc.py
 Comment: 
 
-Filename: helloai-2.1.dist-info/LICENSE
+Filename: helloai-2.2.dist-info/LICENSE
 Comment: 
 
-Filename: helloai-2.1.dist-info/METADATA
+Filename: helloai-2.2.dist-info/METADATA
 Comment: 
 
-Filename: helloai-2.1.dist-info/WHEEL
+Filename: helloai-2.2.dist-info/WHEEL
 Comment: 
 
-Filename: helloai-2.1.dist-info/entry_points.txt
+Filename: helloai-2.2.dist-info/entry_points.txt
 Comment: 
 
-Filename: helloai-2.1.dist-info/top_level.txt
+Filename: helloai-2.2.dist-info/top_level.txt
 Comment: 
 
-Filename: helloai-2.1.dist-info/RECORD
+Filename: helloai-2.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## helloai/__init__.py

```diff
@@ -1,4 +1,4 @@
 from .ext import *
-from .utils import * 
+from .utils import *
 from .core import *
 from .version import *
```

## helloai/builtins.py

```diff
@@ -1,4 +1,4 @@
 from .ext import *
-from .utils import * 
+from .utils import *
 from .core import *
 from .version import *
```

## helloai/runner.py

```diff
@@ -20,16 +20,16 @@
     There is a problem with PyGame on Macs running in a virtual env.
     If the Python used is from the venv, it will not allow full window and
     keyboard interaction. Instead, we need the original framework Python
     to get PyGame working properly.
 
     The problem doesn't occur on Linux and Windows.
     """
-    if sys.platform == 'darwin':  # This is a Mac
-        return 'Library/Frameworks' in sys.executable
+    if sys.platform == "darwin":  # This is a Mac
+        return "Library/Frameworks" in sys.executable
     else:
         return True
 
 
 def _substitute_full_framework_python():
     """Need to change the OS/X Python executable to the full Mac version,
     while maintaining the virtualenv environment, so things still run
@@ -37,50 +37,50 @@
 
     We do this by extract the paths that virtualenv has added to the system
     path, and prefixing them to the current PYTHONPATH.
 
     Then we use os.execv() to start a replacement process that uses the
     same environment as the previous one.
     """
-    PYVER = '{}.{}'.format(*sys.version_info[:2])
-    base_fw = '/Library/Frameworks/Python.framework/Versions/'
-    framework_python = base_fw + '{pv}/bin/python{pv}'.format(pv=PYVER)
-    venv_base = os.environ.get('VIRTUAL_ENV')
+    PYVER = "{}.{}".format(*sys.version_info[:2])
+    base_fw = "/Library/Frameworks/Python.framework/Versions/"
+    framework_python = base_fw + "{pv}/bin/python{pv}".format(pv=PYVER)
+    venv_base = os.environ.get("VIRTUAL_ENV")
     if not venv_base or not os.path.exists(framework_python):
         # Do nothing if virtual env hasn't been set up or if we can't
         # find the framework Python interpreter
         return
     venv_paths = [p for p in sys.path if p.startswith(venv_base)]
     # Need to allow for PYTHONPATH not already existing in environment
-    os.environ['PYTHONPATH'] = ':'.join(venv_paths + [
-        os.environ.get('PYTHONPATH', '')]).rstrip(':')
+    os.environ["PYTHONPATH"] = ":".join(
+        venv_paths + [os.environ.get("PYTHONPATH", "")]
+    ).rstrip(":")
     # Pass command line args to the new process
-    os.execv(framework_python, ['python', '-m', 'helloai'] + sys.argv[1:])
+    os.execv(framework_python, ["python", "-m", "helloai"] + sys.argv[1:])
 
 
 def main():
-
     # Pygame won't run from a normal virtualenv copy of Python on a Mac
     if not _check_python_ok_for_pygame():
         _substitute_full_framework_python()
 
     parser = OptionParser()
     options, args = parser.parse_args()
 
     if len(args) != 1:
         parser.error("You must specify which module to run.")
 
     if __debug__:
-        warnings.simplefilter('default', DeprecationWarning)
+        warnings.simplefilter("default", DeprecationWarning)
     path = args[0]
 
     with open(path) as f:
         src = f.read()
 
-    code = compile(src, os.path.basename(path), 'exec', dont_inherit=True)
+    code = compile(src, os.path.basename(path), "exec", dont_inherit=True)
 
     name, _ = os.path.splitext(os.path.basename(path))
     mod = ModuleType(name)
     mod.__file__ = path
     mod.__name__ = name
     sys.modules[name] = mod
```

## helloai/version.py

```diff
@@ -17,12 +17,12 @@
 # Boston, MA  02111-1307  USA
 
 
 __all__ = ["__version__", "__author__", "__license__"]
 __title__ = "HelloAI"
 __description__ = "Creative coding in Python"
 __url__ = "http://www.moyalab.com"
-__version__ = "2.0"
+__version__ = "2.3"
 __author__ = "moyalab"
 __author_email__ = "iamtopaz@gmail.com"
 __license__ = "GNU GPLv3"
 __copyright__ = "Copyright (C) 2021- MoyaLab"
```

## helloai/core/__init__.py

```diff
@@ -2,21 +2,23 @@
 from .api import *
 from .window import *
 from .camera import *
 from .virtualcamera import *
 from .video_writer import *
 from .image import *
 from .trackbarwin import *
-# from .plotwindow import * 
+
+# from .plotwindow import *
 from .video import *
-from .movie import *    # deprecated
+from .movie import *  # deprecated
 from .colors import *
 from .display import *
 from .vector import *
 from .helper import *
+
 # from tqdm import tqdm as progressbar
 
 # from .__version__ import __title__
 # from .__version__ import __description__
 # from .__version__ import __url__
 # from .__version__ import __version__
 # from .__version__ import __author__
```

## helloai/core/api.py

```diff
@@ -3,88 +3,112 @@
 # -----------------------------------------------------------------------------
 # Copyright (c) 2021- HelloAI Project Contributors
 # -----------------------------------------------------------------------------
 import io
 import re
 import urllib
 import numpy as np
-import pandas as pd 
+import pandas as pd
 import cv2
 import PIL.Image as pImage
+
 # import random as rand
 import os
 import pprint as pp
 import vnoise
 
-from helloai.core.image import Image 
+from helloai.core.image import Image
+
 # from sklearn.preprocessing import MinMaxScaler
 from sklearn.preprocessing import minmax_scale
 
 
-__all__ = ['load_image', 'read_image', 'map', 'pprint', 'save_npy', 'load_npy', 'list_concatenate', 'concatenate', 'save_dataset', 'load_dataset',
-           'one_hot', 'bounding_box', 'flatten', 'read_csv', 'save_csv', 'shape', 'shuffle', 'nparray', 'toarray', 'tolist', 
-           'reshape']
+__all__ = [
+    "load_image",
+    "read_image",
+    "map",
+    "pprint",
+    "save_npy",
+    "load_npy",
+    "list_concatenate",
+    "concatenate",
+    "save_dataset",
+    "load_dataset",
+    "one_hot",
+    "bounding_box",
+    "flatten",
+    "read_csv",
+    "save_csv",
+    "shape",
+    "shuffle",
+    "nparray",
+    "toarray",
+    "tolist",
+    "reshape",
+]
 
 
 # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html
-def normaliz(data, scaler='minmax'):
+def normaliz(data, scaler="minmax"):
     if isinstance(data, list):
         data = np.array(data)
     elif isinstance(data, np.ndarray):
         pass
     else:
         return data
 
-    if scaler == 'minmax':
+    if scaler == "minmax":
         # scaled_data = minmax_scale(data, axis=0, copy=True)
         scaled_data = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))
         return scaled_data
-    elif scaler == 'image':
-        return data.astype('float32') / 255.
+    elif scaler == "image":
+        return data.astype("float32") / 255.0
     else:
         return data
 
 
 def load_image(filename):
     frame = None
     isWeb = False
-    
-    if (re.match(r'\w+://', filename)):
-        # 웹상의 이미지 
+
+    if re.match(r"\w+://", filename):
+        # 웹상의 이미지
         with urllib.request.urlopen(filename) as url:
             f = io.BytesIO(url.read())
             pil_image = pImage.open(f)
             frame = np.array(pil_image)
             isWeb = True
     else:
         frame = cv2.imread(filename)
 
     if isWeb:
-        return Image(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR), 'bgr')
+        return Image(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR), "bgr")
     else:
-        return Image(frame, 'bgr')
+        return Image(frame, "bgr")
 
 
 def read_image(filename):
     return load_image(filename, colorspace)
-    
 
-#vnoise를 이용한 perlin노이즈 
+
+# vnoise를 이용한 perlin노이즈
 # def noise(x, y=None, z=None):
 #     n = vnoise.Noise()
 #     if y == None:
 #         return map(n.noise1(x), -0.5, 0.5, 0, 1)
 #     elif z == None:
 #         return map(n.noise2(x, y), -0.5, 0.5, 0, 1)
 #     else:
 #         return map(n.noise3(x, y, z), -0.5, 0.5, 0, 1)
 
+
 def map(x, in_min, in_max, out_min, out_max):
     return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min
 
+
 def pprint(object, stream=None, indent=4, width=80, depth=None):
     """Pretty-print a Python object to a stream [default is sys.stdout]."""
     printer = pp.PrettyPrinter(stream=stream, indent=indent, width=width, depth=depth)
     printer.pprint(object)
 
 
 # def get_file_list(path=None):
@@ -113,93 +137,102 @@
 
 
 def load_npy(file_name):
     """
     npy로 저장한 파일 읽기
     """
     data = np.load(file_name, allow_pickle=True).item()
-    print(file_name, '파일이 로드되었습니다')
+    print(file_name, "파일이 로드되었습니다")
     return data
 
 
 def list_concatenate(x, *args):
     return np.concatenate((x, *args), axis=0)
 
+
 def concatenate(data, axis=0):
     data = np.concatenate(data, axis=axis)
-    print('@concate type', type(data), len(data))
+    print("@concate type", type(data), len(data))
     return data
 
+
 def save_dataset(path, dataset):
     save_npy(path, dataset)
 
+
 def load_dataset(path):
     return np.load(path, allow_pickle=True).item()
 
+
 def one_hot(labels, data):
     y_train = []
-    eyes = np.eye(len(labels))        
+    eyes = np.eye(len(labels))
     for lbl in data:
         idx = labels.index(lbl)
         y_train.append(eyes[idx])
     return np.array(y_train)
-    
 
-# 2차원 배열에서 boudingbox 구하기 
-#[[1,2], [2,3], [3,4]]
+
+# 2차원 배열에서 boudingbox 구하기
+# [[1,2], [2,3], [3,4]]
 def bounding_box(lmks):
     bb = np.array([np.min(lmks, axis=0), np.max(lmks, axis=0)])
     return bb
 
+
 def reshape(data, shape):
     if isinstance(data, list):
         data = np.array(data)
         data = np.reshape(data, shape)
-        
+
     if isinstance(data, np.ndarray):
         data = np.reshape(data, shape)
     return data
 
+
 def flatten(lmks):
     return lmks.flatten()
 
+
 # https://rfriend.tistory.com/252
-def save_csv(filename, data, sep=' ', header=None):
+def save_csv(filename, data, sep=" ", header=None):
     if isinstance(data, list):
         data = np.array(data)
 
     if isinstance(data, np.ndarray):
         data = pd.DataFrame(data)
-    
+
     if header:
         data.to_csv(
             filename,
             sep=sep,
-            na_rep='NaN', 
-            float_format = '%.2f', # 2 decimal places
-            columns = header, # columns to write
-            index = False  # do not write index
-        ) 
+            na_rep="NaN",
+            float_format="%.2f",  # 2 decimal places
+            columns=header,  # columns to write
+            index=False,  # do not write index
+        )
     else:
         data.to_csv(
             filename,
             header=False,
             columns=None,
             sep=sep,
-            na_rep='NaN', 
-            float_format = '%.2f', # 2 decimal places
-            index = False  # do not write index
-        ) 
+            na_rep="NaN",
+            float_format="%.2f",  # 2 decimal places
+            index=False,  # do not write index
+        )
     # print(filename, '을 저장하였습니다')
 
+
 # https://chrisjune-13837.medium.com/python-%EA%B0%80%EB%B3%80%EC%9D%B8%EC%9E%90-%ED%8C%A8%ED%82%B9-%EC%96%B8%ED%8C%A8%ED%82%B9-a47ee2cdcac3
 def read_csv(filename, **kwargs):
     df = pd.read_csv(filename, **kwargs)
     return df.to_numpy()
 
+
 def shape(data):
     if isinstance(data, list):
         return np.array(data).shape
     elif isinstance(data, np.ndarray):
         return data.shape
     elif isinstance(data, Image):
         return data.shape()
@@ -215,15 +248,16 @@
     if not isinstance(y_data):
         y_data = np.array(y_data)
 
     index = np.arange(len(x_data))
     np.random.shuffle(index)
     return x_data[index], y_data[index]
 
-# ndarray로 바꿔서 반환      
+
+# ndarray로 바꿔서 반환
 def nparray(data):
     if isinstance(data, list):
         return np.array(data)
     elif isinstance(data, Image):
         return data.array
     return data
```

## helloai/core/camera.py

```diff
@@ -1,38 +1,39 @@
 # Part of the MoyaLab project - http://moyalab.com
 # Copyright (C) 2019 Moyalab (immoyalab@gmail.com)
-# 
+#
 # This library is free software; you can redistribute it and/or
 # modify it under the terms of the GNU Lesser General Public
 # License as published by the Free Software Foundation; either
 # version 2.1 of the License, or (at your option) any later version.
-# 
+#
 # This library is distributed in the hope that it will be useful,
 # but WITHOUT ANY WARRANTY; without even the implied warranty of
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # Lesser General Public License for more details.
-# 
+#
 # You should have received a copy of the GNU Lesser General
 # Public License along with this library; if not, write to the
 # Free Software Foundation, Inc., 59 Temple Place, Suite 330,
 # Boston, MA  02111-1307  USA
 
 import builtins
 import cv2
 import time
 from helloai.core.image import Image
 from helloai.core.image import ColorSpace
 from helloai.core.config import *
 
-__all__ = ['Camera']
+__all__ = ["Camera"]
 
 DEFAULT_SIZE = (builtins.WIDTH, builtins.HEIGHT)
 
 # camera 640 x 480
-# scratch3.0  w h -> 480 x 360 
+# scratch3.0  w h -> 480 x 360
+
 
 class Camera:
     def __init__(self, num=0, flip=0, crop=False, scale=1, fps=False, size=(640, 480)):
         """카메라 객체
 
         Args:
             num (int, optional): 카메라 식별 번호. Defaults to 0.
@@ -43,106 +44,109 @@
         self.__num = num
         self.__scale = scale
         self.__flip = flip
         self.__crop = crop
         self.__fps = fps
         self.__frame = None
         self.__capture = cv2.VideoCapture(num, cv2.CAP_DSHOW)
-        time.sleep(1)   # 1sec 카메라가 인식될때 시간이 조금 필요
+        time.sleep(1)  # 1sec 카메라가 인식될때 시간이 조금 필요
         # self.__size = size
-        self.__capture.set(cv2.CAP_PROP_FRAME_WIDTH, size[0]) 
-        self.__capture.set(cv2.CAP_PROP_FRAME_HEIGHT, size[1]) 
+        self.__capture.set(cv2.CAP_PROP_FRAME_WIDTH, size[0])
+        self.__capture.set(cv2.CAP_PROP_FRAME_HEIGHT, size[1])
         self.__capture.set(cv2.CAP_PROP_BUFFERSIZE, 0)
 
     def is_opened(self):
         if not self.__capture or not self.__capture.isOpened():
             return False
         return True
 
     def read(self):
         if not self.__capture.isOpened():
             print("카메라가 동작하지 않습니다")
             return None
-        # fps계산위해서 
+        # fps계산위해서
         timer = cv2.getTickCount()
         ret, frame = self.__capture.read()
         # self.__fps = cv2.getTickFrequency()/(cv2.getTickCount()-timer)
 
-    
         if ret:
-            width = self.__capture.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`
+            width = self.__capture.get(cv2.CAP_PROP_FRAME_WIDTH)  # float `width`
             height = self.__capture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`
 
-
             if self.__flip == 1:
                 frame = cv2.flip(frame, 1)  # 1 좌우, 0 상하 반전
             elif self.__flip == 2:
                 frame = cv2.flip(frame, 0)  # 1 좌우, 0 상하 반전
 
             if self.__crop:
                 if width > height:
                     frame = self.__center_crop(frame, [height, height])
                 else:
                     frame = self.__center_crop(frame, [width, width])
 
             h, w, c = frame.shape
             # frame = cv2.resize(frame, dsize=self.__size, interpolation=cv2.INTER_LINEAR)
-            
+
             # if w > DEFAULT_SIZE or h > DEFAULT_SIZE:
             #     frame = self.__resize(frame)
 
             if self.__scale > 0:
-                frame = cv2.resize(frame, dsize=(w * self.__scale, h * self.__scale), interpolation=cv2.INTER_LINEAR)
+                frame = cv2.resize(
+                    frame,
+                    dsize=(w * self.__scale, h * self.__scale),
+                    interpolation=cv2.INTER_LINEAR,
+                )
             # h, w, c = frame.shape
             # print('height ', h, '  width ', w)
             # self.__frame = frame.copy()
             if self.__fps:
                 frame = self.__put_fps(frame)
             self.__frame = frame
             return Image(self.__frame, ColorSpace.BGR)
         else:
             return None
 
-
     def __center_crop(self, img, dim):
         """Returns center cropped image
         img: image to be center cropped
         dim: dimensions (width, height) to be cropped from center
         """
         width, height = img.shape[1], img.shape[0]
         # process crop width and height for max available dimension
-        crop_width = dim[0] if dim[0]<img.shape[1] else img.shape[1]
-        crop_height = dim[1] if dim[1]<img.shape[0] else img.shape[0]
+        crop_width = dim[0] if dim[0] < img.shape[1] else img.shape[1]
+        crop_height = dim[1] if dim[1] < img.shape[0] else img.shape[0]
 
-        mid_x, mid_y = int(width / 2), int(height /2 )
-        cw2, ch2 = int(crop_width / 2), int(crop_height / 2) 
-        crop_img = img[mid_y - ch2:mid_y + ch2, mid_x - cw2:mid_x + cw2]
+        mid_x, mid_y = int(width / 2), int(height / 2)
+        cw2, ch2 = int(crop_width / 2), int(crop_height / 2)
+        crop_img = img[mid_y - ch2 : mid_y + ch2, mid_x - cw2 : mid_x + cw2]
         return crop_img
 
     def __resize(self, frame):
         h, w, c = frame.shape
         ratio = 1
         if h > w:
             ratio = DEFAULT_SIZE / h
         else:
             ratio = DEFAULT_SIZE / w
 
-        frame = cv2.resize(frame, dsize=(0, 0), fx=ratio, fy=ratio, interpolation=cv2.INTER_LINEAR)
+        frame = cv2.resize(
+            frame, dsize=(0, 0), fx=ratio, fy=ratio, interpolation=cv2.INTER_LINEAR
+        )
         return frame
-    
+
     def __get_fps(self):
         return builtins.fps
 
     def __put_fps(self, frame):
         # cv2.putText(frame,"fps=",(20,40),cv2.FONT_HERSHEY_SIMPLEX,0.7,(127,127,255),2)
         # cv2.putText(frame,str(int(builtins.fps)),(75,40),cv2.FONT_HERSHEY_SIMPLEX,0.7,(127,127,255),2)
         fps_txt = "FPS %01.f" % builtins.fps
         cv2.putText(frame, fps_txt, (0, 18), cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 255, 0))
         return frame
-        
+
     def close(self):
         if self.__capture is not None:
             self.__capture.release()
 
     def __del__(self):
         # body of destructor
         if self.__capture is not None:
```

## helloai/core/colors.py

```diff
@@ -1,58 +1,58 @@
 import colorsys
 import random
 
-__all__ = ['Color']
+__all__ = ["Color"]
+
 
 class Color:
     # Primary Colors
-    BLACK = (0, 0, 0)                   # rgb(0, 0, 0)
-    WHITE = (255, 255, 255)             # rgb(255, 255, 255)    
-    BLUE = (0, 0, 255)                  # rgb(0, 0, 255)
-    YELLOW = (255, 255, 0)              # rgb(255, 255, 0)
-    RED = (255, 0, 0)                   # rgb(255, 0, 0)
-    LEGO_BLUE = (0, 50, 150)            # rgb(0, 50, 150)
-    LEGO_ORANGE = (255, 150, 40)        # rgb(255, 150, 40)
-    VIOLET = (181, 126, 220)            # rgb(181, 126, 220)
-    ORANGE = (255, 165, 0)              # rgb(255, 165, 0)
-    GREEN = (0, 128, 0)                 # rgb(0, 128, 0)
-    GRAY = (128, 128, 128)              # rgb(128, 128, 128)
+    BLACK = (0, 0, 0)  # rgb(0, 0, 0)
+    WHITE = (255, 255, 255)  # rgb(255, 255, 255)
+    BLUE = (0, 0, 255)  # rgb(0, 0, 255)
+    YELLOW = (255, 255, 0)  # rgb(255, 255, 0)
+    RED = (255, 0, 0)  # rgb(255, 0, 0)
+    LEGO_BLUE = (0, 50, 150)  # rgb(0, 50, 150)
+    LEGO_ORANGE = (255, 150, 40)  # rgb(255, 150, 40)
+    VIOLET = (181, 126, 220)  # rgb(181, 126, 220)
+    ORANGE = (255, 165, 0)  # rgb(255, 165, 0)
+    GREEN = (0, 128, 0)  # rgb(0, 128, 0)
+    GRAY = (128, 128, 128)  # rgb(128, 128, 128)
     # Extended Colors
-    IVORY = (255, 255, 240)             # rgb(255, 255, 240)
-    BEIGE = (245, 245, 220)             # rgb(245, 245, 220)
-    WHEAT = (245, 222, 179)             # rgb(245, 222, 179)
-    TAN = (210, 180, 140)               # rgb(210, 180, 140)
-    KHAKI = (195, 176, 145)             # rgb(195, 176, 145)
-    SILVER = (192, 192, 192)            # rgb(192, 192, 192)
-    CHARCOAL = (70, 70, 70)             # rgb(70, 70, 70)
-    NAVYBLUE = (0, 0, 128)              # rgb(0, 0, 128)
-    ROYALBLUE = (8, 76, 158)            # rgb(8, 76, 158)
-    MEDIUMBLUE = (0, 0, 205)            # rgb(0, 0, 205)
-    AZURE = (0, 127, 255)               # rgb(0, 127, 255)
-    CYAN = (0, 255, 255)                # rgb(0, 255, 255)
-    AQUAMARINE = (127, 255, 212)        # rgb(127, 255, 212)
-    TEAL = (0, 128, 128)                # rgb(0, 128, 128)
-    FORESTGREEN = (34, 139, 34)         # rgb(34, 139, 34)
-    OLIVE = (128, 128, 0)               # rgb(128, 128, 0)
-    LIME = (191, 255, 0)                # rgb(191, 255, 0)
-    GOLD = (255, 215, 0)                # rgb(255, 215, 0)
-    SALMON = (250, 128, 114)            # rgb(250, 128, 114)
-    HOTPINK = (252, 15, 192)            # rgb(252, 15, 192)
-    FUCHSIA = (255, 119, 255)           # rgb(255, 119, 255)
-    PUCE = (204, 136, 153)              # rgb(204, 136, 153)
-    PLUM = (132, 49, 121)               # rgb(132, 49, 121)
-    INDIGO = (75, 0, 130)               # rgb(75, 0, 130)
-    MAROON = (128, 0, 0)                # rgb(128, 0, 0)
-    CRIMSON = (220, 20, 60)             # rgb(220, 20, 60)
-    LIGHTGRAY = (211, 211, 211)         # rgb(211, 211, 211)
-    DEFAULT = (211, 211, 211)           # rgb(102, 102, 102)
-    BACKGROUND = (211, 211, 211)           # rgb(102, 102, 102)
+    IVORY = (255, 255, 240)  # rgb(255, 255, 240)
+    BEIGE = (245, 245, 220)  # rgb(245, 245, 220)
+    WHEAT = (245, 222, 179)  # rgb(245, 222, 179)
+    TAN = (210, 180, 140)  # rgb(210, 180, 140)
+    KHAKI = (195, 176, 145)  # rgb(195, 176, 145)
+    SILVER = (192, 192, 192)  # rgb(192, 192, 192)
+    CHARCOAL = (70, 70, 70)  # rgb(70, 70, 70)
+    NAVYBLUE = (0, 0, 128)  # rgb(0, 0, 128)
+    ROYALBLUE = (8, 76, 158)  # rgb(8, 76, 158)
+    MEDIUMBLUE = (0, 0, 205)  # rgb(0, 0, 205)
+    AZURE = (0, 127, 255)  # rgb(0, 127, 255)
+    CYAN = (0, 255, 255)  # rgb(0, 255, 255)
+    AQUAMARINE = (127, 255, 212)  # rgb(127, 255, 212)
+    TEAL = (0, 128, 128)  # rgb(0, 128, 128)
+    FORESTGREEN = (34, 139, 34)  # rgb(34, 139, 34)
+    OLIVE = (128, 128, 0)  # rgb(128, 128, 0)
+    LIME = (191, 255, 0)  # rgb(191, 255, 0)
+    GOLD = (255, 215, 0)  # rgb(255, 215, 0)
+    SALMON = (250, 128, 114)  # rgb(250, 128, 114)
+    HOTPINK = (252, 15, 192)  # rgb(252, 15, 192)
+    FUCHSIA = (255, 119, 255)  # rgb(255, 119, 255)
+    PUCE = (204, 136, 153)  # rgb(204, 136, 153)
+    PLUM = (132, 49, 121)  # rgb(132, 49, 121)
+    INDIGO = (75, 0, 130)  # rgb(75, 0, 130)
+    MAROON = (128, 0, 0)  # rgb(128, 0, 0)
+    CRIMSON = (220, 20, 60)  # rgb(220, 20, 60)
+    LIGHTGRAY = (211, 211, 211)  # rgb(211, 211, 211)
+    DEFAULT = (211, 211, 211)  # rgb(102, 102, 102)
+    BACKGROUND = (211, 211, 211)  # rgb(102, 102, 102)
     # --------------------------------------------------------------
-    
-    
+
     colors = [
         BLACK,
         WHITE,
         BLUE,
         YELLOW,
         RED,
         VIOLET,
@@ -82,162 +82,162 @@
         FUCHSIA,
         PUCE,
         PLUM,
         INDIGO,
         MAROON,
         CRIMSON,
         LIGHTGRAY,
-        DEFAULT
+        DEFAULT,
     ]
 
     # Colors 변환 https://www.rapidtables.com/convert/color/hex-to-rgb.html
     colour_codes = {
-        'indianred': '#CD5C5C',                     # rgb(205, 92, 92)
-        'lightcoral': '#F08080',                    # rgb(240, 128, 128)
-        'salmon': '#FA8072',                        # rgb(250, 128, 114)
-        'darksalmon': '#E9967A',                    # rgb(233, 150, 122)
-        'lightsalmon': '#FFA07A',                   # rgb(255, 160, 122)
-        'crimson': '#DC143C',                       # rgb(220, 20, 60)
-        'red': '#FF0000',                           # rgb(255, 0, 0)
-        'firebrick': '#B22222',                     # rgb(178, 34, 34)
-        'darkred': '#8B0000',                       # rgb(139, 0, 0)
-        'pink': '#FFC0CB',                          # rgb(255, 192, 203)
-        'lightpink': '#FFB6C1',                     # rgb(255, 182, 193)
-        'hotpink': '#FF69B4',                       # rgb(255, 105, 180)
-        'deeppink': '#FF1493',                      # rgb(255, 20, 147)
-        'mediumvioletred': '#C71585',               # rgb(199, 21, 133)
-        'palevioletred': '#DB7093',                 # rgb(219, 112, 147)
-        'lightsalmon': '#FFA07A',                   # rgb(255, 160, 122)
-        'coral': '#FF7F50',                         # rgb(255, 127, 80)
-        'tomato': '#FF6347',                        # rgb(255, 99, 71)
-        'orangered': '#FF4500',                     # rgb(255, 69, 0)
-        'darkorange': '#FF8C00',                    # rgb(255, 140, 0)
-        'orange': '#FFA500',                        # rgb(255, 165, 0)
-        'gold': '#FFD700',                          # rgb(255, 215, 0)
-        'yellow': '#FFFF00',                        # rgb(255, 255, 0)
-        'lightyellow': '#FFFFE0',                   # rgb(255, 255, 224)
-        'lemonchiffon': '#FFFACD',                  # rgb(255, 250, 205)
-        'lightgoldenrodyellow': '#FAFAD2',          # rgb(250, 250, 210)
-        'papayawhip': '#FFEFD5',                    # rgb(255, 250, 205)
-        'moccasin': '#FFE4B5',                      # rgb(255, 228, 181)
-        'peachpuff': '#FFDAB9',                     # rgb(255, 218, 185)
-        'palegoldenrod': '#EEE8AA',                 # rgb(238, 232, 170)
-        'khaki': '#F0E68C',                         # rgb(240, 230, 140)
-        'darkkhaki': '#BDB76B',                     # rgb(189, 183, 107)
-        'lavender': '#E6E6FA',                      # rgb(230, 230, 250)
-        'thistle': '#D8BFD8',                       # rgb(216, 191, 216)
-        'plum': '#DDA0DD',                          # rgb(221, 160, 221)
-        'violet': '#EE82EE',                        # rgb(238, 130, 238)
-        'orchid': '#DA70D6',                        # rgb(218, 112, 214)
-        'fuchsia': '#FF00FF',                       # rgb(255, 0, 255)
-        'magenta': '#FF00FF',                       # rgb(255, 0, 255)
-        'mediumorchid': '#BA55D3',                  # rgb(186, 85, 211)
-        'mediumpurple': '#9370DB',                  # rgb(147, 112, 219)
-        'rebeccapurple': '#663399',                 # rgb(102, 51, 153)
-        'blueviolet': '#8A2BE2',                    # rgb(138, 43, 226)
-        'darkviolet': '#9400D3',                    # rgb(148, 0, 211)
-        'darkorchid': '#9932CC',                    # rgb(153, 50, 204)
-        'darkmagenta': '#8B008B',                   # rgb(139, 0, 139)
-        'purple': '#800080',                        # rgb(128, 0, 128)
-        'indigo': '#4B0082',                        # rgb(75, 0, 130)
-        'slateblue': '#6A5ACD',                     # rgb(106, 90, 205)
-        'darkslateblue': '#483D8B',                 # rgb(72, 61, 139)
-        'mediumslateblue': '#7B68EE',               # rgb(123, 104, 238)
-        'greenyellow': '#ADFF2F',                   # rgb(173, 255, 47)
-        'chartreuse': '#7FFF00',                    # rgb(127, 255, 0)
-        'lawngreen': '#7CFC00',                     # rgb(127, 255, 0)
-        'lime': '#00FF00',                          # rgb(0, 255, 0)
-        'limegreen': '#32CD32',                     # rgb(50, 205, 50)
-        'palegreen': '#98FB98',                     # rgb(152, 251, 152)
-        'lightgreen': '#90EE90',                    # rgb(144, 238, 144)
-        'mediumspringgreen': '#00FA9A',             # rgb(0, 250, 154)
-        'springgreen': '#00FF7F',                   # rgb(0, 255, 127)
-        'mediumseagreen': '#3CB371',                # rgb(60, 179, 113)
-        'seagreen': '#2E8B57',                      # rgb(46, 139, 87)
-        'forestgreen': '#228B22',                   # rgb(34, 139, 34)
-        'green': '#008000',                         # rgb(0, 128, 0)
-        'darkgreen': '#006400',                     # rgb(0, 100, 0)
-        'yellowgreen': '#9ACD32',                   # rgb(154, 205, 50)
-        'olivedrab': '#6B8E23',                     # rgb(107, 142, 35)
-        'olive': '#808000',                         # rgb(128, 128, 0)
-        'darkolivegreen': '#556B2F',                # rgb(85, 107, 47)
-        'mediumaquamarine': '#66CDAA',              # rgb(102, 205, 170)
-        'darkseagreen': '#8FBC8B',                  # rgb(143, 188, 139)
-        'lightseagreen': '#20B2AA',                 # rgb(32, 178, 170)
-        'darkcyan': '#008B8B',                      # rgb(0, 139, 139)
-        'teal': '#008080',                          # rgb(0, 128, 128)
-        'aqua': '#00FFFF',                          # rgb(0, 255, 255)
-        'cyan': '#00FFFF',                          # rgb(0, 255, 255)
-        'lightcyan': '#E0FFFF',                     # rgb(224, 255, 255)
-        'paleturquoise': '#AFEEEE',                 # rgb(175, 238, 238)
-        'aquamarine': '#7FFFD4',                    # rgb(127, 255, 212)
-        'turquoise': '#40E0D0',                     # rgb(64, 224, 208)
-        'mediumturquoise': '#48D1CC',               # rgb(72, 209, 204)
-        'darkturquoise': '#00CED1',                 # rgb(0, 206, 209)
-        'cadetblue': '#5F9EA0',                     # rgb(95, 158, 160)
-        'steelblue': '#4682B4',                     # rgb(70, 130, 180)
-        'lightsteelblue': '#B0C4DE',                # rgb(176, 196, 222)
-        'powderblue': '#B0E0E6',                    # rgb(176, 224, 230)
-        'lightblue': '#ADD8E6',                     # rgb(173, 216, 230)
-        'skyblue': '#87CEEB',                       # rgb(135, 206, 235)
-        'lightskyblue': '#87CEFA',                  # rgb(135, 206, 250)
-        'deepskyblue': '#00BFFF',                   # rgb(0, 191, 255)
-        'dodgerblue': '#1E90FF',                    # rgb(30, 144, 255)
-        'cornflowerblue': '#6495ED',                # rgb(100, 149, 237)
-        'mediumslateblue': '#7B68EE',               # rgb(123, 104, 238)
-        'royalblue': '#4169E1',                     # rgb(65, 105, 225)
-        'blue': '#0000FF',                          # rgb(0, 0, 255)
-        'mediumblue': '#0000CD',                    # rgb(0, 0, 205)
-        'darkblue': '#00008B',                      # rgb(0, 0, 139)
-        'navy': '#000080',                          # rgb(0, 0, 128)
-        'midnightblue': '#191970',                  # rgb(25, 25, 112)
-        'cornsilk': '#FFF8DC',                      # rgb(255, 248, 220)
-        'blanchedalmond': '#FFEBCD',                # rgb(255, 235, 205)
-        'bisque': '#FFE4C4',                        # rgb(255, 228, 196)
-        'navajowhite': '#FFDEAD',                   # rgb(255, 222, 173)
-        'wheat': '#F5DEB3',                         # rgb(245, 222, 179)
-        'burlywood': '#DEB887',                     # rgb(222, 184, 135)
-        'tan': '#D2B48C',                           # rgb(210, 180, 140)
-        'rosybrown': '#BC8F8F',                     # rgb(188, 143, 143)
-        'sandybrown': '#F4A460',                    # rgb(244, 164, 96)
-        'goldenrod': '#DAA520',                     # rgb(218, 165, 32)
-        'darkgoldenrod': '#B8860B',                 # rgb(184, 134, 11)
-        'peru': '#CD853F',                          # rgb(205, 133, 63)
-        'chocolate': '#D2691E',                     # rgb(210, 105, 30)
-        'saddlebrown': '#8B4513',                   # rgb(139, 69, 19)
-        'sienna': '#A0522D',                        # rgb(160, 82, 45)
-        'brown': '#A52A2A',                         # rgb(165, 42, 42)
-        'maroon': '#800000',                        # rgb(128, 0, 0)
-        'white': '#FFFFFF',                         # rgb(255, 255, 255)
-        'snow': '#FFFAFA',                          # rgb(255, 250, 250)
-        'honeydew': '#F0FFF0',                      # rgb(240, 255, 240)
-        'mintcream': '#F5FFFA',                     # rgb(245, 255, 250)
-        'azure': '#F0FFFF',                         # rgb(240, 255, 255)
-        'aliceblue': '#F0F8FF',                     # rgb(240, 248, 255)
-        'ghostwhite': '#F8F8FF',                    # rgb(248, 248, 255)
-        'whitesmoke': '#F5F5F5',                    # rgb(245, 245, 245)
-        'seashell': '#FFF5EE',                      # rgb(255, 245, 238)
-        'beige': '#F5F5DC',                         # rgb(245, 245, 220)
-        'oldlace': '#FDF5E6',                       # rgb(253, 245, 230)
-        'floralwhite': '#FFFAF0',                   # rgb(255, 250, 240)
-        'ivory': '#FFFFF0',                         # rgb(255, 255, 240)
-        'antiquewhite': '#FAEBD7',                  # rgb(250, 235, 215)
-        'linen': '#FAF0E6',                         # rgb(250, 240, 230)
-        'lavenderblush': '#FFF0F5',                 # rgb(255, 240, 245)
-        'mistyrose': '#FFE4E1',                     # rgb(255, 228, 225)
-        'gainsboro': '#DCDCDC',                     # rgb(220, 220, 220)
-        'lightgray': '#D3D3D3',                     # rgb(211, 211, 211)
-        'silver': '#C0C0C0',                        # rgb(192, 192, 192)
-        'darkgray': '#A9A9A9',                      # rgb(169, 169, 169)
-        'gray': '#808080',                          # rgb(128, 128, 128)
-        'dimgray': '#696969',                       # rgb(105, 105, 105)
-        'lightslategray': '#778899',                # rgb(119, 136, 153)
-        'slategray': '#708090',                     # rgb(112, 128, 144)
-        'darkslategray': '#2F4F4F',                 # rgb(47, 79, 79)
-        'black': '#000000',                         # rgb(0, 0, 0)
+        "indianred": "#CD5C5C",  # rgb(205, 92, 92)
+        "lightcoral": "#F08080",  # rgb(240, 128, 128)
+        "salmon": "#FA8072",  # rgb(250, 128, 114)
+        "darksalmon": "#E9967A",  # rgb(233, 150, 122)
+        "lightsalmon": "#FFA07A",  # rgb(255, 160, 122)
+        "crimson": "#DC143C",  # rgb(220, 20, 60)
+        "red": "#FF0000",  # rgb(255, 0, 0)
+        "firebrick": "#B22222",  # rgb(178, 34, 34)
+        "darkred": "#8B0000",  # rgb(139, 0, 0)
+        "pink": "#FFC0CB",  # rgb(255, 192, 203)
+        "lightpink": "#FFB6C1",  # rgb(255, 182, 193)
+        "hotpink": "#FF69B4",  # rgb(255, 105, 180)
+        "deeppink": "#FF1493",  # rgb(255, 20, 147)
+        "mediumvioletred": "#C71585",  # rgb(199, 21, 133)
+        "palevioletred": "#DB7093",  # rgb(219, 112, 147)
+        "lightsalmon": "#FFA07A",  # rgb(255, 160, 122)
+        "coral": "#FF7F50",  # rgb(255, 127, 80)
+        "tomato": "#FF6347",  # rgb(255, 99, 71)
+        "orangered": "#FF4500",  # rgb(255, 69, 0)
+        "darkorange": "#FF8C00",  # rgb(255, 140, 0)
+        "orange": "#FFA500",  # rgb(255, 165, 0)
+        "gold": "#FFD700",  # rgb(255, 215, 0)
+        "yellow": "#FFFF00",  # rgb(255, 255, 0)
+        "lightyellow": "#FFFFE0",  # rgb(255, 255, 224)
+        "lemonchiffon": "#FFFACD",  # rgb(255, 250, 205)
+        "lightgoldenrodyellow": "#FAFAD2",  # rgb(250, 250, 210)
+        "papayawhip": "#FFEFD5",  # rgb(255, 250, 205)
+        "moccasin": "#FFE4B5",  # rgb(255, 228, 181)
+        "peachpuff": "#FFDAB9",  # rgb(255, 218, 185)
+        "palegoldenrod": "#EEE8AA",  # rgb(238, 232, 170)
+        "khaki": "#F0E68C",  # rgb(240, 230, 140)
+        "darkkhaki": "#BDB76B",  # rgb(189, 183, 107)
+        "lavender": "#E6E6FA",  # rgb(230, 230, 250)
+        "thistle": "#D8BFD8",  # rgb(216, 191, 216)
+        "plum": "#DDA0DD",  # rgb(221, 160, 221)
+        "violet": "#EE82EE",  # rgb(238, 130, 238)
+        "orchid": "#DA70D6",  # rgb(218, 112, 214)
+        "fuchsia": "#FF00FF",  # rgb(255, 0, 255)
+        "magenta": "#FF00FF",  # rgb(255, 0, 255)
+        "mediumorchid": "#BA55D3",  # rgb(186, 85, 211)
+        "mediumpurple": "#9370DB",  # rgb(147, 112, 219)
+        "rebeccapurple": "#663399",  # rgb(102, 51, 153)
+        "blueviolet": "#8A2BE2",  # rgb(138, 43, 226)
+        "darkviolet": "#9400D3",  # rgb(148, 0, 211)
+        "darkorchid": "#9932CC",  # rgb(153, 50, 204)
+        "darkmagenta": "#8B008B",  # rgb(139, 0, 139)
+        "purple": "#800080",  # rgb(128, 0, 128)
+        "indigo": "#4B0082",  # rgb(75, 0, 130)
+        "slateblue": "#6A5ACD",  # rgb(106, 90, 205)
+        "darkslateblue": "#483D8B",  # rgb(72, 61, 139)
+        "mediumslateblue": "#7B68EE",  # rgb(123, 104, 238)
+        "greenyellow": "#ADFF2F",  # rgb(173, 255, 47)
+        "chartreuse": "#7FFF00",  # rgb(127, 255, 0)
+        "lawngreen": "#7CFC00",  # rgb(127, 255, 0)
+        "lime": "#00FF00",  # rgb(0, 255, 0)
+        "limegreen": "#32CD32",  # rgb(50, 205, 50)
+        "palegreen": "#98FB98",  # rgb(152, 251, 152)
+        "lightgreen": "#90EE90",  # rgb(144, 238, 144)
+        "mediumspringgreen": "#00FA9A",  # rgb(0, 250, 154)
+        "springgreen": "#00FF7F",  # rgb(0, 255, 127)
+        "mediumseagreen": "#3CB371",  # rgb(60, 179, 113)
+        "seagreen": "#2E8B57",  # rgb(46, 139, 87)
+        "forestgreen": "#228B22",  # rgb(34, 139, 34)
+        "green": "#008000",  # rgb(0, 128, 0)
+        "darkgreen": "#006400",  # rgb(0, 100, 0)
+        "yellowgreen": "#9ACD32",  # rgb(154, 205, 50)
+        "olivedrab": "#6B8E23",  # rgb(107, 142, 35)
+        "olive": "#808000",  # rgb(128, 128, 0)
+        "darkolivegreen": "#556B2F",  # rgb(85, 107, 47)
+        "mediumaquamarine": "#66CDAA",  # rgb(102, 205, 170)
+        "darkseagreen": "#8FBC8B",  # rgb(143, 188, 139)
+        "lightseagreen": "#20B2AA",  # rgb(32, 178, 170)
+        "darkcyan": "#008B8B",  # rgb(0, 139, 139)
+        "teal": "#008080",  # rgb(0, 128, 128)
+        "aqua": "#00FFFF",  # rgb(0, 255, 255)
+        "cyan": "#00FFFF",  # rgb(0, 255, 255)
+        "lightcyan": "#E0FFFF",  # rgb(224, 255, 255)
+        "paleturquoise": "#AFEEEE",  # rgb(175, 238, 238)
+        "aquamarine": "#7FFFD4",  # rgb(127, 255, 212)
+        "turquoise": "#40E0D0",  # rgb(64, 224, 208)
+        "mediumturquoise": "#48D1CC",  # rgb(72, 209, 204)
+        "darkturquoise": "#00CED1",  # rgb(0, 206, 209)
+        "cadetblue": "#5F9EA0",  # rgb(95, 158, 160)
+        "steelblue": "#4682B4",  # rgb(70, 130, 180)
+        "lightsteelblue": "#B0C4DE",  # rgb(176, 196, 222)
+        "powderblue": "#B0E0E6",  # rgb(176, 224, 230)
+        "lightblue": "#ADD8E6",  # rgb(173, 216, 230)
+        "skyblue": "#87CEEB",  # rgb(135, 206, 235)
+        "lightskyblue": "#87CEFA",  # rgb(135, 206, 250)
+        "deepskyblue": "#00BFFF",  # rgb(0, 191, 255)
+        "dodgerblue": "#1E90FF",  # rgb(30, 144, 255)
+        "cornflowerblue": "#6495ED",  # rgb(100, 149, 237)
+        "mediumslateblue": "#7B68EE",  # rgb(123, 104, 238)
+        "royalblue": "#4169E1",  # rgb(65, 105, 225)
+        "blue": "#0000FF",  # rgb(0, 0, 255)
+        "mediumblue": "#0000CD",  # rgb(0, 0, 205)
+        "darkblue": "#00008B",  # rgb(0, 0, 139)
+        "navy": "#000080",  # rgb(0, 0, 128)
+        "midnightblue": "#191970",  # rgb(25, 25, 112)
+        "cornsilk": "#FFF8DC",  # rgb(255, 248, 220)
+        "blanchedalmond": "#FFEBCD",  # rgb(255, 235, 205)
+        "bisque": "#FFE4C4",  # rgb(255, 228, 196)
+        "navajowhite": "#FFDEAD",  # rgb(255, 222, 173)
+        "wheat": "#F5DEB3",  # rgb(245, 222, 179)
+        "burlywood": "#DEB887",  # rgb(222, 184, 135)
+        "tan": "#D2B48C",  # rgb(210, 180, 140)
+        "rosybrown": "#BC8F8F",  # rgb(188, 143, 143)
+        "sandybrown": "#F4A460",  # rgb(244, 164, 96)
+        "goldenrod": "#DAA520",  # rgb(218, 165, 32)
+        "darkgoldenrod": "#B8860B",  # rgb(184, 134, 11)
+        "peru": "#CD853F",  # rgb(205, 133, 63)
+        "chocolate": "#D2691E",  # rgb(210, 105, 30)
+        "saddlebrown": "#8B4513",  # rgb(139, 69, 19)
+        "sienna": "#A0522D",  # rgb(160, 82, 45)
+        "brown": "#A52A2A",  # rgb(165, 42, 42)
+        "maroon": "#800000",  # rgb(128, 0, 0)
+        "white": "#FFFFFF",  # rgb(255, 255, 255)
+        "snow": "#FFFAFA",  # rgb(255, 250, 250)
+        "honeydew": "#F0FFF0",  # rgb(240, 255, 240)
+        "mintcream": "#F5FFFA",  # rgb(245, 255, 250)
+        "azure": "#F0FFFF",  # rgb(240, 255, 255)
+        "aliceblue": "#F0F8FF",  # rgb(240, 248, 255)
+        "ghostwhite": "#F8F8FF",  # rgb(248, 248, 255)
+        "whitesmoke": "#F5F5F5",  # rgb(245, 245, 245)
+        "seashell": "#FFF5EE",  # rgb(255, 245, 238)
+        "beige": "#F5F5DC",  # rgb(245, 245, 220)
+        "oldlace": "#FDF5E6",  # rgb(253, 245, 230)
+        "floralwhite": "#FFFAF0",  # rgb(255, 250, 240)
+        "ivory": "#FFFFF0",  # rgb(255, 255, 240)
+        "antiquewhite": "#FAEBD7",  # rgb(250, 235, 215)
+        "linen": "#FAF0E6",  # rgb(250, 240, 230)
+        "lavenderblush": "#FFF0F5",  # rgb(255, 240, 245)
+        "mistyrose": "#FFE4E1",  # rgb(255, 228, 225)
+        "gainsboro": "#DCDCDC",  # rgb(220, 220, 220)
+        "lightgray": "#D3D3D3",  # rgb(211, 211, 211)
+        "silver": "#C0C0C0",  # rgb(192, 192, 192)
+        "darkgray": "#A9A9A9",  # rgb(169, 169, 169)
+        "gray": "#808080",  # rgb(128, 128, 128)
+        "dimgray": "#696969",  # rgb(105, 105, 105)
+        "lightslategray": "#778899",  # rgb(119, 136, 153)
+        "slategray": "#708090",  # rgb(112, 128, 144)
+        "darkslategray": "#2F4F4F",  # rgb(47, 79, 79)
+        "black": "#000000",  # rgb(0, 0, 0)
     }
 
     @classmethod
     def random(cls):
         r = random.randint(1, (len(cls.colors) - 1))
         return cls.colors[r]
 
@@ -252,96 +252,94 @@
     @classmethod
     def hsv(cls, tpl):
         hsv_float = colorsys.rgb_to_hsv(*tpl)
         return (hsv_float[0] * 180, hsv_float[1] * 255, hsv_float[2])
 
     @classmethod
     def hsv_to_rgb(cls, HSV):
-        ''' Converts an integer HSV tuple (value range from 0 to 255) to an RGB tuple '''
+        """Converts an integer HSV tuple (value range from 0 to 255) to an RGB tuple"""
 
         # Unpack the HSV tuple for readability
         H, S, V = HSV
 
         # Check if the color is Grayscale
         if S == 0:
             R = V
             G = V
             B = V
             return (R, G, B)
 
         # Make hue 0-5
-        region = H // 43;
+        region = H // 43
 
         # Find remainder part, make it from 0-255
-        remainder = (H - (region * 43)) * 6; 
+        remainder = (H - (region * 43)) * 6
 
         # Calculate temp vars, doing integer multiplication
-        P = (V * (255 - S)) >> 8;
-        Q = (V * (255 - ((S * remainder) >> 8))) >> 8;
-        T = (V * (255 - ((S * (255 - remainder)) >> 8))) >> 8;
-
+        P = (V * (255 - S)) >> 8
+        Q = (V * (255 - ((S * remainder) >> 8))) >> 8
+        T = (V * (255 - ((S * (255 - remainder)) >> 8))) >> 8
 
         # Assign temp vars based on color cone region
         if region == 0:
             R = V
             G = T
             B = P
 
         elif region == 1:
-            R = Q; 
-            G = V; 
-            B = P;
+            R = Q
+            G = V
+            B = P
 
         elif region == 2:
-            R = P; 
-            G = V; 
-            B = T;
+            R = P
+            G = V
+            B = T
 
         elif region == 3:
-            R = P; 
-            G = Q; 
-            B = V;
+            R = P
+            G = Q
+            B = V
 
         elif region == 4:
-            R = T; 
-            G = P; 
-            B = V;
-
-        else: 
-            R = V; 
-            G = P; 
-            B = Q;
+            R = T
+            G = P
+            B = V
+
+        else:
+            R = V
+            G = P
+            B = Q
         return (R, G, B)
-    
+
     def RGB_2_HSV(RGB):
-        ''' Converts an integer RGB tuple (value range from 0 to 255) to an HSV tuple '''
+        """Converts an integer RGB tuple (value range from 0 to 255) to an HSV tuple"""
 
         # Unpack the tuple for readability
         R, G, B = RGB
 
         # Compute the H value by finding the maximum of the RGB values
         RGB_Max = max(RGB)
         RGB_Min = min(RGB)
 
         # Compute the value
-        V = RGB_Max;
+        V = RGB_Max
         if V == 0:
             H = S = 0
-            return (H,S,V)
-
+            return (H, S, V)
 
         # Compute the saturation value
         S = 255 * (RGB_Max - RGB_Min) // V
 
         if S == 0:
             H = 0
             return (H, S, V)
 
         # Compute the Hue
         if RGB_Max == R:
-            H = 0 + 43*(G - B)//(RGB_Max - RGB_Min)
+            H = 0 + 43 * (G - B) // (RGB_Max - RGB_Min)
         elif RGB_Max == G:
-            H = 85 + 43*(B - R)//(RGB_Max - RGB_Min)
-        else: # RGB_MAX == B
-            H = 171 + 43*(R - G)//(RGB_Max - RGB_Min)
+            H = 85 + 43 * (B - R) // (RGB_Max - RGB_Min)
+        else:  # RGB_MAX == B
+            H = 171 + 43 * (R - G) // (RGB_Max - RGB_Min)
 
         return (H, S, V)
```

## helloai/core/config.py

```diff
@@ -1,52 +1,54 @@
+__all__ = [
+    "MAX_DIMENSION",
+    "DEFAULT_HEIGHT",
+    "DEFAULT_WIDTH",
+    "is_notebook",
+    "is_colab",
+    "merge_dicts",
+]
 
 
-__all__ = ['MAX_DIMENSION', 'DEFAULT_HEIGHT', 'DEFAULT_WIDTH', 'is_notebook', 'is_colab', 'merge_dicts']
-
-
-# 이 모듈을 helloai에서만 사용하는 것으로, 
-# HelloAI의 모든 모듈에 import 될수 있어서, 
+# 이 모듈을 helloai에서만 사용하는 것으로,
+# HelloAI의 모든 모듈에 import 될수 있어서,
 # helloai모듈을 import해서 사용해서는 안된다.
 
 MAX_DIMENSION = 1024
-DEFAULT_HEIGHT= 640
+DEFAULT_HEIGHT = 640
 DEFAULT_WIDTH = 640
 
 # def is_notebook():
 #     # https://stackoverflow.com/questions/15411967/how-can-i-check-if-code-is-executed-in-the-ipython-notebook
 #     print('@config:', hasattr(__builtins__,'__IPYTHON__'))
 #     return hasattr(__builtins__,'__IPYTHON__')
 
+
 def is_notebook():
     try:
         shell = get_ipython().__class__.__name__
-        if shell == 'ZMQInteractiveShell':
-            return True   # Jupyter notebook or qtconsole
-        elif shell == 'TerminalInteractiveShell':
+        if shell == "ZMQInteractiveShell":
+            return True  # Jupyter notebook or qtconsole
+        elif shell == "TerminalInteractiveShell":
             return False  # Terminal running IPython
         else:
             return False  # Other type (?)
     except NameError:
-        return False      # Probably standard Python interpreter
+        return False  # Probably standard Python interpreter
 
 
 def is_colab():
     try:
         shell = get_ipython().__class__.__module__
-        if shell == 'google.colab._shell':
-            return True   
+        if shell == "google.colab._shell":
+            return True
         else:
-            return False  
+            return False
     except NameError:
         return False
 
 
 def merge_dicts(defaut_options, options):
-    # defaut_options를 options으로 업데이트 
-     ret_opts = defaut_options.copy()
-     ret_opts.update(options)
-     print('merge_dicts', options)
-     return ret_opts
-
-
-
-     
+    # defaut_options를 options으로 업데이트
+    ret_opts = defaut_options.copy()
+    ret_opts.update(options)
+    print("merge_dicts", options)
+    return ret_opts
```

## helloai/core/core.py

```diff
@@ -1,40 +1,175 @@
 import __main__
 import os
 import sys
 import builtins
 import time
-import math 
+import math
+
 # from threading import Event, Thread
 import cv2
 import keyboard
 
 from threading import Thread
-  
+
 from .singlestore import SingleStore
 from .colors import Color
 
-__all__ = ['loop', 'setup', 'run', 'wait_key', 'key_pressed', 'delay', 'frame_rate', 'size', 'noloop']
+__all__ = [
+    "loop",
+    "setup",
+    "run",
+    "wait_key",
+    "key_pressed",
+    "delay",
+    "frame_rate",
+    "size",
+    "noloop",
+    "stop",
+    "end",
+]
 
 KEY_TABLE = [
-    'nul', 'soh', 'stx', 'etx', 'eot', 'enq', 'ack', 'bel', 'bs', 'tab', 'lf', 'vt', 'ff', 'cr', 'so', 'si', 'dle',
-    'dc1', 'dc2', 'dc3', 'dc4', 'nak', 'syn', 'etb', 'can', 'em', 'sub', 'esc', 'fs', 'gs', 'rs', 'us', 'space', '!',
-    '"', '#', '$', '%', '&', '\'', '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7',
-    '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',
-    'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e',
-    'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'l', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|',
-    '}', '~', 'del'
+    "nul",
+    "soh",
+    "stx",
+    "etx",
+    "eot",
+    "enq",
+    "ack",
+    "bel",
+    "bs",
+    "tab",
+    "lf",
+    "vt",
+    "ff",
+    "cr",
+    "so",
+    "si",
+    "dle",
+    "dc1",
+    "dc2",
+    "dc3",
+    "dc4",
+    "nak",
+    "syn",
+    "etb",
+    "can",
+    "em",
+    "sub",
+    "esc",
+    "fs",
+    "gs",
+    "rs",
+    "us",
+    "space",
+    "!",
+    '"',
+    "#",
+    "$",
+    "%",
+    "&",
+    "'",
+    "(",
+    ")",
+    "*",
+    "+",
+    ",",
+    "-",
+    ".",
+    "/",
+    "0",
+    "1",
+    "2",
+    "3",
+    "4",
+    "5",
+    "6",
+    "7",
+    "8",
+    "9",
+    ":",
+    ";",
+    "<",
+    "=",
+    ">",
+    "?",
+    "@",
+    "A",
+    "B",
+    "C",
+    "D",
+    "E",
+    "F",
+    "G",
+    "H",
+    "I",
+    "J",
+    "K",
+    "L",
+    "M",
+    "N",
+    "O",
+    "P",
+    "Q",
+    "R",
+    "S",
+    "T",
+    "U",
+    "V",
+    "W",
+    "X",
+    "Y",
+    "Z",
+    "[",
+    "\\",
+    "]",
+    "^",
+    "_",
+    "`",
+    "a",
+    "b",
+    "c",
+    "d",
+    "e",
+    "f",
+    "g",
+    "h",
+    "i",
+    "j",
+    "k",
+    "l",
+    "m",
+    "l",
+    "o",
+    "p",
+    "q",
+    "r",
+    "s",
+    "t",
+    "u",
+    "v",
+    "w",
+    "x",
+    "y",
+    "z",
+    "{",
+    "|",
+    "}",
+    "~",
+    "del",
 ]
 
 
 loop_flag = True
 noloop_flag = False
 
 setup_method = None
 loop_method = None
+end_method = None
 key_pressed_method = None
 mouse_event_method = None
 # cancel_future_calls = None
 mouse_down_time = time.time()
 
 loop_frame_rate = 60
 single_store = SingleStore()
@@ -45,170 +180,178 @@
 builtins.mouse_y = 0
 builtins.pmouse_x = 0
 builtins.pmouse_y = 0
 builtins.fps = 0
 
 builtins.mouse_pressed = False
 
-builtins.WIDTH = 640 
-builtins.HEIGHT = 480 
+builtins.WIDTH = 640
+builtins.HEIGHT = 480
 builtins.COLOR = Color.DEFAULT
 
 builtins.windows = []
 
 prev_time = 0
 
 
-
-
-
 def __put_fps():
     global prev_time
 
     cur_time = time.time()
     sec = cur_time - prev_time
     prev_time = cur_time
-    fps_val = 1/(sec)
+    fps_val = 1 / (sec)
     fps_val = round(fps_val)
     builtins.fps = fps_val
     # fps_txt = "%01.f" % fps_val
-    
+
+
 def bye():
     global loop_flag
     loop_flag = False
     # delay(1)
     # if len(builtins.windows) > 0:
     #     builtins.windows = []
     #     cv2.destroyAllWindows()
     # print(builtins.windows)
     # for name in builtins.windows:
     #     cv2.destroyWindow(name)
     builtins.windows = []
     cv2.destroyAllWindows()
-    print('__bye__')
+    # print('__bye__')
+    end_method()
     exit()
 
 
-def call_repeatedly(interval, func, *args):
-    stopped = Event()
+def stop():
+    bye()
 
-    def loop():
-        while not stopped.wait(interval):   # the first call is in `interval` secs
-            func(*args)
-    Thread(target=loop).start()
-    return stopped.set
+
+# def call_repeatedly(interval, func, *args):
+#     stopped = Event()
+
+#     def loop():
+#         while not stopped.wait(interval):   # the first call is in `interval` secs
+#             func(*args)
+#     Thread(target=loop).start()
+#     return stopped.set
 
 
 def size(width, height):
-    builtins.WIDTH = width 
-    builtins.HEIGHT = height 
+    builtins.WIDTH = width
+    builtins.HEIGHT = height
+
 
 def setup():
     pass
 
 
 def loop():
     pass
 
 
+def end():
+    pass
+
+
 def key_pressed(key):
-    if key == 'esc' or key == 'q' or key == 'Q':
-        print('__key__', key)
+    if key == "esc" or key == "q" or key == "Q":
+        print("__key__", key)
         bye()
 
 
 def __key_pressed(key):
     # print('__key_pressed');
-    if key == 'esc' or key == 'q' or key == 'Q':
+    if key == "esc" or key == "q" or key == "Q":
         # 프로그램에서 종료 처리를 하도록 해준다
         if key_pressed_method:
             key_pressed_method(key)
         bye()
 
     else:
         if key_pressed_method:
             key_pressed_method(key)
 
 
-
 def mouse_event(name, event, x, y, flags=None, params=None):
     global mouse_down_time
     global mouse_x
     global mouse_y
 
     event_name = None
     if event == cv2.EVENT_LBUTTONDOWN:
         event_name = "left-down"
         builtins.mouse_pressed = True
         mouse_down_time = time.time()
     elif event == cv2.EVENT_LBUTTONUP:
         builtins.mouse_pressed = False
         diff = time.time() - mouse_down_time
         if diff < 0.1:
-            event_name = 'click'
+            event_name = "click"
         else:
             event_name = "left-up"
     elif event == cv2.EVENT_RBUTTONDOWN:
         event_name = "right-down"
     elif event == cv2.EVENT_RBUTTONUP:
         event_name = "right-up"
     elif event == cv2.EVENT_MOUSEMOVE:
         event_name = "move"
 
-    builtins.mouse_x = x 
-    builtins.mouse_y = y 
+    builtins.mouse_x = x
+    builtins.mouse_y = y
 
-    if hasattr(__main__, 'mouse_event'):
+    if hasattr(__main__, "mouse_event"):
         if event_name is not None:
             __main__.mouse_event(name, event_name, x, y)
 
 
 def delay(ms):
     """
     ms가 0일때는 아무키 입력할때 까지 기다림
     """
     if ms == 0:
         if len(builtins.windows) > 0:
             cv2.waitKey(0)
         else:
-            time.sleep(60 * 60 * 1000 / 1000.)  # 1hr
-    else:    
+            time.sleep(60 * 60 * 1000 / 1000.0)  # 1hr
+    else:
         if len(builtins.windows) > 0:
             cv2.waitKey(int(ms))
-        else:    
-            time.sleep(float(ms) / 1000.)
-        
+        else:
+            time.sleep(float(ms) / 1000.0)
 
 
 def wait_key(ms):
-    print('windows :', len(builtins.windows))
+    print("windows :", len(builtins.windows))
     if ms == 0:
         if len(builtins.windows) > 0:
             key = cv2.waitKey(ms)
             if key == 27:
                 bye()
-            else:    
+            else:
                 __key_pressed(chr(key))
             return key
         else:
-            key = input('press any key and enter: ')
+            key = input("press any key and enter: ")
             __key_pressed(key)
             return key
-    else:        
+    else:
         key = cv2.waitKey(ms)
         if key == 27:
             bye()
-        else:    
+        else:
             __key_pressed(chr(key))
         return key
 
+
 def noloop():
     global noloop_flag
     noloop_flag = True
-    
+
+
 # https://pynput.readthedocs.io/en/latest/keyboard.html#monitoring-the-keyboard
 # for pynput
 # def on_press(key):
 #     # print('[helloai] on_press')
 #     pass
 
 
@@ -224,40 +367,49 @@
 #             __key_pressed(key.char)
 #         else:
 #             ks = key_str(key)
 #             __key_pressed(ks)
 
 # keyboard.add_hotkey('esc', lambda: bye())
 
+
 def print_pressed_keys(e):
     for code in keyboard._pressed_events:
         __key_pressed(e.name)
-        
+
+
 keyboard.hook(print_pressed_keys)
 
+
 def run():
     global loop_flag
     global noloop_flag
     global setup_method
     global loop_method
-    
+    global end_method
+
     global key_pressed_method
     global cancel_future_calls
 
-    if hasattr(__main__, 'setup'):
+    if hasattr(__main__, "setup"):
         setup_method = __main__.setup
     else:
         setup_method = setup
 
-    if hasattr(__main__, 'loop'):
+    if hasattr(__main__, "loop"):
         loop_method = __main__.loop
     else:
         loop_method = loop
 
-    if hasattr(__main__, 'key_pressed'):
+    if hasattr(__main__, "end"):
+        end_method = __main__.end
+    else:
+        end_method = end
+
+    if hasattr(__main__, "key_pressed"):
         key_pressed_method = __main__.key_pressed
     else:
         key_pressed_method = key_pressed
 
     # if hasattr(__main__, 'mouse_event'):
     #     mouse_event_method = __main__.mouse_event
     # else:
@@ -271,28 +423,28 @@
     # if os.name != 'posix':
     #     listener = keyboard.Listener(
     #         on_press=on_press,
     #         on_release=on_release)
     #     listener.start()
 
     builtins.key_pressed = __key_pressed
-    
+
     # 실행
     setup_method()
     while loop_flag:
         try:
             frame_exe_time = 1 / loop_frame_rate * 1000
             start = time.time()
 
             # pfs
             __put_fps()
             loop_method()
             builtins.pmouse_x = builtins.mouse_x
             builtins.pmouse_y = builtins.mouse_y
-            
+
             delay(1)
             # key = cv2.waitKey(1)
             # print('Key.......', key)
             # if key == 27:
             #     bye()
             # elif key != -1 and key != 0:
             #     key_str = KEY_TABLE[key]
@@ -304,23 +456,23 @@
             # print('run_time ', run_time)
             # print('delay time ', frame_exe_time - run_time)
             delay_time = frame_exe_time - run_time
             if delay_time > 0:
                 delay(delay_time)
 
         except KeyboardInterrupt:
-            print('__bye__')
+            print("__bye__")
             exit()
 
         if noloop_flag:
             loop_flag = False
             # 동시에 끝나지 않고, 실행이 끝난 상태를 유지한다.
             # wait_key(0)
             exit()
 
 
 def frame_rate(value):
     """
     대략적인 프레임 속도를 지정한다.
     """
     global loop_frame_rate
-    loop_frame_rate = value
+    loop_frame_rate = value
```

## helloai/core/display.py

```diff
@@ -1,59 +1,59 @@
 import math
 import matplotlib.image as img
 import matplotlib.pyplot as plt
 import numpy as np
 from helloai.core.config import *
 from helloai.core.image import Image as hImage
 
-__all__ = ['Display', 'show']
+__all__ = ["Display", "show"]
 
-class Display:
 
+class Display:
     def __init__(self):
         self.__is_notebook = is_notebook() or is_colab()
         # print('is notebook?', self.__is_notebook)
         if not self.__is_notebook:
-            raise Exception('이 클래스는 쥬피터노트북 환경에서만 사용 가능합니다')
+            raise Exception("이 클래스는 쥬피터노트북 환경에서만 사용 가능합니다")
 
     # def show(self, img, labels=None):
     #     frame = None
     #     if isinstance(img, hImage):
     #         if img.colorspace == 'gray':
     #             frame = img.frame
     #         elif img.colorspace == 'bgra' or img.colorspace == 'rgra':
-    #             frame = img.frame[:,:, (2, 1, 0, 3)] 
+    #             frame = img.frame[:,:, (2, 1, 0, 3)]
     #         else:
     #             frame = img.frame[:,:,::-1]
     #     elif isinstance(img, np.ndarray):
     #         frame = img
     #     plt.imshow(frame)
 
+
 def show(imgs, labels=None):
     if not is_notebook() and not is_colab():
-        print('Notebook 환경에서만 사용할 수 있는 함수입니다')
+        print("Notebook 환경에서만 사용할 수 있는 함수입니다")
         return
 
     if isinstance(imgs, hImage):
         plt.imshow(imgs.frame)
         return
-    
+
     n_col = 3
-    n_row = math.ceil(len(imgs)/n_col)
-    axes=[]
-    fig=plt.figure(figsize=(10,10))
+    n_row = math.ceil(len(imgs) / n_col)
+    axes = []
+    fig = plt.figure(figsize=(10, 10))
 
-    for idx in range(n_row*n_col):
-        if idx > len(imgs)-1:
+    for idx in range(n_row * n_col):
+        if idx > len(imgs) - 1:
             continue
         frame = imgs[idx].frame
 
-        axes.append( fig.add_subplot(n_row, n_col, idx+1) )
+        axes.append(fig.add_subplot(n_row, n_col, idx + 1))
         if labels:
-            axes[-1].set_title(labels[idx])  
+            axes[-1].set_title(labels[idx])
         else:
-            subplot_title=("Subplot"+str(idx))
-            axes[-1].set_title(subplot_title)  
+            subplot_title = "Subplot" + str(idx)
+            axes[-1].set_title(subplot_title)
         plt.imshow(frame)
-    fig.tight_layout()    
-    plt.show()    
-
+    fig.tight_layout()
+    plt.show()
```

## helloai/core/helper.py

```diff
@@ -1,25 +1,28 @@
 import math
 import numpy as np
 
-__all__ = ['distance', 'angle3p']
+__all__ = ["distance", "angle3p"]
 
 
 def distance(p1, p2):
     x1, y1 = p1
     x2, y2 = p2
-    c = math.sqrt((x1 - x2)**2 + (y1 - y2)**2)
+    c = math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)
     return c
 
+
 # P1-P2-P2의 각도를 시계방향으로
 
 
 def angle3p(p1, p2, p3):
-    ang = math.degrees(math.atan2(
-        p3[1]-p2[1], p3[0]-p2[0]) - math.atan2(p1[1]-p2[1], p1[0]-p2[0]))
+    ang = math.degrees(
+        math.atan2(p3[1] - p2[1], p3[0] - p2[0])
+        - math.atan2(p1[1] - p2[1], p1[0] - p2[0])
+    )
     return ang + 360 if ang < 0 else ang
 
 
 # def angle3p(p1, p2, p3):
 #     a = np.array(p1)
 #     b = np.array(p2)
 #     c = np.array(p3)
```

## helloai/core/image.py

```diff
@@ -1029,15 +1029,14 @@
                 print("두 이미지의 컬러 채널이 다릅니다")
                 return None
 
             other = cv2.add(self_frame, other_frame)
         return Image(other, ColorSpace.BGR)
 
     def diff(self, img):
-
         frame = self.__frame.copy()
         other = img.frame.copy()
         diff = cv2.absdiff(frame, other)
         gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
         blur = cv2.GaussianBlur(gray, (5, 5), 0)
         _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)
         dilated = cv2.dilate(thresh, None, iterations=3)
@@ -1050,15 +1049,14 @@
         else:
             # if self.__colorSpace != other.colorspace:
             #     return None
             other = cv2.subtract(self.__frame, other.frame)
         return Image(other)
 
     def __div__(self, other):
-
         if self.__is_number(other):
             other = cv2.divide(self.__frame, other)
         return Image(other)
 
     def __truediv__(self, other):
         if self.__is_number(other):
             other = cv2.divide(self.__frame, other)
```

## helloai/core/movie.py

```diff
@@ -1,94 +1,96 @@
 import os
 import cv2
-from helloai.core.image import Image 
+from helloai.core.image import Image
+
+__all__ = ["Movie"]
 
-__all__ = ['Movie']
 
 class Movie:
     """[deprecated]
-    Video 클래스를 사용하세요. 
+    Video 클래스를 사용하세요.
     2021.03.20
     """
+
     def __init__(self, name):
         self.__name = name
         self.__capture = cv2.VideoCapture(name)
         self.__width = int(self.__capture.get(cv2.CAP_PROP_FRAME_WIDTH))
         self.__height = int(self.__capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
-        self.__frame_count = int(self.__capture.get(cv2.CAP_PROP_FRAME_COUNT)) # 총프레임수
-        self.__frame_rate = int(self.__capture.get(cv2.CAP_PROP_FPS)) # 프레임레이트(fps)
+        self.__frame_count = int(self.__capture.get(cv2.CAP_PROP_FRAME_COUNT))  # 총프레임수
+        self.__frame_rate = int(self.__capture.get(cv2.CAP_PROP_FPS))  # 프레임레이트(fps)
         self.__fps = self.__frame_rate
         self.__fcc = None
         self.__out = None
         self.__fps = self.__frame_rate
         self.__writable = False
 
     def get_recorder(self, path, name):
         if self.__out:
             return self
-        
+
         # avi
         # self.__fcc = cv2.VideoWriter_fourcc(*'XVID')
         # self.__out = cv2.VideoWriter(os.path.join(path, f'{name}.avi'), self.__fcc, self.__fps, (self.__width, self.__height))
         # print('recorder name :', os.path.join(path, f'{name}.avi'))
-        
+
         # mp4
-        self.__fcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')
-        self.__out = cv2.VideoWriter(os.path.join(path, f'{name}.mp4'), self.__fcc, self.__fps, (self.__width, self.__height))
-        print('recorder name :', os.path.join(path, f'{name}.mp4'))
+        self.__fcc = cv2.VideoWriter_fourcc("m", "p", "4", "v")
+        self.__out = cv2.VideoWriter(
+            os.path.join(path, f"{name}.mp4"),
+            self.__fcc,
+            self.__fps,
+            (self.__width, self.__height),
+        )
+        print("recorder name :", os.path.join(path, f"{name}.mp4"))
         return self
 
     def read(self):
-        if(self.__capture.get(cv2.CAP_PROP_POS_FRAMES) == self.__capture.get(cv2.CAP_PROP_FRAME_COUNT)):
-            print('영상 재상이 끝났습니다')
+        if self.__capture.get(cv2.CAP_PROP_POS_FRAMES) == self.__capture.get(
+            cv2.CAP_PROP_FRAME_COUNT
+        ):
+            print("영상 재상이 끝났습니다")
             return None
-        
+
         ret, frame = self.__capture.read()
         if ret:
             return Image(frame)
         else:
             return None
 
     @property
     def is_end(self):
-        return (self.__capture.get(cv2.CAP_PROP_POS_FRAMES) == self.__capture.get(cv2.CAP_PROP_FRAME_COUNT))
-    
+        return self.__capture.get(cv2.CAP_PROP_POS_FRAMES) == self.__capture.get(
+            cv2.CAP_PROP_FRAME_COUNT
+        )
+
     @property
     def options(self):
-        return {
-            'height': self.__height,
-            'width':self.__width,
-            'fps': self.__fps
-        }
+        return {"height": self.__height, "width": self.__width, "fps": self.__fps}
 
     @property
     def frame_count(self):
         return self.__frame_count
 
-
     def write(self, img):
         if not isinstance(img, Image):
             return
         if self.__out:
             self.__out.write(img.frame)
 
     def release(self):
         # body of destructor
         if self.__capture is not None:
             self.__capture.release()
             self.__capture = None
-            
+
         if self.__out is not None:
             self.__out.release()
             self.__out = None
 
-    
-
     def __del__(self):
         # body of destructor
         if self.__capture is not None:
             self.__capture.release()
-            
+
         if self.__out is not None:
             self.__out.release()
-
-
```

## helloai/core/plotwindow.py

```diff
@@ -1,76 +1,78 @@
 import builtins
 import os
+
 # from pynput import keyboard
 
 import matplotlib.pyplot as plt
 import numpy as np
 from helloai import *
 
-__all__ = ['PlotWindow']
+__all__ = ["PlotWindow"]
+
 
 class PlotWindow:
     def __init__(self):
-        self.__name = 'no-name'
+        self.__name = "no-name"
         self.__plt = plt
         # self.__plt.plot([1, 2, 3, 4])
-        self.__plt.ylabel('some numbers')
+        self.__plt.ylabel("some numbers")
         self.__plt.ion()
-        _ = self.__plt.connect('button_press_event', self.__on_mouse)
-        _ = self.__plt.connect('key_press_event', self.__on_key)
-        _ = self.__plt.connect('close_event', self.__on_close)
+        _ = self.__plt.connect("button_press_event", self.__on_mouse)
+        _ = self.__plt.connect("key_press_event", self.__on_key)
+        _ = self.__plt.connect("close_event", self.__on_close)
         self.__plt.show()
-        
+
     def __del__(self):
         self.__plt.close()
 
     def __on_mouse(self, event):
         # print('[plot] you pressed', event.button, event.xdata, event.ydata)
         if builtins.mouse_event:
             builtins.mouse_event(self.__name, 21, event.xdata, event.ydata, None, None)
-            
+
     def __on_key(self, event):
-        print('[plot] you pressed', event.key, event.xdata, event.ydata)
+        print("[plot] you pressed", event.key, event.xdata, event.ydata)
         key = event.key
-        if key == 'escape':
-            key = 'esc'
-        elif key == 'q' or key == 'Q':
+        if key == "escape":
+            key = "esc"
+        elif key == "q" or key == "Q":
             self.__close_input()
 
-        if hasattr(builtins, 'key_pressed') and builtins.key_pressed:
+        if hasattr(builtins, "key_pressed") and builtins.key_pressed:
             builtins.key_pressed(key)
 
     def __on_close(self, event):
         # self.__close_input()
         pass
 
     def __close_input(self):
         # if os.name != 'posix':
         #     controler = keyboard.Controller()
-        #     controler.press(keyboard.Key.enter) 
+        #     controler.press(keyboard.Key.enter)
         #     controler.release(keyboard.Key.enter)
         pass
 
     def show(self):
         self.__plt.draw()
         self.__plt.pause(0.001)
-        
+
     def ylabel(self, label):
         self.__plt.ylabel(label)
-        
+
     def xlabel(self, label):
         self.__plt.xlabel(label)
 
     def update(self):
         self.__plt.draw()
         self.__plt.pause(0.001)
 
     def close(self):
         self.__plt.close()
-    
+
     def plot(self, *args, scalex=True, scaley=True, data=None, **kwargs):
         self.__plt.plot(*args, scalex=scalex, scaley=scaley, data=data, **kwargs)
         self.update()
 
     def easy_plot(self):
         pass
```

## helloai/core/trackbarwin.py

```diff
@@ -1,24 +1,24 @@
 import cv2
 import numpy as np
 import uuid
 from .window import Window
 from .image import Image
 
-__all__ = ['TrackbarWindow']
+__all__ = ["TrackbarWindow"]
 
 
 def nothing(x):
     pass
 
 
 class TrackbarWindow(Window):
     def __init__(self, name):
         super().__init__(name)
         cv2.createTrackbar("Value", self.name, 0, 100, nothing)
 
     def get_value(self):
-        val = cv2.getTrackbarPos('Value', self.name)
+        val = cv2.getTrackbarPos("Value", self.name)
         return val
 
     def set_value(self, val):
-        cv2.setTrackbarPos('Value', self.name, val)
+        cv2.setTrackbarPos("Value", self.name, val)
```

## helloai/core/vector.py

```diff
@@ -16,20 +16,20 @@
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
 
 from collections import namedtuple
 import numpy as np
 from numpy.random import random
 
-__all__ = ['Vector', 'Point']
+__all__ = ["Vector", "Point"]
 
 # Floating point precision for vectors.
 EPSILON = 1e-8
 
-Point = namedtuple('Point', ['x', 'y', 'z'])
+Point = namedtuple("Point", ["x", "y", "z"])
 Point.__new__.__defaults__ = (None, None, 0)
 
 
 class Vector(Point):
     """Describes a vector in two or three dimensional space.
 
     A Vector -- specifically an Euclidean (or geometric) vector -- in
@@ -317,16 +317,17 @@
         :param other:
         :type other: Vector
 
         :returns: The angle between `self` and `other` (in radians)
         :rtype: float
 
         """
-        return np.arccos((np.dot(self._array, other._array)) /
-                         (self.magnitude * other.magnitude))
+        return np.arccos(
+            (np.dot(self._array, other._array)) / (self.magnitude * other.magnitude)
+        )
 
     @property
     def magnitude(self):
         """The magnitude of the vector.
 
         Examples::
 
@@ -409,25 +410,23 @@
         """
         vec = cls.random_2D()
         vec.angle = angle
         return vec
 
     @classmethod
     def random_2D(cls):
-        """Return a random 2D unit vector.
-        """
+        """Return a random 2D unit vector."""
         x, y = 2 * (random(2) - 0.5)
         vec = cls(x, y)
         vec.normalize()
         return vec
 
     @classmethod
     def random_3D(cls):
-        """Return a new random 3D unit vector.
-        """
+        """Return a new random 3D unit vector."""
         x, y, z = random(3)
         vec = cls(x, y, z)
         vec.normalize()
         return vec
 
     def copy(self):
         """Return a copy of the current point.
@@ -455,22 +454,21 @@
             [2, 3, 4]
 
         """
         for k in self._array:
             yield k
 
     def __eq__(self, other):
-        if hasattr(other, '_array') and self._array.shape == other._array.shape:
+        if hasattr(other, "_array") and self._array.shape == other._array.shape:
             return np.all(np.absolute(self._array - other._array) < EPSILON)
         return False
 
     def __neq__(self, other):
-        if hasattr(other, '_array') and self._array.shape == other._array.shape:
-            return not np.all(np.absolute(
-                self._array - other._array) < EPSILON)
+        if hasattr(other, "_array") and self._array.shape == other._array.shape:
+            return not np.all(np.absolute(self._array - other._array) < EPSILON)
         return True
 
     def __repr__(self):
         class_name = self.__class__.__name__
         fvalues = (class_name, self.x, self.y, self.z)
         return "{}({:.2f}, {:.2f}, {:.2f})".format(*fvalues)
```

## helloai/core/video.py

```diff
@@ -1,90 +1,91 @@
 import os
 import cv2
-from helloai.core.image import Image 
+from helloai.core.image import Image
+
+__all__ = ["Video"]
 
-__all__ = ['Video']
 
 class Video:
     def __init__(self, name):
         self.__name = name
         self.__capture = cv2.VideoCapture(name)
         self.__width = int(self.__capture.get(cv2.CAP_PROP_FRAME_WIDTH))
         self.__height = int(self.__capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
-        self.__frame_count = int(self.__capture.get(cv2.CAP_PROP_FRAME_COUNT)) # 총프레임수
-        self.__frame_rate = int(self.__capture.get(cv2.CAP_PROP_FPS)) # 프레임레이트(fps)
+        self.__frame_count = int(self.__capture.get(cv2.CAP_PROP_FRAME_COUNT))  # 총프레임수
+        self.__frame_rate = int(self.__capture.get(cv2.CAP_PROP_FPS))  # 프레임레이트(fps)
         self.__fps = self.__frame_rate
         self.__fcc = None
         self.__out = None
         self.__fps = self.__frame_rate
         self.__writable = False
 
     def get_recorder(self, path, name):
         if self.__out:
             return self
-        
+
         # avi
         # self.__fcc = cv2.VideoWriter_fourcc(*'XVID')
         # self.__out = cv2.VideoWriter(os.path.join(path, f'{name}.avi'), self.__fcc, self.__fps, (self.__width, self.__height))
         # print('recorder name :', os.path.join(path, f'{name}.avi'))
-        
+
         # mp4
-        self.__fcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')
-        self.__out = cv2.VideoWriter(os.path.join(path, f'{name}.mp4'), self.__fcc, self.__fps, (self.__width, self.__height))
-        print('recorder name :', os.path.join(path, f'{name}.mp4'))
+        self.__fcc = cv2.VideoWriter_fourcc("m", "p", "4", "v")
+        self.__out = cv2.VideoWriter(
+            os.path.join(path, f"{name}.mp4"),
+            self.__fcc,
+            self.__fps,
+            (self.__width, self.__height),
+        )
+        print("recorder name :", os.path.join(path, f"{name}.mp4"))
         return self
 
     def read(self):
-        if(self.__capture.get(cv2.CAP_PROP_POS_FRAMES) == self.__capture.get(cv2.CAP_PROP_FRAME_COUNT)):
-            print('영상 재상이 끝났습니다')
+        if self.__capture.get(cv2.CAP_PROP_POS_FRAMES) == self.__capture.get(
+            cv2.CAP_PROP_FRAME_COUNT
+        ):
+            print("영상 재상이 끝났습니다")
             return None
-        
+
         ret, frame = self.__capture.read()
         if ret:
             return Image(frame)
         else:
             return None
 
     @property
     def is_end(self):
-        return (self.__capture.get(cv2.CAP_PROP_POS_FRAMES) == self.__capture.get(cv2.CAP_PROP_FRAME_COUNT))
-    
+        return self.__capture.get(cv2.CAP_PROP_POS_FRAMES) == self.__capture.get(
+            cv2.CAP_PROP_FRAME_COUNT
+        )
+
     @property
     def options(self):
-        return {
-            'height': self.__height,
-            'width':self.__width,
-            'fps': self.__fps
-        }
+        return {"height": self.__height, "width": self.__width, "fps": self.__fps}
 
     @property
     def frame_count(self):
         return self.__frame_count
 
-
     def write(self, img):
         if not isinstance(img, Image):
             return
         if self.__out:
             self.__out.write(img.frame)
 
     def release(self):
         # body of destructor
         if self.__capture is not None:
             self.__capture.release()
             self.__capture = None
-            
+
         if self.__out is not None:
             self.__out.release()
             self.__out = None
 
-    
-
     def __del__(self):
         # body of destructor
         if self.__capture is not None:
             self.__capture.release()
-            
+
         if self.__out is not None:
             self.__out.release()
-
-
```

## helloai/core/video_writer.py

```diff
@@ -1,33 +1,39 @@
 import os
 import cv2
 import uuid
-from helloai.core.image import Image 
+from helloai.core.image import Image
+
+__all__ = ["VideoWriter"]
 
-__all__ = ['VideoWriter']
 
 class VideoWriter:
     def __init__(self, path, capture):
         self.__options = capture.options
-        print('options : ', self.__options)
+        print("options : ", self.__options)
 
-        self.__width = int(self.__options['width'])
-        self.__height = int(self.__options['height'])
-        self.__fps = self.__options['fps']
-        self.__name = str(uuid.uuid4()).split('-')[0]
-        
-        self.__fcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')
-        self.__out = cv2.VideoWriter(os.path.join(path, f'{self.__name}.mp4'), self.__fcc, self.__fps, (self.__width, self.__height))
+        self.__width = int(self.__options["width"])
+        self.__height = int(self.__options["height"])
+        self.__fps = self.__options["fps"]
+        self.__name = str(uuid.uuid4()).split("-")[0]
+
+        self.__fcc = cv2.VideoWriter_fourcc("m", "p", "4", "v")
+        self.__out = cv2.VideoWriter(
+            os.path.join(path, f"{self.__name}.mp4"),
+            self.__fcc,
+            self.__fps,
+            (self.__width, self.__height),
+        )
         self.__writable = False
         self.__frame_count = 0
         # avi
         # self.__fcc = cv2.VideoWriter_fourcc(*'XVID')
         # self.__out = cv2.VideoWriter(os.path.join(path, f'{name}.avi'), self.__fcc, self.__fps, (self.__width, self.__height))
         # print('recorder name :', os.path.join(path, f'{name}.avi'))
-        
+
         # mp4
         # self.__fcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')
         # self.__out = cv2.VideoWriter(os.path.join(path, f'{name}.mp4'), self.__fcc, self.__fps, (self.__width, self.__height))
         # print('recorder name :', os.path.join(path, f'{name}.mp4'))
 
     @property
     def frame_count(self):
@@ -44,9 +50,7 @@
         if self.__out is not None:
             self.__out.release()
             self.__out = None
 
     def __del__(self):
         if self.__out is not None:
             self.__out.release()
-
-
```

## helloai/core/virtualcamera.py

```diff
@@ -1,77 +1,79 @@
 import builtins
-import cv2 
-import requests 
-import numpy as np 
+import cv2
+import requests
+import numpy as np
 import time
 from urllib.parse import urlparse
 
-from .image import Image 
+from .image import Image
 
-__all__ = ['VirtualCamera']
+__all__ = ["VirtualCamera"]
 
 
 class VirtualCamera:
     """
     flip: 1 좌우, 0 상하 반전
     """
+
     def __init__(self, url, flip=True):
-        if not url.startswith("http://") and not url.startswith('https://'):
-            print('카메라의 주소가 잘못되었습니다')
-        
+        if not url.startswith("http://") and not url.startswith("https://"):
+            print("카메라의 주소가 잘못되었습니다")
+
         self.__url = url
         self.__flip = flip
         self.__width = builtins.WIDTH
         self.__height = builtins.HEIGHT
         self.__channel = 3
         self.__type = None
         self.__capture = None
         self.__frame = np.zeros((self.__height, self.__width, self.__channel))
-        
-        if 'videostream.cgi' in self.__url:
+
+        if "videostream.cgi" in self.__url:
             # kamibot ai camera
-            self.__type = 'ai'
-            if '@' not in self.__url:
+            self.__type = "ai"
+            if "@" not in self.__url:
                 parts = urlparse(self.__url)
                 # "http://192.168.66.1:9527/videostream.cgi"
                 # parts- ParseResult(scheme='http', netloc='192.168.66.1:9527', path='/videostream.cgi', params='', query='', fragment='')
-                self.__url = f'{parts.scheme}://admin:admin@{parts.netloc}{parts.path}'
+                self.__url = f"{parts.scheme}://admin:admin@{parts.netloc}{parts.path}"
                 # url = "http://admin:admin@192.168.66.1:9527/videostream.cgi"
                 self.__capture = cv2.VideoCapture(self.__url)
-                time.sleep(1)   # 1sec 카메라가 인식될때 시간이 조금 필요
+                time.sleep(1)  # 1sec 카메라가 인식될때 시간이 조금 필요
         else:
-            self.__type = 'app'
-    
+            self.__type = "app"
+
     def read(self):
-        if self.__type == 'ai':
+        if self.__type == "ai":
             return self.__read_from_aicamera()
         else:
             return self.__read_from_app()
 
     def __read_from_aicamera(self):
         ret, frame = self.__capture.read()
         if ret:
             self.__frame = frame
         return Image(frame)
 
     def __read_from_app(self):
         try:
-            r = requests.get(self.__url, stream=True) 
+            r = requests.get(self.__url, stream=True)
         except:
-            print('카메라 서버에 문제가 있습니다')
+            print("카메라 서버에 문제가 있습니다")
             return Image(self.__frame)
 
-        if(r.status_code == 200): 
-            bytes = b'' 
-            for chunk in r.iter_content(chunk_size=1024): 
-                bytes += chunk 
-                a = bytes.find(b'\xff\xd8') 
-                b = bytes.find(b'\xff\xd9') 
-                if a != -1 and b != -1: 
-                    jpg = bytes[a:b+2] 
-                    bytes = bytes[b+2:] 
-                    frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR) 
+        if r.status_code == 200:
+            bytes = b""
+            for chunk in r.iter_content(chunk_size=1024):
+                bytes += chunk
+                a = bytes.find(b"\xff\xd8")
+                b = bytes.find(b"\xff\xd9")
+                if a != -1 and b != -1:
+                    jpg = bytes[a : b + 2]
+                    bytes = bytes[b + 2 :]
+                    frame = cv2.imdecode(
+                        np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR
+                    )
                     if self.__flip:
                         frame = cv2.flip(frame, 1)  # 1 좌우, 0 상하 반전
                         self.__frame = frame
         return Image(self.__frame)
-
```

## helloai/core/window.py

```diff
@@ -2,26 +2,26 @@
 import sys
 import os
 import time
 import cv2
 import numpy as np
 import uuid
 
-from PIL import Image as pilImage 
+from PIL import Image as pilImage
 from PIL import ImageDraw
 from PIL import ImageFont
 
 
 from helloai.core.image import Image, ColorSpace
 from helloai.core.singlestore import SingleStore
 from helloai.core.config import *
 from helloai.core.colors import *
 
 
-__all__ = ['Window']
+__all__ = ["Window"]
 
 
 # DEFAULT_HEIGHT= 480
 # DEFAULT_WIDTH = 480
 # INIT_DISPLAY = cv2.putText(np.zeros((DEFAULT_HEIGHT, DEFAULT_WIDTH, 3)),
 #                            'HelloAI', (5, 15), cv2.FONT_HERSHEY_TRIPLEX,
 #                            0.5, (0, 255, 255), 1, cv2.LINE_AA)
@@ -29,32 +29,31 @@
 
 class Window:
     def __init__(self, name=None, size=(640, 480)):
         self.__image = None
         if name is not None:
             self.__name = name.replace(" ", "-")
         else:
-            self.__name = str(uuid.uuid4()).split('-')[0]
+            self.__name = str(uuid.uuid4()).split("-")[0]
 
         builtins.WIDTH = size[0]
         builtins.HEIGHT = size[1]
-        
-        
+
         self.singlestore = SingleStore()
         self.__image = self.__create_default_image()
         cv2.namedWindow(self.__name)
         cv2.imshow(self.__name, self.__image.frame)
         cv2.setMouseCallback(self.__name, self.mouse_event)
         self.__add_window()
         # cv2.imshow(self.__name, self.__image.frame)
         print(self)
-    
+
     def __repr__(self):
-        return f"<HelloAI.Window Object Title:{self.__name}, Size:({self.size}) ,at memory location: ({hex(id(self))})>"    
-    
+        return f"<HelloAI.Window Object Title:{self.__name}, Size:({self.size}) ,at memory location: ({hex(id(self))})>"
+
     def __add_window(self):
         if self.__name not in builtins.windows:
             builtins.windows.append(self.__name)
 
     def __remove_window(self):
         if self.__name in builtins.windows:
             builtins.windows.remove(self.__name)
@@ -68,15 +67,15 @@
     def mouse_event(self, event, x, y, flags, params):
         # if self.singlestore.mouse_event:
         #     self.singlestore.mouse_event(self.__name, event, x, y, flags, params)
         if builtins.mouse_event:
             builtins.mouse_event(self.__name, event, x, y, flags, params)
 
     def show(self, img=None):
-        # RGB 이미지가 정상 표시되도록 
+        # RGB 이미지가 정상 표시되도록
         if img:
             self.__image = img
         frame = self.__image.frame.copy()
         # # RGB이미지를 정상 표시하기 위해서, 채널을
         # if self.__image.colorspace == ColorSpace.GRAY:
         #      pass
         # elif self.__image.colorspace == ColorSpace.RGBA:
@@ -102,85 +101,87 @@
     #         if self.__image.colorspace == ColorSpace.RGB:
     #             frame = frame[:, :, ::-1]
     #             cv2.imshow(self.__name, frame)
     #         elif self.__image.colorspace == ColorSpace.BGR:
     #             cv2.imshow(self.__name, frame)
     #     else:
     #         cv2.imshow(self.__name, frame)
-        
+
     def update(self, img):
         self.show(img)
 
     def save(self, path, name=None):
         """
         jpg파일로 저장
         """
-        if path != None and path.endswith('/'):
+        if path != None and path.endswith("/"):
             path = path[:-1]
-        
+
         if not os.path.isdir(path):
             os.mkdir(path)
 
         if not name:
             name = str(round(time.time() * 1000))
 
-        filename = f'{path}/{name}.jpg'
+        filename = f"{path}/{name}.jpg"
         cv2.imwrite(filename, self.__image.frame)
         # print(filename, '을 저장하였습니다')
 
     @property
     def image(self):
         return self.__image.copy()
 
     @property
     def name(self):
         return self.__name
 
     @property
     def size(self):
-        return (self.__image.frame.shape[1],self.__image.frame.shape[0]) 
-    
+        return (self.__image.frame.shape[1], self.__image.frame.shape[0])
+
     @property
     def width(self):
         return self.__image.frame.shape[1]
-    
+
     @property
     def height(self):
         return self.__image.frame.shape[0]
-    
+
     def close(self):
         cv2.destroyWindow(self.__name)
         self.__remove_window()
         if len(builtins.windows) == 0:
             sys.exit()
-    
+
     # ---------------------------------------------------------------------------------------------
     # https://pillow.readthedocs.io/en/stable/reference/ImageDraw.html#PIL.ImageDraw.ImageDraw.arc
     def point(self, x, y, color=Color.RED):
         pimg = self.__image.to_pilimage()
         draw = ImageDraw.Draw(pimg)
         draw.point((x, y), fill=color)
         img = Image.from_pilimage(pimg)
         self.__image = img
         # cv2.imshow(self.__name, img.frame)
-        
+
     def line(self, start, end, color=Color.RED, thickness=1):
         pimg = self.__image.to_pilimage()
         draw = ImageDraw.Draw(pimg)
-        draw.line([start[0] , start[1],  end[0], end[1]], fill=color, width=thickness )
+        draw.line([start[0], start[1], end[0], end[1]], fill=color, width=thickness)
         img = Image.from_pilimage(pimg)
         self.__image = img
 
-    def rectangle(self, start, end, outline=(0, 0, 0), fill=None, thickness=1 ):
-        (x1, y1) = start 
+    def rectangle(self, start, end, outline=(0, 0, 0), fill=None, thickness=1):
+        (x1, y1) = start
         (x2, y2) = end
-        
+
         pimg = self.__image.to_pilimage()
         draw = ImageDraw.Draw(pimg)
-        draw.rectangle(((x1, y1), (x2, y2)), outline=outline, width=thickness, fill=fill)
+        draw.rectangle(
+            ((x1, y1), (x2, y2)), outline=outline, width=thickness, fill=fill
+        )
         img = Image.from_pilimage(pimg)
         self.__image = img
         return self
 
     def ellipse(self, xy, width, height, fill=None, outline=(0, 0, 0), thickness=1):
         x, y = xy
         x1 = int(x - (width / 2))
@@ -188,73 +189,81 @@
         x2 = int(x + (width / 2))
         y2 = int(y + (height / 2))
         pimg = self.__image.to_pilimage()
         draw = ImageDraw.Draw(pimg)
         draw.ellipse([x1, y1, x2, y2], fill=fill, outline=outline, width=thickness)
         img = Image.from_pilimage(pimg)
         self.__image = img
-        
+
     def arc(self, x, y, width, height, start, end, fill=None, thickness=1):
         x1 = int(x - (width / 2))
         y1 = int(y - (height / 2))
         x2 = int(x + (width / 2))
         y2 = int(y + (height / 2))
         pimg = self.__image.to_pilimage()
         draw = ImageDraw.Draw(pimg)
         draw.arc([x1, y1, x2, y2], start=start, end=end, fill=fill, width=thickness)
         img = Image.from_pilimage(pimg)
         self.__image = img
-        
-    def chord(self, x, y, width, height, start, end, fill=None, outline=None, thickness=1):
+
+    def chord(
+        self, x, y, width, height, start, end, fill=None, outline=None, thickness=1
+    ):
         x1 = int(x - (width / 2))
         y1 = int(y - (height / 2))
         x2 = int(x + (width / 2))
         y2 = int(y + (height / 2))
         pimg = self.__image.to_pilimage()
         draw = ImageDraw.Draw(pimg)
-        draw.arc([x1, y1, x2, y2], start=start, end=end, fill=fill, outline=outline, width=thickness)
+        draw.arc(
+            [x1, y1, x2, y2],
+            start=start,
+            end=end,
+            fill=fill,
+            outline=outline,
+            width=thickness,
+        )
         img = Image.from_pilimage(pimg)
         self.__image = img
 
     # [(x, y), (x, y), ...]
     def polygon(self, points, fill=None, outline=None):
         pimg = self.__image.to_pilimage()
         draw = ImageDraw.Draw(pimg)
         draw.polygon(points, fill=fill, outline=outline)
         img = Image.from_pilimage(pimg)
         self.__image = img
-        
+
     # https://qiita.com/mo256man/items/82da5138eeacc420499d
-    def text(self, xy, text='HelloAI', size=14, color=(0,0,0)):
+    def text(self, xy, text="HelloAI", size=14, color=(0, 0, 0)):
         """
         color = (r,g,b)
         """
         # PIL로 저장해서 한글 표시
         x, y = xy
-        FONT_PATH = './assets/fonts/gulim.ttc'
-        pimg =  self.__image.to_pilimage()
+        FONT_PATH = "./assets/fonts/gulim.ttc"
+        pimg = self.__image.to_pilimage()
         draw = ImageDraw.Draw(pimg)
-        font_ttf = ImageFont.truetype(font = FONT_PATH, size=size) # TrueType（TTF）
-        draw.text(xy = (x,y), text = text, fill = color, font = font_ttf)
+        font_ttf = ImageFont.truetype(font=FONT_PATH, size=size)  # TrueType（TTF）
+        draw.text(xy=(x, y), text=text, fill=color, font=font_ttf)
         img = Image.from_pilimage(pimg)
         self.__image = img
 
     def background(self, color):
-            """윈도우 배경색상을 바꾼다.
+        """윈도우 배경색상을 바꾼다.
 
-            Args:
-                color (int or tuple): 색상 (r, g, b)
+        Args:
+            color (int or tuple): 색상 (r, g, b)
 
-            Returns:
-                None
-            """
-            if isinstance(color, int):
-                color = (color, color, color)
-            elif isinstance(color, tuple):
-                if len(color) == 1:
-                    color = (color[0], color[0], color[0])
-                elif len(color) == 3:  
-                    pass
-                elif len(color) == 4:
-                      color = (color[0],color[1],color[0])
-            self.__image.frame[:,:] = color[::-1]
-            
+        Returns:
+            None
+        """
+        if isinstance(color, int):
+            color = (color, color, color)
+        elif isinstance(color, tuple):
+            if len(color) == 1:
+                color = (color[0], color[0], color[0])
+            elif len(color) == 3:
+                pass
+            elif len(color) == 4:
+                color = (color[0], color[1], color[0])
+        self.__image.frame[:, :] = color[::-1]
```

## helloai/ext/__init__.py

```diff
@@ -1,5 +1,6 @@
 from .hands_detector import *
 from .pose_detector import *
 from .face_detector import *
 from .tmimage import *
 from .aruco import *
+from .regressor import *
```

## helloai/ext/aruco/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-from .aruco import *
+from .aruco import *
```

## helloai/ext/aruco/aruco.py

```diff
@@ -1,15 +1,15 @@
 # https://mecaruco2.readthedocs.io/en/latest/notebooks_rst/Aruco/aruco_basics.html
 import cv2
 import cv2.aruco as aruco
 import numpy as np
 import os
 from helloai.core.image import Image
 
-__all__ = ['ArUco']
+__all__ = ["ArUco"]
 
 
 class ArUco:
     def __init__(self):
         self.__img = None
         self.__markers = None
 
@@ -17,20 +17,20 @@
         self.process(img, marker_size, draw)
 
     def process_(self, img, marker_size=6, draw=True):
         total_markers = 1000
         frame = img.frame.copy()
         img_gray = img.to_gray().frame
 
-        key = getattr(
-            aruco, f'DICT_{marker_size}X{marker_size}_{total_markers}')
+        key = getattr(aruco, f"DICT_{marker_size}X{marker_size}_{total_markers}")
         arucoDict = aruco.Dictionary_get(key)
         arucoParam = aruco.DetectorParameters_create()
         bboxs, ids, rejected = aruco.detectMarkers(
-            img_gray, arucoDict, parameters=arucoParam)
+            img_gray, arucoDict, parameters=arucoParam
+        )
 
         if draw:
             frame = aruco.drawDetectedMarkers(frame.copy(), bboxs, ids)
 
         corners = []
         if bboxs:
             for i in range(len(ids)):
@@ -46,20 +46,20 @@
         return self.__img, self.__markers
 
     def process(self, img, marker_size=6, draw=True):
         total_markers = 1000
         frame = img.frame.copy()
         img_gray = img.to_gray().frame
 
-        key = getattr(
-            aruco, f'DICT_{marker_size}X{marker_size}_{total_markers}')
+        key = getattr(aruco, f"DICT_{marker_size}X{marker_size}_{total_markers}")
         arucoDict = aruco.Dictionary_get(key)
         arucoParam = aruco.DetectorParameters_create()
         bboxs, ids, rejected = aruco.detectMarkers(
-            img_gray, arucoDict, parameters=arucoParam)
+            img_gray, arucoDict, parameters=arucoParam
+        )
 
         if draw:
             frame = aruco.drawDetectedMarkers(frame.copy(), bboxs, ids)
 
         corners = []
         if bboxs:
             for i in range(len(ids)):
@@ -113,16 +113,18 @@
 
         h, w, c = frame_over.shape
 
         pts1 = np.array([tl, tr, br, bl])
         pts2 = np.float32([[0, 0], [w, 0], [w, h], [0, h]])
         matrix, _ = cv2.findHomography(pts2, pts1)
         frame_out = cv2.warpPerspective(
-            frame_over, matrix, (frame.shape[1], frame.shape[0]))
+            frame_over, matrix, (frame.shape[1], frame.shape[0])
+        )
         cv2.fillConvexPoly(frame, pts1.astype(int), (0, 0, 0))
         frame_out = frame + frame_out
 
         if drawId:
-            cv2.putText(frame_out, str(id), tl,
-                        cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 255), 2)
+            cv2.putText(
+                frame_out, str(id), tl, cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 255), 2
+            )
 
         return Image(frame_out)
```

## helloai/ext/aruco/aruco_test.py

```diff
@@ -11,32 +11,34 @@
     """
     myList = os.listdir(path)
     noOfMarkers = len(myList)
     print("Total Number of Markers Detected:", noOfMarkers)
     augDics = {}
     for imgPath in myList:
         key = int(os.path.splitext(imgPath)[0])
-        imgAug = cv2.imread(f'{path}/{imgPath}')
+        imgAug = cv2.imread(f"{path}/{imgPath}")
         augDics[key] = imgAug
     return augDics
 
+
 def findArucoMarkers(img, markerSize=6, totalMarkers=250, draw=True):
     """
     :param img: image in which to find the aruco markers
     :param markerSize: the size of the markers
     :param totalMarkers: total number of markers that compose the dictionary
     :param draw: flag to draw bbox around markers detected
     :return: bounding boxes and id numbers of markers detected
     """
     imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
-    key = getattr(aruco, f'DICT_{markerSize}X{markerSize}_{totalMarkers}')
+    key = getattr(aruco, f"DICT_{markerSize}X{markerSize}_{totalMarkers}")
     arucoDict = aruco.Dictionary_get(key)
     arucoParam = aruco.DetectorParameters_create()
-    bboxs, ids, rejected = aruco.detectMarkers(imgGray,
-                                               arucoDict, parameters=arucoParam)
+    bboxs, ids, rejected = aruco.detectMarkers(
+        imgGray, arucoDict, parameters=arucoParam
+    )
     # print(ids)
     if draw:
         aruco.drawDetectedMarkers(img, bboxs)
 
     return [bboxs, ids]
 
 
@@ -60,16 +62,15 @@
     pts2 = np.float32([[0, 0], [w, 0], [w, h], [0, h]])
     matrix, _ = cv2.findHomography(pts2, pts1)
     imgOut = cv2.warpPerspective(imgAug, matrix, (img.shape[1], img.shape[0]))
     cv2.fillConvexPoly(img, pts1.astype(int), (0, 0, 0))
     imgOut = img + imgOut
 
     if drawId:
-        cv2.putText(imgOut, str(id), tl, cv2.FONT_HERSHEY_PLAIN, 2,
-                    (255, 0, 255), 2)
+        cv2.putText(imgOut, str(id), tl, cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 255), 2)
 
     return imgOut
 
 
 def main():
     cap = cv2.VideoCapture(1)
     augDics = loadAugImages("Markers")
@@ -85,8 +86,8 @@
                     img = augmentAruco(bbox, id, img, augDics[int(id)])
 
         cv2.imshow("Image", img)
         cv2.waitKey(1)
 
 
 if __name__ == "__main__":
-    main()
+    main()
```

## helloai/ext/face_detector/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-from .face_detector import *
+from .face_detector import *
```

## helloai/ext/face_detector/face_detector.py

```diff
@@ -6,94 +6,104 @@
 import cv2
 import numpy as np
 import mediapipe as mp
 from collections import deque
 
 from helloai.core.image import Image
 
-__all__ = ['FaceDetector']
+__all__ = ["FaceDetector"]
 
 
 class FaceDetector:
     def __init__(self, min_detection_confidence=0.5):
         self.__is_model_loaded = False
         self.__face = None
         self.__landmarks = None
         self.__min_detection_confidence = min_detection_confidence
         self.__draw = True
         self.load_model()
-        
 
     def load_model(self):
         if not self.__is_model_loaded:
             mp_face_detection = mp.solutions.face_detection
             self.__face = mp_face_detection.FaceDetection(
                 min_detection_confidence=self.__min_detection_confidence
             )
             self.__is_model_loaded = True
 
     def process(self, img, draw=True):
-        
         if not self.__is_model_loaded:
-            print('모델이 준비되지 않았습니다')
+            print("모델이 준비되지 않았습니다")
             return img, []
 
         self.__draw = draw
         image = img.frame.copy()
-        
-        
-        # 검출 
+
+        # 검출
         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
         results = self.__face.process(image)
         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
         result = []
-        
-        # 그리기 
+
+        # 그리기
         if results.detections is not None:
             for detection in results.detections:
                 data = {}
-                # data['id'] = detection.label_id 
-                
-                brect = self.__calc_bounding_rect(image, detection.location_data.relative_bounding_box, draw)
-                data['bound'] = brect   # start_x, start_y, end_x, end_y
-                
-                debug_image, landmark_point = self.__draw_landmarks(image, detection.location_data, draw)
-                data['keypoints'] = landmark_point
+                # data['id'] = detection.label_id
+
+                brect = self.__calc_bounding_rect(
+                    image, detection.location_data.relative_bounding_box, draw
+                )
+                data["bound"] = brect  # start_x, start_y, end_x, end_y
+
+                debug_image, landmark_point = self.__draw_landmarks(
+                    image, detection.location_data, draw
+                )
+                data["keypoints"] = landmark_point
                 result.append(data)
         # # return Image(debug_image), result
         return Image(image), result
 
-
     def __calc_bounding_rect(self, image, bounding_box, draw):
-        
         image_width, image_height = image.shape[1], image.shape[0]
         xmin = min(int(bounding_box.xmin * image_width), image_width - 1)
         ymin = min(int(bounding_box.ymin * image_height), image_height - 1)
-        
+
         width = min(int(bounding_box.width * image_width), image_width - 1)
         height = min(int(bounding_box.height * image_height), image_height - 1)
-        
+
         if draw:
             cv2.line(image, (xmin, ymin), (xmin + width, ymin), (0, 255, 0), 2)
-            cv2.line(image, (xmin + width, ymin), (xmin + width, ymin + height), (0, 255, 0), 2)
-            cv2.line(image, (xmin + width, ymin + height), (xmin, ymin + height), (0, 255, 0), 2)
+            cv2.line(
+                image,
+                (xmin + width, ymin),
+                (xmin + width, ymin + height),
+                (0, 255, 0),
+                2,
+            )
+            cv2.line(
+                image,
+                (xmin + width, ymin + height),
+                (xmin, ymin + height),
+                (0, 255, 0),
+                2,
+            )
             cv2.line(image, (xmin, ymin + height), (xmin, ymin), (0, 255, 0), 2)
-        
-        return [xmin, ymin, xmin + width, ymin + height]
 
+        return [xmin, ymin, xmin + width, ymin + height]
 
     def __draw_landmarks(self, image, location_data, draw):
         image_width, image_height = image.shape[1], image.shape[0]
         landmark_point = []
 
         # キーポイント
         for index, landmark in enumerate(location_data.relative_keypoints):
             # print('@x ', landmark.x)
             # print('@y ', landmark.y)
-  
+
             landmark_x = min(int(landmark.x * image_width), image_width - 1)
             landmark_y = min(int(landmark.y * image_height), image_height - 1)
 
             landmark_point.append((landmark_x, landmark_y))
             if draw:
                 if index == 0:  # left eye
                     cv2.circle(image, (landmark_x, landmark_y), 5, (0, 255, 0), 2)
@@ -104,10 +114,7 @@
                 if index == 3:  # mouth
                     cv2.circle(image, (landmark_x, landmark_y), 5, (0, 255, 0), 2)
                 if index == 4:  # left eye
                     cv2.circle(image, (landmark_x, landmark_y), 5, (0, 255, 0), 2)
                 if index == 5:  # right eye
                     cv2.circle(image, (landmark_x, landmark_y), 5, (0, 255, 0), 2)
         return image, landmark_point
-
-        
-
```

## helloai/ext/hands_detector/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-from .hands_detector import *
+from .hands_detector import *
```

## helloai/ext/hands_detector/hands_detector.py

```diff
@@ -3,25 +3,27 @@
 import math
 import cv2
 import numpy as np
 import mediapipe as mp
 
 from helloai.core.image import Image
 
-__all__ = ['HandsDetector']
+__all__ = ["HandsDetector"]
 tip_ids = [4, 8, 12, 16, 20]
 
+
 class HandsDetector:
     def __init__(self, num_hands=1):
         self.__mp_drawing = mp.solutions.drawing_utils
         self.__mp_hands = mp.solutions.hands
         self.__hands = self.__mp_hands.Hands(
             max_num_hands=num_hands,
-            min_detection_confidence=0.5, 
-            min_tracking_confidence=0.5)
+            min_detection_confidence=0.5,
+            min_tracking_confidence=0.5,
+        )
         self.__landmarks = []
         self.__angles = []
         self.__draw = True
 
     def load_model(self):
         pass
 
@@ -29,119 +31,132 @@
         self.__draw = draw
 
         image = image.frame
         h, w, c = image.shape
 
         image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)
         image.flags.writeable = False
-        results = self.__hands.process(image) 
-        
+        results = self.__hands.process(image)
+
         image.flags.writeable = True
         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
-        
+
         if results.multi_hand_landmarks:
             self.__landmarks = []
             angles = []
             handness = self.__handness(results)
             for hand_landmarks in results.multi_hand_landmarks:
                 lmks = []
-                joint = np.zeros((21,3))
-                
+                joint = np.zeros((21, 3))
+
                 if self.__draw:
-                    self.__mp_drawing.draw_landmarks(image, hand_landmarks, 
-                                        self.__mp_hands.HAND_CONNECTIONS,
-                                        self.__mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),
-                                        self.__mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2))
+                    self.__mp_drawing.draw_landmarks(
+                        image,
+                        hand_landmarks,
+                        self.__mp_hands.HAND_CONNECTIONS,
+                        self.__mp_drawing.DrawingSpec(
+                            color=(121, 22, 76), thickness=2, circle_radius=4
+                        ),
+                        self.__mp_drawing.DrawingSpec(
+                            color=(250, 44, 250), thickness=2, circle_radius=2
+                        ),
+                    )
 
                 for id, lm in enumerate(hand_landmarks.landmark):
-                    px, py, pz = int(lm.x * w), int(lm.y * h), int(lm.z * w)  # 이미지 크기 기준으로 변환
+                    px, py, pz = (
+                        int(lm.x * w),
+                        int(lm.y * h),
+                        int(lm.z * w),
+                    )  # 이미지 크기 기준으로 변환
                     lmks.append([px, py, pz])
                     joint[id] = [px, py, pz]
-                    
+
                 angle = self.__find_angle(joint)
                 angles.append(angle)
                 self.__landmarks.append(lmks)
         else:
             self.__landmarks = []
             handness = []
             angles = []
-            
+
         # return Image(image), (self.__landmarks, handness, angles)
         result = []
         if len(self.__landmarks) > 0:
             result = self.__landmarks[0]  # 한쪽 손만 사용...
-            
-        return Image(image), result
 
+        return Image(image), result
 
     def __handness(self, results):
-        ret=[]
+        ret = []
         for handness in results.multi_handedness:
             # print('***', handness.classification[0].label)
             ret.append(handness.classification[0].label.lower())
         return ret
 
-
     def __find_angle(self, joint):
         self.__angles = []
         # Compute angles between joints
-        v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:] # Parent joint
-        v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:] # Child joint
-        v = v2 - v1 # [20,3]
+        v1 = joint[
+            [0, 1, 2, 3, 0, 5, 6, 7, 0, 9, 10, 11, 0, 13, 14, 15, 0, 17, 18, 19], :
+        ]  # Parent joint
+        v2 = joint[
+            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], :
+        ]  # Child joint
+        v = v2 - v1  # [20,3]
         # Normalize v
         v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]
-        
+
         # Get angle using arcos of dot product
-        angle = np.arccos(np.einsum('nt,nt->n',
-            v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], 
-            v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]
-        self.__angles = np.degrees(angle) # Convert radian to degree
+        angle = np.arccos(
+            np.einsum(
+                "nt,nt->n",
+                v[[0, 1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18], :],
+                v[[1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19], :],
+            )
+        )  # [15,]
+        self.__angles = np.degrees(angle)  # Convert radian to degree
         # data = np.array([angle], dtype=np.float32)
         return self.__angles.tolist()
 
-
     def fingers_up(self):
         if len(self.__landmarks) == 0:
-            return [0,0,0,0,0]
+            return [0, 0, 0, 0, 0]
 
         lmlist = self.__landmarks[0]
         fingers = []
         if len(lmlist) != 0:
             # 엄지 x값 비교
             if lmlist[tip_ids[0]][1] < lmlist[tip_ids[0] - 1][1]:
                 fingers.append(1)
             else:
                 fingers.append(0)
-            # y값 비교 
+            # y값 비교
             for i in range(1, 5):
                 if lmlist[tip_ids[i]][2] < lmlist[tip_ids[i] - 2][2]:
                     fingers.append(1)
                 else:
                     fingers.append(0)
         return fingers
 
-
     def distance(self, p1, p2, image, draw=True):
-        
         image = image.frame
         r = 10
         t = 3
         x1, y1, _ = p1
         x2, y2, _ = p2
         cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
-        
+
         if draw:
             cv2.line(image, (x1, y1), (x2, y2), (255, 0, 255), t)
             cv2.circle(image, (x1, y1), r, (255, 0, 255), cv2.FILLED)
             cv2.circle(image, (x2, y2), r, (255, 0, 255), cv2.FILLED)
             cv2.circle(image, (cx, cy), r, (0, 0, 255), cv2.FILLED)
         length = math.hypot(x2 - x1, y2 - y1)
-       
-        return length,  Image(image), [x1, y1, x2, y2, cx, cy]
 
+        return length, Image(image), [x1, y1, x2, y2, cx, cy]
 
     def __del__(self):
-        '''
+        """
         del handsdetector
-        '''
+        """
         if self.__hands:
             self.__hands.close()
```

## helloai/ext/pose_detector/pose_detector.py

```diff
@@ -6,92 +6,107 @@
 import numpy as np
 import mediapipe as mp
 from collections import deque
 
 from helloai.core.image import Image
 
 
-__all__ = ['PoseDetector']
+__all__ = ["PoseDetector"]
+
 
 class PoseDetector:
     def __init__(self):
         self.__mp_drawing = mp.solutions.drawing_utils
         self.__mp_pose = mp.solutions.pose
-        self.__pose = self.__mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
+        self.__pose = self.__mp_pose.Pose(
+            min_detection_confidence=0.5, min_tracking_confidence=0.5
+        )
         self.__landmarks = []
         self.load_model()
-        
+
     def load_model(self):
         pass
-    
+
     def process(self, image, draw=True):
         image = image.frame.copy()
         image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)
         image.flags.writeable = False
-        results = self.__pose.process(image) 
-        
+        results = self.__pose.process(image)
+
         # Draw the face detection annotations on the image.
         image.flags.writeable = True
         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
-        
+
         if results.pose_landmarks:
             ret = []
             # ret = results.pose_landmarks
 
             for id, lm in enumerate(results.pose_landmarks.landmark):
                 h, w, c = image.shape
                 cx, cy, cz = int(lm.x * w), int(lm.y * h), int(lm.z * w)
                 ret.append([cx, cy, cz])
 
             self.__landmarks = ret
             if draw:
-                self.__mp_drawing.draw_landmarks(image, 
-                                             results.pose_landmarks, 
-                                             self.__mp_pose.POSE_CONNECTIONS,
-                                             self.__mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4), 
-                                             self.__mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2))
+                self.__mp_drawing.draw_landmarks(
+                    image,
+                    results.pose_landmarks,
+                    self.__mp_pose.POSE_CONNECTIONS,
+                    self.__mp_drawing.DrawingSpec(
+                        color=(121, 22, 76), thickness=2, circle_radius=4
+                    ),
+                    self.__mp_drawing.DrawingSpec(
+                        color=(250, 44, 250), thickness=2, circle_radius=2
+                    ),
+                )
         else:
             ret = []
             self.__landmarks = ret
-            
-        return Image(image), self.__landmarks
 
+        return Image(image), self.__landmarks
 
     def calc_angle(self, image, p1, p2, p3, draw=True):
         image = image.frame
-        
+
         # x1, y1 = self.__landmarks[p1][1:3]
         # x2, y2 = self.__landmarks[p2][1:3]
         # x3, y3 = self.__landmarks[p3][1:3]
-        
+
         x1, y1, _ = p1
         x2, y2, _ = p2
         x3, y3, _ = p3
-        
 
         # Calculate the Angle
-        angle = math.degrees(math.atan2(y3 - y2, x3 - x2) -
-                             math.atan2(y1 - y2, x1 - x2))
+        angle = math.degrees(
+            math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2)
+        )
         if angle < 0:
             angle += 360
 
         # Draw
         if draw:
             image = cv2.line(image, (x1, y1), (x2, y2), (255, 255, 255), 3)
             image = cv2.line(image, (x3, y3), (x2, y2), (255, 255, 255), 3)
             image = cv2.circle(image, (x1, y1), 10, (0, 0, 255), cv2.FILLED)
             image = cv2.circle(image, (x1, y1), 15, (0, 0, 255), 2)
             image = cv2.circle(image, (x2, y2), 10, (0, 0, 255), cv2.FILLED)
             image = cv2.circle(image, (x2, y2), 15, (0, 0, 255), 2)
             image = cv2.circle(image, (x3, y3), 10, (0, 0, 255), cv2.FILLED)
             image = cv2.circle(image, (x3, y3), 15, (0, 0, 255), 2)
-            image = cv2.putText(image, str(int(angle)), (x2 - 50, y2 + 50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)
+            image = cv2.putText(
+                image,
+                str(int(angle)),
+                (x2 - 50, y2 + 50),
+                cv2.FONT_HERSHEY_PLAIN,
+                2,
+                (0, 0, 255),
+                2,
+            )
         return angle, Image(image)
 
-
     def distance(self, p1, p2, image, draw=True):
         image = image.frame
         r = 15
         t = 3
         x1, y1 = self.__landmarks[p1][1:3]
         x2, y2 = self.__landmarks[p2][1:3]
         cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
@@ -101,11 +116,10 @@
             cv2.circle(image, (x1, y1), r, (255, 0, 255), cv2.FILLED)
             cv2.circle(image, (x2, y2), r, (255, 0, 255), cv2.FILLED)
             cv2.circle(image, (cx, cy), r, (0, 0, 255), cv2.FILLED)
         length = math.hypot(x2 - x1, y2 - y1)
 
         return length, Image(image), [x1, y1, x2, y2, cx, cy]
 
-
     def __del__(self):
         if self.__pose:
             self.__pose.close()
```

## helloai/ext/tmimage/tm_imageproject.py

```diff
@@ -76,15 +76,15 @@
 
         prediction = self.__model.predict(data_for_model)
 
         alist = prediction[0].tolist()
         index = alist.index(max(alist))
         self.__label = self.__labels[index]
         self.__confidence = round(alist[index], 3)  # round(n,2)
-        
+
         return self.__labels[index]
 
     # This function proportionally resizes the image from your webcam to 224 pixels high
     def __image_resize(self, img, height, inter=cv2.INTER_AREA):
         dim = None
         (h, w) = img.shape[:2]
         r = height / float(h)
```

## helloai/utils/PID.py

```diff
@@ -31,18 +31,22 @@
 
         return result
 
     def draw(self, img, cVal):
         h, w, _ = img.shape
         if self.axis == 0:
             cv2.line(img, (self.targetVal, 0), (self.targetVal, h), (255, 0, 255), 1)
-            cv2.line(img, (self.targetVal, cVal[1]), (cVal[0], cVal[1]), (255, 0, 255), 1, 0)
+            cv2.line(
+                img, (self.targetVal, cVal[1]), (cVal[0], cVal[1]), (255, 0, 255), 1, 0
+            )
         else:
             cv2.line(img, (0, self.targetVal), (w, self.targetVal), (255, 0, 255), 1)
-            cv2.line(img, (cVal[0], self.targetVal), (cVal[0], cVal[1]), (255, 0, 255), 1, 0)
+            cv2.line(
+                img, (cVal[0], self.targetVal), (cVal[0], cVal[1]), (255, 0, 255), 1, 0
+            )
 
         cv2.circle(img, tuple(cVal), 5, (255, 0, 255), cv2.FILLED)
 
         return img
 
 
 def main():
@@ -60,18 +64,23 @@
             cx, cy = bboxs[0]["center"]
             xVal = int(xPID.update(cx))
             yVal = int(yPID.update(cy))
 
             xPID.draw(img, [cx, cy])
             yPID.draw(img, [cx, cy])
 
-            cv2.putText(img, f'x:{xVal} , y:{yVal} ', (x, y - 100), cv2.FONT_HERSHEY_PLAIN, 3,
-                        (255, 0, 0), 3)
+            cv2.putText(
+                img,
+                f"x:{xVal} , y:{yVal} ",
+                (x, y - 100),
+                cv2.FONT_HERSHEY_PLAIN,
+                3,
+                (255, 0, 0),
+                3,
+            )
 
         cv2.imshow("Image", img)
         cv2.waitKey(1)
 
 
 if __name__ == "__main__":
     main()
-    
-
```

## helloai/utils/__init__.py

```diff
@@ -1,7 +1,5 @@
 from .fetcher import *
 from .voc import *
 from .rand import *
 from .time import *
 from .utils import *
-
-
```

## helloai/utils/cvzone.py

```diff
@@ -17,15 +17,19 @@
     :param scale: bigger~1+ ans smaller~1-
     :return: Stacked Image
     """
     imgList = copy.deepcopy(_imgList)
 
     # make the array full by adding blank img, otherwise the openCV can't work
     totalImages = len(imgList)
-    rows = totalImages // cols if totalImages // cols * cols == totalImages else totalImages // cols + 1
+    rows = (
+        totalImages // cols
+        if totalImages // cols * cols == totalImages
+        else totalImages // cols + 1
+    )
     blankImages = cols * rows - totalImages
 
     width = imgList[0].shape[1]
     height = imgList[0].shape[0]
     imgBlank = np.zeros((height, width, 3), np.uint8)
     imgList.extend([imgBlank] * blankImages)
 
@@ -42,16 +46,15 @@
         for x in range(cols):
             line.append(imgList[y * cols + x])
         hor[y] = np.hstack(line)
     ver = np.vstack(hor)
     return ver
 
 
-def cornerRect(img, bbox, l=30, t=5, rt=1,
-               colorR=(255, 0, 255), colorC=(0, 255, 0)):
+def cornerRect(img, bbox, l=30, t=5, rt=1, colorR=(255, 0, 255), colorC=(0, 255, 0)):
     """
     :param img: Image to draw on.
     :param bbox: Bounding box [x, y, w, h]
     :param l: length of the corner line
     :param t: thickness of the corner line
     :param rt: thickness of the rectangle
     :param colorR: Color of the Rectangle
@@ -74,42 +77,49 @@
     # Bottom Right  x1,y1
     cv2.line(img, (x1, y1), (x1 - l, y1), colorC, t)
     cv2.line(img, (x1, y1), (x1, y1 - l), colorC, t)
 
     return img
 
 
-def findContours(img, imgPre, minArea=1000, sort=True, filter=0, drawCon=True, c=(255, 0, 0)):
+def findContours(
+    img, imgPre, minArea=1000, sort=True, filter=0, drawCon=True, c=(255, 0, 0)
+):
     """
     Finds Contours in an image
     :param img: Image on which we want to draw
     :param imgPre: Image on which we want to find contours
     :param minArea: Minimum Area to detect as valid contour
     :param sort: True will sort the contours by area (biggest first)
     :param filter: Filters based on the corner points e.g. 4 = Rectangle or square
     :param drawCon: draw contours boolean
     :return: Foudn contours with [contours, Area, BoundingBox, Center]
     """
     conFound = []
     imgContours = img.copy()
-    contours, hierarchy = cv2.findContours(imgPre, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
+    contours, hierarchy = cv2.findContours(
+        imgPre, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE
+    )
 
     for cnt in contours:
         area = cv2.contourArea(cnt)
         if area > minArea:
             peri = cv2.arcLength(cnt, True)
             approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
             # print(len(approx))
             if len(approx) == filter or filter == 0:
-                if drawCon: cv2.drawContours(imgContours, cnt, -1, c, 3)
+                if drawCon:
+                    cv2.drawContours(imgContours, cnt, -1, c, 3)
                 x, y, w, h = cv2.boundingRect(approx)
                 cx, cy = x + (w // 2), y + (h // 2)
                 cv2.rectangle(imgContours, (x, y), (x + w, y + h), c, 2)
                 cv2.circle(imgContours, (x + (w // 2), y + (h // 2)), 5, c, cv2.FILLED)
-                conFound.append({"cnt": cnt, "area": area, "bbox": [x, y, w, h], "center": [cx, cy]})
+                conFound.append(
+                    {"cnt": cnt, "area": area, "bbox": [x, y, w, h], "center": [cx, cy]}
+                )
 
     if sort:
         conFound = sorted(conFound, key=lambda x: x["area"], reverse=True)
 
     return imgContours, conFound
 
 
@@ -119,18 +129,18 @@
     *_, mask = cv2.split(imgFront)
     maskBGRA = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGRA)
     maskBGR = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
     imgRGBA = cv2.bitwise_and(imgFront, maskBGRA)
     imgRGB = cv2.cvtColor(imgRGBA, cv2.COLOR_BGRA2BGR)
 
     imgMaskFull = np.zeros((hb, wb, cb), np.uint8)
-    imgMaskFull[pos[1]:hf + pos[1], pos[0]:wf + pos[0], :] = imgRGB
+    imgMaskFull[pos[1] : hf + pos[1], pos[0] : wf + pos[0], :] = imgRGB
     imgMaskFull2 = np.ones((hb, wb, cb), np.uint8) * 255
     maskBGRInv = cv2.bitwise_not(maskBGR)
-    imgMaskFull2[pos[1]:hf + pos[1], pos[0]:wf + pos[0], :] = maskBGRInv
+    imgMaskFull2[pos[1] : hf + pos[1], pos[0] : wf + pos[0], :] = maskBGRInv
 
     imgBack = cv2.bitwise_and(imgBack, imgMaskFull2)
     imgBack = cv2.bitwise_or(imgBack, imgMaskFull)
 
     return imgBack
 
 
@@ -138,17 +148,27 @@
     h, w = img.shape[:2]
     center = (w / 2, h / 2)
     rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=angle, scale=scale)
     img = cv2.warpAffine(src=img, M=rotate_matrix, dsize=(w, h))
     return img
 
 
-def putTextRect(img, text, pos, scale=3, thickness=3, colorT=(255, 255, 255),
-                colorR=(255, 0, 255), font=cv2.FONT_HERSHEY_PLAIN,
-                offset=10, border=None, colorB=(0, 255, 0)):
+def putTextRect(
+    img,
+    text,
+    pos,
+    scale=3,
+    thickness=3,
+    colorT=(255, 255, 255),
+    colorR=(255, 0, 255),
+    font=cv2.FONT_HERSHEY_PLAIN,
+    offset=10,
+    border=None,
+    colorB=(0, 255, 0),
+):
     """
     Creates Text with Rectangle Background
     :param img: Image to put text rect on
     :param text: Text inside the rect
     :param pos: Starting position of the rect x1,y1
     :param scale: Scale of the text
     :param thickness: Thickness of the text
```

## helloai/utils/fetcher.py

```diff
@@ -1,9 +1,7 @@
-
-
 import os
 import uuid
 from urllib.request import urlopen
 import tempfile
 from tempfile import NamedTemporaryFile
 from shutil import unpack_archive
 from urllib.parse import urlparse
@@ -11,90 +9,87 @@
 import zipfile
 from zipfile import ZipFile
 import gzip
 import tarfile
 import requests
 
 
-__all__ = ['fetch', 'unzip', 'fetch_and_unzip']
+__all__ = ["fetch", "unzip", "fetch_and_unzip"]
 
 
 def fetch(url, folder=None, file_name=None):
-    
     if not folder:
         # Temp folder
         folder = tempfile.gettempdir()
         # print('folder: ', folder)
 
     # 폴더가 없으면 만들고, 있으면 안 만든다.
     os.makedirs(folder, exist_ok=True)
 
     # 파싱
     parts = urlparse(url)
     # print(parts)
 
     if not file_name:
-        # 확장자 찾기 
-        file_ext = os.path.splitext(parts.path)[1]   
+        # 확장자 찾기
+        file_ext = os.path.splitext(parts.path)[1]
         # print('extension : ', file_ext, type(file_ext), len(file_ext))
 
-        file_name = os.path.basename(parts.path)  #eds_report.csv
+        file_name = os.path.basename(parts.path)  # eds_report.csv
         # print('file_name : ', file_name, type(file_name), len(file_name))
-        
+
         if not file_name:
             # 임시 파일을 만든다.
-            file_name = str(uuid.uuid4()).split('-')[0] + '.tmp'
+            file_name = str(uuid.uuid4()).split("-")[0] + ".tmp"
             # print('temp filename : ', type(file_name), file_name)
-        
-        # 확장자가 있다는 것은 파일명이 있다는 것으로 간주 
+
+        # 확장자가 있다는 것은 파일명이 있다는 것으로 간주
         # if file_ext in ('.gz', '.zip', 'gzip', 'bzip2', 'lzma'):
         #     names = parts.path.split('/')
         #     file_name = names[-1]
         #     print('filename : ', file_name)
         # else:
         #     # 임시 파일을 만든다.
         #     # file_name = uuid.uuid4().split('-')[0]
         #     file_name = str(uuid.uuid4()).split('-')[0] + '.tmp'
         #     print('temp word filename : ', type(file_name), file_name)
 
     # print('download at ', os.path.join(folder, file_name))
-    
-    with open(os.path.join(folder, file_name), 'wb') as my_file:
+
+    with open(os.path.join(folder, file_name), "wb") as my_file:
         data = requests.get(url)
         my_file.write(data.content)
         return os.path.join(folder, file_name)
-        
+
     return None
 
 
 def unzip(path):
     path_to_zip_file = path
     directory_to_extract_to = os.path.dirname(path_to_zip_file)
 
     # print('unzip file:', path_to_zip_file)
     # print('unzip folder:', directory_to_extract_to)
-    
-    # 확장자 찾기 
+
+    # 확장자 찾기
     file_ext = os.path.splitext(path_to_zip_file)[1]
     # print('extension : ', file_ext, type(file_ext), len(file_ext))
-    
-    
-    
-    if file_ext in ('.gz', '.gzip', '.bzip2', '.lzma'):
-        tar = tarfile.open(path_to_zip_file, mode='r:*')
-        dir_name = tar.getmembers()[0].name.split('/')[0]
+
+    if file_ext in (".gz", ".gzip", ".bzip2", ".lzma"):
+        tar = tarfile.open(path_to_zip_file, mode="r:*")
+        dir_name = tar.getmembers()[0].name.split("/")[0]
         # print('dir name: ', dir_name)
 
         tar.extractall(path=directory_to_extract_to)
         tar.close()
         return os.path.join(directory_to_extract_to, dir_name)
-    elif file_ext in ('.zip',):
-        with ZipFile(path_to_zip_file, 'r') as zipObj:
-            dir_name = zipObj.namelist()[0].split('/')[0]
+    elif file_ext in (".zip",):
+        with ZipFile(path_to_zip_file, "r") as zipObj:
+            dir_name = zipObj.namelist()[0].split("/")[0]
             # print('dir name: ', dir_name)
             zipObj.extractall(path=directory_to_extract_to)
             return os.path.join(directory_to_extract_to, dir_name)
     return None
 
+
 def fetch_and_unzip(url, folder=None, file_name=None):
     return unzip(fetch(url, folder, file_name))
-
```

## helloai/utils/rand.py

```diff
@@ -21,18 +21,23 @@
 
 from .utils import constrain
 from .utils import SINCOS_LENGTH
 from .utils import PRE_COS
 
 __all__ = [
     # PERLIN NOISE FUNCTIONS
-    'noise', 'noise_detail', 'noise_seed',
-
+    "noise",
+    "noise_detail",
+    "noise_seed",
     # RANDOM NUMBER GENERATION
-    'random', 'random_uniform', 'random_gaussian', 'random_seed', 'random_range'
+    "random",
+    "random_uniform",
+    "random_gaussian",
+    "random_seed",
+    "random_range",
 ]
 
 # Most of the perlin noise code is based on the original Processing
 # implementation of the noise function. toxi (+ other folks) put a
 # bunch of comments on the Processing version, and I've added them
 # here too for context.
 #
@@ -251,23 +256,24 @@
     """Set the seed used to generate random numbers.
 
     :param seed: The required seed value.
     :type seed: int
     """
     rand.seed(seed)
 
+
 def random(num, size=1):
     """
-    0 ~ num 사이의 정수 size개를 뽑는다 
+    0 ~ num 사이의 정수 size개를 뽑는다
     """
     if size == 1:
         return rand.randrange(0, num)
     else:
         # 0 ~ num 사이의 정수값 size개를 뽑아낸다.
         np.random.randint(num, size=size)
 
 
 def random_range(start, end):
     """
-    0 ~ num 사이의 정수 
+    0 ~ num 사이의 정수
     """
-    return rand.randrange(start, end)
+    return rand.randrange(start, end)
```

## helloai/utils/utils.py

```diff
@@ -22,36 +22,57 @@
 import math
 from math import ceil, floor, exp, log, sqrt, modf
 from math import degrees, radians
 from math import sin, cos, tan
 from math import asin, acos, atan, atan2
 
 import numpy as np
+import pandas as pd
 
 __all__ = [
     # TRIG FUNCTIONS
-    'sin', 'cos', 'tan', 'degrees', 'radians',
-
+    "sin",
+    "cos",
+    "tan",
+    "degrees",
+    "radians",
     # INVERSE TRIG FUNCTIONS
-    'asin', 'acos', 'atan', 'atan2',
-
+    "asin",
+    "acos",
+    "atan",
+    "atan2",
     # TRIG CONSTANTS
-    'TWO_PI', 'PI', 'HALF_PI', 'QUARTER_PI', 'TAU', 'HALF_TAU',
-
+    "TWO_PI",
+    "PI",
+    "HALF_PI",
+    "QUARTER_PI",
+    "TAU",
+    "HALF_TAU",
     # MATH FUNCTIONS FROM THE STANDARD LIBRARY (abs and round are
     # available in builtins.)
-    'ceil', 'floor', 'exp', 'log', 'sqrt',
-
+    "ceil",
+    "floor",
+    "exp",
+    "log",
+    "sqrt",
     # MATH FUNCTIONS DEFINED HERE
-
-    'constrain', 'lerp', 'remap', 'normalize', 'distance', 'dist',
-    'magnitude', 'mag', 'sq', 'fract',
-
+    "constrain",
+    "lerp",
+    "remap",
+    "normalize",
+    "distance",
+    "dist",
+    "magnitude",
+    "mag",
+    "sq",
+    "fract",
     # ANGLE
-    'angle3p',
+    "angle3p",
+    # PANDAS
+    "to_csv",
 ]
 
 TWO_PI = 2 * math.pi
 PI = math.pi
 HALF_PI = math.pi / 2.0
 QUARTER_PI = math.pi / 4.0
 
@@ -280,15 +301,15 @@
     :param number: The number to be squared.
     :type number: float
 
     :returns: The square of the number.
     :rtype: float
 
     """
-    return number ** 2
+    return number**2
 
 
 def fract(number):
     """Calculates the fractional part of a number.
 
     Examples ::
 
@@ -305,33 +326,38 @@
     :rtype: float
 
     """
     return modf(number)[0]
 
 
 def angle3p(p1, p2, p3):
-    """3점 사이의 각도 계산 
+    """3점 사이의 각도 계산
 
     Args:
         p1 : (x1, y1)
         p2 : (x2, y2)
         p3 : (x3, y3)
 
     Returns:
-        시계 반대방향의 각도       
+        시계 반대방향의 각도
     """
-    Ax, Ay = p1[0]-p2[0], p1[1]-p2[1]
-    Cx, Cy = p3[0]-p2[0], p3[1]-p2[1]
+    Ax, Ay = p1[0] - p2[0], p1[1] - p2[1]
+    Cx, Cy = p3[0] - p2[0], p3[1] - p2[1]
     a = math.atan2(Ay, Ax)
     c = math.atan2(Cy, Cx)
     if a < 0:
-        a += math.pi*2
+        a += math.pi * 2
     if c < 0:
-        c += math.pi*2
+        c += math.pi * 2
 
-    rad = (math.pi*2 + c - a) if a > c else (c - a)
-    return rad * 180/math.pi
+    rad = (math.pi * 2 + c - a) if a > c else (c - a)
+    return rad * 180 / math.pi
 
 
 # Helpful aliases
 dist = distance
 mag = magnitude
+
+
+def to_csv(values, path="values.csv"):
+    if isinstance(values, list):
+        pd.DataFrame(values).to_csv(path, sep=",", header=False, index=False)
```

## helloai/utils/voc.py

```diff
@@ -1,72 +1,82 @@
 import os
 import glob
 import pandas as pd
 import xml.etree.ElementTree as ET
 
-__all__ = ['Voc']
+__all__ = ["Voc"]
 
 
 class Voc:
     @classmethod
     def read(cls, path):
         value = None
         tree = ET.parse(path)
         root = tree.getroot()
-        for member in root.findall('object'):
-            bbx = member.find('bndbox')
-            xmin = int(bbx.find('xmin').text)
-            ymin = int(bbx.find('ymin').text)
-            xmax = int(bbx.find('xmax').text)
-            ymax = int(bbx.find('ymax').text)
-            label = member.find('name').text
+        for member in root.findall("object"):
+            bbx = member.find("bndbox")
+            xmin = int(bbx.find("xmin").text)
+            ymin = int(bbx.find("ymin").text)
+            xmax = int(bbx.find("xmax").text)
+            ymax = int(bbx.find("ymax").text)
+            label = member.find("name").text
 
             value = (
-                    int(root.find('size')[0].text),
-                    int(root.find('size')[1].text),
-                    label,
-                    xmin,
-                    ymin,
-                    xmax,
-                    ymax
-                    )
+                int(root.find("size")[0].text),
+                int(root.find("size")[1].text),
+                label,
+                xmin,
+                ymin,
+                xmax,
+                ymax,
+            )
         return value
-        
-        
+
     @classmethod
     def to_csv(cls, path, name):
         xml_list = []
-        for xml_file in glob.glob(path + '/*.xml'):
+        for xml_file in glob.glob(path + "/*.xml"):
             tree = ET.parse(xml_file)
             root = tree.getroot()
-            for member in root.findall('object'):
-                bbx = member.find('bndbox')
-                xmin = int(bbx.find('xmin').text)
-                ymin = int(bbx.find('ymin').text)
-                xmax = int(bbx.find('xmax').text)
-                ymax = int(bbx.find('ymax').text)
-                label = member.find('name').text
-
-                value = (root.find('filename').text,
-                        int(root.find('size')[0].text),
-                        int(root.find('size')[1].text),
-                        label,
-                        xmin,
-                        ymin,
-                        xmax,
-                        ymax
-                        )
+            for member in root.findall("object"):
+                bbx = member.find("bndbox")
+                xmin = int(bbx.find("xmin").text)
+                ymin = int(bbx.find("ymin").text)
+                xmax = int(bbx.find("xmax").text)
+                ymax = int(bbx.find("ymax").text)
+                label = member.find("name").text
+
+                value = (
+                    root.find("filename").text,
+                    int(root.find("size")[0].text),
+                    int(root.find("size")[1].text),
+                    label,
+                    xmin,
+                    ymin,
+                    xmax,
+                    ymax,
+                )
                 xml_list.append(value)
 
-        column_name = ['filename', 'width', 'height','class', 'xmin', 'ymin', 'xmax', 'ymax']
+        column_name = [
+            "filename",
+            "width",
+            "height",
+            "class",
+            "xmin",
+            "ymin",
+            "xmax",
+            "ymax",
+        ]
         xml_df = pd.DataFrame(xml_list, columns=column_name)
-        xml_df.to_csv('labels_{}.csv'.format(name), index=None)
+        xml_df.to_csv("labels_{}.csv".format(name), index=None)
         return xml_df.to_numpy()
 
+
 # def main():
 #     datasets = ['train', 'dev', 'test']
 #     for ds in datasets:
 #         image_path = os.path.join(os.getcwd(), ds, 'annotations')
 #         xml_df = xml_to_csv(image_path)
 #         xml_df.to_csv('labels_{}.csv'.format(ds), index=None)
 #         print('Successfully converted xml to csv.')
-# main()
+# main()
```

## Comparing `helloai-2.1.dist-info/LICENSE` & `helloai-2.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `helloai-2.1.dist-info/METADATA` & `helloai-2.2.dist-info/METADATA`

 * *Files 20% similar despite different names*

```diff
@@ -1,39 +1,44 @@
 Metadata-Version: 2.1
 Name: helloai
-Version: 2.1
+Version: 2.2
 Summary: A Python Library For AI Education
 Home-page: http://www.moyalab.com
-Download-URL: https://www.moyalab.com
 Author: devdio
-Author-email: iammoyalab@gmail.com
+Author-email: devdio.kei@gmail.com
 License: GNU GPLv3
+Download-URL: https://www.moyalab.com
 Keywords: Kamibot,AI,Robot,CV
+Platform: UNKNOWN
 Classifier: Intended Audience :: Education
 Classifier: Operating System :: Microsoft :: Windows
 Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
 Classifier: Topic :: Education
-Requires-Python: >=3.10
+Requires-Python: >=3.9
 Description-Content-Type: text/markdown
 License-File: LICENSE
-Requires-Dist: opencv-contrib-python
-Requires-Dist: numpy (==1.25.1)
-Requires-Dist: vnoise (==0.1.0)
-Requires-Dist: Random-Word (==1.0.11)
-Requires-Dist: matplotlib (==3.7.2)
-Requires-Dist: pandas (==2.0.3)
-Requires-Dist: scikit-learn (==1.3.0)
-Requires-Dist: scipy (==1.11.1)
-Requires-Dist: mediapipe (==0.8.11)
-Requires-Dist: tensorflow (==2.10.1)
-Requires-Dist: tensorflow-datasets (==4.9.0)
-Requires-Dist: keyboard (==0.13.5)
-Requires-Dist: Pillow (==8.3.2)
-Requires-Dist: tqdm (==4.41.1)
-Requires-Dist: imutils (==0.5.4)
-Requires-Dist: PyYAML (==6.0)
+Requires-Dist: opencv-contrib-python ==4.8.0.76
+Requires-Dist: numpy ==1.25.1
+Requires-Dist: vnoise ==0.1.0
+Requires-Dist: Random-Word ==1.0.11
+Requires-Dist: matplotlib ==3.7.2
+Requires-Dist: pandas ==2.0.3
+Requires-Dist: scikit-learn ==1.3.0
+Requires-Dist: scipy ==1.11.1
+Requires-Dist: mediapipe ==0.9.1.0
+Requires-Dist: tensorflow ==2.10.1
+Requires-Dist: tensorflow-datasets ==4.9.0
+Requires-Dist: keyboard ==0.13.5
+Requires-Dist: Pillow ==8.3.2
+Requires-Dist: tqdm ==4.41.1
+Requires-Dist: imutils ==0.5.4
+Requires-Dist: PyYAML ==6.0
 
 ## A Python Library For AI Education
 ---
 Under development and use it under your own responsibility.
 
+- 2.3 Changed the version of mediapipe.
+
```

## Comparing `helloai-2.1.dist-info/RECORD` & `helloai-2.2.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,52 +1,54 @@
 hi.py,sha256=Ri5rYCISFQ77zH3QvMLMgvR35V2-tcarOQMxjObHV0k,559
-helloai/__init__.py,sha256=V4pQyGWp6B05BkQOP1ZSxB4Yi04utfTmnc8uJ2p5S_g,84
+helloai/__init__.py,sha256=OdXEdtXaE39Xa6Su0SYFu21TYACr5QwtWciRx2nAseM,83
 helloai/__main__.py,sha256=9xbdgcFm03y78mteoMLcB4SxzekL3Fh0DH4xO4ncLao,40
-helloai/builtins.py,sha256=V4pQyGWp6B05BkQOP1ZSxB4Yi04utfTmnc8uJ2p5S_g,84
-helloai/runner.py,sha256=dZBEmT2eCgGn2Ny1vER92M5U7Nwl3c3FfVy752Ferz8,3684
-helloai/version.py,sha256=_y2tWv5vxdbFuMG0axOdyMmpsnvew95hU5qJCBrxR1o,1144
-helloai/core/__init__.py,sha256=O94qHd3rN629Scp1_ThWvejostJOgpZCnLgluuz2Fo8,676
-helloai/core/api.py,sha256=ztRRRYE53ZVYTl0m2DbUpIVGbPeEpRIgW4E-kwwtJWA,6407
-helloai/core/camera.py,sha256=ROZ60Ggs7tPEv3DvvUMt1iXYFMJHXczwAxwKML1TOJU,5606
-helloai/core/colors.py,sha256=WGSRDnNqldRGB1J66XbCTD_7CSfsC25UC-EBq5AkqU4,16195
-helloai/core/config.py,sha256=4VsxyPKQfb0dPpy2y0ksd3y4GiV-vv53F9NcW3iaOro,1526
-helloai/core/core.py,sha256=v1h_7fZ_varABaMja3sIYGCKZy-LoEknTvEDegy8wwk,8536
-helloai/core/display.py,sha256=3ZOW3gdh0VBXSgJij1w9_CUjxJyLc6QObz3t01Jtdjk,1812
-helloai/core/helper.py,sha256=1555YJrcCfqZ8iIGmwZ5EoZtxZLvZ1BMO-VgmC3uaBw,720
-helloai/core/image.py,sha256=tu7dcRpHjmqSkf0qEn2OGnyDhd_ArqDSLwTjrqw7OdU,52108
-helloai/core/movie.py,sha256=uqT1hbyjUcyNF5COUwSi2wbHsQ-A5B89pX4rjRmmpus,2828
+helloai/builtins.py,sha256=OdXEdtXaE39Xa6Su0SYFu21TYACr5QwtWciRx2nAseM,83
+helloai/runner.py,sha256=n_su_Li4hp-eF0O7AKIf-GnjXrtmmkuEkiMnIaI5xYQ,3688
+helloai/version.py,sha256=6mtAJFWKKm7DGvJH6GTs4AmX6m7trdbIzOx1JsO0r4k,1144
+helloai/core/__init__.py,sha256=pWaegMmo2D81_wh8ePTOFOoGjPYkKthZ3mbbC3yn0C4,675
+helloai/core/api.py,sha256=Hr4V0y015hq3O0sidsSoW2txQoe85yw5SSLx6nPC6qk,6434
+helloai/core/camera.py,sha256=lNKASqqGI1bH1NWRKr9Bcu6AWRStdgbfIXZOdDwWnHE,5675
+helloai/core/colors.py,sha256=78FD6NpeNnUTy2KQi57x8kW1lJf0k5UXkk6t8zFbYVw,12976
+helloai/core/config.py,sha256=OLyowf4-OsWOQ7rOh7P3tpAfiTEyDd-RWtMUNrsYvSU,1531
+helloai/core/core.py,sha256=piBUYQ5sa44yGWv5hCSyMBONVGMnxLX7pC9zFakeB6c,9388
+helloai/core/display.py,sha256=HDAHjTmXDgBNohuCaukCKd13SwcH09E_2RXH5yGHZio,1808
+helloai/core/helper.py,sha256=9ikpFdU-QntYWd2-VNkPm274ZpMFVX1Tyb2vMxn0gHE,749
+helloai/core/image.py,sha256=Ee8-LKxDSr9945fWYWYWF-b15qZEdDGfP6K3H7JFgr0,52106
+helloai/core/movie.py,sha256=CnTYrGpWitx-y0wDKsJAKV5cq_hGAsGmh1eBUDVfGK0,2824
 helloai/core/mytimer.py,sha256=a-i9uQ6weJWpCvR9pwffFTV7z5IMzc-DMP_3M19fUW4,790
-helloai/core/plotwindow.py,sha256=CVn49VzrDdnN2q6hTjZJISXpr4gkzPSW4-q1BhNvyBM,2468
+helloai/core/plotwindow.py,sha256=Snqubno7JlJND08fPhQTIa2nz9Q8Y9z6TT2xFI3rMQo,2431
 helloai/core/singlestore.py,sha256=FaF_xXSKxCXGkYBSa0pH1RLM4PiHcL7EEqMRtGg_QoY,285
 helloai/core/sketch.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-helloai/core/trackbarwin.py,sha256=xNOtAyib-2HBzbp4IdPn9qs5DGNapbj0WiHrh6-iyfg,489
-helloai/core/vector.py,sha256=SQyMRTfIgi-mkDu-9mRYiHNloFFui1AIaZ_yyK1qObY,13096
-helloai/core/video.py,sha256=-m3V7YTKoLU8caMGDizDD2P4jCmy2pX7NyKGO3VKeTs,2834
-helloai/core/video_writer.py,sha256=tlHc8Bqw6Xl3bFJN9HyiUrr-ajWgtyJpuLtvyPfyLYw,1800
-helloai/core/virtualcamera.py,sha256=fpkAdqR16zbWjNCPSg0pUrkAKp2zHP8ixhicsy0vNqQ,2683
-helloai/core/window.py,sha256=FPO2yBZjCAx-iMAM29GMTcSCVHQ4KhtpaR8qVWLXQmM,8984
-helloai/ext/__init__.py,sha256=RPbrBL3GrYm9-YpF6QVGoeQvTlC3yE9oDaYbwTcZhm8,132
-helloai/ext/aruco/__init__.py,sha256=pBJy3orfSNmJsuIM6Ed1CxklyITkpuFWYQ6NhA7vGkI,20
-helloai/ext/aruco/aruco.py,sha256=12KNHebQViHcgVDpW6TyZwu_q98TqscMlzwSf8domgo,4330
-helloai/ext/aruco/aruco_test.py,sha256=kvHFwHiT8L9_BFI185rqie68OECPoc4TyD-nT6ToSwo,3111
-helloai/ext/face_detector/__init__.py,sha256=BZkDzzAqcUUz85D0dCDxsBNn8n5cjGoY9Ia14iKtFPo,28
-helloai/ext/face_detector/face_detector.py,sha256=L-LO4JBa68v44xBFhD1ZANhcOIaWQf5JtSKsSgpzM5s,4379
-helloai/ext/hands_detector/__init__.py,sha256=ApigGpO0JJadr5JYPFda7jBAjWkpDZrhSLcvNq_Vekc,29
-helloai/ext/hands_detector/hands_detector.py,sha256=EBzvU1JF33XxQNsqH-jBUyC9DU3AsSPRT4MzLkc_nW4,5110
+helloai/core/trackbarwin.py,sha256=aoUMX_ZsFnMUTBePiIubPSorTPqmQcxWBtj7bWuEHso,489
+helloai/core/vector.py,sha256=psdy8ZQlqfFw56ph-zWiugz2eaAhMMP3kM5hm0aDcw0,13056
+helloai/core/video.py,sha256=m5CnbZ8Vvr8GMbsN5yFXrO6jQF2cQ0tiknYUrZl6Qx4,2831
+helloai/core/video_writer.py,sha256=DXo5CFvD6aLsb3wYAa3sWVc62RbEEV-0ki4YKj3ai8k,1845
+helloai/core/virtualcamera.py,sha256=mbD9NxRixum6_GtJE3vygJe8P3L0qFBEiRCUKLiAASI,2699
+helloai/core/window.py,sha256=u6YNy6RqSL5SEHxz284FL5axzpZen27Yr5WNppqbeWo,8911
+helloai/ext/__init__.py,sha256=THOJn3_gxHnTTb-iZeMOFzA1U5NpDpdtN-IXZ3OptSQ,157
+helloai/ext/aruco/__init__.py,sha256=OK_8HXYcK9DU2pLtMPaKXl8Knw3WqpeL8V2fpaTYhVM,21
+helloai/ext/aruco/aruco.py,sha256=tpjO8QvRnZXoqijOLKBzD8IJ8WYi5A4OWnRSOa_0_OI,4339
+helloai/ext/aruco/aruco_test.py,sha256=z6OgM6Xn2ZJn--hgscExIUou8pJdOQnMBDSoNozIbgA,3062
+helloai/ext/face_detector/__init__.py,sha256=z9o3H3gpgnDZs4qDGZ3Bj4lmjvhdYbZt4mw6VF_iT3M,29
+helloai/ext/face_detector/face_detector.py,sha256=hUZLCccDvjclMuotrd0TrI-a5lxn_GOcgn--g4Y2fX8,4523
+helloai/ext/hands_detector/__init__.py,sha256=fqJZTfaeu2WignHUas5js7Nf3JAzXka-VM90WXkO5s0,30
+helloai/ext/hands_detector/hands_detector.py,sha256=3nGNaJBkj92D5YJ7bnNZNO33yxkBpRG-KOKtOXdmqrI,5432
 helloai/ext/pose_detector/__init__.py,sha256=QguF5SXTtX5IPUqEpgZEGzfnlqOqFORAJwt_Jvw9Gs4,30
-helloai/ext/pose_detector/pose_detector.py,sha256=eeHQdrU1ghf79oYnikH7ZBLUh6f1ktckJbC1hoAqdyE,4053
+helloai/ext/pose_detector/pose_detector.py,sha256=BdcRKXYhdiW5bj6JJmvzzWT3cZ0YKeJPTjQNdy-Wmos,4169
+helloai/ext/regressor/__init__.py,sha256=hyslN7d8bRAunlwvk1ELfq_Xf8l300KzJpYwAiaW3FU,25
+helloai/ext/regressor/regressor.py,sha256=w360Nd0O9VSRKehEaYpGHly1vs-pCxUi7yB6zJdsC-g,1203
 helloai/ext/tmimage/__init__.py,sha256=pgohsQKUp4Db8RKWvyNIw5PkEhl5eOoPzV5RnlGMi2Q,31
-helloai/ext/tmimage/tm_imageproject.py,sha256=ULo-psiy1TzM3MJiEpusoptWBLjCEQnAMuRV-Hg5pkQ,4986
-helloai/utils/PID.py,sha256=7oqO77_OK6cxZeuToS0OG9ijD5BaTuItviAULQ91N_A,2241
-helloai/utils/__init__.py,sha256=4C5yes7NsQi9Pe4sBJqBxp2rCSrcECkcglwwjehg3FI,112
-helloai/utils/cvzone.py,sha256=UjKcFtbWJwY1gqpzCr-SpojGqwN1trFhGPW-FPjOkdo,6672
-helloai/utils/fetcher.py,sha256=aR-J-WXwKCrp8abA1dhR-7MoK3iu3pvY6Dv2K3-yOo0,3288
-helloai/utils/rand.py,sha256=uFgfu62MyU1b9Oi71UIa3ZxSrhjZ6fb1f-oD-59Y6s8,6915
+helloai/ext/tmimage/tm_imageproject.py,sha256=PxBPrCERACocIe6lov5DE1ffjIEBJ8WTU3I8CWpaHpc,4978
+helloai/utils/PID.py,sha256=eL2Ji7ffCrgMIkYacXEKKNsdqTT9Zd5X9RAAOwd_3gA,2394
+helloai/utils/__init__.py,sha256=E0vqfRCg1TYeh69Jd5ct6wy2fjJ0OJXGwfQN5-dxEyE,108
+helloai/utils/cvzone.py,sha256=ER5fkU3rktKg5bkgIAy6g1x2OC8fK8QpKyeVMGA4Jxk,6790
+helloai/utils/fetcher.py,sha256=eZc7tS-E-p67Pey-461CDpOE0iDUJ2McdmbJ-FtaPyc,3225
+helloai/utils/rand.py,sha256=giuACjPFyemfIGbYwDxlA8uugpf5M-4Hg45kRrnkXlU,6939
 helloai/utils/time.py,sha256=xxCmMa4BLR97XZ8eEiut56MbspqSdhHlwakasTcwHvA,1090
-helloai/utils/utils.py,sha256=A93aoftOy_mntZlrA_3ODBFFKsCalWYs-bL_QSdtzeY,6878
-helloai/utils/voc.py,sha256=huResDWRG7JOlSazK_GND4u5p4-3U0F1CIoqwe-zS6M,2428
-helloai-2.1.dist-info/LICENSE,sha256=5PGNxtToA4KbNqWf6UDn1qHur4bv8yERYgebnSXaTbo,849
-helloai-2.1.dist-info/METADATA,sha256=LMpWk3nvc1cRPvwH0_Q8j9YwQBR-sjvjG9loMeXuW_s,1225
-helloai-2.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-helloai-2.1.dist-info/entry_points.txt,sha256=uYhY3fMjzHmOb2xC2RHHhjUKx7e8qQxL_v9K-crGxco,44
-helloai-2.1.dist-info/top_level.txt,sha256=5yUPQL2AnwMAOXlF0Pr-nQv2i1TY3FSPUO1T6qowdRY,11
-helloai-2.1.dist-info/RECORD,,
+helloai/utils/utils.py,sha256=QLCpMS4txzpecl8-FF4Am8FVvLX2hhGLVK2PYZhlYrw,7173
+helloai/utils/voc.py,sha256=QFoi4rC-qD_YVFMESLQW7-c6WIeDCnsQaLbfQQ2MLg8,2483
+helloai-2.2.dist-info/LICENSE,sha256=5PGNxtToA4KbNqWf6UDn1qHur4bv8yERYgebnSXaTbo,849
+helloai-2.2.dist-info/METADATA,sha256=lXQPZ4-dWeqgzNmoNn6BL04_hoF3bSopkckjBheXXHQ,1371
+helloai-2.2.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+helloai-2.2.dist-info/entry_points.txt,sha256=7fHwYmjh0uiTc7QQTEYLi_tmdikMyul1e8IH8jeztEc,45
+helloai-2.2.dist-info/top_level.txt,sha256=5yUPQL2AnwMAOXlF0Pr-nQv2i1TY3FSPUO1T6qowdRY,11
+helloai-2.2.dist-info/RECORD,,
```

