# Comparing `tmp/function_sampler-0.2-pp39-pypy39_pp73-manylinux_2_28_x86_64.whl.zip` & `tmp/function_sampler-0.2.1-pp39-pypy39_pp73-manylinux_2_28_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,28 +1,28 @@
-Zip file size: 362368 bytes, number of entries: 26
-drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 13:23 function_sampler-0.2.dist-info/
-drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 13:23 function_sampler/
-drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 13:23 function_sampler.libs/
--rw-r--r--  2.0 unx      119 b- defN 24-May-13 13:23 function_sampler-0.2.dist-info/WHEEL
--rw-r--r--  2.0 unx       17 b- defN 24-May-13 13:23 function_sampler-0.2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    10174 b- defN 24-May-13 13:23 function_sampler-0.2.dist-info/LICENSE
--rw-r--r--  2.0 unx     8466 b- defN 24-May-13 13:23 function_sampler-0.2.dist-info/METADATA
--rw-rw-r--  2.0 unx     1878 b- defN 24-May-13 13:23 function_sampler-0.2.dist-info/RECORD
-drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 13:23 function_sampler/fsm/
-drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 13:23 function_sampler/config/
--rw-r--r--  2.0 unx      330 b- defN 24-May-13 13:23 function_sampler/logger.py
--rw-r--r--  2.0 unx    14621 b- defN 24-May-13 13:23 function_sampler/json.py
--rw-r--r--  2.0 unx     1132 b- defN 24-May-13 13:23 function_sampler/cache.py
--rw-r--r--  2.0 unx     2640 b- defN 24-May-13 13:23 function_sampler/regex_constants.py
--rw-r--r--  2.0 unx    12987 b- defN 24-May-13 13:23 function_sampler/sampler.py
--rw-r--r--  2.0 unx      454 b- defN 24-May-13 13:23 function_sampler/__init__.py
--rw-r--r--  2.0 unx     5675 b- defN 24-May-13 13:23 function_sampler/utils.py
--rw-r--r--  2.0 unx     7297 b- defN 24-May-13 13:23 function_sampler/fsm/regex.py
--rw-r--r--  2.0 unx      298 b- defN 24-May-13 13:23 function_sampler/fsm/__init__.py
--rwxr-xr-x  2.0 unx   706888 b- defN 24-May-13 13:23 function_sampler/fsm/fsm_utils.pypy39-pp73-x86_64-linux-gnu.so
--rw-r--r--  2.0 unx      658 b- defN 24-May-13 13:23 function_sampler/fsm/utils.py
--rw-r--r--  2.0 unx     3434 b- defN 24-May-13 13:23 function_sampler/fsm/tokenizer_fsm_patch.py
--rw-r--r--  2.0 unx     3065 b- defN 24-May-13 13:23 function_sampler/config/token_mapper.py
--rw-r--r--  2.0 unx      126 b- defN 24-May-13 13:23 function_sampler/config/__init__.py
--rw-r--r--  2.0 unx      633 b- defN 24-May-13 13:23 function_sampler/config/config.py
--rw-r--r--  2.0 unx     3825 b- defN 24-May-13 13:23 function_sampler/config/utils.py
-26 files, 784717 bytes uncompressed, 358704 bytes compressed:  54.3%
+Zip file size: 363053 bytes, number of entries: 26
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 16:50 function_sampler/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 16:50 function_sampler.libs/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 16:50 function_sampler-0.2.1.dist-info/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 16:50 function_sampler/fsm/
+drwxr-xr-x  2.0 unx        0 b- stor 24-May-13 16:50 function_sampler/config/
+-rw-r--r--  2.0 unx      330 b- defN 24-May-13 16:50 function_sampler/logger.py
+-rw-r--r--  2.0 unx    14621 b- defN 24-May-13 16:50 function_sampler/json.py
+-rw-r--r--  2.0 unx     1132 b- defN 24-May-13 16:50 function_sampler/cache.py
+-rw-r--r--  2.0 unx     2640 b- defN 24-May-13 16:50 function_sampler/regex_constants.py
+-rw-r--r--  2.0 unx    14928 b- defN 24-May-13 16:50 function_sampler/sampler.py
+-rw-r--r--  2.0 unx      454 b- defN 24-May-13 16:50 function_sampler/__init__.py
+-rw-r--r--  2.0 unx     5675 b- defN 24-May-13 16:50 function_sampler/utils.py
+-rw-r--r--  2.0 unx     7297 b- defN 24-May-13 16:50 function_sampler/fsm/regex.py
+-rw-r--r--  2.0 unx      298 b- defN 24-May-13 16:50 function_sampler/fsm/__init__.py
+-rwxr-xr-x  2.0 unx   706888 b- defN 24-May-13 16:50 function_sampler/fsm/fsm_utils.pypy39-pp73-x86_64-linux-gnu.so
+-rw-r--r--  2.0 unx      658 b- defN 24-May-13 16:50 function_sampler/fsm/utils.py
+-rw-r--r--  2.0 unx     3434 b- defN 24-May-13 16:50 function_sampler/fsm/tokenizer_fsm_patch.py
+-rw-r--r--  2.0 unx     3065 b- defN 24-May-13 16:50 function_sampler/config/token_mapper.py
+-rw-r--r--  2.0 unx      126 b- defN 24-May-13 16:50 function_sampler/config/__init__.py
+-rw-r--r--  2.0 unx      633 b- defN 24-May-13 16:50 function_sampler/config/config.py
+-rw-r--r--  2.0 unx     3825 b- defN 24-May-13 16:50 function_sampler/config/utils.py
+-rw-r--r--  2.0 unx      119 b- defN 24-May-13 16:50 function_sampler-0.2.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       17 b- defN 24-May-13 16:50 function_sampler-0.2.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    10174 b- defN 24-May-13 16:50 function_sampler-0.2.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx     8468 b- defN 24-May-13 16:50 function_sampler-0.2.1.dist-info/METADATA
+-rw-rw-r--  2.0 unx     1888 b- defN 24-May-13 16:50 function_sampler-0.2.1.dist-info/RECORD
+26 files, 786670 bytes uncompressed, 359365 bytes compressed:  54.3%
```

## zipnote {}

```diff
@@ -1,29 +1,14 @@
-Filename: function_sampler-0.2.dist-info/
-Comment: 
-
 Filename: function_sampler/
 Comment: 
 
 Filename: function_sampler.libs/
 Comment: 
 
-Filename: function_sampler-0.2.dist-info/WHEEL
-Comment: 
-
-Filename: function_sampler-0.2.dist-info/top_level.txt
-Comment: 
-
-Filename: function_sampler-0.2.dist-info/LICENSE
-Comment: 
-
-Filename: function_sampler-0.2.dist-info/METADATA
-Comment: 
-
-Filename: function_sampler-0.2.dist-info/RECORD
+Filename: function_sampler-0.2.1.dist-info/
 Comment: 
 
 Filename: function_sampler/fsm/
 Comment: 
 
 Filename: function_sampler/config/
 Comment: 
@@ -72,8 +57,23 @@
 
 Filename: function_sampler/config/config.py
 Comment: 
 
 Filename: function_sampler/config/utils.py
 Comment: 
 
+Filename: function_sampler-0.2.1.dist-info/WHEEL
+Comment: 
+
+Filename: function_sampler-0.2.1.dist-info/top_level.txt
+Comment: 
+
+Filename: function_sampler-0.2.1.dist-info/LICENSE
+Comment: 
+
+Filename: function_sampler-0.2.1.dist-info/METADATA
+Comment: 
+
+Filename: function_sampler-0.2.1.dist-info/RECORD
+Comment: 
+
 Zip file comment:
```

## function_sampler/sampler.py

```diff
@@ -2,120 +2,157 @@
 Tool Call sampler.
 
 Yes I know how messy this code is. I'll clean it up when I get the chance.
 """
 
 import functools
 import time
-from typing import (
-    Any,
-    Dict,
-    List,
-    Union
-)
-
+from typing import Any, Dict, List, Union
 from concurrent.futures import ThreadPoolExecutor
 
 import torch
 from transformers import LogitsProcessor, PreTrainedTokenizer
 
 from .config import TokenMap
 from .config.config import ToolCallSamplerConfig
-from .fsm import (
-    FSMState, 
-    FsmTokenizer
-)
-
+from .fsm import FSMState, FsmTokenizer
 from .logger import get_logger
-
-from .utils import (
-    build_masks,
-    bundle_sampling,
-    tokenize_dicts,
-    compute_fsm
-)
+from .utils import build_masks, bundle_sampling, tokenize_dicts, compute_fsm
 
 logger = get_logger()
 
 
 class ToolCallSampler(LogitsProcessor):
     """
     A logits processor designed to facilitate the generation and sampling of function calls and their arguments.
+
+    Attributes:
+        tokenizer (PreTrainedTokenizer): A tokenizer compatible with Hugging Face's Transformers library,
+            used for encoding and decoding text.
+        functions (List[Dict], optional): A list of dictionaries representing the available functions
+            and their metadata. Defaults to None.
+        config (Union[ToolCallSamplerConfig, Dict[str, Any]], optional): Configuration for the sampler,
+            either as a ToolCallSamplerConfig object or as a dictionary that can be parsed into one.
+            Defaults to None.
+
+    The class is initialized with a tokenizer for handling text encoding/decoding, a list of function
+    definitions for determining valid function calls and arguments, and a configuration object for
+    fine-tuning the sampling behavior. It extends the `LogitsProcessor` class from Hugging Face's
+    Transformers, enabling it to be integrated into the text generation pipeline to control the
+    likelihood of generating specific tokens based on the current context and predefined constraints.
     """
 
     def __init__(
         self,
         tokenizer: PreTrainedTokenizer,
         functions: List[Dict] = None,
         config: Union[ToolCallSamplerConfig, Dict[str, Any]] = None,
-        **kwargs
+        **kwargs,
     ):
         self.tokenizer = tokenizer
-        self.functions = functions or []
-        self.config = self._parse_config(config, kwargs)
-        self._initialize_tokens()
+        self.functions = functions
+
+        # If config is a dictionary or None, parse it with Pydantic model
+        if isinstance(config, dict) or config is None:
+            config = ToolCallSamplerConfig(**config or {}, **kwargs)
+        elif not isinstance(config, ToolCallSamplerConfig):
+            raise ValueError(
+                "config must be a ToolCallSamplerConfig instance or a dictionary"
+            )
+
+        self.config = config
+
+        self.open_func_token = (
+            self.config.open_func_token if self.config.open_func_token else "<tool_call>"
+        )
+        self.close_func_token = (
+            self.config.open_func_token
+            if self.config.open_func_token
+            else "</tool_call>"
+        )
+        self.generate_close_func_token = (
+            config.generate_close_func_token
+            if config.generate_close_func_token
+            else True
+        )
+        self.open_func_token_length = len(
+            self.tokenizer.encode(self.open_func_token, add_special_tokens=False)
+        )
+
+        logger.debug(self.open_func_token)
+        logger.debug(self.close_func_token)
+
+        self.end_on_function_call = self.config.end_on_function_call
+
         self.vocab_size = len(tokenizer)
-        self.token_masks = self._build_token_masks()
+
+        self.json_tokens = (
+            self.config.json_tokens.model_dump()
+            if self.config.json_tokens
+            else TokenMap.build(tokenizer=tokenizer).model_dump()
+        )
+
+        #
+        # convert json_tokens dict into a dict with values of long tensors, instead of allowed token ids
+        self.token_masks = {}
+        build_masks(
+            tokenizer=self.tokenizer,
+            token_masks=self.token_masks,
+            json_tokens=self.json_tokens,
+            vocab_size=self.vocab_size,
+        )
+
+        # sampling flags and misc
+        self.identified_function = None
+
+        self.last_open_key_quote_index = -1
+
         self.function_maps = tokenize_dicts(self.functions, self.tokenizer)
+
+        # we launch computation of all FSM's at the begining,
+        # if one is needed before it is finished, we block until it is done.
+        # otherwise, it should be ready by the time we need it.
         self.fsm_results = {}
         self.executor = ThreadPoolExecutor()
-        self._compute_all_fsms()
-        self._reset_sampling_state()
-        self._set_sampling_params()
-
-    def _parse_config(self, config, kwargs):
-        if isinstance(config, dict) or config is None:
-            return ToolCallSamplerConfig(**config or {}, **kwargs)
-        elif isinstance(config, ToolCallSamplerConfig):
-            return config
-        else:
-            raise ValueError("config must be a ToolCallSamplerConfig instance or a dictionary")
 
-    def _initialize_tokens(self):
-        config = self.config
-        self.open_func_token = config.open_func_token or "<tool_call>"
-        self.close_func_token = config.close_func_token or "</tool_call>"
-        self.generate_close_func_token = config.generate_close_func_token
-        self.end_on_function_call = config.end_on_function_call
-        self.open_func_token_length = len(self.tokenizer.encode(self.open_func_token, add_special_tokens=False))
-
-    def _build_token_masks(self):
-        json_tokens = self.config.json_tokens.model_dump() if self.config.json_tokens else TokenMap.build(self.tokenizer).model_dump()
-        token_masks = {}
-        build_masks(self.tokenizer, token_masks, json_tokens, self.vocab_size)
-        return token_masks
+        self.fsm_tokenizer = FsmTokenizer(tokenizer)
 
-    def _compute_all_fsms(self):
         for key, function in self.function_maps.items():
-            future = self.executor.submit(compute_fsm, FsmTokenizer(self.tokenizer), function)
-            future.add_done_callback(functools.partial(self._populate_fsm_result, key=key))
+            future = self.executor.submit(compute_fsm, self.fsm_tokenizer, function)
+            future.add_done_callback(
+                functools.partial(self.populate_fsm_result, key=key)
+            )
 
-    def _populate_fsm_result(self, future, key):
-        self.fsm_results[key] = future.result()
-
-    def _reset_sampling_state(self):
         self.next_tokens = []
         self.fsm = None
         self.fsm_state = FSMState(0)
         self.fsm_seq_start_idx = None
         self.function_key = None
         self.generation_finished = False
         self.do_sample = False
         self.last_open_quote_idx = -1
         self.first_fsm_token = False
         self.input_ids_split_idx = None
         self.total_time = 0
 
-    def _set_sampling_params(self):
-        self.temperature = self.config.temperature
-        self.top_p = self.config.top_p
-        self.top_k = self.config.top_k
-        self.repetition_penalty = self.config.repetition_penalty
+        # Sampling params. these are only used when generating values for params / args.
+        # when not generating a value, they are ignored.
+        self.temperature = config.temperature if config.temperature else None
+        self.top_p = config.top_p if config.top_p else None
+        self.top_k = config.top_k if config.top_k else None
+        self.repetition_penalty = (
+            config.repetition_penalty if config.repetition_penalty else None
+        )
+
+    def populate_fsm_result(self, future, key):
+        # Callback function to populate the results dict upon future completion
+        self.fsm_results[key] = future.result()
 
     def __del__(self):
+        # Ensure executor resources are freed when the instance is destroyed
         self.executor.shutdown(wait=False)
 
     def _determine_function(self, start_sequence):
         # Convert the start_sequence list to a tuple for comparison
         start_tuple = tuple(start_sequence)
 
         # Find all key-value pairs where the key starts with start_tuple
@@ -128,18 +165,15 @@
         if matching_items:
             return matching_items
         else:
             # Return None if no matching items are found
             return None
 
     def _wait_for_fsm_result(self, key, timeout=None):
-        """
-        Wait for the FSM result associated with `key` to be populated.
-        really only needed to prevent a key error if somehow the fsm isnt returned yet. 
-        """
+        """Wait for the FSM result associated with `key` to be populated."""
         start_time = time.time()
         while key not in self.fsm_results:
             if timeout and (time.time() - start_time) > timeout:
                 raise TimeoutError(f"Waiting for FSM result for '{key}' timed out.")
             time.sleep(0.1)  # Sleep to prevent busy waiting
         return self.fsm_results[key]
 
@@ -326,8 +360,8 @@
                     top_p=self.top_p,
                     top_k=self.top_k,
                     repetition_penalty=self.repetition_penalty,
                 )
 
             t = time.time() - start_time
             self.total_time += t
-        return scores
+        return scores
```

## Comparing `function_sampler-0.2.dist-info/LICENSE` & `function_sampler-0.2.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `function_sampler-0.2.dist-info/METADATA` & `function_sampler-0.2.1.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: function-sampler
-Version: 0.2
+Version: 0.2.1
 Summary: Function calling Logit Sampler
 Home-page: https://github.com/unaidedelf8777/function-sampler/
 Author: unaidedelf8777
 Author-email: thwackyy.y@gmail.com
 License: Apache 2.0
 Classifier: Programming Language :: Rust
 Classifier: Programming Language :: Python :: Implementation :: CPython
```

## Comparing `function_sampler-0.2.dist-info/RECORD` & `function_sampler-0.2.1.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-function_sampler-0.2.dist-info/WHEEL,sha256=wrtYONpHi43lTKxjsQpGJGOcVNFki6o88Q9sbZk05A0,119
-function_sampler-0.2.dist-info/top_level.txt,sha256=4u0ZhZlyWIkf82yDduaWOFlZColoetxaDpUGHs9Qm2E,17
-function_sampler-0.2.dist-info/LICENSE,sha256=aYSSIb-5AFPeITTvXm1UAoe0uYBiMmSS8flvXaaFUks,10174
-function_sampler-0.2.dist-info/METADATA,sha256=M-xM93ocAGjYWPZBlKV8i58CtWK4XTAIk-JXSgY7NyA,8466
-function_sampler-0.2.dist-info/RECORD,,
 function_sampler/logger.py,sha256=v63E5Ara3ad5ZOfRS0Y9cAJM2iVykgTspeVZkN8JIS0,330
 function_sampler/json.py,sha256=g3_7CCGh3D9LFGygdLC6IW6ey_zsyG8kycbRwEKj7Yw,14621
 function_sampler/cache.py,sha256=MpoSW1iVFpbeOqVWRzRFyjWToXdDSVe8hrCV4209Y_A,1132
 function_sampler/regex_constants.py,sha256=xiE8TyuT7iRY8wJNqRkWS1Z9MSYdnArmy278FcS30ws,2640
-function_sampler/sampler.py,sha256=0Ds2KnAut-Kst74twNbVrwCmKdGE3p54V1lgeQv8apc,12987
+function_sampler/sampler.py,sha256=Lfu8cXDNnsOs_tAQJ_ZEOG8ETa_To-V2LbGMLu0f958,14928
 function_sampler/__init__.py,sha256=B1TRa8VSXv8nErU4nsdJyxJ6Vhp44i0TeEqHeFvVJ1A,454
 function_sampler/utils.py,sha256=GsFHxG2QKBJUXp_XqJv_8NOoSMOpsowwiEGTj9gINxc,5675
 function_sampler/fsm/regex.py,sha256=B0asefLtRava5H-g2lITmRB182fYH5MpQ5fFO2gh8Gc,7297
 function_sampler/fsm/__init__.py,sha256=t2xNMQivbfdRAuK2L2ZHi3Nzyji2smXk7vR0RA6W0zw,298
 function_sampler/fsm/fsm_utils.pypy39-pp73-x86_64-linux-gnu.so,sha256=XeJLc7oB4l3ubz29QCwZ2mxTLMOKgIcH-6440Shysfk,706888
 function_sampler/fsm/utils.py,sha256=fADmZuMoeMb1Q_QsiOzuslBhpYUMXlVplMhlYUIlNLI,658
 function_sampler/fsm/tokenizer_fsm_patch.py,sha256=l52R20KoCjPUYwuFcuKlhSt-V4kyrxqYiacIFA2s2xg,3434
 function_sampler/config/token_mapper.py,sha256=QLdgcb8OfHPnYBGw56SQvZ1TI5dzmTJ9LEQ02d5q94A,3065
 function_sampler/config/__init__.py,sha256=TD4AUdrbJEYfiaClpnZ1_o0iWBaJtd8s7etRumZEwzc,126
 function_sampler/config/config.py,sha256=YkGek6Vu5L4XMSjQxagcgWjr1MNV9IAN34ItU98O-_w,633
 function_sampler/config/utils.py,sha256=HSp7fJ3XxF4NCdZ5dEyuz17vRh_VxvLI--fNQkSxCMM,3825
+function_sampler-0.2.1.dist-info/WHEEL,sha256=wrtYONpHi43lTKxjsQpGJGOcVNFki6o88Q9sbZk05A0,119
+function_sampler-0.2.1.dist-info/top_level.txt,sha256=4u0ZhZlyWIkf82yDduaWOFlZColoetxaDpUGHs9Qm2E,17
+function_sampler-0.2.1.dist-info/LICENSE,sha256=aYSSIb-5AFPeITTvXm1UAoe0uYBiMmSS8flvXaaFUks,10174
+function_sampler-0.2.1.dist-info/METADATA,sha256=fYwyTnhuofF-LLW6oC17a8-ddMuvNCpFTQgXhJK_Kdo,8468
+function_sampler-0.2.1.dist-info/RECORD,,
```

