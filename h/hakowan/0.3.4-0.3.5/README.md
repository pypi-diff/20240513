# Comparing `tmp/hakowan-0.3.4-py3-none-any.whl.zip` & `tmp/hakowan-0.3.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,81 +1,82 @@
-Zip file size: 505031 bytes, number of entries: 79
--rw-r--r--  2.0 unx      546 b- defN 24-May-04 21:01 hakowan/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-04 21:01 hakowan/py.typed
--rw-r--r--  2.0 unx       27 b- defN 24-May-04 21:01 hakowan/common/__init__.py
--rw-r--r--  2.0 unx     1965 b- defN 24-May-04 21:01 hakowan/common/color.py
--rw-r--r--  2.0 unx      265 b- defN 24-May-04 21:01 hakowan/common/default.py
--rw-r--r--  2.0 unx      135 b- defN 24-May-04 21:01 hakowan/common/envmaps.py
--rw-r--r--  2.0 unx      131 b- defN 24-May-04 21:01 hakowan/common/exception.py
--rw-r--r--  2.0 unx      117 b- defN 24-May-04 21:01 hakowan/common/logger.py
--rw-r--r--  2.0 unx     6543 b- defN 24-May-04 21:01 hakowan/common/named_colors.py
--rw-r--r--  2.0 unx      691 b- defN 24-May-04 21:01 hakowan/common/to_color.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-04 21:01 hakowan/common/colormap/__init__.py
--rw-r--r--  2.0 unx     2614 b- defN 24-May-04 21:01 hakowan/common/colormap/colorbrewer2.py
--rw-r--r--  2.0 unx     1235 b- defN 24-May-04 21:01 hakowan/common/colormap/colormap.py
--rw-r--r--  2.0 unx    19025 b- defN 24-May-04 21:01 hakowan/common/colormap/coolwarm.py
--rw-r--r--  2.0 unx    11519 b- defN 24-May-04 21:01 hakowan/common/colormap/inferno.py
--rw-r--r--  2.0 unx    11515 b- defN 24-May-04 21:01 hakowan/common/colormap/magma.py
--rw-r--r--  2.0 unx      575 b- defN 24-May-04 21:01 hakowan/common/colormap/named_colormaps.py
--rw-r--r--  2.0 unx    11517 b- defN 24-May-04 21:01 hakowan/common/colormap/plasma.py
--rw-r--r--  2.0 unx    10794 b- defN 24-May-04 21:01 hakowan/common/colormap/turbo.py
--rw-r--r--  2.0 unx    11519 b- defN 24-May-04 21:01 hakowan/common/colormap/viridis.py
--rw-r--r--  2.0 unx      106 b- defN 24-May-04 21:01 hakowan/compiler/__init__.py
--rw-r--r--  2.0 unx    10577 b- defN 24-May-04 21:01 hakowan/compiler/attribute.py
--rw-r--r--  2.0 unx     8519 b- defN 24-May-04 21:01 hakowan/compiler/channel.py
--rw-r--r--  2.0 unx     4044 b- defN 24-May-04 21:01 hakowan/compiler/color.py
--rw-r--r--  2.0 unx     2548 b- defN 24-May-04 21:01 hakowan/compiler/compile.py
--rw-r--r--  2.0 unx     2054 b- defN 24-May-04 21:01 hakowan/compiler/scene.py
--rw-r--r--  2.0 unx     8690 b- defN 24-May-04 21:01 hakowan/compiler/texture.py
--rw-r--r--  2.0 unx    11628 b- defN 24-May-04 21:01 hakowan/compiler/transform.py
--rw-r--r--  2.0 unx      478 b- defN 24-May-04 21:01 hakowan/compiler/utils.py
--rw-r--r--  2.0 unx    11311 b- defN 24-May-04 21:01 hakowan/compiler/view.py
--rw-r--r--  2.0 unx      292 b- defN 24-May-04 21:01 hakowan/envmaps/README.md
--rw-r--r--  2.0 unx   426040 b- defN 24-May-04 21:01 hakowan/envmaps/museum.exr
--rw-r--r--  2.0 unx        0 b- defN 24-May-04 21:01 hakowan/grammar/__init__.py
--rw-r--r--  2.0 unx      127 b- defN 24-May-04 21:01 hakowan/grammar/channel/__init__.py
--rw-r--r--  2.0 unx     4375 b- defN 24-May-04 21:01 hakowan/grammar/channel/channel.py
--rw-r--r--  2.0 unx      476 b- defN 24-May-04 21:01 hakowan/grammar/channel/curvestyle.py
--rw-r--r--  2.0 unx      250 b- defN 24-May-04 21:01 hakowan/grammar/channel/material/__init__.py
--rw-r--r--  2.0 unx     3766 b- defN 24-May-04 21:01 hakowan/grammar/channel/material/material.py
--rw-r--r--  2.0 unx      366 b- defN 24-May-04 21:01 hakowan/grammar/channel/material/medium.py
--rw-r--r--  2.0 unx       48 b- defN 24-May-04 21:01 hakowan/grammar/dataframe/__init__.py
--rw-r--r--  2.0 unx     1279 b- defN 24-May-04 21:01 hakowan/grammar/dataframe/dataframe.py
--rw-r--r--  2.0 unx       25 b- defN 24-May-04 21:01 hakowan/grammar/layer/__init__.py
--rw-r--r--  2.0 unx    14156 b- defN 24-May-04 21:01 hakowan/grammar/layer/layer.py
--rw-r--r--  2.0 unx      416 b- defN 24-May-04 21:01 hakowan/grammar/layer/layer_spec.py
--rw-r--r--  2.0 unx       46 b- defN 24-May-04 21:01 hakowan/grammar/mark/__init__.py
--rw-r--r--  2.0 unx      375 b- defN 24-May-04 21:01 hakowan/grammar/mark/mark.py
--rw-r--r--  2.0 unx      158 b- defN 24-May-04 21:01 hakowan/grammar/scale/__init__.py
--rw-r--r--  2.0 unx     1301 b- defN 24-May-04 21:01 hakowan/grammar/scale/attribute.py
--rw-r--r--  2.0 unx      285 b- defN 24-May-04 21:01 hakowan/grammar/scale/offset.py
--rw-r--r--  2.0 unx     2887 b- defN 24-May-04 21:01 hakowan/grammar/scale/scale.py
--rw-r--r--  2.0 unx       23 b- defN 24-May-04 21:01 hakowan/grammar/texture/__init__.py
--rw-r--r--  2.0 unx     3328 b- defN 24-May-04 21:01 hakowan/grammar/texture/texture.py
--rw-r--r--  2.0 unx       25 b- defN 24-May-04 21:01 hakowan/grammar/transform/__init__.py
--rw-r--r--  2.0 unx     3737 b- defN 24-May-04 21:01 hakowan/grammar/transform/transform.py
--rw-r--r--  2.0 unx      361 b- defN 24-May-04 21:01 hakowan/render/__init__.py
--rw-r--r--  2.0 unx    10517 b- defN 24-May-04 21:01 hakowan/render/bsdf.py
--rw-r--r--  2.0 unx      200 b- defN 24-May-04 21:01 hakowan/render/color.py
--rw-r--r--  2.0 unx     1344 b- defN 24-May-04 21:01 hakowan/render/emitter.py
--rw-r--r--  2.0 unx      623 b- defN 24-May-04 21:01 hakowan/render/film.py
--rw-r--r--  2.0 unx     3095 b- defN 24-May-04 21:01 hakowan/render/icosphere.py
--rw-r--r--  2.0 unx     1798 b- defN 24-May-04 21:01 hakowan/render/integrator.py
--rw-r--r--  2.0 unx      950 b- defN 24-May-04 21:01 hakowan/render/medium.py
--rw-r--r--  2.0 unx     4023 b- defN 24-May-04 21:01 hakowan/render/render.py
--rw-r--r--  2.0 unx      587 b- defN 24-May-04 21:01 hakowan/render/sampler.py
--rw-r--r--  2.0 unx     1057 b- defN 24-May-04 21:01 hakowan/render/sensor.py
--rw-r--r--  2.0 unx    17387 b- defN 24-May-04 21:01 hakowan/render/shape.py
--rw-r--r--  2.0 unx      593 b- defN 24-May-04 21:01 hakowan/render/spectrum.py
--rw-r--r--  2.0 unx     4731 b- defN 24-May-04 21:01 hakowan/render/texture.py
--rw-r--r--  2.0 unx      137 b- defN 24-May-04 21:01 hakowan/setup/__init__.py
--rw-r--r--  2.0 unx     3410 b- defN 24-May-04 21:01 hakowan/setup/config.py
--rw-r--r--  2.0 unx     1096 b- defN 24-May-04 21:01 hakowan/setup/emitter.py
--rw-r--r--  2.0 unx     1144 b- defN 24-May-04 21:01 hakowan/setup/film.py
--rw-r--r--  2.0 unx     3123 b- defN 24-May-04 21:01 hakowan/setup/integrator.py
--rw-r--r--  2.0 unx     1009 b- defN 24-May-04 21:01 hakowan/setup/sampler.py
--rw-r--r--  2.0 unx     1441 b- defN 24-May-04 21:01 hakowan/setup/sensor.py
--rw-r--r--  2.0 unx    11335 b- defN 24-May-04 21:01 hakowan-0.3.4.dist-info/LICENSE
--rw-r--r--  2.0 unx       81 b- defN 16-Jan-01 00:00 hakowan-0.3.4.dist-info/WHEEL
--rw-r--r--  2.0 unx     1266 b- defN 16-Jan-01 00:00 hakowan-0.3.4.dist-info/METADATA
--rw-r--r--  2.0 unx     6726 b- defN 16-Jan-01 00:00 hakowan-0.3.4.dist-info/RECORD
-79 files, 692503 bytes uncompressed, 494385 bytes compressed:  28.6%
+Zip file size: 506729 bytes, number of entries: 80
+-rw-r--r--  2.0 unx      546 b- defN 24-May-13 02:09 hakowan/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-13 02:09 hakowan/py.typed
+-rw-r--r--  2.0 unx       27 b- defN 24-May-13 02:09 hakowan/common/__init__.py
+-rw-r--r--  2.0 unx     1965 b- defN 24-May-13 02:09 hakowan/common/color.py
+-rw-r--r--  2.0 unx      265 b- defN 24-May-13 02:09 hakowan/common/default.py
+-rw-r--r--  2.0 unx      135 b- defN 24-May-13 02:09 hakowan/common/envmaps.py
+-rw-r--r--  2.0 unx      131 b- defN 24-May-13 02:09 hakowan/common/exception.py
+-rw-r--r--  2.0 unx      117 b- defN 24-May-13 02:09 hakowan/common/logger.py
+-rw-r--r--  2.0 unx     6543 b- defN 24-May-13 02:09 hakowan/common/named_colors.py
+-rw-r--r--  2.0 unx      691 b- defN 24-May-13 02:09 hakowan/common/to_color.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-13 02:09 hakowan/common/colormap/__init__.py
+-rw-r--r--  2.0 unx     2614 b- defN 24-May-13 02:09 hakowan/common/colormap/colorbrewer2.py
+-rw-r--r--  2.0 unx     1235 b- defN 24-May-13 02:09 hakowan/common/colormap/colormap.py
+-rw-r--r--  2.0 unx    19025 b- defN 24-May-13 02:09 hakowan/common/colormap/coolwarm.py
+-rw-r--r--  2.0 unx    11519 b- defN 24-May-13 02:09 hakowan/common/colormap/inferno.py
+-rw-r--r--  2.0 unx    11515 b- defN 24-May-13 02:09 hakowan/common/colormap/magma.py
+-rw-r--r--  2.0 unx      575 b- defN 24-May-13 02:09 hakowan/common/colormap/named_colormaps.py
+-rw-r--r--  2.0 unx    11517 b- defN 24-May-13 02:09 hakowan/common/colormap/plasma.py
+-rw-r--r--  2.0 unx    10794 b- defN 24-May-13 02:09 hakowan/common/colormap/turbo.py
+-rw-r--r--  2.0 unx    11519 b- defN 24-May-13 02:09 hakowan/common/colormap/viridis.py
+-rw-r--r--  2.0 unx      106 b- defN 24-May-13 02:09 hakowan/compiler/__init__.py
+-rw-r--r--  2.0 unx    10577 b- defN 24-May-13 02:09 hakowan/compiler/attribute.py
+-rw-r--r--  2.0 unx     9276 b- defN 24-May-13 02:09 hakowan/compiler/channel.py
+-rw-r--r--  2.0 unx     4044 b- defN 24-May-13 02:09 hakowan/compiler/color.py
+-rw-r--r--  2.0 unx     2548 b- defN 24-May-13 02:09 hakowan/compiler/compile.py
+-rw-r--r--  2.0 unx     2054 b- defN 24-May-13 02:09 hakowan/compiler/scene.py
+-rw-r--r--  2.0 unx     8690 b- defN 24-May-13 02:09 hakowan/compiler/texture.py
+-rw-r--r--  2.0 unx    12585 b- defN 24-May-13 02:09 hakowan/compiler/transform.py
+-rw-r--r--  2.0 unx      478 b- defN 24-May-13 02:09 hakowan/compiler/utils.py
+-rw-r--r--  2.0 unx    11665 b- defN 24-May-13 02:09 hakowan/compiler/view.py
+-rw-r--r--  2.0 unx      292 b- defN 24-May-13 02:09 hakowan/envmaps/README.md
+-rw-r--r--  2.0 unx   426040 b- defN 24-May-13 02:09 hakowan/envmaps/museum.exr
+-rw-r--r--  2.0 unx        0 b- defN 24-May-13 02:09 hakowan/grammar/__init__.py
+-rw-r--r--  2.0 unx      175 b- defN 24-May-13 02:09 hakowan/grammar/channel/__init__.py
+-rw-r--r--  2.0 unx     4859 b- defN 24-May-13 02:09 hakowan/grammar/channel/channel.py
+-rw-r--r--  2.0 unx      476 b- defN 24-May-13 02:09 hakowan/grammar/channel/curvestyle.py
+-rw-r--r--  2.0 unx      250 b- defN 24-May-13 02:09 hakowan/grammar/channel/material/__init__.py
+-rw-r--r--  2.0 unx     3766 b- defN 24-May-13 02:09 hakowan/grammar/channel/material/material.py
+-rw-r--r--  2.0 unx      366 b- defN 24-May-13 02:09 hakowan/grammar/channel/material/medium.py
+-rw-r--r--  2.0 unx       48 b- defN 24-May-13 02:09 hakowan/grammar/dataframe/__init__.py
+-rw-r--r--  2.0 unx     1279 b- defN 24-May-13 02:09 hakowan/grammar/dataframe/dataframe.py
+-rw-r--r--  2.0 unx       25 b- defN 24-May-13 02:09 hakowan/grammar/layer/__init__.py
+-rw-r--r--  2.0 unx    14537 b- defN 24-May-13 02:09 hakowan/grammar/layer/layer.py
+-rw-r--r--  2.0 unx      416 b- defN 24-May-13 02:09 hakowan/grammar/layer/layer_spec.py
+-rw-r--r--  2.0 unx       46 b- defN 24-May-13 02:09 hakowan/grammar/mark/__init__.py
+-rw-r--r--  2.0 unx      375 b- defN 24-May-13 02:09 hakowan/grammar/mark/mark.py
+-rw-r--r--  2.0 unx      158 b- defN 24-May-13 02:09 hakowan/grammar/scale/__init__.py
+-rw-r--r--  2.0 unx     1301 b- defN 24-May-13 02:09 hakowan/grammar/scale/attribute.py
+-rw-r--r--  2.0 unx      285 b- defN 24-May-13 02:09 hakowan/grammar/scale/offset.py
+-rw-r--r--  2.0 unx     2887 b- defN 24-May-13 02:09 hakowan/grammar/scale/scale.py
+-rw-r--r--  2.0 unx       23 b- defN 24-May-13 02:09 hakowan/grammar/texture/__init__.py
+-rw-r--r--  2.0 unx     3328 b- defN 24-May-13 02:09 hakowan/grammar/texture/texture.py
+-rw-r--r--  2.0 unx       25 b- defN 24-May-13 02:09 hakowan/grammar/transform/__init__.py
+-rw-r--r--  2.0 unx     4089 b- defN 24-May-13 02:09 hakowan/grammar/transform/transform.py
+-rw-r--r--  2.0 unx      361 b- defN 24-May-13 02:09 hakowan/render/__init__.py
+-rw-r--r--  2.0 unx     3851 b- defN 24-May-13 02:09 hakowan/render/base_shapes.py
+-rw-r--r--  2.0 unx    10517 b- defN 24-May-13 02:09 hakowan/render/bsdf.py
+-rw-r--r--  2.0 unx      200 b- defN 24-May-13 02:09 hakowan/render/color.py
+-rw-r--r--  2.0 unx     1167 b- defN 24-May-13 02:09 hakowan/render/emitter.py
+-rw-r--r--  2.0 unx      623 b- defN 24-May-13 02:09 hakowan/render/film.py
+-rw-r--r--  2.0 unx     1798 b- defN 24-May-13 02:09 hakowan/render/integrator.py
+-rw-r--r--  2.0 unx      950 b- defN 24-May-13 02:09 hakowan/render/medium.py
+-rw-r--r--  2.0 unx     4023 b- defN 24-May-13 02:09 hakowan/render/render.py
+-rw-r--r--  2.0 unx      587 b- defN 24-May-13 02:09 hakowan/render/sampler.py
+-rw-r--r--  2.0 unx     1057 b- defN 24-May-13 02:09 hakowan/render/sensor.py
+-rw-r--r--  2.0 unx    20521 b- defN 24-May-13 02:09 hakowan/render/shape.py
+-rw-r--r--  2.0 unx      593 b- defN 24-May-13 02:09 hakowan/render/spectrum.py
+-rw-r--r--  2.0 unx     4731 b- defN 24-May-13 02:09 hakowan/render/texture.py
+-rw-r--r--  2.0 unx      549 b- defN 24-May-13 02:09 hakowan/render/utils.py
+-rw-r--r--  2.0 unx      137 b- defN 24-May-13 02:09 hakowan/setup/__init__.py
+-rw-r--r--  2.0 unx     3410 b- defN 24-May-13 02:09 hakowan/setup/config.py
+-rw-r--r--  2.0 unx     1096 b- defN 24-May-13 02:09 hakowan/setup/emitter.py
+-rw-r--r--  2.0 unx     1144 b- defN 24-May-13 02:09 hakowan/setup/film.py
+-rw-r--r--  2.0 unx     3123 b- defN 24-May-13 02:09 hakowan/setup/integrator.py
+-rw-r--r--  2.0 unx     1009 b- defN 24-May-13 02:09 hakowan/setup/sampler.py
+-rw-r--r--  2.0 unx     1441 b- defN 24-May-13 02:09 hakowan/setup/sensor.py
+-rw-r--r--  2.0 unx    11335 b- defN 24-May-13 02:09 hakowan-0.3.5.dist-info/LICENSE
+-rw-r--r--  2.0 unx       81 b- defN 16-Jan-01 00:00 hakowan-0.3.5.dist-info/WHEEL
+-rw-r--r--  2.0 unx     1266 b- defN 16-Jan-01 00:00 hakowan-0.3.5.dist-info/METADATA
+-rw-r--r--  2.0 unx     6807 b- defN 16-Jan-01 00:00 hakowan-0.3.5.dist-info/RECORD
+80 files, 700179 bytes uncompressed, 495957 bytes compressed:  29.2%
```

## zipnote {}

```diff
@@ -159,29 +159,29 @@
 
 Filename: hakowan/grammar/transform/transform.py
 Comment: 
 
 Filename: hakowan/render/__init__.py
 Comment: 
 
+Filename: hakowan/render/base_shapes.py
+Comment: 
+
 Filename: hakowan/render/bsdf.py
 Comment: 
 
 Filename: hakowan/render/color.py
 Comment: 
 
 Filename: hakowan/render/emitter.py
 Comment: 
 
 Filename: hakowan/render/film.py
 Comment: 
 
-Filename: hakowan/render/icosphere.py
-Comment: 
-
 Filename: hakowan/render/integrator.py
 Comment: 
 
 Filename: hakowan/render/medium.py
 Comment: 
 
 Filename: hakowan/render/render.py
@@ -198,14 +198,17 @@
 
 Filename: hakowan/render/spectrum.py
 Comment: 
 
 Filename: hakowan/render/texture.py
 Comment: 
 
+Filename: hakowan/render/utils.py
+Comment: 
+
 Filename: hakowan/setup/__init__.py
 Comment: 
 
 Filename: hakowan/setup/config.py
 Comment: 
 
 Filename: hakowan/setup/emitter.py
@@ -219,20 +222,20 @@
 
 Filename: hakowan/setup/sampler.py
 Comment: 
 
 Filename: hakowan/setup/sensor.py
 Comment: 
 
-Filename: hakowan-0.3.4.dist-info/LICENSE
+Filename: hakowan-0.3.5.dist-info/LICENSE
 Comment: 
 
-Filename: hakowan-0.3.4.dist-info/WHEEL
+Filename: hakowan-0.3.5.dist-info/WHEEL
 Comment: 
 
-Filename: hakowan-0.3.4.dist-info/METADATA
+Filename: hakowan-0.3.5.dist-info/METADATA
 Comment: 
 
-Filename: hakowan-0.3.4.dist-info/RECORD
+Filename: hakowan-0.3.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## hakowan/__init__.py

```diff
@@ -1,10 +1,10 @@
 """ Hakowan: A 3D data visualization grammer """
 
-__version__ = "0.3.4"
+__version__ = "0.3.5"
 
 from .common import logger
 from .setup import Config as config
 from .grammar import dataframe, mark, channel, scale, texture, transform
 from .grammar.layer import Layer as layer
 from .grammar.scale import Attribute as attribute
 from .grammar.channel import material
```

## hakowan/compiler/channel.py

```diff
@@ -8,14 +8,15 @@
 from ..grammar.channel import (
     BumpMap,
     Channel,
     Covariance,
     Normal,
     NormalMap,
     Position,
+    Shape,
     Size,
     VectorField,
 )
 from ..grammar.channel.material import (
     Conductor,
     Dielectric,
     Diffuse,
@@ -46,25 +47,27 @@
 def preprocess_channels(view: View):
     """Preprocess channels in a view.
 
     Determine the active position, normal, size, uv and material channels. Among these, position,
     normal and uv channels can be automatically generate from data frame if not specified. Size and
     material will be set to default if not specified.
 
-    :param view: The view to be pre-processed. Update will be made in place.
+    Args:
+        view (View): The view to be pre-processed. Update will be made in place.
     """
     _preprocess_channels(view)
 
 
 def process_channels(view: View):
     """Process the channels in a view.
 
     This step applies scales and textures on the corresponding data.
 
-    :param view: The view to be processed. Update will be made in place.
+    Args:
+        view (View): The view to be processed. Update will be made in place.
     """
     _process_channels(view)
 
 
 ### Private API
 
 
@@ -83,14 +86,17 @@
                     view.size_channel = channel
             case VectorField():
                 if view.vector_field_channel is None:
                     view.vector_field_channel = channel
             case Covariance():
                 if view.covariance_channel is None:
                     view.covariance_channel = channel
+            case Shape():
+                if view.shape_channel is None:
+                    view.shape_channel = channel
             case Material():
                 if view.material_channel is None:
                     view.material_channel = channel
             case BumpMap():
                 if view.bump_map is None:
                     view.bump_map = channel
             case NormalMap():
@@ -143,14 +149,24 @@
                 view._active_attributes.append(style.direction)
     if view.covariance_channel is not None:
         assert isinstance(view.covariance_channel, Covariance)
         assert isinstance(view.covariance_channel.data, Attribute)
         attr = view.covariance_channel.data
         compute_scaled_attribute(df, attr)
         view._active_attributes.append(attr)
+    if view.shape_channel is not None:
+        assert isinstance(view.shape_channel, Shape)
+        assert view.shape_channel.base_shape in ["sphere", "cube", "disk"]
+        if view.shape_channel.orientation is not None:
+            if isinstance(view.shape_channel.orientation, str):
+                view.shape_channel.orientation = Attribute(view.shape_channel.orientation)
+            assert isinstance(view.shape_channel.orientation, Attribute)
+            attr = view.shape_channel.orientation
+            compute_scaled_attribute(df, attr)
+            view._active_attributes.append(attr)
     if view.bump_map is not None:
         tex = view.bump_map.texture
         assert tex is not None
         if isinstance(tex, Texture):
             view._active_attributes += apply_texture(df, tex, view.uv_attribute)
             view.uv_attribute = tex._uv
     if view.normal_map is not None:
```

## hakowan/compiler/transform.py

```diff
@@ -1,19 +1,20 @@
 from .view import View
 from ..grammar.mark import Mark
 from ..grammar.dataframe import DataFrame
 from ..grammar.scale import Attribute
 from ..grammar.transform import (
-    Transform,
-    Filter,
-    UVMesh,
     Affine,
+    Boundary,
     Compute,
     Explode,
+    Filter,
     Norm,
+    Transform,
+    UVMesh,
 )
 from ..common import logger
 
 import copy
 import lagrange
 import numpy as np
 
@@ -272,14 +273,41 @@
             transform.norm_attr_name,
             element=input_attr.element_type,
             usage=input_attr.usage,
             initial_values=norm_data,
         )
 
 
+def _apply_boundary_transform(view: View, transform: Boundary):
+    df = view.data_frame
+    assert df is not None
+    assert transform is not None
+    mesh = df.mesh
+
+    unified_mesh = lagrange.unify_index_buffer(
+        mesh, attribute_names=transform.attributes
+    )
+    unified_mesh.initialize_edges()
+
+    is_boundary = np.array(
+        [unified_mesh.is_boundary_edge(e) for e in range(unified_mesh.num_edges)]
+    )
+    bd_edge_indices = np.arange(unified_mesh.num_edges)[is_boundary == 1]
+    bd_edges = np.array(
+        [unified_mesh.get_edge_vertices(ei) for ei in bd_edge_indices], dtype=np.uint32
+    )
+
+    bd_mesh = lagrange.SurfaceMesh()
+    bd_mesh.add_vertices(unified_mesh.vertices)
+    bd_mesh.add_polygons(bd_edges)
+    lagrange.remove_isolated_vertices(bd_mesh)
+
+    df.mesh = bd_mesh
+
+
 def apply_transform(view: View):
     """Apply a chain of transforms specified by view.transform to view.data_frame.
     Transforms are applied in the order specified by the chain.
     """
 
     def _apply(t: Transform | None):
         if t is None:
@@ -301,11 +329,14 @@
                 _apply_compute_transform(view, t)
             case Explode():
                 assert view.data_frame is not None
                 _apply_explode_transform(view, t)
             case Norm():
                 assert view.data_frame is not None
                 _apply_norm_transform(view, t)
+            case Boundary():
+                assert view.data_frame is not None
+                _apply_boundary_transform(view, t)
             case _:
                 raise NotImplementedError(f"Unsupported transform: {type(t)}!")
 
     _apply(view.transform)
```

## hakowan/compiler/view.py

```diff
@@ -1,16 +1,17 @@
 from ..grammar.channel import (
+    BumpMap,
     Channel,
-    Position,
+    Covariance,
     Normal,
+    NormalMap,
+    Position,
+    Shape,
     Size,
     VectorField,
-    Covariance,
-    BumpMap,
-    NormalMap,
 )
 from ..grammar.channel.material import Material
 from ..grammar.dataframe import DataFrame
 from ..grammar.mark import Mark
 from ..grammar.scale import Attribute
 from ..grammar.transform import Transform
 from ..common import logger
@@ -30,27 +31,28 @@
     global_transform: npt.NDArray = field(default_factory=lambda: np.eye(4))
 
     _position_channel: Position | None = None
     _normal_channel: Normal | None = None
     _size_channel: Size | None = None
     _vector_field_channel: VectorField | None = None
     _covariance_channel: Covariance | None = None
+    _shape_channel: Shape | None = None
     _material_channel: Material | None = None
     _uv_attribute: Attribute | None = None
     _bump_map: BumpMap | None = None
     _normal_map: NormalMap | None = None
 
     _active_attributes: list[Attribute] = field(default_factory=list)
     _bbox: npt.NDArray | None = None
 
     def initialize_bbox(self):
         assert self.data_frame is not None
         if self.data_frame.roi_box is not None:
-            # df.roi_box remains the same in object reference frame.
-            transformed_roi_box = np.array(df.roi_box, dtype=np.float64)
+            # self.data_frame.roi_box remains the same in object reference frame.
+            transformed_roi_box = np.array(self.data_frame.roi_box, dtype=np.float64)
             assert transformed_roi_box.shape == (2, 3)
             roi_min = transformed_roi_box[0]
             roi_max = transformed_roi_box[1]
             roi_corner = np.array(
                 [
                     [roi_min[0], roi_min[1], roi_min[2], 1],
                     [roi_min[0], roi_min[1], roi_max[2], 1],
@@ -72,15 +74,17 @@
             )
         else:
             mesh = self.data_frame.mesh
             if mesh.num_vertices == 0:
                 return
 
             vertices = mesh.vertices
-            vertices = (self.global_transform[:3, :3] @ vertices.T).T + self.global_transform[:3, 3].T
+            vertices = (
+                self.global_transform[:3, :3] @ vertices.T
+            ).T + self.global_transform[:3, 3].T
             bbox_min = np.amin(vertices, axis=0)
             bbox_max = np.amax(vertices, axis=0)
             self.bbox = np.stack([bbox_min, bbox_max])
 
     def validate(self):
         """Validate the currvent view is complete.
         A view is complete if data_frame and mark are both not None
@@ -263,14 +267,23 @@
         assert isinstance(channel, Covariance)
         if isinstance(channel.data, str):
             channel.data = Attribute(name=channel.data)
         assert isinstance(channel.data, Attribute)
         self._covariance_channel = channel
 
     @property
+    def shape_channel(self) -> Shape | None:
+        return self._shape_channel
+
+    @shape_channel.setter
+    def shape_channel(self, channel: Shape):
+        assert isinstance(channel, Shape)
+        self._shape_channel = channel
+
+    @property
     def material_channel(self) -> Material | None:
         return self._material_channel
 
     @material_channel.setter
     def material_channel(self, channel: Material):
         assert isinstance(channel, Material)
         self._material_channel = channel
```

## hakowan/grammar/channel/__init__.py

```diff
@@ -1,2 +1,12 @@
-from .channel import Channel, Position, Normal, Size, VectorField, Covariance, BumpMap, NormalMap
+from .channel import (
+    BumpMap,
+    Channel,
+    Covariance,
+    Normal,
+    NormalMap,
+    Position,
+    Shape,
+    Size,
+    VectorField,
+)
 from .material import Medium
```

## hakowan/grammar/channel/channel.py

```diff
@@ -84,32 +84,48 @@
     refinement_level: int = 0
     style: CurveStyle | None = None
     end_type: str = "point"
 
 
 @dataclass(slots=True)
 class Covariance(Channel):
-    """ Covariance channel
+    """Covariance channel
 
     This class is used to specify the mapping from an attribute to the covariance matrix channel.
     The covariance channel only applies to point mark. It is represented as a per-vertex 3x3
     symmetric matrix, which defines the stretch and rotation of the point marks.
 
     Attributes:
         data (AttributeLike): The attribute used to encode the covariance matrix.
         full: (bool): If True, the full covariance matrix is stored in the attribute.
             If False, its "square root", M, is stored. The full covariance matrix is âˆ‘ := M @ M^T.
             The matrix M represenst the stretch and rotation transform applied on each mark.
-        base_shape (str): The base shape of the covariance matrix. Options include "sphere" and
-            "cube". The default value is "sphere".
     """
 
     data: AttributeLike
     full: bool = False
+
+
+@dataclass(slots=True)
+class Shape(Channel):
+    """Shape channel
+
+    This class is used to specify the mapping from an attribute to the shape channel.
+    This channel is only used for point mark.
+
+    Attributes:
+        base_shape (str): The base shape used to represent a point.
+            Options include "sphere", "disk" and "cube".
+            The default value is "sphere".
+        orientation (AttributeLike | None): The attribute used to encode the normal orientation
+            of the shape. If None, orientation will be identity (i.e. normal along z-axis).
+    """
+
     base_shape: str = "sphere"
+    orientation: Optional[AttributeLike] = None
 
 
 @dataclass(slots=True)
 class BumpMap(Channel):
     """Bump map channel
 
     This class specifies the bump map channel.
@@ -118,14 +134,15 @@
         texture (TextureLike | None): The texture used to encode the bump map.
         scale (float): The scale of the bump map. The default value is 1.0.
     """
 
     texture: TextureLike
     scale: float = 1.0
 
+
 @dataclass(slots=True)
 class NormalMap(Channel):
     """Normal map channel
 
     This class specifies the normal map channel.
 
     Attributes:
```

## hakowan/grammar/layer/layer.py

```diff
@@ -1,33 +1,34 @@
 from .layer_spec import LayerSpec
 from ..dataframe import DataFrame, DataFrameLike
 from ..mark import Mark
 from ..channel import (
+    BumpMap,
     Channel,
-    Position,
+    Covariance,
     Normal,
+    NormalMap,
+    Position,
+    Shape,
     Size,
     VectorField,
-    Covariance,
-    BumpMap,
-    NormalMap,
 )
 from ..channel.material import (
-    Material,
-    Diffuse,
     Conductor,
-    RoughConductor,
+    Dielectric,
+    Diffuse,
+    Hair,
+    Material,
     Plastic,
-    RoughPlastic,
     Principled,
-    ThinPrincipled,
-    Dielectric,
-    ThinDielectric,
+    RoughConductor,
     RoughDielectric,
-    Hair,
+    RoughPlastic,
+    ThinDielectric,
+    ThinPrincipled,
 )
 from ..transform import Transform, Affine
 from ..scale import Attribute
 from ..texture import TextureLike
 
 from dataclasses import dataclass, field
 from pathlib import Path
@@ -161,14 +162,15 @@
 
     def channel(
         self,
         *,
         position: Position | str | None = None,
         normal: Normal | str | None = None,
         size: float | str | Size | None = None,
+        shape: str | Shape | None = None,
         vector_field: VectorField | str | None = None,
         covariance: Covariance | str | None = None,
         material: Material | None = None,
         bump_map: BumpMap | TextureLike | None = None,
         normal_map: NormalMap | TextureLike | None = None,
         in_place: bool = False,
     ) -> "Layer":
@@ -209,14 +211,22 @@
             if isinstance(size, (int, float)):
                 l._spec.channels.append(Size(data=float(size)))
             else:
                 assert isinstance(
                     size, (Size, str)
                 ), f"Unsupported size type: {type(size)}!"
                 l._spec.channels.append(convert(size, Size))
+        if shape is not None:
+            if isinstance(shape, str):
+                l._spec.channels.append(Shape(base_shape=shape))
+            else:
+                assert isinstance(
+                    shape, Shape
+                ), f"Unsupported shape type: {type(shape)}!"
+                l._spec.channels.append(shape)
         if vector_field is not None:
             assert isinstance(
                 vector_field, (VectorField, str)
             ), f"Unsupported vector_field type: {type(vector_field)}!"
             l._spec.channels.append(convert(vector_field, VectorField))
         if covariance is not None:
             assert isinstance(
```

## hakowan/grammar/transform/transform.py

```diff
@@ -1,8 +1,8 @@
-from dataclasses import dataclass
+from dataclasses import dataclass, field
 from typing import Callable, Optional
 import copy
 import numpy.typing as npt
 
 from ..scale import Attribute, AttributeLike
 
 
@@ -124,7 +124,18 @@
         norm_attr_name: The name of the output norm attribute.
         order: The order of the norm. Default is 2, which is the L2 norm.
     """
 
     data: AttributeLike
     norm_attr_name: str
     order: int = 2
+
+
+@dataclass(slots=True)
+class Boundary(Transform):
+    """ Compute the boundary of a mesh.
+
+    Attributes:
+        attributes: The attributes to take into account when computing the boundary.
+            i.e. discontinuities in these attributes will be considered as boundaries.
+    """
+    attributes: list[str] = field(default_factory=list)
```

## hakowan/render/emitter.py

```diff
@@ -1,39 +1,34 @@
 from ..setup.emitter import Emitter, Point, Envmap
 from .spectrum import generate_spectrum_config
+from .utils import rotation
 
 from typing import Any
 import numpy.typing as npt
 import numpy as np
 import mitsuba as mi
 
 
-def rotation(from_vector: npt.NDArray, to_vector: npt.NDArray):
-    axis = np.cross(from_vector, to_vector)
-    angle = np.degrees(np.arccos(np.dot(from_vector, to_vector)))
-    return mi.ScalarTransform4f.rotate(axis, angle)  # type: ignore
-
-
 def generate_emitter_config(emitter: Emitter) -> dict:
     """Generate a Mitsuba emitter description dict from a Emitter."""
 
     mi_config: dict[str, Any] = {}
 
     match emitter:
         case Point():
             mi_config["type"] = "point"
             mi_config["position"] = list(emitter.position)
             mi_config["intensity"] = generate_spectrum_config(emitter.intensity)
         case Envmap():
             mi_config["type"] = "envmap"
             mi_config["filename"] = str(emitter.filename)
             mi_config["scale"] = emitter.scale
-            mi_config["to_world"] = rotation(
-                np.array([0, 1, 0]), np.array(emitter.up)
-            ) @ mi.ScalarTransform4f.rotate( # type: ignore
+            mi_config["to_world"] = mi.ScalarTransform4f(  # type: ignore
+                rotation(np.array([0, 1, 0]), np.array(emitter.up))
+            ) @ mi.ScalarTransform4f.rotate(  # type: ignore
                 [0, 1, 0],
                 emitter.rotation,
             )
         case _:
             raise NotImplementedError(f"Unknown emitter type: {type(emitter)}")
 
     return mi_config
```

## hakowan/render/shape.py

```diff
@@ -1,15 +1,16 @@
 from .bsdf import generate_bsdf_config
-from .icosphere import create_icosphere
+from .base_shapes import create_icosphere, create_disk
 from .medium import generate_medium_config
 from ..common import logger
 from ..compiler import View
 from ..grammar.scale import Attribute
 from ..grammar.channel.curvestyle import Bend
 from ..grammar.channel.material import Dielectric
+from .utils import rotation
 
 from typing import Any
 import copy
 import lagrange
 import mitsuba as mi
 import numpy as np
 import numpy.typing as npt
@@ -17,19 +18,20 @@
 import re
 import tempfile
 
 
 def extract_size(view: View, default_size=0.01):
     """Extract the size attribute from a view.
 
-    :param view: The view to extract size from.
-    :param n: The cardinality of size attribute.
-    :param default_size: The default size if size attribute is not specified.
+    Args:
+        view: The view to extract size from.
+        default_size: The default size if size attribute is not specified.
 
-    :return: A list of size values of length n.
+    Returns:
+        A list of size values of length n.
     """
     assert view.data_frame is not None
     mesh = view.data_frame.mesh
 
     if view.size_channel is not None:
         match view.size_channel.data:
             case float():
@@ -46,18 +48,19 @@
     else:
         return default_size
 
 
 def extract_transform_from_covariances(view: View):
     """Extract the affine transform from covariance attribute from a view.
 
-    :param view: The view to extract covariance from.
+    Args:
+        view: The view to extract covariance from.
 
-    :return: A list of n 3x3 affine transform matrices, M,
-        where the covariance matrix is M @ M^T.
+    Returns:
+        A list of n 3x3 affine transform matrices, M, where the covariance matrix is M @ M^T.
     """
     assert view.data_frame is not None
     mesh = view.data_frame.mesh
 
     assert view.covariance_channel is not None
     assert isinstance(view.covariance_channel.data, Attribute)
     attr_name = view.covariance_channel.data._internal_name
@@ -73,43 +76,115 @@
         S_diag = np.apply_along_axis(lambda _s: np.diag(_s), 1, S)
         return U @ np.sqrt(S_diag)
     else:
         return attr.data.reshape(-1, 3, 3)
 
 
 def generate_point_config(view: View, stamp: str, index: int):
-    """Generate point cloud shapes from a View."""
+    """Generate point cloud shapes from a View.
+
+    Args:
+        view: The view to generate point cloud shapes from.
+        stamp: The time stamp string used for creating a unique filename.
+        index: The index of the view.
+
+    Returns:
+        The mitsuba config for the point cloud shapes.
+    """
     assert view.data_frame is not None
     mesh = view.data_frame.mesh
     shapes: list[dict[str, Any]] = []
     shape_group: dict[str, Any] = {}
 
+    # Extract shape
+    base_shape = "sphere"
+    if view.shape_channel is not None:
+        base_shape = view.shape_channel.base_shape
+
     if view.covariance_channel is None:
         # Compute radii
         radii = extract_size(view)
         if np.isscalar(radii):
             radii = [radii] * mesh.num_vertices
         assert len(radii) == mesh.num_vertices
 
         # Generate spheres.
         global_transform = mi.ScalarTransform4f(view.global_transform)  # type: ignore
-        shapes = list(
-            map(
-                lambda itr: {
-                    "type": "sphere",
-                    "center": itr[1].tolist(),
-                    "radius": radii[itr[0]],
-                    "to_world": global_transform,
-                },
-                enumerate(mesh.vertices),
-            )
-        )
-    else:
+        match base_shape:
+            case "sphere":
+                # Ignore normal as sphere is invariant under rotation.
+                shapes = list(
+                    map(
+                        lambda itr: {
+                            "type": "sphere",
+                            "center": itr[1].tolist(),
+                            "radius": radii[itr[0]],
+                            "to_world": global_transform,
+                        },
+                        enumerate(mesh.vertices),
+                    )
+                )
+            case "cube" | "disk":
+                local_transforms = [
+                    np.array(
+                        [
+                            [radii[i], 0, 0, mesh.vertices[i][0]],
+                            [0, radii[i], 0, mesh.vertices[i][1]],
+                            [0, 0, radii[i], mesh.vertices[i][2]],
+                            [0, 0, 0, 1],
+                        ]
+                    )
+                    for i in range(mesh.num_vertices)
+                ]
+
+                # Apply normal rotation if necessary
+                if (
+                    view.shape_channel is not None
+                    and view.shape_channel.orientation is not None
+                ):
+                    assert isinstance(view.shape_channel.orientation, Attribute)
+                    normal_attr_name = view.shape_channel.orientation._internal_name
+                    assert normal_attr_name is not None
+                    assert mesh.has_attribute(normal_attr_name)
+
+                    z = np.array([0, 0, 1])
+                    normals = mesh.attribute(normal_attr_name).data  # type: ignore
+
+                    for i, m in enumerate(local_transforms):
+                        m[:, :] = m @ rotation(z, normals[i])
+
+                if base_shape == "cube":
+                    # Generate cubes.
+                    shapes = list(
+                        map(
+                            lambda itr: {
+                                "type": "cube",
+                                "to_world": global_transform @ local_transforms[itr[0]],
+                            },
+                            enumerate(mesh.vertices),
+                        )
+                    )
+                elif base_shape == "disk":
+                    disk = create_disk(16)
+                    tmp_dir = pathlib.Path(tempfile.gettempdir())
+                    filename = tmp_dir / f"{stamp}-view-{index:03}.ply"
+                    logger.debug(f"Saving point mark shape to '{str(filename)}'.")
+                    lagrange.io.save_mesh(filename, disk)  # type: ignore
+                    base_shape_config = {
+                        "type": "ply",
+                        "filename": str(filename.resolve()),
+                        "face_normals": True,
+                    }
+                    shapes = [
+                        base_shape_config | {"to_world": global_transform @ m}
+                        for m in local_transforms
+                    ]
+    else:  # with covariance
         # Generate base shape config.
-        match view.covariance_channel.base_shape:
+        match base_shape:
             case "sphere":
                 # Generate point mark shape.
                 sphere = create_icosphere(1)
                 tmp_dir = pathlib.Path(tempfile.gettempdir())
                 filename = tmp_dir / f"{stamp}-view-{index:03}.ply"
                 logger.debug(f"Saving point mark shape to '{str(filename)}'.")
                 lagrange.io.save_mesh(filename, sphere)  # type: ignore
@@ -298,15 +373,17 @@
     mesh = view.data_frame.mesh
     shapes: list[dict[str, Any]] = []
 
     # The radius of the linearcurve shape in Mitsuba 3.4.0 will not be transformed using the
     # `to_world` transform. This seems to be a bug on Mitsuba's part. Thus, we use a temporary fix
     # to bypass this bug.
     # TODO: Update once Mitsuba fixed the bug.
-    scale_correction_factor = np.trace(view.global_transform[:3, :3]) / 3
+    scale_correction_factor = np.absolute(
+        np.cbrt(np.linalg.det(view.global_transform[:3, :3]))
+    )
 
     # Generate curve file
     if view.vector_field_channel is not None:
         base, ctrl_pts_1, ctrl_pts_2, tip, base_size, tip_size = extract_vector_field(
             view
         )
     else:
@@ -360,16 +437,17 @@
     return mi_config
 
 
 def _rename_attributes(mesh: lagrange.SurfaceMesh, active_attributes: list[Attribute]):
     """Rename generic scalar and vector attribute with suffix "_0". This is required by mitsuba to
     correct parse them from a ply file.
 
-    :param mesh: The mesh to rename attributes.
-    :param active_attributes: The list of active attributes.
+    Args:
+        mesh: The mesh to rename attributes.
+        active_attributes: The list of active attributes.
     """
     processed_names = set()
     for attr in active_attributes:
         name = attr._internal_name
         assert name is not None
         if lagrange.SurfaceMesh.attr_name_is_reserved(name):
             continue
@@ -398,19 +476,21 @@
     """Generate the mitsuba config for a mesh.
 
     It does the following things:
     1. Rename all generic scalar/vector attributes with _0 suffix.
     2. Save the mesh and all active attributes in ply format in a temp directory.
     3. Generate the bsdf config associated with the shape.
 
-    :param view: The view to generate mesh config from.
-    :param stamp: The time stamp string used for creating a unique filename.
-    :param index: The index of the view.
+    Args:
+        view: The view to generate mesh config from.
+        stamp: The time stamp string used for creating a unique filename.
+        index: The index of the view.
 
-    :return: The mitsuba config for the mesh view.
+    Returns:
+        The mitsuba config for the mesh view.
     """
     assert view.data_frame is not None
     mesh = copy.copy(view.data_frame.mesh)  # Shallow copy
     if not mesh.is_triangle_mesh:
         logger.debug("Convert dataframe to triangle mesh.")
         lagrange.triangulate_polygonal_facets(mesh)
```

## Comparing `hakowan/render/icosphere.py` & `hakowan/render/base_shapes.py`

 * *Files 14% similar despite different names*

```diff
@@ -106,7 +106,31 @@
     icosphere.add_triangles(np.array(triangles, dtype=np.uint32))
     icosphere.create_attribute(
         "vertex_normal",
         usage=lagrange.AttributeUsage.Normal,
         initial_values=np.array(vertices, dtype=np.float64),
     )
     return icosphere
+
+def create_disk(vertex_count):
+    """ Generate a disk centered at the origin with radius 1 facing z direction.
+
+    Args:
+        vertex_count (int): Number of vertices on the disk boundary.
+
+    Returns:
+        lagrange.SurfaceMesh: The generated disk mesh.
+    """
+    vertices = np.zeros((vertex_count + 1, 3))
+    angle = np.linspace(0, 2 * np.pi, vertex_count, endpoint=False)
+    vertices[1:, 0] = np.cos(angle)
+    vertices[1:, 1] = np.sin(angle)
+
+    disk = lagrange.SurfaceMesh()
+    disk.add_vertices(vertices)
+
+    triangles = np.zeros((vertex_count, 3), dtype=np.uint32)
+    triangles[:, 1] = np.arange(1, vertex_count + 1)
+    triangles[:, 2] = np.roll(np.arange(1, vertex_count + 1), -1)
+    disk.add_triangles(triangles)
+
+    return disk
```

## Comparing `hakowan-0.3.4.dist-info/LICENSE` & `hakowan-0.3.5.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `hakowan-0.3.4.dist-info/METADATA` & `hakowan-0.3.5.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: hakowan
-Version: 0.3.4
+Version: 0.3.5
 Summary: Hakowan: A 3D data visualization grammer 
 Author-email: Qingnan Zhou <qnzhou@gmail.com>, Zhicheng Liu <leozcliu@umd.edu>
 Requires-Python: >=3.10
 Description-Content-Type: text/markdown
 Classifier: License :: OSI Approved :: Apache Software License
 Requires-Dist: lagrange-open~=6.22
 Requires-Dist: mitsuba~=3.4
```

## Comparing `hakowan-0.3.4.dist-info/RECORD` & `hakowan-0.3.5.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-hakowan/__init__.py,sha256=2_Dx1JirMPAHeitjjYhEPMPaIGNy4muMQ9meAUNuPt8,546
+hakowan/__init__.py,sha256=gnWYHXWPJeWQ8WZ2duH-CgWBQqi7ZH9Z_8Fy0_gsaR8,546
 hakowan/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 hakowan/common/__init__.py,sha256=Es4t__Ougt4aIMVKMOgjGs9aOXiEJrs5teaNhaMPQwQ,27
 hakowan/common/color.py,sha256=OYVuD8LeWn6Loa7Dj6k_Rm6s8shU_mBAxim8thchD7s,1965
 hakowan/common/default.py,sha256=h-4Xlqzd9T7QV3_NMy_tcKHGLX1jTcx0tMqav5rUN0s,265
 hakowan/common/envmaps.py,sha256=Jr3lEsdQfJOQzDkP4NwrKTXUFECTLHZpji-9dBhwix8,135
 hakowan/common/exception.py,sha256=DtdFVsD2dcqJkOdMKYlzBU4VoIC2IE0u4Hi7VbNACIE,131
 hakowan/common/logger.py,sha256=NSoSPOVvjpOwWCzrb9GQjYXG1NHgsBQj5KcyoqMaHS8,117
@@ -16,64 +16,65 @@
 hakowan/common/colormap/magma.py,sha256=YHBr21VsBJUi4w9M8ssaobGJcN069UcHXEGDpnU5tgM,11515
 hakowan/common/colormap/named_colormaps.py,sha256=nlUscHOuyHU2DrOAhe2ERFNPv7eifTGdXdukwkWL810,575
 hakowan/common/colormap/plasma.py,sha256=UtOEEi2bDnJze6I4QBC6EbMU7nPPXQkkP_zs5H8nqss,11517
 hakowan/common/colormap/turbo.py,sha256=q9IEw3A2SQvJvjsREqLnnRan2QKfD5G8zjUheo_4Aok,10794
 hakowan/common/colormap/viridis.py,sha256=41EUbAYyUrPImo6vmWN7Y4CNE1e1WZ6Oa2wSlwENH4Y,11519
 hakowan/compiler/__init__.py,sha256=tA-nLriuWMbhV0WtcFUPmzGYI3zWEIfgU88WjTzeNxs,106
 hakowan/compiler/attribute.py,sha256=zhQZvUV2n3MaJduMy9xXoUw3owZdT1CTBejRWM1ebCo,10577
-hakowan/compiler/channel.py,sha256=lzg1nySwGwvkGMvpiVEtMy_Q6SqnpEx2Nzpah1ID_A0,8519
+hakowan/compiler/channel.py,sha256=ucSjhgHlFRRiFgN34vXWQG0fjdyNsc4tFdW88SXcuY8,9276
 hakowan/compiler/color.py,sha256=dP3xsToRoWVBpk7h6bvegx1ZXOloVz27BBPDwWMkUXU,4044
 hakowan/compiler/compile.py,sha256=3A_Ea-86azpReUJU99gghc5WfeYwDXcnT8GqS25Key0,2548
 hakowan/compiler/scene.py,sha256=Zlf5mqgw_Ia__3Ed8oFmov4RsVa6IM3-UGuvusD150Q,2054
 hakowan/compiler/texture.py,sha256=-wrINMWkyhN8i4dk7lzGxmQxMa94GlZ5LjC5kex1RiI,8690
-hakowan/compiler/transform.py,sha256=Kj6wgHaPD3GUVIOzV7jdGgXWRaMk37WahdbM6djl4K4,11628
+hakowan/compiler/transform.py,sha256=gLCSpPIRKftP6XHwa1gq7_67Qnmtiyl3oSnCh9mnt5Y,12585
 hakowan/compiler/utils.py,sha256=_FPSZwRAO6sDfZZEbSlQ8voKYU7qfop59h02EtSgVYI,478
-hakowan/compiler/view.py,sha256=OVDm1aJ3SCQJ_ZgimRQz9e7KzrkXOcjRxSQx30sbYXU,11311
+hakowan/compiler/view.py,sha256=i8VY9T-yPJY1tuduLmL6kRQTlGqEpU9qaNrlbRbjZrc,11665
 hakowan/envmaps/README.md,sha256=II8qn_GiLnrMP1dme2jz7gw2H7CgE93_NCNfAqNPFyI,292
 hakowan/envmaps/museum.exr,sha256=jji5kECaqM5KbOloAay-uuvxw8mVFPsPrBuQnuPTV9k,426040
 hakowan/grammar/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-hakowan/grammar/channel/__init__.py,sha256=r4B7q9GGvXFb5mw957SrATv8zPLj0DoNIBf0r3L21EQ,127
-hakowan/grammar/channel/channel.py,sha256=-2J9TCkyTrPQw27DkMMp5JlXSEKGjkopB3HqVZPEO80,4375
+hakowan/grammar/channel/__init__.py,sha256=yJsdSM6gblPutcrU3N5Htqp7DwwPtFT17470FP8Fn3Q,175
+hakowan/grammar/channel/channel.py,sha256=gNfaTWft-98sJRxuK56X1gaYzOzzcI1E2UcCcxFtHCw,4859
 hakowan/grammar/channel/curvestyle.py,sha256=um0-id1cf2y76osuP0psxlRK6lSvdTWXssXse0Ftrrs,476
 hakowan/grammar/channel/material/__init__.py,sha256=l4wAnbE8F9agPWkwmui7C6GrtfSgR4tofyDF_m7XodY,250
 hakowan/grammar/channel/material/material.py,sha256=qfYv75FiOZmegswRSCDWff6BAO1YblVaIAG7MrU1PSc,3766
 hakowan/grammar/channel/material/medium.py,sha256=l2BRc7RxFmY5shliMqe4ZxTikubn6sWu3IZSWqnL_-Q,366
 hakowan/grammar/dataframe/__init__.py,sha256=FSTbsha_pZPaVYQlZDj6c1O0S0OR9YxduO4g4_ZKnWI,48
 hakowan/grammar/dataframe/dataframe.py,sha256=-8I5UfknuaEIBUXNAnwVLPNay5iNMDW_dvg_pxhQBZw,1279
 hakowan/grammar/layer/__init__.py,sha256=rUK8cKRc_4TLUve8KToqkRDT08nGAdyhRJXNnS_WET4,25
-hakowan/grammar/layer/layer.py,sha256=SKiRCRNUDkI8Nt9-qqx_94O-xhZUhwth9CJ_kxW21Do,14156
+hakowan/grammar/layer/layer.py,sha256=Dzlc2S3qhZRXpN_BkWiNbTNaBJlwno76gGwBJ15GXnM,14537
 hakowan/grammar/layer/layer_spec.py,sha256=b9HxiVCq35GatEuab_I6GbYx3zKCKvw23TpDw1AC_hA,416
 hakowan/grammar/mark/__init__.py,sha256=dTMweYPxH1N_SzlpFmDQttk6OHFZRRtjOVLNjpiJe0Y,46
 hakowan/grammar/mark/mark.py,sha256=gDJl9ZYoT2QFsNuhkwpdPoFiu_EM0flCR7IVxMylx7w,375
 hakowan/grammar/scale/__init__.py,sha256=JhKpNd03udnmkcqg6FFrQ9xOgCn9ttM0W9Ok-yLGGOs,158
 hakowan/grammar/scale/attribute.py,sha256=Rye5DSRAt4dOPjrbAWONzBekRYNZ2e6H0g_xrK3pTxI,1301
 hakowan/grammar/scale/offset.py,sha256=k74iahzhD9OoeQhgIHozdbDD5DmQW7RsnyXPOd2pS7c,285
 hakowan/grammar/scale/scale.py,sha256=UF0YgXJZQXiCpdAD_QLgbtvjdYqpZCfE2V_b7OMjtt0,2887
 hakowan/grammar/texture/__init__.py,sha256=22AvZjOML-F14nsVXopKGXPasdIxtIxybiJQUQ01k5I,23
 hakowan/grammar/texture/texture.py,sha256=SoLcCJvL2yJ8BnUlaNmEeyVraPs7fLEWHnmD8Xa8hmk,3328
 hakowan/grammar/transform/__init__.py,sha256=dENM5wNH4Xils3v7SAh-xc5BVR5awJltaqjI-SEJhQU,25
-hakowan/grammar/transform/transform.py,sha256=hYwZpvdOkgze3LsuxPJBVpzUTnKUmNDJd0FdCVLymLs,3737
+hakowan/grammar/transform/transform.py,sha256=euTidyLUVgabL6TsJtrfInO1XpJzmbvvIPqipMe9buc,4089
 hakowan/render/__init__.py,sha256=yyuJL_k1dQH5hAmcslrlLtym0V4gu1lnrL0BdSkUHMo,361
+hakowan/render/base_shapes.py,sha256=ox4H6SypWTtPu4yd8Mez8C5CFRNgr7jHQVtkNcA3tSE,3851
 hakowan/render/bsdf.py,sha256=ldK7Sd9sfDi4lbetEZdjd0DvkD-78brDZFW7g97Fvt4,10517
 hakowan/render/color.py,sha256=vYggCpD8p_ixmyj80Amw_A1-TdvHQbDfgz9H7A3IMpg,200
-hakowan/render/emitter.py,sha256=3hREbf-Ri_9lZdG_nbHNw_vBvcict-4bdjqmeABUCco,1344
+hakowan/render/emitter.py,sha256=5larn_8veKU6fkYmvDRCfSRLZrOihtRLoDspkivkYCM,1167
 hakowan/render/film.py,sha256=PEiqPkbvQmn1dwyI-kXy6vHiAflCTLtagMMs7ysIdsE,623
-hakowan/render/icosphere.py,sha256=MvaU4gD4tl0biLergDLttuOgbNbcvekxS13VkR8-Mrc,3095
 hakowan/render/integrator.py,sha256=hp7kZtoXbTSmMqP6XQZaDbBdC8DeaHiYn1mqTfr3Flg,1798
 hakowan/render/medium.py,sha256=-S1vk4dMfTeXFT26hl9KfwbbnAjzHYv2ooiLMHxy5xs,950
 hakowan/render/render.py,sha256=-aw86oyuKS1dcYHcj1DfseL1aRHsRBCFwLiUvBk6zu4,4023
 hakowan/render/sampler.py,sha256=3UCcVgqPbTMc-JkB9E5_ud5DFoM5Lr80Bb92Gxm7mIo,587
 hakowan/render/sensor.py,sha256=U_sEVoDiK_kH-XZEeGiDEYLcf-HZMl5_GEL71mYOZ3g,1057
-hakowan/render/shape.py,sha256=csDffoMV4bn1TbbL-9mXS-sFfbK1fK91KvZ8d_WLYS4,17387
+hakowan/render/shape.py,sha256=k6-Yo2vSvRr7HQhK8jKbFar5inBfqP4kkkzbzu8Ho78,20521
 hakowan/render/spectrum.py,sha256=Y2Dee9Ld8s0pbKPtfIjhRsFOKhDjRCfBMz_PPj_oJ9w,593
 hakowan/render/texture.py,sha256=nb_chofhfs1v8NSI7RbZBuyDJhLgKMGIecQRY9RiTn4,4731
+hakowan/render/utils.py,sha256=OLjns5m55Z0Rv7xu7Mhp7ioi5HsSPwK4zy_Kz0SPfwQ,549
 hakowan/setup/__init__.py,sha256=nD9QWvUI4fRlQeAfsUuMJOB93cT3xSIrsthAb5695NE,137
 hakowan/setup/config.py,sha256=HVITR-k3fRwq4OJqYpczpV_cnoNimslvSvxBgSI-U0s,3410
 hakowan/setup/emitter.py,sha256=Hs-WN1cPABCMu-AhdGmE6fwFkE010_xtOQQDoEBNvQc,1096
 hakowan/setup/film.py,sha256=HwdV2930tfFElp58rrmYg7tRhMR4cMoi6rus7VfE4CQ,1144
 hakowan/setup/integrator.py,sha256=KlWcwrYFyil7mXd6jyGNlN6GoUYkxXtmfvNQBgC7OKQ,3123
 hakowan/setup/sampler.py,sha256=iyZdHyZsnxOsBOKs8934dG9GzggaZ-WLmX8dJj5NEpg,1009
 hakowan/setup/sensor.py,sha256=SSPu__qxSGafaaToBqP1QutHCOzedezg1JQijUk-UtA,1441
-hakowan-0.3.4.dist-info/LICENSE,sha256=hr3V2vq3dFEES2_W0u-rI-NBDOZY6wl_BMBPT1Su1i8,11335
-hakowan-0.3.4.dist-info/WHEEL,sha256=EZbGkh7Ie4PoZfRQ8I0ZuP9VklN_TvcZ6DSE5Uar4z4,81
-hakowan-0.3.4.dist-info/METADATA,sha256=pfg4dwrmHb4clEZvmFu-eNtTtU5-gq1lBTxuW0F8ixk,1266
-hakowan-0.3.4.dist-info/RECORD,,
+hakowan-0.3.5.dist-info/LICENSE,sha256=hr3V2vq3dFEES2_W0u-rI-NBDOZY6wl_BMBPT1Su1i8,11335
+hakowan-0.3.5.dist-info/WHEEL,sha256=EZbGkh7Ie4PoZfRQ8I0ZuP9VklN_TvcZ6DSE5Uar4z4,81
+hakowan-0.3.5.dist-info/METADATA,sha256=b7DGGCBUxxFKb7nErjQIxvDc-1In_lpm8u0mMr_jmLM,1266
+hakowan-0.3.5.dist-info/RECORD,,
```

