# Comparing `tmp/virtualenv-20.8.1.tar.gz` & `tmp/virtualenv-20.9.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "virtualenv-20.8.1.tar", last modified: Fri Sep 24 10:37:02 2021, max compression
+gzip compressed data, was "virtualenv-20.9.0.tar", last modified: Sat Oct 23 10:59:55 2021, max compression
```

## Comparing `virtualenv-20.8.1.tar` & `virtualenv-20.9.0.tar`

### file list

```diff
@@ -1,258 +1,264 @@
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/
--rw-r--r--   0 runner    (1001) docker     (121)      752 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.coveragerc
--rw-r--r--   0 runner    (1001) docker     (121)       36 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.dockerignore
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.364204 virtualenv-20.8.1/.github/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.372203 virtualenv-20.8.1/.github/ISSUE_TEMPLATE/
--rw-r--r--   0 runner    (1001) docker     (121)      335 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.github/ISSUE_TEMPLATE/bug-report.md
--rw-r--r--   0 runner    (1001) docker     (121)      440 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.github/ISSUE_TEMPLATE/bug_report.md
--rw-r--r--   0 runner    (1001) docker     (121)      676 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.github/ISSUE_TEMPLATE/config.yml
--rw-r--r--   0 runner    (1001) docker     (121)      762 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.github/ISSUE_TEMPLATE/feature-request.md
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.372203 virtualenv-20.8.1/.github/workflows/
--rw-r--r--   0 runner    (1001) docker     (121)     5493 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.github/workflows/check.yml
--rw-r--r--   0 runner    (1001) docker     (121)     1219 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.pre-commit-config.yaml
--rw-r--r--   0 runner    (1001) docker     (121)      269 2021-09-24 10:36:53.000000 virtualenv-20.8.1/.readthedocs.yml
--rw-r--r--   0 runner    (1001) docker     (121)     1074 2021-09-24 10:36:53.000000 virtualenv-20.8.1/LICENSE
--rw-r--r--   0 runner    (1001) docker     (121)     3547 2021-09-24 10:37:02.416204 virtualenv-20.8.1/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)     1907 2021-09-24 10:36:53.000000 virtualenv-20.8.1/README.md
--rw-r--r--   0 runner    (1001) docker     (121)      405 2021-09-24 10:36:53.000000 virtualenv-20.8.1/codecov.yaml
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.376204 virtualenv-20.8.1/docs/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.376204 virtualenv-20.8.1/docs/_static/
--rw-r--r--   0 runner    (1001) docker     (121)     1115 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/_static/custom.css
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.376204 virtualenv-20.8.1/docs/changelog/
--rw-r--r--   0 runner    (1001) docker     (121)      592 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/changelog/examples.rst
--rw-r--r--   0 runner    (1001) docker     (121)     1083 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/changelog/template.jinja2
--rw-r--r--   0 runner    (1001) docker     (121)    43985 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/changelog.rst
--rw-r--r--   0 runner    (1001) docker     (121)     3384 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/cli_interface.rst
--rw-r--r--   0 runner    (1001) docker     (121)     2481 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/conf.py
--rw-r--r--   0 runner    (1001) docker     (121)     9824 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/development.rst
--rw-r--r--   0 runner    (1001) docker     (121)     3683 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/extend.rst
--rw-r--r--   0 runner    (1001) docker     (121)     4370 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/index.rst
--rw-r--r--   0 runner    (1001) docker     (121)     5858 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/installation.rst
--rw-r--r--   0 runner    (1001) docker     (121)     9339 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/render_cli.py
--rw-r--r--   0 runner    (1001) docker     (121)    15617 2021-09-24 10:36:53.000000 virtualenv-20.8.1/docs/user_guide.rst
--rw-r--r--   0 runner    (1001) docker     (121)      540 2021-09-24 10:36:53.000000 virtualenv-20.8.1/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (121)     4480 2021-09-24 10:37:02.420204 virtualenv-20.8.1/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (121)      380 2021-09-24 10:36:53.000000 virtualenv-20.8.1/setup.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.368203 virtualenv-20.8.1/src/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.376204 virtualenv-20.8.1/src/virtualenv/
--rw-r--r--   0 runner    (1001) docker     (121)      205 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2900 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/__main__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.380204 virtualenv-20.8.1/src/virtualenv/activation/
--rw-r--r--   0 runner    (1001) docker     (121)      486 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1341 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/activator.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.380204 virtualenv-20.8.1/src/virtualenv/activation/bash/
--rw-r--r--   0 runner    (1001) docker     (121)      312 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/bash/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2176 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/bash/activate.sh
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.380204 virtualenv-20.8.1/src/virtualenv/activation/batch/
--rw-r--r--   0 runner    (1001) docker     (121)      733 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/batch/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1031 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/batch/activate.bat
--rw-r--r--   0 runner    (1001) docker     (121)      510 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/batch/deactivate.bat
--rw-r--r--   0 runner    (1001) docker     (121)       24 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/batch/pydoc.bat
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.380204 virtualenv-20.8.1/src/virtualenv/activation/cshell/
--rw-r--r--   0 runner    (1001) docker     (121)      344 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/cshell/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1468 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/cshell/activate.csh
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.380204 virtualenv-20.8.1/src/virtualenv/activation/fish/
--rw-r--r--   0 runner    (1001) docker     (121)      251 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/fish/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3099 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/fish/activate.fish
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.380204 virtualenv-20.8.1/src/virtualenv/activation/nushell/
--rw-r--r--   0 runner    (1001) docker     (121)     1078 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/nushell/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1306 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/nushell/activate.nu
--rw-r--r--   0 runner    (1001) docker     (121)      333 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/nushell/deactivate.nu
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.380204 virtualenv-20.8.1/src/virtualenv/activation/powershell/
--rw-r--r--   0 runner    (1001) docker     (121)      256 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/powershell/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1807 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/powershell/activate.ps1
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.380204 virtualenv-20.8.1/src/virtualenv/activation/python/
--rw-r--r--   0 runner    (1001) docker     (121)     1323 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/python/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1208 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/python/activate_this.py
--rw-r--r--   0 runner    (1001) docker     (121)     2372 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/activation/via_template.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.384204 virtualenv-20.8.1/src/virtualenv/app_data/
--rw-r--r--   0 runner    (1001) docker     (121)     1468 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/app_data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2129 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/app_data/base.py
--rw-r--r--   0 runner    (1001) docker     (121)     1310 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/app_data/na.py
--rw-r--r--   0 runner    (1001) docker     (121)     1006 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/app_data/read_only.py
--rw-r--r--   0 runner    (1001) docker     (121)     5598 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/app_data/via_disk_folder.py
--rw-r--r--   0 runner    (1001) docker     (121)      770 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/app_data/via_tempdir.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.384204 virtualenv-20.8.1/src/virtualenv/config/
--rw-r--r--   0 runner    (1001) docker     (121)       57 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/config/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.384204 virtualenv-20.8.1/src/virtualenv/config/cli/
--rw-r--r--   0 runner    (1001) docker     (121)       57 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/config/cli/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4666 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/config/cli/parser.py
--rw-r--r--   0 runner    (1001) docker     (121)     2694 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/config/convert.py
--rw-r--r--   0 runner    (1001) docker     (121)      869 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/config/env_var.py
--rw-r--r--   0 runner    (1001) docker     (121)     2840 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/config/ini.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.384204 virtualenv-20.8.1/src/virtualenv/create/
--rw-r--r--   0 runner    (1001) docker     (121)       57 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8928 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/creator.py
--rw-r--r--   0 runner    (1001) docker     (121)     3342 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/debug.py
--rw-r--r--   0 runner    (1001) docker     (121)     3540 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/describe.py
--rw-r--r--   0 runner    (1001) docker     (121)     1717 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/pyenv_cfg.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.384204 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5662 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/_virtualenv.py
--rw-r--r--   0 runner    (1001) docker     (121)     4357 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/api.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.388204 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      546 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/builtin_way.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.388204 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/
--rw-r--r--   0 runner    (1001) docker     (121)       57 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2392 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/common.py
--rw-r--r--   0 runner    (1001) docker     (121)     3752 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/cpython2.py
--rw-r--r--   0 runner    (1001) docker     (121)     3312 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/cpython3.py
--rw-r--r--   0 runner    (1001) docker     (121)    12620 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/mac_os.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.388204 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/pypy/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/pypy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     1816 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/pypy/common.py
--rw-r--r--   0 runner    (1001) docker     (121)     3547 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/pypy/pypy2.py
--rw-r--r--   0 runner    (1001) docker     (121)     1924 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/pypy/pypy3.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.388204 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/python2/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/python2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4276 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/python2/python2.py
--rw-r--r--   0 runner    (1001) docker     (121)     6903 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/python2/site.py
--rw-r--r--   0 runner    (1001) docker     (121)     5477 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/ref.py
--rw-r--r--   0 runner    (1001) docker     (121)     4552 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/via_global_self_do.py
--rw-r--r--   0 runner    (1001) docker     (121)      685 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/store.py
--rw-r--r--   0 runner    (1001) docker     (121)     2955 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/create/via_global_ref/venv.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.392204 virtualenv-20.8.1/src/virtualenv/discovery/
--rw-r--r--   0 runner    (1001) docker     (121)       57 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/discovery/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     6384 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/discovery/builtin.py
--rw-r--r--   0 runner    (1001) docker     (121)     5312 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/discovery/cached_py_info.py
--rw-r--r--   0 runner    (1001) docker     (121)     1241 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/discovery/discover.py
--rw-r--r--   0 runner    (1001) docker     (121)    22786 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/discovery/py_info.py
--rw-r--r--   0 runner    (1001) docker     (121)     4790 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/discovery/py_spec.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.392204 virtualenv-20.8.1/src/virtualenv/discovery/windows/
--rw-r--r--   0 runner    (1001) docker     (121)     1200 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/discovery/windows/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5451 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/discovery/windows/pep514.py
--rw-r--r--   0 runner    (1001) docker     (121)     1995 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/info.py
--rw-r--r--   0 runner    (1001) docker     (121)     1594 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/report.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.392204 virtualenv-20.8.1/src/virtualenv/run/
--rw-r--r--   0 runner    (1001) docker     (121)     6090 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/run/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.392204 virtualenv-20.8.1/src/virtualenv/run/plugin/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/run/plugin/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     2117 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/run/plugin/activators.py
--rw-r--r--   0 runner    (1001) docker     (121)     1854 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/run/plugin/base.py
--rw-r--r--   0 runner    (1001) docker     (121)     3494 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/run/plugin/creators.py
--rw-r--r--   0 runner    (1001) docker     (121)     1156 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/run/plugin/discovery.py
--rw-r--r--   0 runner    (1001) docker     (121)     1074 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/run/plugin/seeders.py
--rw-r--r--   0 runner    (1001) docker     (121)     2563 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/run/session.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.392204 virtualenv-20.8.1/src/virtualenv/seed/
--rw-r--r--   0 runner    (1001) docker     (121)       57 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.392204 virtualenv-20.8.1/src/virtualenv/seed/embed/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4182 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/base_embed.py
--rw-r--r--   0 runner    (1001) docker     (121)     2167 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/pip_invoke.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.392204 virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.396204 virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/pip_install/
--rw-r--r--   0 runner    (1001) docker     (121)        0 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/pip_install/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     8481 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/pip_install/base.py
--rw-r--r--   0 runner    (1001) docker     (121)     1307 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/pip_install/copy.py
--rw-r--r--   0 runner    (1001) docker     (121)     2362 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/pip_install/symlink.py
--rw-r--r--   0 runner    (1001) docker     (121)     6032 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/via_app_data.py
--rw-r--r--   0 runner    (1001) docker     (121)     1209 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/seeder.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.396204 virtualenv-20.8.1/src/virtualenv/seed/wheels/
--rw-r--r--   0 runner    (1001) docker     (121)      226 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     4472 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/acquire.py
--rw-r--r--   0 runner    (1001) docker     (121)     1845 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/bundle.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.404204 virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/
--rw-r--r--   0 runner    (1001) docker     (121)     1787 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)  1522101 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/pip-20.3.4-py2.py3-none-any.whl
--rw-r--r--   0 runner    (1001) docker     (121)  1555100 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/pip-21.2.4-py3-none-any.whl
--rw-r--r--   0 runner    (1001) docker     (121)   583493 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/setuptools-44.1.1-py2.py3-none-any.whl
--rw-r--r--   0 runner    (1001) docker     (121)   785194 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/setuptools-50.3.2-py3-none-any.whl
--rw-r--r--   0 runner    (1001) docker     (121)   816725 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/setuptools-58.1.0-py3-none-any.whl
--rw-r--r--   0 runner    (1001) docker     (121)    35161 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/wheel-0.37.0-py2.py3-none-any.whl
--rw-r--r--   0 runner    (1001) docker     (121)    12874 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/periodic_update.py
--rw-r--r--   0 runner    (1001) docker     (121)     3960 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/seed/wheels/util.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.404204 virtualenv-20.8.1/src/virtualenv/util/
--rw-r--r--   0 runner    (1001) docker     (121)      199 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)      352 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/error.py
--rw-r--r--   0 runner    (1001) docker     (121)     4727 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/lock.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.404204 virtualenv-20.8.1/src/virtualenv/util/path/
--rw-r--r--   0 runner    (1001) docker     (121)      401 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/path/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.404204 virtualenv-20.8.1/src/virtualenv/util/path/_pathlib/
--rw-r--r--   0 runner    (1001) docker     (121)      340 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/path/_pathlib/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3772 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/path/_pathlib/via_os_path.py
--rw-r--r--   0 runner    (1001) docker     (121)      745 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/path/_permission.py
--rw-r--r--   0 runner    (1001) docker     (121)     2393 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/path/_sync.py
--rw-r--r--   0 runner    (1001) docker     (121)      709 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/path/_win.py
--rw-r--r--   0 runner    (1001) docker     (121)     1463 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/six.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.404204 virtualenv-20.8.1/src/virtualenv/util/subprocess/
--rw-r--r--   0 runner    (1001) docker     (121)      801 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/subprocess/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)     5697 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/subprocess/_win_subprocess.py
--rw-r--r--   0 runner    (1001) docker     (121)     1054 2021-09-24 10:36:53.000000 virtualenv-20.8.1/src/virtualenv/util/zipapp.py
--rw-r--r--   0 runner    (1001) docker     (121)       65 2021-09-24 10:37:02.000000 virtualenv-20.8.1/src/virtualenv/version.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.376204 virtualenv-20.8.1/src/virtualenv.egg-info/
--rw-r--r--   0 runner    (1001) docker     (121)     3547 2021-09-24 10:37:02.000000 virtualenv-20.8.1/src/virtualenv.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (121)     7820 2021-09-24 10:37:02.000000 virtualenv-20.8.1/src/virtualenv.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (121)        1 2021-09-24 10:37:02.000000 virtualenv-20.8.1/src/virtualenv.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (121)     1621 2021-09-24 10:37:02.000000 virtualenv-20.8.1/src/virtualenv.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (121)      609 2021-09-24 10:37:02.000000 virtualenv-20.8.1/src/virtualenv.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (121)       11 2021-09-24 10:37:02.000000 virtualenv-20.8.1/src/virtualenv.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (121)        1 2021-09-24 10:37:02.000000 virtualenv-20.8.1/src/virtualenv.egg-info/zip-safe
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.404204 virtualenv-20.8.1/tasks/
--rw-r--r--   0 runner    (1001) docker     (121)     5824 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tasks/__main__zipapp.py
--rw-r--r--   0 runner    (1001) docker     (121)    11391 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tasks/make_zipapp.py
--rwxr-xr-x   0 runner    (1001) docker     (121)     3314 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tasks/update_embedded.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.404204 virtualenv-20.8.1/tests/
--rw-r--r--   0 runner    (1001) docker     (121)    12069 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.408204 virtualenv-20.8.1/tests/integration/
--rw-r--r--   0 runner    (1001) docker     (121)      753 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/integration/test_run_int.py
--rw-r--r--   0 runner    (1001) docker     (121)     3270 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/integration/test_zipapp.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.408204 virtualenv-20.8.1/tests/unit/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.408204 virtualenv-20.8.1/tests/unit/activation/
--rw-r--r--   0 runner    (1001) docker     (121)     9974 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/conftest.py
--rw-r--r--   0 runner    (1001) docker     (121)      870 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_activate_this.py
--rw-r--r--   0 runner    (1001) docker     (121)     1686 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_activation_support.py
--rw-r--r--   0 runner    (1001) docker     (121)      643 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_bash.py
--rw-r--r--   0 runner    (1001) docker     (121)     1241 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_batch.py
--rw-r--r--   0 runner    (1001) docker     (121)      367 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_csh.py
--rw-r--r--   0 runner    (1001) docker     (121)      705 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_fish.py
--rw-r--r--   0 runner    (1001) docker     (121)      727 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_nushell.py
--rw-r--r--   0 runner    (1001) docker     (121)     1265 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_powershell.py
--rw-r--r--   0 runner    (1001) docker     (121)     3685 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/activation/test_python_activator.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.408204 virtualenv-20.8.1/tests/unit/config/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.408204 virtualenv-20.8.1/tests/unit/config/cli/
--rw-r--r--   0 runner    (1001) docker     (121)     1708 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/config/cli/test_parser.py
--rw-r--r--   0 runner    (1001) docker     (121)     3240 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/config/test___main__.py
--rw-r--r--   0 runner    (1001) docker     (121)     3380 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/config/test_env_var.py
--rw-r--r--   0 runner    (1001) docker     (121)      738 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/config/test_ini.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.408204 virtualenv-20.8.1/tests/unit/create/
--rw-r--r--   0 runner    (1001) docker     (121)     3960 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.412204 virtualenv-20.8.1/tests/unit/create/console_app/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/tests/unit/create/console_app/demo/
--rw-r--r--   0 runner    (1001) docker     (121)       69 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/console_app/demo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (121)       69 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/console_app/demo/__main__.py
--rw-r--r--   0 runner    (1001) docker     (121)      197 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/console_app/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (121)       38 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/console_app/setup.py
--rw-r--r--   0 runner    (1001) docker     (121)    26154 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/test_creator.py
--rw-r--r--   0 runner    (1001) docker     (121)     1060 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/test_interpreters.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/tests/unit/create/via_global_ref/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/tests/unit/create/via_global_ref/greet/
--rw-r--r--   0 runner    (1001) docker     (121)      482 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/via_global_ref/greet/greet2.c
--rw-r--r--   0 runner    (1001) docker     (121)      653 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/via_global_ref/greet/greet3.c
--rw-r--r--   0 runner    (1001) docker     (121)      330 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/via_global_ref/greet/setup.py
--rw-r--r--   0 runner    (1001) docker     (121)      234 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/via_global_ref/test_api.py
--rw-r--r--   0 runner    (1001) docker     (121)     2057 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/via_global_ref/test_build_c_ext.py
--rw-r--r--   0 runner    (1001) docker     (121)  3354125 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/create/virtualenv-16.7.9-py2.py3-none-any.whl
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/tests/unit/discovery/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/tests/unit/discovery/py_info/
--rw-r--r--   0 runner    (1001) docker     (121)    11464 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/discovery/py_info/test_py_info.py
--rw-r--r--   0 runner    (1001) docker     (121)     2141 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/discovery/py_info/test_py_info_exe_based_of.py
--rw-r--r--   0 runner    (1001) docker     (121)     2976 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/discovery/test_discovery.py
--rw-r--r--   0 runner    (1001) docker     (121)     3747 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/discovery/test_py_spec.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/tests/unit/discovery/windows/
--rw-r--r--   0 runner    (1001) docker     (121)     7651 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/discovery/windows/test_windows_pep514.py
--rw-r--r--   0 runner    (1001) docker     (121)     5915 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/discovery/windows/winreg-mock-values.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.372203 virtualenv-20.8.1/tests/unit/seed/
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/tests/unit/seed/embed/
--rw-r--r--   0 runner    (1001) docker     (121)      367 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/seed/embed/test_base_embed.py
--rw-r--r--   0 runner    (1001) docker     (121)     8924 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/seed/embed/test_bootstrap_link_via_app_data.py
--rw-r--r--   0 runner    (1001) docker     (121)     3133 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/seed/embed/test_pip_invoke.py
-drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-09-24 10:37:02.416204 virtualenv-20.8.1/tests/unit/seed/wheels/
--rw-r--r--   0 runner    (1001) docker     (121)     2447 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/seed/wheels/test_acquire.py
--rw-r--r--   0 runner    (1001) docker     (121)     1130 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/seed/wheels/test_acquire_find_wheel.py
--rw-r--r--   0 runner    (1001) docker     (121)    18214 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/seed/wheels/test_periodic_update.py
--rw-r--r--   0 runner    (1001) docker     (121)      901 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/seed/wheels/test_wheels_util.py
--rw-r--r--   0 runner    (1001) docker     (121)     1146 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/test_run.py
--rw-r--r--   0 runner    (1001) docker     (121)      685 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tests/unit/test_util.py
--rw-r--r--   0 runner    (1001) docker     (121)     4261 2021-09-24 10:36:53.000000 virtualenv-20.8.1/tox.ini
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/
+-rw-r--r--   0 runner    (1001) docker     (121)      752 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.coveragerc
+-rw-r--r--   0 runner    (1001) docker     (121)       36 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.dockerignore
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.039361 virtualenv-20.9.0/.github/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.043361 virtualenv-20.9.0/.github/ISSUE_TEMPLATE/
+-rw-r--r--   0 runner    (1001) docker     (121)      335 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.github/ISSUE_TEMPLATE/bug-report.md
+-rw-r--r--   0 runner    (1001) docker     (121)      440 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.github/ISSUE_TEMPLATE/bug_report.md
+-rw-r--r--   0 runner    (1001) docker     (121)      676 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.github/ISSUE_TEMPLATE/config.yml
+-rw-r--r--   0 runner    (1001) docker     (121)      776 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.github/ISSUE_TEMPLATE/feature-request.md
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.043361 virtualenv-20.9.0/.github/workflows/
+-rw-r--r--   0 runner    (1001) docker     (121)     5635 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.github/workflows/check.yml
+-rw-r--r--   0 runner    (1001) docker     (121)     1219 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.pre-commit-config.yaml
+-rw-r--r--   0 runner    (1001) docker     (121)      269 2021-10-23 10:59:48.000000 virtualenv-20.9.0/.readthedocs.yml
+-rw-r--r--   0 runner    (1001) docker     (121)     1074 2021-10-23 10:59:48.000000 virtualenv-20.9.0/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (121)     3547 2021-10-23 10:59:55.067361 virtualenv-20.9.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (121)     1907 2021-10-23 10:59:48.000000 virtualenv-20.9.0/README.md
+-rw-r--r--   0 runner    (1001) docker     (121)      317 2021-10-23 10:59:48.000000 virtualenv-20.9.0/codecov.yml
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/docs/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/docs/_static/
+-rw-r--r--   0 runner    (1001) docker     (121)     1115 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/_static/custom.css
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/docs/changelog/
+-rw-r--r--   0 runner    (1001) docker     (121)      131 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/changelog/2182.bugfix.txt
+-rw-r--r--   0 runner    (1001) docker     (121)      122 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/changelog/2205.bugfix.rst
+-rw-r--r--   0 runner    (1001) docker     (121)       68 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/changelog/2218.misc.rst
+-rw-r--r--   0 runner    (1001) docker     (121)       83 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/changelog/2220.feature.rst
+-rw-r--r--   0 runner    (1001) docker     (121)       72 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/changelog/2221.bugfix.rst
+-rw-r--r--   0 runner    (1001) docker     (121)      592 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/changelog/examples.rst
+-rw-r--r--   0 runner    (1001) docker     (121)     1083 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/changelog/template.jinja2
+-rw-r--r--   0 runner    (1001) docker     (121)    43985 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/changelog.rst
+-rw-r--r--   0 runner    (1001) docker     (121)     3389 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/cli_interface.rst
+-rw-r--r--   0 runner    (1001) docker     (121)     2481 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/conf.py
+-rw-r--r--   0 runner    (1001) docker     (121)     9824 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/development.rst
+-rw-r--r--   0 runner    (1001) docker     (121)     3683 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/extend.rst
+-rw-r--r--   0 runner    (1001) docker     (121)     4370 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/index.rst
+-rw-r--r--   0 runner    (1001) docker     (121)     5858 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/installation.rst
+-rw-r--r--   0 runner    (1001) docker     (121)     9339 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/render_cli.py
+-rw-r--r--   0 runner    (1001) docker     (121)    15617 2021-10-23 10:59:48.000000 virtualenv-20.9.0/docs/user_guide.rst
+-rw-r--r--   0 runner    (1001) docker     (121)      540 2021-10-23 10:59:48.000000 virtualenv-20.9.0/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (121)     4478 2021-10-23 10:59:55.071361 virtualenv-20.9.0/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (121)      380 2021-10-23 10:59:48.000000 virtualenv-20.9.0/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.039361 virtualenv-20.9.0/src/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/
+-rw-r--r--   0 runner    (1001) docker     (121)      205 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2900 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/__main__.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/activation/
+-rw-r--r--   0 runner    (1001) docker     (121)      486 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1411 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/activator.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/activation/bash/
+-rw-r--r--   0 runner    (1001) docker     (121)      312 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/bash/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2176 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/bash/activate.sh
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/activation/batch/
+-rw-r--r--   0 runner    (1001) docker     (121)      733 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/batch/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1024 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/batch/activate.bat
+-rw-r--r--   0 runner    (1001) docker     (121)      510 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/batch/deactivate.bat
+-rw-r--r--   0 runner    (1001) docker     (121)       24 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/batch/pydoc.bat
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/activation/cshell/
+-rw-r--r--   0 runner    (1001) docker     (121)      344 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/cshell/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1468 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/cshell/activate.csh
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/activation/fish/
+-rw-r--r--   0 runner    (1001) docker     (121)      251 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/fish/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3099 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/fish/activate.fish
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/activation/nushell/
+-rw-r--r--   0 runner    (1001) docker     (121)     1078 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/nushell/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1306 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/nushell/activate.nu
+-rw-r--r--   0 runner    (1001) docker     (121)      333 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/nushell/deactivate.nu
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/activation/powershell/
+-rw-r--r--   0 runner    (1001) docker     (121)      256 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/powershell/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1807 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/powershell/activate.ps1
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/activation/python/
+-rw-r--r--   0 runner    (1001) docker     (121)     1323 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/python/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1208 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/python/activate_this.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2372 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/activation/via_template.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv/app_data/
+-rw-r--r--   0 runner    (1001) docker     (121)     1468 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/app_data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2129 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/app_data/base.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1310 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/app_data/na.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1006 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/app_data/read_only.py
+-rw-r--r--   0 runner    (1001) docker     (121)     5598 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/app_data/via_disk_folder.py
+-rw-r--r--   0 runner    (1001) docker     (121)      770 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/app_data/via_tempdir.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/config/
+-rw-r--r--   0 runner    (1001) docker     (121)       57 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/config/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/config/cli/
+-rw-r--r--   0 runner    (1001) docker     (121)       57 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/config/cli/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4666 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/config/cli/parser.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2694 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/config/convert.py
+-rw-r--r--   0 runner    (1001) docker     (121)      869 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/config/env_var.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2840 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/config/ini.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/create/
+-rw-r--r--   0 runner    (1001) docker     (121)       57 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     8928 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/creator.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3342 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/debug.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3540 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/describe.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1717 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/pyenv_cfg.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/
+-rw-r--r--   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     5662 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/_virtualenv.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4357 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/api.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/
+-rw-r--r--   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)      546 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/builtin_way.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/
+-rw-r--r--   0 runner    (1001) docker     (121)       57 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2392 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/common.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3752 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/cpython2.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3312 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/cpython3.py
+-rw-r--r--   0 runner    (1001) docker     (121)    12620 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/mac_os.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/pypy/
+-rw-r--r--   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/pypy/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1816 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/pypy/common.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3563 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/pypy/pypy2.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2551 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/pypy/pypy3.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/python2/
+-rw-r--r--   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/python2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4276 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/python2/python2.py
+-rw-r--r--   0 runner    (1001) docker     (121)     6903 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/python2/site.py
+-rw-r--r--   0 runner    (1001) docker     (121)     5477 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/ref.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4552 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/via_global_self_do.py
+-rw-r--r--   0 runner    (1001) docker     (121)      685 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/store.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2955 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/create/via_global_ref/venv.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/discovery/
+-rw-r--r--   0 runner    (1001) docker     (121)       57 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/discovery/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     6384 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/discovery/builtin.py
+-rw-r--r--   0 runner    (1001) docker     (121)     5312 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/discovery/cached_py_info.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1241 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/discovery/discover.py
+-rw-r--r--   0 runner    (1001) docker     (121)    22786 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/discovery/py_info.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4790 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/discovery/py_spec.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/discovery/windows/
+-rw-r--r--   0 runner    (1001) docker     (121)     1200 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/discovery/windows/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     5451 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/discovery/windows/pep514.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1995 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/info.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1445 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/report.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/run/
+-rw-r--r--   0 runner    (1001) docker     (121)     6090 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/run/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/run/plugin/
+-rw-r--r--   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/run/plugin/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2225 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/run/plugin/activators.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1854 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/run/plugin/base.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3494 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/run/plugin/creators.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1156 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/run/plugin/discovery.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1074 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/run/plugin/seeders.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2563 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/run/session.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.051361 virtualenv-20.9.0/src/virtualenv/seed/
+-rw-r--r--   0 runner    (1001) docker     (121)       57 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.055361 virtualenv-20.9.0/src/virtualenv/seed/embed/
+-rw-r--r--   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4182 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/base_embed.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2167 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/pip_invoke.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.055361 virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/
+-rw-r--r--   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.055361 virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/pip_install/
+-rw-r--r--   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/pip_install/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     8481 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/pip_install/base.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1307 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/pip_install/copy.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2362 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/pip_install/symlink.py
+-rw-r--r--   0 runner    (1001) docker     (121)     6032 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/via_app_data.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1209 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/seeder.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.055361 virtualenv-20.9.0/src/virtualenv/seed/wheels/
+-rw-r--r--   0 runner    (1001) docker     (121)      226 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4472 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/acquire.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1845 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/bundle.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.059361 virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/
+-rw-r--r--   0 runner    (1001) docker     (121)     1787 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)  1522101 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/pip-20.3.4-py2.py3-none-any.whl
+-rw-r--r--   0 runner    (1001) docker     (121)  1723581 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/pip-21.3.1-py3-none-any.whl
+-rw-r--r--   0 runner    (1001) docker     (121)   583493 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/setuptools-44.1.1-py2.py3-none-any.whl
+-rw-r--r--   0 runner    (1001) docker     (121)   785194 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/setuptools-50.3.2-py3-none-any.whl
+-rw-r--r--   0 runner    (1001) docker     (121)   946220 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/setuptools-58.3.0-py3-none-any.whl
+-rw-r--r--   0 runner    (1001) docker     (121)    35161 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/wheel-0.37.0-py2.py3-none-any.whl
+-rw-r--r--   0 runner    (1001) docker     (121)    12874 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/periodic_update.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3960 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/seed/wheels/util.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.059361 virtualenv-20.9.0/src/virtualenv/util/
+-rw-r--r--   0 runner    (1001) docker     (121)      199 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)      352 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/error.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4812 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/lock.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.059361 virtualenv-20.9.0/src/virtualenv/util/path/
+-rw-r--r--   0 runner    (1001) docker     (121)      401 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/path/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.059361 virtualenv-20.9.0/src/virtualenv/util/path/_pathlib/
+-rw-r--r--   0 runner    (1001) docker     (121)      340 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/path/_pathlib/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3772 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/path/_pathlib/via_os_path.py
+-rw-r--r--   0 runner    (1001) docker     (121)      745 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/path/_permission.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2393 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/path/_sync.py
+-rw-r--r--   0 runner    (1001) docker     (121)      709 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/path/_win.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1463 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/six.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/src/virtualenv/util/subprocess/
+-rw-r--r--   0 runner    (1001) docker     (121)      801 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/subprocess/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     5697 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/subprocess/_win_subprocess.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1054 2021-10-23 10:59:48.000000 virtualenv-20.9.0/src/virtualenv/util/zipapp.py
+-rw-r--r--   0 runner    (1001) docker     (121)       65 2021-10-23 10:59:54.000000 virtualenv-20.9.0/src/virtualenv/version.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.047361 virtualenv-20.9.0/src/virtualenv.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (121)     3547 2021-10-23 10:59:54.000000 virtualenv-20.9.0/src/virtualenv.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (121)     8013 2021-10-23 10:59:55.000000 virtualenv-20.9.0/src/virtualenv.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (121)        1 2021-10-23 10:59:54.000000 virtualenv-20.9.0/src/virtualenv.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (121)     1621 2021-10-23 10:59:54.000000 virtualenv-20.9.0/src/virtualenv.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (121)      607 2021-10-23 10:59:54.000000 virtualenv-20.9.0/src/virtualenv.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (121)       11 2021-10-23 10:59:54.000000 virtualenv-20.9.0/src/virtualenv.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (121)        1 2021-10-23 10:59:54.000000 virtualenv-20.9.0/src/virtualenv.egg-info/zip-safe
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/tasks/
+-rw-r--r--   0 runner    (1001) docker     (121)     5824 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tasks/__main__zipapp.py
+-rw-r--r--   0 runner    (1001) docker     (121)    11391 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tasks/make_zipapp.py
+-rwxr-xr-x   0 runner    (1001) docker     (121)     3314 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tasks/update_embedded.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/tests/
+-rw-r--r--   0 runner    (1001) docker     (121)    12069 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/tests/integration/
+-rw-r--r--   0 runner    (1001) docker     (121)      753 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/integration/test_run_int.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3270 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/integration/test_zipapp.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/tests/unit/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/tests/unit/activation/
+-rw-r--r--   0 runner    (1001) docker     (121)     9974 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (121)      870 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_activate_this.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1686 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_activation_support.py
+-rw-r--r--   0 runner    (1001) docker     (121)      482 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_activator.py
+-rw-r--r--   0 runner    (1001) docker     (121)      643 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_bash.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1241 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_batch.py
+-rw-r--r--   0 runner    (1001) docker     (121)      367 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_csh.py
+-rw-r--r--   0 runner    (1001) docker     (121)      705 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_fish.py
+-rw-r--r--   0 runner    (1001) docker     (121)      727 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_nushell.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1265 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_powershell.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3685 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/activation/test_python_activator.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/tests/unit/config/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/tests/unit/config/cli/
+-rw-r--r--   0 runner    (1001) docker     (121)     1708 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/config/cli/test_parser.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3240 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/config/test___main__.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3380 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/config/test_env_var.py
+-rw-r--r--   0 runner    (1001) docker     (121)      738 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/config/test_ini.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.063361 virtualenv-20.9.0/tests/unit/create/
+-rw-r--r--   0 runner    (1001) docker     (121)     3960 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/create/console_app/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/create/console_app/demo/
+-rw-r--r--   0 runner    (1001) docker     (121)       69 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/console_app/demo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (121)       69 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/console_app/demo/__main__.py
+-rw-r--r--   0 runner    (1001) docker     (121)      197 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/console_app/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (121)       38 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/console_app/setup.py
+-rw-r--r--   0 runner    (1001) docker     (121)    26154 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/test_creator.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1060 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/test_interpreters.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/create/via_global_ref/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/create/via_global_ref/greet/
+-rw-r--r--   0 runner    (1001) docker     (121)      482 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/via_global_ref/greet/greet2.c
+-rw-r--r--   0 runner    (1001) docker     (121)      653 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/via_global_ref/greet/greet3.c
+-rw-r--r--   0 runner    (1001) docker     (121)      330 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/via_global_ref/greet/setup.py
+-rw-r--r--   0 runner    (1001) docker     (121)      234 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/via_global_ref/test_api.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2057 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/via_global_ref/test_build_c_ext.py
+-rw-r--r--   0 runner    (1001) docker     (121)  3354125 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/create/virtualenv-16.7.9-py2.py3-none-any.whl
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/discovery/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/discovery/py_info/
+-rw-r--r--   0 runner    (1001) docker     (121)    11457 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/discovery/py_info/test_py_info.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2141 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/discovery/py_info/test_py_info_exe_based_of.py
+-rw-r--r--   0 runner    (1001) docker     (121)     2976 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/discovery/test_discovery.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3747 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/discovery/test_py_spec.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/discovery/windows/
+-rw-r--r--   0 runner    (1001) docker     (121)     7651 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/discovery/windows/test_windows_pep514.py
+-rw-r--r--   0 runner    (1001) docker     (121)     5915 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/discovery/windows/winreg-mock-values.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.043361 virtualenv-20.9.0/tests/unit/seed/
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/seed/embed/
+-rw-r--r--   0 runner    (1001) docker     (121)      367 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/seed/embed/test_base_embed.py
+-rw-r--r--   0 runner    (1001) docker     (121)     8924 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/seed/embed/test_bootstrap_link_via_app_data.py
+-rw-r--r--   0 runner    (1001) docker     (121)     3133 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/seed/embed/test_pip_invoke.py
+drwxr-xr-x   0 runner    (1001) docker     (121)        0 2021-10-23 10:59:55.067361 virtualenv-20.9.0/tests/unit/seed/wheels/
+-rw-r--r--   0 runner    (1001) docker     (121)     2447 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/seed/wheels/test_acquire.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1130 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/seed/wheels/test_acquire_find_wheel.py
+-rw-r--r--   0 runner    (1001) docker     (121)    18214 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/seed/wheels/test_periodic_update.py
+-rw-r--r--   0 runner    (1001) docker     (121)      901 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/seed/wheels/test_wheels_util.py
+-rw-r--r--   0 runner    (1001) docker     (121)     1146 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/test_run.py
+-rw-r--r--   0 runner    (1001) docker     (121)      685 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tests/unit/test_util.py
+-rw-r--r--   0 runner    (1001) docker     (121)     4261 2021-10-23 10:59:48.000000 virtualenv-20.9.0/tox.ini
```

### Comparing `virtualenv-20.8.1/.coveragerc` & `virtualenv-20.9.0/.coveragerc`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/.github/ISSUE_TEMPLATE/config.yml` & `virtualenv-20.9.0/.github/ISSUE_TEMPLATE/config.yml`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/.github/ISSUE_TEMPLATE/feature-request.md` & `virtualenv-20.9.0/.github/ISSUE_TEMPLATE/feature-request.md`

 * *Files 16% similar despite different names*

```diff
@@ -4,19 +4,19 @@
 title: ''
 labels: enhancement
 assignees: ''
 
 ---
 
 **What's the problem this feature will solve?**
-<!-- What are you trying to do, that you are unable to achieve with pip as it currently stands? -->
+<!-- What are you trying to do, that you are unable to achieve with virtualenv as it currently stands? -->
 
 **Describe the solution you'd like**
 <!-- Clear and concise description of what you want to happen. -->
 
 <!-- Provide examples of real world use cases that this would enable and how it solves the problem described above. -->
 
 **Alternative Solutions**
-<!-- Have you tried to workaround the problem using pip or other tools? Or a different approach to solving this issue? Please elaborate here. -->
+<!-- Have you tried to workaround the problem using virtualenv or other tools? Or a different approach to solving this issue? Please elaborate here. -->
 
 **Additional context**
 <!-- Add any other context, links, etc. about the feature here. -->
```

### Comparing `virtualenv-20.8.1/.github/workflows/check.yml` & `virtualenv-20.9.0/.github/workflows/check.yml`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,18 @@
 name: check
 on:
   push:
   pull_request:
   schedule:
     - cron: "0 8 * * *"
 
+concurrency:
+  group: check-${{ github.ref }}
+  cancel-in-progress: true
+
 jobs:
   lint:
     runs-on: ubuntu-latest
     steps:
       - uses: actions/checkout@v2
       - uses: actions/setup-python@v2
       - uses: pre-commit/action@v2.0.0
@@ -26,17 +30,19 @@
         py:
           - 3.10.0-rc.1
           - 3.9
           - 3.8
           - 3.7
           - 3.6
           - 3.5
-          - pypy3
+          - pypy-3.6
+          - pypy-3.7-v7.3.6rc3
+          - pypy-3.8-v7.3.6rc3
           - 2.7
-          - pypy2
+          - pypy-2.7
         include:
           - { os: macos-latest, py: brew@py3 }
     steps:
       - name: Install OS dependencies
         run: |
           for i in 1 2 3; do
             echo "try $i" && \
```

### Comparing `virtualenv-20.8.1/.pre-commit-config.yaml` & `virtualenv-20.9.0/.pre-commit-config.yaml`

 * *Files 7% similar despite different names*

```diff
@@ -8,15 +8,15 @@
   - id: check-merge-conflict
   - id: check-yaml
   - id: check-toml
   - id: debug-statements
   - id: end-of-file-fixer
   - id: trailing-whitespace
 - repo: https://github.com/asottile/pyupgrade
-  rev: v2.26.0
+  rev: v2.29.0
   hooks:
   - id: pyupgrade
 - repo: https://github.com/PyCQA/isort
   rev: 5.9.3
   hooks:
   - id: isort
 - repo: https://github.com/psf/black
@@ -24,27 +24,27 @@
   hooks:
   - id: black
     args: [--safe]
 - repo: https://github.com/asottile/blacken-docs
   rev: v1.11.0
   hooks:
   - id: blacken-docs
-    additional_dependencies: [black==20.8b1]
+    additional_dependencies: [black==21.9b0]
 - repo: https://github.com/pre-commit/pygrep-hooks
   rev: v1.9.0
   hooks:
   - id: rst-backticks
 - repo: https://github.com/tox-dev/tox-ini-fmt
   rev: "0.5.1"
   hooks:
   - id: tox-ini-fmt
     args: ["-p", "fix_lint"]
 - repo: https://github.com/asottile/setup-cfg-fmt
-  rev: v1.17.0
+  rev: v1.18.0
   hooks:
   - id: setup-cfg-fmt
     args: [--min-py3-version, "3.5", "--max-py-version", "3.10"]
 - repo: https://github.com/PyCQA/flake8
-  rev: "3.9.2"
+  rev: "4.0.1"
   hooks:
   - id: flake8
-    additional_dependencies: ["flake8-bugbear == 21.4.3"]
+    additional_dependencies: ["flake8-bugbear == 21.9.2"]
```

### Comparing `virtualenv-20.8.1/LICENSE` & `virtualenv-20.9.0/LICENSE`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/PKG-INFO` & `virtualenv-20.9.0/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: virtualenv
-Version: 20.8.1
+Version: 20.9.0
 Summary: Virtual Python Environment builder
 Home-page: https://virtualenv.pypa.io/
 Author: Bernat Gabor
 Author-email: gaborjbernat@gmail.com
 Maintainer: Bernat Gabor
 Maintainer-email: gaborjbernat@gmail.com
 License: MIT
```

### Comparing `virtualenv-20.8.1/README.md` & `virtualenv-20.9.0/README.md`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/_static/custom.css` & `virtualenv-20.9.0/docs/_static/custom.css`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/changelog/examples.rst` & `virtualenv-20.9.0/docs/changelog/examples.rst`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/changelog/template.jinja2` & `virtualenv-20.9.0/docs/changelog/template.jinja2`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/changelog.rst` & `virtualenv-20.9.0/docs/changelog.rst`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/cli_interface.rst` & `virtualenv-20.9.0/docs/cli_interface.rst`

 * *Files 1% similar despite different names*

```diff
@@ -29,15 +29,15 @@
 
 .. _conf_file:
 
 Configuration file
 ^^^^^^^^^^^^^^^^^^
 
 virtualenv looks for a standard ini configuration file. The exact location depends on the operating system you're using,
-as determined by :pypi:`appdirs` application configuration definition. The configuration file location is printed as at
+as determined by :pypi:`platformdirs` application configuration definition. The configuration file location is printed as at
 the end of the output when ``--help`` is passed.
 
 The keys of the settings are derived from the command line option (left strip the ``-`` characters, and replace ``-``
 with ``_``). Where multiple flags are available first found wins (where order is as it shows up under the ``--help``).
 
 For example, :option:`--python <python>` would be specified as:
```

### Comparing `virtualenv-20.8.1/docs/conf.py` & `virtualenv-20.9.0/docs/conf.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/development.rst` & `virtualenv-20.9.0/docs/development.rst`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/extend.rst` & `virtualenv-20.9.0/docs/extend.rst`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/index.rst` & `virtualenv-20.9.0/docs/index.rst`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/installation.rst` & `virtualenv-20.9.0/docs/installation.rst`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/render_cli.py` & `virtualenv-20.9.0/docs/render_cli.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/docs/user_guide.rst` & `virtualenv-20.9.0/docs/user_guide.rst`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/pyproject.toml` & `virtualenv-20.9.0/pyproject.toml`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/setup.cfg` & `virtualenv-20.9.0/setup.cfg`

 * *Files 0% similar despite different names*

```diff
@@ -38,15 +38,15 @@
 	Tracker=https://github.com/pypa/virtualenv/issues
 
 [options]
 packages = find:
 install_requires = 
 	backports.entry_points_selectable>=1.0.4
 	distlib>=0.3.1,<1
-	filelock>=3.0.0,<4
+	filelock>=3.2,<4
 	platformdirs>=2,<3
 	six>=1.9.0,<2   # keep it >=1.9.0 as it may cause problems on LTS platforms
 	importlib-metadata>=0.12;python_version<"3.8"
 	importlib-resources>=1.0;python_version<"3.7"
 	pathlib2>=2.3.3,<3;python_version < '3.4' and sys.platform != 'win32'
 python_requires = >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*
 package_dir =
```

### Comparing `virtualenv-20.8.1/src/virtualenv/__main__.py` & `virtualenv-20.9.0/src/virtualenv/__main__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/activator.py` & `virtualenv-20.9.0/src/virtualenv/activation/activator.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,24 +1,25 @@
 from __future__ import absolute_import, unicode_literals
 
+import os
 from abc import ABCMeta, abstractmethod
 
 from six import add_metaclass
 
 
 @add_metaclass(ABCMeta)
 class Activator(object):
     """Generates an activate script for the virtual environment"""
 
     def __init__(self, options):
         """Create a new activator generator.
 
         :param options: the parsed options as defined within :meth:`add_parser_arguments`
         """
-        self.flag_prompt = options.prompt
+        self.flag_prompt = os.path.basename(os.getcwd()) if options.prompt == "." else options.prompt
 
     @classmethod
     def supports(cls, interpreter):
         """Check if the activation script is supported in the given interpreter.
 
         :param interpreter: the interpreter we need to support
         :return: ``True`` if supported, ``False`` otherwise
```

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/bash/activate.sh` & `virtualenv-20.9.0/src/virtualenv/activation/bash/activate.sh`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/batch/__init__.py` & `virtualenv-20.9.0/src/virtualenv/activation/batch/__init__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/batch/activate.bat` & `virtualenv-20.9.0/src/virtualenv/activation/batch/activate.bat`

 * *Files 1% similar despite different names*

```diff
@@ -13,15 +13,14 @@
     )
 )
 if not defined VIRTUAL_ENV_DISABLE_PROMPT (
     set "ENV_PROMPT=__VIRTUAL_PROMPT__"
     if NOT DEFINED ENV_PROMPT (
         for %%d in ("%VIRTUAL_ENV%") do set "ENV_PROMPT=(%%~nxd) "
     )
-    )
     set "PROMPT=%ENV_PROMPT%%PROMPT%"
 )
 
 REM Don't use () to avoid problems with them in %PATH%
 if defined _OLD_VIRTUAL_PYTHONHOME goto ENDIFVHOME
     set "_OLD_VIRTUAL_PYTHONHOME=%PYTHONHOME%"
 :ENDIFVHOME
```

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/cshell/activate.csh` & `virtualenv-20.9.0/src/virtualenv/activation/cshell/activate.csh`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/fish/activate.fish` & `virtualenv-20.9.0/src/virtualenv/activation/fish/activate.fish`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/nushell/__init__.py` & `virtualenv-20.9.0/src/virtualenv/activation/nushell/__init__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/nushell/activate.nu` & `virtualenv-20.9.0/src/virtualenv/activation/nushell/activate.nu`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/powershell/activate.ps1` & `virtualenv-20.9.0/src/virtualenv/activation/powershell/activate.ps1`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/python/__init__.py` & `virtualenv-20.9.0/src/virtualenv/activation/python/__init__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/python/activate_this.py` & `virtualenv-20.9.0/src/virtualenv/activation/python/activate_this.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/activation/via_template.py` & `virtualenv-20.9.0/src/virtualenv/activation/via_template.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/app_data/__init__.py` & `virtualenv-20.9.0/src/virtualenv/app_data/__init__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/app_data/base.py` & `virtualenv-20.9.0/src/virtualenv/app_data/base.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/app_data/na.py` & `virtualenv-20.9.0/src/virtualenv/app_data/na.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/app_data/read_only.py` & `virtualenv-20.9.0/src/virtualenv/app_data/read_only.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/app_data/via_disk_folder.py` & `virtualenv-20.9.0/src/virtualenv/app_data/via_disk_folder.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/app_data/via_tempdir.py` & `virtualenv-20.9.0/src/virtualenv/app_data/via_tempdir.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/config/cli/parser.py` & `virtualenv-20.9.0/src/virtualenv/config/cli/parser.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/config/convert.py` & `virtualenv-20.9.0/src/virtualenv/config/convert.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/config/env_var.py` & `virtualenv-20.9.0/src/virtualenv/config/env_var.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/config/ini.py` & `virtualenv-20.9.0/src/virtualenv/config/ini.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/creator.py` & `virtualenv-20.9.0/src/virtualenv/create/creator.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/debug.py` & `virtualenv-20.9.0/src/virtualenv/create/debug.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/describe.py` & `virtualenv-20.9.0/src/virtualenv/create/describe.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/pyenv_cfg.py` & `virtualenv-20.9.0/src/virtualenv/create/pyenv_cfg.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/_virtualenv.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/_virtualenv.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/api.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/api.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/builtin_way.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/builtin_way.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/common.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/common.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/cpython2.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/cpython2.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/cpython3.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/cpython3.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/cpython/mac_os.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/cpython/mac_os.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/pypy/common.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/pypy/common.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/pypy/pypy2.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/pypy/pypy2.py`

 * *Files 1% similar despite different names*

```diff
@@ -108,14 +108,14 @@
 
     @classmethod
     def modules(cls):
         return super(Pypy2Windows, cls).modules() + ["ntpath"]
 
     @classmethod
     def _shared_libs(cls):
-        return ["libpypy-c.dll", "libffi-7.dll"]
+        return ["libpypy-c.dll", "libffi-7.dll", "libffi-8.dll"]
 
     @classmethod
     def sources(cls, interpreter):
         for src in super(Pypy2Windows, cls).sources(interpreter):
             yield src
         yield PathRefToDest(Path(interpreter.system_prefix) / "libs", dest=lambda self, s: self.dest / s.name)
```

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/pypy/pypy3.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/pypy/pypy3.py`

 * *Files 20% similar despite different names*

```diff
@@ -24,42 +24,52 @@
 
 class PyPy3Posix(PyPy3, PosixSupports):
     """PyPy 2 on POSIX"""
 
     @property
     def stdlib(self):
         """PyPy3 respects sysconfig only for the host python, virtual envs is instead lib/pythonx.y/site-packages"""
-        return self.dest / "lib" / "python{}".format(self.interpreter.version_release_str) / "site-packages"
+        return self.dest / "lib" / "pypy{}".format(self.interpreter.version_release_str) / "site-packages"
 
     @classmethod
     def _shared_libs(cls):
         return ["libpypy3-c.so", "libpypy3-c.dylib"]
 
     def to_lib(self, src):
         return self.dest / "lib" / src.name
 
     @classmethod
     def sources(cls, interpreter):
         for src in super(PyPy3Posix, cls).sources(interpreter):
             yield src
+        # Also copy/symlink anything under prefix/lib, which, for "portable"
+        # PyPy builds, includes the tk,tcl runtime and a number of shared
+        # objects. In distro-specific builds or on conda this should be empty
+        # (on PyPy3.8+ it will, like on CPython, hold the stdlib).
         host_lib = Path(interpreter.system_prefix) / "lib"
+        stdlib = Path(interpreter.system_stdlib)
         if host_lib.exists() and host_lib.is_dir():
             for path in host_lib.iterdir():
+                if stdlib == path:
+                    # For PyPy3.8+ the stdlib lives in lib/pypy3.8
+                    # We need to avoid creating a symlink to it since that
+                    # will defeat the purpose of a virtualenv
+                    continue
                 yield PathRefToDest(path, dest=cls.to_lib)
 
 
 class Pypy3Windows(PyPy3, WindowsSupports):
-    """PyPy 2 on Windows"""
+    """PyPy 3 on Windows"""
 
     @property
     def stdlib(self):
         """PyPy3 respects sysconfig only for the host python, virtual envs is instead Lib/site-packages"""
         return self.dest / "Lib" / "site-packages"
 
     @property
     def bin_dir(self):
         """PyPy3 needs to fallback to pypy definition"""
         return self.dest / "Scripts"
 
     @classmethod
     def _shared_libs(cls):
-        return ["libpypy3-c.dll", "libffi-7.dll"]
+        return ["libpypy3-c.dll", "libffi-7.dll", "libffi-8.dll"]
```

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/python2/python2.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/python2/python2.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/python2/site.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/python2/site.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/ref.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/ref.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/builtin/via_global_self_do.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/builtin/via_global_self_do.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/store.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/store.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/create/via_global_ref/venv.py` & `virtualenv-20.9.0/src/virtualenv/create/via_global_ref/venv.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/discovery/builtin.py` & `virtualenv-20.9.0/src/virtualenv/discovery/builtin.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/discovery/cached_py_info.py` & `virtualenv-20.9.0/src/virtualenv/discovery/cached_py_info.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/discovery/discover.py` & `virtualenv-20.9.0/src/virtualenv/discovery/discover.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/discovery/py_info.py` & `virtualenv-20.9.0/src/virtualenv/discovery/py_info.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/discovery/py_spec.py` & `virtualenv-20.9.0/src/virtualenv/discovery/py_spec.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/discovery/windows/__init__.py` & `virtualenv-20.9.0/src/virtualenv/discovery/windows/__init__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/discovery/windows/pep514.py` & `virtualenv-20.9.0/src/virtualenv/discovery/windows/pep514.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/info.py` & `virtualenv-20.9.0/src/virtualenv/info.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/report.py` & `virtualenv-20.9.0/src/virtualenv/report.py`

 * *Files 15% similar despite different names*

```diff
@@ -20,21 +20,17 @@
 
 def setup_report(verbosity, show_pid=False):
     _clean_handlers(LOGGER)
     if verbosity > MAX_LEVEL:
         verbosity = MAX_LEVEL  # pragma: no cover
     level = LEVELS[verbosity]
     msg_format = "%(message)s"
-    filelock_logger = logging.getLogger("filelock")
     if level <= logging.DEBUG:
         locate = "module"
         msg_format = "%(relativeCreated)d {} [%(levelname)s %({})s:%(lineno)d]".format(msg_format, locate)
-        filelock_logger.setLevel(level)
-    else:
-        filelock_logger.setLevel(logging.WARN)
     if show_pid:
         msg_format = "[%(process)d] " + msg_format
     formatter = logging.Formatter(ensure_str(msg_format))
     stream_handler = logging.StreamHandler(stream=sys.stdout)
     stream_handler.setLevel(level)
     LOGGER.setLevel(logging.NOTSET)
     stream_handler.setFormatter(formatter)
```

### Comparing `virtualenv-20.8.1/src/virtualenv/run/__init__.py` & `virtualenv-20.9.0/src/virtualenv/run/__init__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/run/plugin/activators.py` & `virtualenv-20.9.0/src/virtualenv/run/plugin/activators.py`

 * *Files 6% similar despite different names*

```diff
@@ -39,15 +39,18 @@
             self._extract_activators(self.default) if options.activators is self.default else options.activators
         )
         self.active = {k: v for k, v in self.possible.items() if k in selected_activators}
         self.parser.add_argument(
             "--prompt",
             dest="prompt",
             metavar="prompt",
-            help="provides an alternative prompt prefix for this environment",
+            help=(
+                "provides an alternative prompt prefix for this environment "
+                "(value of . means name of the current working directory)"
+            ),
             default=None,
         )
         for activator in self.active.values():
             activator.add_parser_arguments(self.parser, self.interpreter)
 
     def create(self, options):
         return [activator_class(options) for activator_class in self.active.values()]
```

### Comparing `virtualenv-20.8.1/src/virtualenv/run/plugin/base.py` & `virtualenv-20.9.0/src/virtualenv/run/plugin/base.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/run/plugin/creators.py` & `virtualenv-20.9.0/src/virtualenv/run/plugin/creators.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/run/plugin/discovery.py` & `virtualenv-20.9.0/src/virtualenv/run/plugin/discovery.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/run/plugin/seeders.py` & `virtualenv-20.9.0/src/virtualenv/run/plugin/seeders.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/run/session.py` & `virtualenv-20.9.0/src/virtualenv/run/session.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/embed/base_embed.py` & `virtualenv-20.9.0/src/virtualenv/seed/embed/base_embed.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/embed/pip_invoke.py` & `virtualenv-20.9.0/src/virtualenv/seed/embed/pip_invoke.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/pip_install/base.py` & `virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/pip_install/base.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/pip_install/copy.py` & `virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/pip_install/copy.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/pip_install/symlink.py` & `virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/pip_install/symlink.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/embed/via_app_data/via_app_data.py` & `virtualenv-20.9.0/src/virtualenv/seed/embed/via_app_data/via_app_data.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/seeder.py` & `virtualenv-20.9.0/src/virtualenv/seed/seeder.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/acquire.py` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/acquire.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/bundle.py` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/bundle.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/__init__.py` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,36 +2,36 @@
 
 from virtualenv.seed.wheels.util import Wheel
 from virtualenv.util.path import Path
 
 BUNDLE_FOLDER = Path(__file__).absolute().parent
 BUNDLE_SUPPORT = {
     "3.10": {
-        "pip": "pip-21.2.4-py3-none-any.whl",
-        "setuptools": "setuptools-58.1.0-py3-none-any.whl",
+        "pip": "pip-21.3.1-py3-none-any.whl",
+        "setuptools": "setuptools-58.3.0-py3-none-any.whl",
         "wheel": "wheel-0.37.0-py2.py3-none-any.whl",
     },
     "3.9": {
-        "pip": "pip-21.2.4-py3-none-any.whl",
-        "setuptools": "setuptools-58.1.0-py3-none-any.whl",
+        "pip": "pip-21.3.1-py3-none-any.whl",
+        "setuptools": "setuptools-58.3.0-py3-none-any.whl",
         "wheel": "wheel-0.37.0-py2.py3-none-any.whl",
     },
     "3.8": {
-        "pip": "pip-21.2.4-py3-none-any.whl",
-        "setuptools": "setuptools-58.1.0-py3-none-any.whl",
+        "pip": "pip-21.3.1-py3-none-any.whl",
+        "setuptools": "setuptools-58.3.0-py3-none-any.whl",
         "wheel": "wheel-0.37.0-py2.py3-none-any.whl",
     },
     "3.7": {
-        "pip": "pip-21.2.4-py3-none-any.whl",
-        "setuptools": "setuptools-58.1.0-py3-none-any.whl",
+        "pip": "pip-21.3.1-py3-none-any.whl",
+        "setuptools": "setuptools-58.3.0-py3-none-any.whl",
         "wheel": "wheel-0.37.0-py2.py3-none-any.whl",
     },
     "3.6": {
-        "pip": "pip-21.2.4-py3-none-any.whl",
-        "setuptools": "setuptools-58.1.0-py3-none-any.whl",
+        "pip": "pip-21.3.1-py3-none-any.whl",
+        "setuptools": "setuptools-58.3.0-py3-none-any.whl",
         "wheel": "wheel-0.37.0-py2.py3-none-any.whl",
     },
     "3.5": {
         "pip": "pip-20.3.4-py2.py3-none-any.whl",
         "setuptools": "setuptools-50.3.2-py3-none-any.whl",
         "wheel": "wheel-0.37.0-py2.py3-none-any.whl",
     },
```

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/pip-20.3.4-py2.py3-none-any.whl` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/pip-20.3.4-py2.py3-none-any.whl`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/pip-21.2.4-py3-none-any.whl` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/pip-21.3.1-py3-none-any.whl`

 * *Files 19% similar despite different names*

#### zipinfo {}

```diff
@@ -1,404 +1,417 @@
-Zip file size: 1555100 bytes, number of entries: 402
--rw-r--r--  2.0 unx      357 b- defN 21-Aug-12 14:54 pip/__init__.py
--rw-r--r--  2.0 unx     1198 b- defN 21-Aug-12 14:54 pip/__main__.py
--rw-r--r--  2.0 unx      286 b- defN 21-Aug-12 14:54 pip/py.typed
--rw-r--r--  2.0 unx      573 b- defN 21-Aug-12 14:54 pip/_internal/__init__.py
--rw-r--r--  2.0 unx    10121 b- defN 21-Aug-12 14:54 pip/_internal/build_env.py
--rw-r--r--  2.0 unx     9958 b- defN 21-Aug-12 14:54 pip/_internal/cache.py
--rw-r--r--  2.0 unx    13725 b- defN 21-Aug-12 14:54 pip/_internal/configuration.py
--rw-r--r--  2.0 unx    13170 b- defN 21-Aug-12 14:54 pip/_internal/exceptions.py
--rw-r--r--  2.0 unx      351 b- defN 21-Aug-12 14:54 pip/_internal/main.py
--rw-r--r--  2.0 unx     7063 b- defN 21-Aug-12 14:54 pip/_internal/pyproject.py
--rw-r--r--  2.0 unx     6484 b- defN 21-Aug-12 14:54 pip/_internal/self_outdated_check.py
--rw-r--r--  2.0 unx    11740 b- defN 21-Aug-12 14:54 pip/_internal/wheel_builder.py
--rw-r--r--  2.0 unx      132 b- defN 21-Aug-12 14:54 pip/_internal/cli/__init__.py
--rw-r--r--  2.0 unx     6399 b- defN 21-Aug-12 14:54 pip/_internal/cli/autocompletion.py
--rw-r--r--  2.0 unx     7596 b- defN 21-Aug-12 14:54 pip/_internal/cli/base_command.py
--rw-r--r--  2.0 unx    28283 b- defN 21-Aug-12 14:54 pip/_internal/cli/cmdoptions.py
--rw-r--r--  2.0 unx      760 b- defN 21-Aug-12 14:54 pip/_internal/cli/command_context.py
--rw-r--r--  2.0 unx     2472 b- defN 21-Aug-12 14:54 pip/_internal/cli/main.py
--rw-r--r--  2.0 unx     2614 b- defN 21-Aug-12 14:54 pip/_internal/cli/main_parser.py
--rw-r--r--  2.0 unx    10788 b- defN 21-Aug-12 14:54 pip/_internal/cli/parser.py
--rw-r--r--  2.0 unx     8300 b- defN 21-Aug-12 14:54 pip/_internal/cli/progress_bars.py
--rw-r--r--  2.0 unx    16548 b- defN 21-Aug-12 14:54 pip/_internal/cli/req_command.py
--rw-r--r--  2.0 unx     5076 b- defN 21-Aug-12 14:54 pip/_internal/cli/spinners.py
--rw-r--r--  2.0 unx      116 b- defN 21-Aug-12 14:54 pip/_internal/cli/status_codes.py
--rw-r--r--  2.0 unx     3776 b- defN 21-Aug-12 14:54 pip/_internal/commands/__init__.py
--rw-r--r--  2.0 unx     7237 b- defN 21-Aug-12 14:54 pip/_internal/commands/cache.py
--rw-r--r--  2.0 unx     1570 b- defN 21-Aug-12 14:54 pip/_internal/commands/check.py
--rw-r--r--  2.0 unx     2914 b- defN 21-Aug-12 14:54 pip/_internal/commands/completion.py
--rw-r--r--  2.0 unx     8962 b- defN 21-Aug-12 14:54 pip/_internal/commands/configuration.py
--rw-r--r--  2.0 unx     6647 b- defN 21-Aug-12 14:54 pip/_internal/commands/debug.py
--rw-r--r--  2.0 unx     4949 b- defN 21-Aug-12 14:54 pip/_internal/commands/download.py
--rw-r--r--  2.0 unx     2785 b- defN 21-Aug-12 14:54 pip/_internal/commands/freeze.py
--rw-r--r--  2.0 unx     1664 b- defN 21-Aug-12 14:54 pip/_internal/commands/hash.py
--rw-r--r--  2.0 unx     1132 b- defN 21-Aug-12 14:54 pip/_internal/commands/help.py
--rw-r--r--  2.0 unx     4781 b- defN 21-Aug-12 14:54 pip/_internal/commands/index.py
--rw-r--r--  2.0 unx    27493 b- defN 21-Aug-12 14:54 pip/_internal/commands/install.py
--rw-r--r--  2.0 unx    11753 b- defN 21-Aug-12 14:54 pip/_internal/commands/list.py
--rw-r--r--  2.0 unx     5543 b- defN 21-Aug-12 14:54 pip/_internal/commands/search.py
--rw-r--r--  2.0 unx     7974 b- defN 21-Aug-12 14:54 pip/_internal/commands/show.py
--rw-r--r--  2.0 unx     3480 b- defN 21-Aug-12 14:54 pip/_internal/commands/uninstall.py
--rw-r--r--  2.0 unx     6189 b- defN 21-Aug-12 14:54 pip/_internal/commands/wheel.py
--rw-r--r--  2.0 unx      858 b- defN 21-Aug-12 14:54 pip/_internal/distributions/__init__.py
--rw-r--r--  2.0 unx     1206 b- defN 21-Aug-12 14:54 pip/_internal/distributions/base.py
--rw-r--r--  2.0 unx      645 b- defN 21-Aug-12 14:54 pip/_internal/distributions/installed.py
--rw-r--r--  2.0 unx     3862 b- defN 21-Aug-12 14:54 pip/_internal/distributions/sdist.py
--rw-r--r--  2.0 unx     1183 b- defN 21-Aug-12 14:54 pip/_internal/distributions/wheel.py
--rw-r--r--  2.0 unx       30 b- defN 21-Aug-12 14:54 pip/_internal/index/__init__.py
--rw-r--r--  2.0 unx    17645 b- defN 21-Aug-12 14:54 pip/_internal/index/collector.py
--rw-r--r--  2.0 unx    36138 b- defN 21-Aug-12 14:54 pip/_internal/index/package_finder.py
--rw-r--r--  2.0 unx     6557 b- defN 21-Aug-12 14:54 pip/_internal/index/sources.py
--rw-r--r--  2.0 unx    13292 b- defN 21-Aug-12 14:54 pip/_internal/locations/__init__.py
--rw-r--r--  2.0 unx     5871 b- defN 21-Aug-12 14:54 pip/_internal/locations/_distutils.py
--rw-r--r--  2.0 unx     7918 b- defN 21-Aug-12 14:54 pip/_internal/locations/_sysconfig.py
--rw-r--r--  2.0 unx     1579 b- defN 21-Aug-12 14:54 pip/_internal/locations/base.py
--rw-r--r--  2.0 unx     1576 b- defN 21-Aug-12 14:54 pip/_internal/metadata/__init__.py
--rw-r--r--  2.0 unx     7928 b- defN 21-Aug-12 14:54 pip/_internal/metadata/base.py
--rw-r--r--  2.0 unx     5200 b- defN 21-Aug-12 14:54 pip/_internal/metadata/pkg_resources.py
--rw-r--r--  2.0 unx       63 b- defN 21-Aug-12 14:54 pip/_internal/models/__init__.py
--rw-r--r--  2.0 unx      946 b- defN 21-Aug-12 14:54 pip/_internal/models/candidate.py
--rw-r--r--  2.0 unx     6262 b- defN 21-Aug-12 14:54 pip/_internal/models/direct_url.py
--rw-r--r--  2.0 unx     2557 b- defN 21-Aug-12 14:54 pip/_internal/models/format_control.py
--rw-r--r--  2.0 unx     1058 b- defN 21-Aug-12 14:54 pip/_internal/models/index.py
--rw-r--r--  2.0 unx     9809 b- defN 21-Aug-12 14:54 pip/_internal/models/link.py
--rw-r--r--  2.0 unx      738 b- defN 21-Aug-12 14:54 pip/_internal/models/scheme.py
--rw-r--r--  2.0 unx     4474 b- defN 21-Aug-12 14:54 pip/_internal/models/search_scope.py
--rw-r--r--  2.0 unx     1877 b- defN 21-Aug-12 14:54 pip/_internal/models/selection_prefs.py
--rw-r--r--  2.0 unx     3870 b- defN 21-Aug-12 14:54 pip/_internal/models/target_python.py
--rw-r--r--  2.0 unx     3541 b- defN 21-Aug-12 14:54 pip/_internal/models/wheel.py
--rw-r--r--  2.0 unx       50 b- defN 21-Aug-12 14:54 pip/_internal/network/__init__.py
--rw-r--r--  2.0 unx    11645 b- defN 21-Aug-12 14:54 pip/_internal/network/auth.py
--rw-r--r--  2.0 unx     2100 b- defN 21-Aug-12 14:54 pip/_internal/network/cache.py
--rw-r--r--  2.0 unx     6016 b- defN 21-Aug-12 14:54 pip/_internal/network/download.py
--rw-r--r--  2.0 unx     7615 b- defN 21-Aug-12 14:54 pip/_internal/network/lazy_wheel.py
--rw-r--r--  2.0 unx    16582 b- defN 21-Aug-12 14:54 pip/_internal/network/session.py
--rw-r--r--  2.0 unx     4059 b- defN 21-Aug-12 14:54 pip/_internal/network/utils.py
--rw-r--r--  2.0 unx     1791 b- defN 21-Aug-12 14:54 pip/_internal/network/xmlrpc.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_internal/operations/__init__.py
--rw-r--r--  2.0 unx     5295 b- defN 21-Aug-12 14:54 pip/_internal/operations/check.py
--rw-r--r--  2.0 unx    10556 b- defN 21-Aug-12 14:54 pip/_internal/operations/freeze.py
--rw-r--r--  2.0 unx    24848 b- defN 21-Aug-12 14:54 pip/_internal/operations/prepare.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_internal/operations/build/__init__.py
--rw-r--r--  2.0 unx     1165 b- defN 21-Aug-12 14:54 pip/_internal/operations/build/metadata.py
--rw-r--r--  2.0 unx     1917 b- defN 21-Aug-12 14:54 pip/_internal/operations/build/metadata_legacy.py
--rw-r--r--  2.0 unx     1106 b- defN 21-Aug-12 14:54 pip/_internal/operations/build/wheel.py
--rw-r--r--  2.0 unx     3227 b- defN 21-Aug-12 14:54 pip/_internal/operations/build/wheel_legacy.py
--rw-r--r--  2.0 unx       51 b- defN 21-Aug-12 14:54 pip/_internal/operations/install/__init__.py
--rw-r--r--  2.0 unx     1396 b- defN 21-Aug-12 14:54 pip/_internal/operations/install/editable_legacy.py
--rw-r--r--  2.0 unx     4405 b- defN 21-Aug-12 14:54 pip/_internal/operations/install/legacy.py
--rw-r--r--  2.0 unx    29466 b- defN 21-Aug-12 14:54 pip/_internal/operations/install/wheel.py
--rw-r--r--  2.0 unx     2831 b- defN 21-Aug-12 14:54 pip/_internal/req/__init__.py
--rw-r--r--  2.0 unx    15826 b- defN 21-Aug-12 14:54 pip/_internal/req/constructors.py
--rw-r--r--  2.0 unx    17408 b- defN 21-Aug-12 14:54 pip/_internal/req/req_file.py
--rw-r--r--  2.0 unx    31671 b- defN 21-Aug-12 14:54 pip/_internal/req/req_install.py
--rw-r--r--  2.0 unx     7572 b- defN 21-Aug-12 14:54 pip/_internal/req/req_set.py
--rw-r--r--  2.0 unx     4182 b- defN 21-Aug-12 14:54 pip/_internal/req/req_tracker.py
--rw-r--r--  2.0 unx    23821 b- defN 21-Aug-12 14:54 pip/_internal/req/req_uninstall.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_internal/resolution/__init__.py
--rw-r--r--  2.0 unx      557 b- defN 21-Aug-12 14:54 pip/_internal/resolution/base.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_internal/resolution/legacy/__init__.py
--rw-r--r--  2.0 unx    17552 b- defN 21-Aug-12 14:54 pip/_internal/resolution/legacy/resolver.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/__init__.py
--rw-r--r--  2.0 unx     5290 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/base.py
--rw-r--r--  2.0 unx    18842 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/candidates.py
--rw-r--r--  2.0 unx    26859 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/factory.py
--rw-r--r--  2.0 unx     5285 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/found_candidates.py
--rw-r--r--  2.0 unx     8420 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/provider.py
--rw-r--r--  2.0 unx     2600 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/reporter.py
--rw-r--r--  2.0 unx     5455 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/requirements.py
--rw-r--r--  2.0 unx    10523 b- defN 21-Aug-12 14:54 pip/_internal/resolution/resolvelib/resolver.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_internal/utils/__init__.py
--rw-r--r--  2.0 unx     1015 b- defN 21-Aug-12 14:54 pip/_internal/utils/_log.py
--rw-r--r--  2.0 unx     1185 b- defN 21-Aug-12 14:54 pip/_internal/utils/appdirs.py
--rw-r--r--  2.0 unx     1884 b- defN 21-Aug-12 14:54 pip/_internal/utils/compat.py
--rw-r--r--  2.0 unx     5454 b- defN 21-Aug-12 14:54 pip/_internal/utils/compatibility_tags.py
--rw-r--r--  2.0 unx      242 b- defN 21-Aug-12 14:54 pip/_internal/utils/datetime.py
--rw-r--r--  2.0 unx     3200 b- defN 21-Aug-12 14:54 pip/_internal/utils/deprecation.py
--rw-r--r--  2.0 unx     2994 b- defN 21-Aug-12 14:54 pip/_internal/utils/direct_url_helpers.py
--rw-r--r--  2.0 unx     1249 b- defN 21-Aug-12 14:54 pip/_internal/utils/distutils_args.py
--rw-r--r--  2.0 unx     1169 b- defN 21-Aug-12 14:54 pip/_internal/utils/encoding.py
--rw-r--r--  2.0 unx     1055 b- defN 21-Aug-12 14:54 pip/_internal/utils/entrypoints.py
--rw-r--r--  2.0 unx     5893 b- defN 21-Aug-12 14:54 pip/_internal/utils/filesystem.py
--rw-r--r--  2.0 unx      761 b- defN 21-Aug-12 14:54 pip/_internal/utils/filetypes.py
--rw-r--r--  2.0 unx     3170 b- defN 21-Aug-12 14:54 pip/_internal/utils/glibc.py
--rw-r--r--  2.0 unx     5167 b- defN 21-Aug-12 14:54 pip/_internal/utils/hashes.py
--rw-r--r--  2.0 unx      810 b- defN 21-Aug-12 14:54 pip/_internal/utils/inject_securetransport.py
--rw-r--r--  2.0 unx    12344 b- defN 21-Aug-12 14:54 pip/_internal/utils/logging.py
--rw-r--r--  2.0 unx    23644 b- defN 21-Aug-12 14:54 pip/_internal/utils/misc.py
--rw-r--r--  2.0 unx     1329 b- defN 21-Aug-12 14:54 pip/_internal/utils/models.py
--rw-r--r--  2.0 unx     2900 b- defN 21-Aug-12 14:54 pip/_internal/utils/packaging.py
--rw-r--r--  2.0 unx     3224 b- defN 21-Aug-12 14:54 pip/_internal/utils/parallel.py
--rw-r--r--  2.0 unx     1106 b- defN 21-Aug-12 14:54 pip/_internal/utils/pkg_resources.py
--rw-r--r--  2.0 unx     5047 b- defN 21-Aug-12 14:54 pip/_internal/utils/setuptools_build.py
--rw-r--r--  2.0 unx    10043 b- defN 21-Aug-12 14:54 pip/_internal/utils/subprocess.py
--rw-r--r--  2.0 unx     7950 b- defN 21-Aug-12 14:54 pip/_internal/utils/temp_dir.py
--rw-r--r--  2.0 unx     9050 b- defN 21-Aug-12 14:54 pip/_internal/utils/unpacking.py
--rw-r--r--  2.0 unx     1798 b- defN 21-Aug-12 14:54 pip/_internal/utils/urls.py
--rw-r--r--  2.0 unx     3564 b- defN 21-Aug-12 14:54 pip/_internal/utils/virtualenv.py
--rw-r--r--  2.0 unx     6290 b- defN 21-Aug-12 14:54 pip/_internal/utils/wheel.py
--rw-r--r--  2.0 unx      596 b- defN 21-Aug-12 14:54 pip/_internal/vcs/__init__.py
--rw-r--r--  2.0 unx     2962 b- defN 21-Aug-12 14:54 pip/_internal/vcs/bazaar.py
--rw-r--r--  2.0 unx    17347 b- defN 21-Aug-12 14:54 pip/_internal/vcs/git.py
--rw-r--r--  2.0 unx     5076 b- defN 21-Aug-12 14:54 pip/_internal/vcs/mercurial.py
--rw-r--r--  2.0 unx    11866 b- defN 21-Aug-12 14:54 pip/_internal/vcs/subversion.py
--rw-r--r--  2.0 unx    23276 b- defN 21-Aug-12 14:54 pip/_internal/vcs/versioncontrol.py
--rw-r--r--  2.0 unx     4703 b- defN 21-Aug-12 14:54 pip/_vendor/__init__.py
--rw-r--r--  2.0 unx    25907 b- defN 21-Aug-12 14:54 pip/_vendor/appdirs.py
--rw-r--r--  2.0 unx    43628 b- defN 21-Aug-12 14:54 pip/_vendor/distro.py
--rw-r--r--  2.0 unx   273394 b- defN 21-Aug-12 14:54 pip/_vendor/pyparsing.py
--rw-r--r--  2.0 unx    34549 b- defN 21-Aug-12 14:54 pip/_vendor/six.py
--rw-r--r--  2.0 unx      364 b- defN 21-Aug-12 14:54 pip/_vendor/vendor.txt
--rw-r--r--  2.0 unx      302 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/__init__.py
--rw-r--r--  2.0 unx     1295 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/_cmd.py
--rw-r--r--  2.0 unx     4882 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/adapter.py
--rw-r--r--  2.0 unx      805 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/cache.py
--rw-r--r--  2.0 unx      695 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/compat.py
--rw-r--r--  2.0 unx    14149 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/controller.py
--rw-r--r--  2.0 unx     2533 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/filewrapper.py
--rw-r--r--  2.0 unx     4070 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/heuristics.py
--rw-r--r--  2.0 unx     7091 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/serialize.py
--rw-r--r--  2.0 unx      690 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/wrapper.py
--rw-r--r--  2.0 unx       86 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/caches/__init__.py
--rw-r--r--  2.0 unx     4153 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/caches/file_cache.py
--rw-r--r--  2.0 unx      856 b- defN 21-Aug-12 14:54 pip/_vendor/cachecontrol/caches/redis_cache.py
--rw-r--r--  2.0 unx       62 b- defN 21-Aug-12 14:54 pip/_vendor/certifi/__init__.py
--rw-r--r--  2.0 unx      255 b- defN 21-Aug-12 14:54 pip/_vendor/certifi/__main__.py
--rw-r--r--  2.0 unx   259465 b- defN 21-Aug-12 14:54 pip/_vendor/certifi/cacert.pem
--rw-r--r--  2.0 unx     2840 b- defN 21-Aug-12 14:54 pip/_vendor/certifi/core.py
--rw-r--r--  2.0 unx     3271 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/__init__.py
--rw-r--r--  2.0 unx    31254 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/big5freq.py
--rw-r--r--  2.0 unx     1757 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/big5prober.py
--rw-r--r--  2.0 unx     9411 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/chardistribution.py
--rw-r--r--  2.0 unx     3839 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/charsetgroupprober.py
--rw-r--r--  2.0 unx     5110 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/charsetprober.py
--rw-r--r--  2.0 unx     3590 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/codingstatemachine.py
--rw-r--r--  2.0 unx     1200 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/compat.py
--rw-r--r--  2.0 unx     1855 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/cp949prober.py
--rw-r--r--  2.0 unx     1661 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/enums.py
--rw-r--r--  2.0 unx     3950 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/escprober.py
--rw-r--r--  2.0 unx    10510 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/escsm.py
--rw-r--r--  2.0 unx     3749 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/eucjpprober.py
--rw-r--r--  2.0 unx    13546 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/euckrfreq.py
--rw-r--r--  2.0 unx     1748 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/euckrprober.py
--rw-r--r--  2.0 unx    31621 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/euctwfreq.py
--rw-r--r--  2.0 unx     1747 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/euctwprober.py
--rw-r--r--  2.0 unx    20715 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/gb2312freq.py
--rw-r--r--  2.0 unx     1754 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/gb2312prober.py
--rw-r--r--  2.0 unx    13838 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/hebrewprober.py
--rw-r--r--  2.0 unx    25777 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/jisfreq.py
--rw-r--r--  2.0 unx    19643 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/jpcntx.py
--rw-r--r--  2.0 unx   105697 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/langbulgarianmodel.py
--rw-r--r--  2.0 unx    99571 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/langgreekmodel.py
--rw-r--r--  2.0 unx    98776 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/langhebrewmodel.py
--rw-r--r--  2.0 unx   102498 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/langhungarianmodel.py
--rw-r--r--  2.0 unx   131180 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/langrussianmodel.py
--rw-r--r--  2.0 unx   103312 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/langthaimodel.py
--rw-r--r--  2.0 unx    95946 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/langturkishmodel.py
--rw-r--r--  2.0 unx     5370 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/latin1prober.py
--rw-r--r--  2.0 unx     3413 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/mbcharsetprober.py
--rw-r--r--  2.0 unx     2012 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/mbcsgroupprober.py
--rw-r--r--  2.0 unx    25481 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/mbcssm.py
--rw-r--r--  2.0 unx     6136 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/sbcharsetprober.py
--rw-r--r--  2.0 unx     4309 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/sbcsgroupprober.py
--rw-r--r--  2.0 unx     3774 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/sjisprober.py
--rw-r--r--  2.0 unx    12503 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/universaldetector.py
--rw-r--r--  2.0 unx     2766 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/utf8prober.py
--rw-r--r--  2.0 unx      242 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/version.py
--rw-r--r--  2.0 unx        1 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/cli/__init__.py
--rw-r--r--  2.0 unx     2747 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/cli/chardetect.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/metadata/__init__.py
--rw-r--r--  2.0 unx    19474 b- defN 21-Aug-12 14:54 pip/_vendor/chardet/metadata/languages.py
--rw-r--r--  2.0 unx      239 b- defN 21-Aug-12 14:54 pip/_vendor/colorama/__init__.py
--rw-r--r--  2.0 unx     2522 b- defN 21-Aug-12 14:54 pip/_vendor/colorama/ansi.py
--rw-r--r--  2.0 unx    10517 b- defN 21-Aug-12 14:54 pip/_vendor/colorama/ansitowin32.py
--rw-r--r--  2.0 unx     1915 b- defN 21-Aug-12 14:54 pip/_vendor/colorama/initialise.py
--rw-r--r--  2.0 unx     5404 b- defN 21-Aug-12 14:54 pip/_vendor/colorama/win32.py
--rw-r--r--  2.0 unx     6438 b- defN 21-Aug-12 14:54 pip/_vendor/colorama/winterm.py
--rw-r--r--  2.0 unx      581 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/__init__.py
--rw-r--r--  2.0 unx    41408 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/compat.py
--rw-r--r--  2.0 unx    51059 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/database.py
--rw-r--r--  2.0 unx    20739 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/index.py
--rw-r--r--  2.0 unx    51965 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/locators.py
--rw-r--r--  2.0 unx    14811 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/manifest.py
--rw-r--r--  2.0 unx     4344 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/markers.py
--rw-r--r--  2.0 unx    39109 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/metadata.py
--rw-r--r--  2.0 unx    10820 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/resources.py
--rw-r--r--  2.0 unx    17248 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/scripts.py
--rw-r--r--  2.0 unx    96768 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/t32.exe
--rw-r--r--  2.0 unx   105984 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/t64.exe
--rw-r--r--  2.0 unx    67558 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/util.py
--rw-r--r--  2.0 unx    23508 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/version.py
--rw-r--r--  2.0 unx    90112 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/w32.exe
--rw-r--r--  2.0 unx    99840 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/w64.exe
--rw-r--r--  2.0 unx    43062 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/wheel.py
--rw-r--r--  2.0 unx      274 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/_backport/__init__.py
--rw-r--r--  2.0 unx      971 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/_backport/misc.py
--rw-r--r--  2.0 unx    25707 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/_backport/shutil.py
--rw-r--r--  2.0 unx     2617 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/_backport/sysconfig.cfg
--rw-r--r--  2.0 unx    26854 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/_backport/sysconfig.py
--rw-r--r--  2.0 unx    92628 b- defN 21-Aug-12 14:54 pip/_vendor/distlib/_backport/tarfile.py
--rw-r--r--  2.0 unx     1160 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/__init__.py
--rw-r--r--  2.0 unx    16728 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/_ihatexml.py
--rw-r--r--  2.0 unx    32353 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/_inputstream.py
--rw-r--r--  2.0 unx    77040 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/_tokenizer.py
--rw-r--r--  2.0 unx     4931 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/_utils.py
--rw-r--r--  2.0 unx    83464 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/constants.py
--rw-r--r--  2.0 unx   117186 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/html5parser.py
--rw-r--r--  2.0 unx    15759 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/serializer.py
--rw-r--r--  2.0 unx      109 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/_trie/__init__.py
--rw-r--r--  2.0 unx     1013 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/_trie/_base.py
--rw-r--r--  2.0 unx     1775 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/_trie/py.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/filters/__init__.py
--rw-r--r--  2.0 unx      919 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/filters/alphabeticalattributes.py
--rw-r--r--  2.0 unx      286 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/filters/base.py
--rw-r--r--  2.0 unx     2945 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/filters/inject_meta_charset.py
--rw-r--r--  2.0 unx     3643 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/filters/lint.py
--rw-r--r--  2.0 unx    10588 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/filters/optionaltags.py
--rw-r--r--  2.0 unx    26897 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/filters/sanitizer.py
--rw-r--r--  2.0 unx     1214 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/filters/whitespace.py
--rw-r--r--  2.0 unx      679 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treeadapters/__init__.py
--rw-r--r--  2.0 unx     1715 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treeadapters/genshi.py
--rw-r--r--  2.0 unx     1776 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treeadapters/sax.py
--rw-r--r--  2.0 unx     3592 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treebuilders/__init__.py
--rw-r--r--  2.0 unx    14565 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treebuilders/base.py
--rw-r--r--  2.0 unx     8925 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treebuilders/dom.py
--rw-r--r--  2.0 unx    12836 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treebuilders/etree.py
--rw-r--r--  2.0 unx    14766 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treebuilders/etree_lxml.py
--rw-r--r--  2.0 unx     5719 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treewalkers/__init__.py
--rw-r--r--  2.0 unx     7476 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treewalkers/base.py
--rw-r--r--  2.0 unx     1413 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treewalkers/dom.py
--rw-r--r--  2.0 unx     4551 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treewalkers/etree.py
--rw-r--r--  2.0 unx     6357 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treewalkers/etree_lxml.py
--rw-r--r--  2.0 unx     2309 b- defN 21-Aug-12 14:54 pip/_vendor/html5lib/treewalkers/genshi.py
--rw-r--r--  2.0 unx      849 b- defN 21-Aug-12 14:54 pip/_vendor/idna/__init__.py
--rw-r--r--  2.0 unx     3453 b- defN 21-Aug-12 14:54 pip/_vendor/idna/codec.py
--rw-r--r--  2.0 unx      360 b- defN 21-Aug-12 14:54 pip/_vendor/idna/compat.py
--rw-r--r--  2.0 unx    12826 b- defN 21-Aug-12 14:54 pip/_vendor/idna/core.py
--rw-r--r--  2.0 unx    42350 b- defN 21-Aug-12 14:54 pip/_vendor/idna/idnadata.py
--rw-r--r--  2.0 unx     1933 b- defN 21-Aug-12 14:54 pip/_vendor/idna/intranges.py
--rw-r--r--  2.0 unx       21 b- defN 21-Aug-12 14:54 pip/_vendor/idna/package_data.py
--rw-r--r--  2.0 unx   201849 b- defN 21-Aug-12 14:54 pip/_vendor/idna/uts46data.py
--rw-r--r--  2.0 unx     1118 b- defN 21-Aug-12 14:54 pip/_vendor/msgpack/__init__.py
--rw-r--r--  2.0 unx       20 b- defN 21-Aug-12 14:54 pip/_vendor/msgpack/_version.py
--rw-r--r--  2.0 unx     1081 b- defN 21-Aug-12 14:54 pip/_vendor/msgpack/exceptions.py
--rw-r--r--  2.0 unx     6088 b- defN 21-Aug-12 14:54 pip/_vendor/msgpack/ext.py
--rw-r--r--  2.0 unx    38026 b- defN 21-Aug-12 14:54 pip/_vendor/msgpack/fallback.py
--rw-r--r--  2.0 unx      661 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/__about__.py
--rw-r--r--  2.0 unx      497 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/__init__.py
--rw-r--r--  2.0 unx    11488 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/_manylinux.py
--rw-r--r--  2.0 unx     4378 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/_musllinux.py
--rw-r--r--  2.0 unx     1629 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/_structures.py
--rw-r--r--  2.0 unx     8487 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/markers.py
--rw-r--r--  2.0 unx     4676 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/requirements.py
--rw-r--r--  2.0 unx    30964 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/specifiers.py
--rw-r--r--  2.0 unx    15714 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/tags.py
--rw-r--r--  2.0 unx     4200 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/utils.py
--rw-r--r--  2.0 unx    14665 b- defN 21-Aug-12 14:54 pip/_vendor/packaging/version.py
--rw-r--r--  2.0 unx      130 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/__init__.py
--rw-r--r--  2.0 unx     3469 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/build.py
--rw-r--r--  2.0 unx     6096 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/check.py
--rw-r--r--  2.0 unx     4098 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/colorlog.py
--rw-r--r--  2.0 unx     1071 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/compat.py
--rw-r--r--  2.0 unx     1129 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/dirtools.py
--rw-r--r--  2.0 unx     6112 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/envbuild.py
--rw-r--r--  2.0 unx     2463 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/meta.py
--rw-r--r--  2.0 unx    13258 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/wrappers.py
--rw-r--r--  2.0 unx      563 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/in_process/__init__.py
--rw-r--r--  2.0 unx    10833 b- defN 21-Aug-12 14:54 pip/_vendor/pep517/in_process/_in_process.py
--rw-r--r--  2.0 unx   108277 b- defN 21-Aug-12 14:54 pip/_vendor/pkg_resources/__init__.py
--rw-r--r--  2.0 unx      562 b- defN 21-Aug-12 14:54 pip/_vendor/pkg_resources/py31compat.py
--rw-r--r--  2.0 unx     4857 b- defN 21-Aug-12 14:54 pip/_vendor/progress/__init__.py
--rw-r--r--  2.0 unx     2854 b- defN 21-Aug-12 14:54 pip/_vendor/progress/bar.py
--rw-r--r--  2.0 unx     1372 b- defN 21-Aug-12 14:54 pip/_vendor/progress/counter.py
--rw-r--r--  2.0 unx     1380 b- defN 21-Aug-12 14:54 pip/_vendor/progress/spinner.py
--rw-r--r--  2.0 unx     5113 b- defN 21-Aug-12 14:54 pip/_vendor/requests/__init__.py
--rw-r--r--  2.0 unx      441 b- defN 21-Aug-12 14:54 pip/_vendor/requests/__version__.py
--rw-r--r--  2.0 unx     1096 b- defN 21-Aug-12 14:54 pip/_vendor/requests/_internal_utils.py
--rw-r--r--  2.0 unx    21548 b- defN 21-Aug-12 14:54 pip/_vendor/requests/adapters.py
--rw-r--r--  2.0 unx     6402 b- defN 21-Aug-12 14:54 pip/_vendor/requests/api.py
--rw-r--r--  2.0 unx    10207 b- defN 21-Aug-12 14:54 pip/_vendor/requests/auth.py
--rw-r--r--  2.0 unx      465 b- defN 21-Aug-12 14:54 pip/_vendor/requests/certs.py
--rw-r--r--  2.0 unx     2045 b- defN 21-Aug-12 14:54 pip/_vendor/requests/compat.py
--rw-r--r--  2.0 unx    18430 b- defN 21-Aug-12 14:54 pip/_vendor/requests/cookies.py
--rw-r--r--  2.0 unx     3250 b- defN 21-Aug-12 14:54 pip/_vendor/requests/exceptions.py
--rw-r--r--  2.0 unx     3972 b- defN 21-Aug-12 14:54 pip/_vendor/requests/help.py
--rw-r--r--  2.0 unx      757 b- defN 21-Aug-12 14:54 pip/_vendor/requests/hooks.py
--rw-r--r--  2.0 unx    34924 b- defN 21-Aug-12 14:54 pip/_vendor/requests/models.py
--rw-r--r--  2.0 unx      695 b- defN 21-Aug-12 14:54 pip/_vendor/requests/packages.py
--rw-r--r--  2.0 unx    30168 b- defN 21-Aug-12 14:54 pip/_vendor/requests/sessions.py
--rw-r--r--  2.0 unx     4188 b- defN 21-Aug-12 14:54 pip/_vendor/requests/status_codes.py
--rw-r--r--  2.0 unx     3005 b- defN 21-Aug-12 14:54 pip/_vendor/requests/structures.py
--rw-r--r--  2.0 unx    31394 b- defN 21-Aug-12 14:54 pip/_vendor/requests/utils.py
--rw-r--r--  2.0 unx      537 b- defN 21-Aug-12 14:54 pip/_vendor/resolvelib/__init__.py
--rw-r--r--  2.0 unx     5638 b- defN 21-Aug-12 14:54 pip/_vendor/resolvelib/providers.py
--rw-r--r--  2.0 unx     1364 b- defN 21-Aug-12 14:54 pip/_vendor/resolvelib/reporters.py
--rw-r--r--  2.0 unx    17225 b- defN 21-Aug-12 14:54 pip/_vendor/resolvelib/resolvers.py
--rw-r--r--  2.0 unx     4794 b- defN 21-Aug-12 14:54 pip/_vendor/resolvelib/structs.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_vendor/resolvelib/compat/__init__.py
--rw-r--r--  2.0 unx      156 b- defN 21-Aug-12 14:54 pip/_vendor/resolvelib/compat/collections_abc.py
--rw-r--r--  2.0 unx    18257 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/__init__.py
--rw-r--r--  2.0 unx     3314 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/_asyncio.py
--rw-r--r--  2.0 unx     1944 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/_utils.py
--rw-r--r--  2.0 unx     1496 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/after.py
--rw-r--r--  2.0 unx     1376 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/before.py
--rw-r--r--  2.0 unx     1908 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/before_sleep.py
--rw-r--r--  2.0 unx     1383 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/nap.py
--rw-r--r--  2.0 unx     6645 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/retry.py
--rw-r--r--  2.0 unx     2790 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/stop.py
--rw-r--r--  2.0 unx     2145 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/tornadoweb.py
--rw-r--r--  2.0 unx     6691 b- defN 21-Aug-12 14:54 pip/_vendor/tenacity/wait.py
--rw-r--r--  2.0 unx      230 b- defN 21-Aug-12 14:54 pip/_vendor/tomli/__init__.py
--rw-r--r--  2.0 unx    22415 b- defN 21-Aug-12 14:54 pip/_vendor/tomli/_parser.py
--rw-r--r--  2.0 unx     2681 b- defN 21-Aug-12 14:54 pip/_vendor/tomli/_re.py
--rw-r--r--  2.0 unx     2763 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/__init__.py
--rw-r--r--  2.0 unx    10811 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/_collections.py
--rw-r--r--  2.0 unx       63 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/_version.py
--rw-r--r--  2.0 unx    18754 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/connection.py
--rw-r--r--  2.0 unx    37131 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/connectionpool.py
--rw-r--r--  2.0 unx     8217 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/exceptions.py
--rw-r--r--  2.0 unx     8579 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/fields.py
--rw-r--r--  2.0 unx     2440 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/filepost.py
--rw-r--r--  2.0 unx    19763 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/poolmanager.py
--rw-r--r--  2.0 unx     5985 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/request.py
--rw-r--r--  2.0 unx    28203 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/response.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/__init__.py
--rw-r--r--  2.0 unx      957 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/_appengine_environ.py
--rw-r--r--  2.0 unx    11034 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/appengine.py
--rw-r--r--  2.0 unx     4538 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/ntlmpool.py
--rw-r--r--  2.0 unx    16891 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/pyopenssl.py
--rw-r--r--  2.0 unx    34434 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/securetransport.py
--rw-r--r--  2.0 unx     7097 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/socks.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/_securetransport/__init__.py
--rw-r--r--  2.0 unx    17649 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/_securetransport/bindings.py
--rw-r--r--  2.0 unx    13908 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/contrib/_securetransport/low_level.py
--rw-r--r--  2.0 unx      108 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/packages/__init__.py
--rw-r--r--  2.0 unx    34666 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/packages/six.py
--rw-r--r--  2.0 unx        0 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/packages/backports/__init__.py
--rw-r--r--  2.0 unx     1417 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/packages/backports/makefile.py
--rw-r--r--  2.0 unx      927 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/packages/ssl_match_hostname/__init__.py
--rw-r--r--  2.0 unx     5679 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/packages/ssl_match_hostname/_implementation.py
--rw-r--r--  2.0 unx     1155 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/__init__.py
--rw-r--r--  2.0 unx     4920 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/connection.py
--rw-r--r--  2.0 unx     1604 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/proxy.py
--rw-r--r--  2.0 unx      498 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/queue.py
--rw-r--r--  2.0 unx     4123 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/request.py
--rw-r--r--  2.0 unx     3510 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/response.py
--rw-r--r--  2.0 unx    21391 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/retry.py
--rw-r--r--  2.0 unx    17177 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/ssl_.py
--rw-r--r--  2.0 unx     6931 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/ssltransport.py
--rw-r--r--  2.0 unx    10003 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/timeout.py
--rw-r--r--  2.0 unx    14047 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/url.py
--rw-r--r--  2.0 unx     5404 b- defN 21-Aug-12 14:54 pip/_vendor/urllib3/util/wait.py
--rw-r--r--  2.0 unx    10579 b- defN 21-Aug-12 14:54 pip/_vendor/webencodings/__init__.py
--rw-r--r--  2.0 unx     8979 b- defN 21-Aug-12 14:54 pip/_vendor/webencodings/labels.py
--rw-r--r--  2.0 unx     1305 b- defN 21-Aug-12 14:54 pip/_vendor/webencodings/mklabels.py
--rw-r--r--  2.0 unx     6563 b- defN 21-Aug-12 14:54 pip/_vendor/webencodings/tests.py
--rw-r--r--  2.0 unx     4307 b- defN 21-Aug-12 14:54 pip/_vendor/webencodings/x_user_defined.py
--rw-r--r--  2.0 unx     1090 b- defN 21-Aug-12 14:54 pip-21.2.4.dist-info/LICENSE.txt
--rw-r--r--  2.0 unx     4165 b- defN 21-Aug-12 14:54 pip-21.2.4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 21-Aug-12 14:54 pip-21.2.4.dist-info/WHEEL
--rw-r--r--  2.0 unx      125 b- defN 21-Aug-12 14:54 pip-21.2.4.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        4 b- defN 21-Aug-12 14:54 pip-21.2.4.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    36624 b- defN 21-Aug-12 14:54 pip-21.2.4.dist-info/RECORD
-402 files, 5419061 bytes uncompressed, 1497034 bytes compressed:  72.4%
+Zip file size: 1723581 bytes, number of entries: 415
+-rw-r--r--  2.0 unx      357 b- defN 21-Oct-22 15:15 pip/__init__.py
+-rw-r--r--  2.0 unx     1198 b- defN 21-Oct-22 15:15 pip/__main__.py
+-rw-r--r--  2.0 unx      286 b- defN 21-Oct-22 15:15 pip/py.typed
+-rw-r--r--  2.0 unx      573 b- defN 21-Oct-22 15:15 pip/_internal/__init__.py
+-rw-r--r--  2.0 unx     9950 b- defN 21-Oct-22 15:15 pip/_internal/build_env.py
+-rw-r--r--  2.0 unx     9441 b- defN 21-Oct-22 15:15 pip/_internal/cache.py
+-rw-r--r--  2.0 unx    13153 b- defN 21-Oct-22 15:15 pip/_internal/configuration.py
+-rw-r--r--  2.0 unx    12762 b- defN 21-Oct-22 15:15 pip/_internal/exceptions.py
+-rw-r--r--  2.0 unx      340 b- defN 21-Oct-22 15:15 pip/_internal/main.py
+-rw-r--r--  2.0 unx     7215 b- defN 21-Oct-22 15:15 pip/_internal/pyproject.py
+-rw-r--r--  2.0 unx     6393 b- defN 21-Oct-22 15:15 pip/_internal/self_outdated_check.py
+-rw-r--r--  2.0 unx    12247 b- defN 21-Oct-22 15:15 pip/_internal/wheel_builder.py
+-rw-r--r--  2.0 unx      132 b- defN 21-Oct-22 15:15 pip/_internal/cli/__init__.py
+-rw-r--r--  2.0 unx     6399 b- defN 21-Oct-22 15:15 pip/_internal/cli/autocompletion.py
+-rw-r--r--  2.0 unx     7790 b- defN 21-Oct-22 15:15 pip/_internal/cli/base_command.py
+-rw-r--r--  2.0 unx    28391 b- defN 21-Oct-22 15:15 pip/_internal/cli/cmdoptions.py
+-rw-r--r--  2.0 unx      760 b- defN 21-Oct-22 15:15 pip/_internal/cli/command_context.py
+-rw-r--r--  2.0 unx     2472 b- defN 21-Oct-22 15:15 pip/_internal/cli/main.py
+-rw-r--r--  2.0 unx     2614 b- defN 21-Oct-22 15:15 pip/_internal/cli/main_parser.py
+-rw-r--r--  2.0 unx    10788 b- defN 21-Oct-22 15:15 pip/_internal/cli/parser.py
+-rw-r--r--  2.0 unx     8300 b- defN 21-Oct-22 15:15 pip/_internal/cli/progress_bars.py
+-rw-r--r--  2.0 unx    17097 b- defN 21-Oct-22 15:15 pip/_internal/cli/req_command.py
+-rw-r--r--  2.0 unx     5076 b- defN 21-Oct-22 15:15 pip/_internal/cli/spinners.py
+-rw-r--r--  2.0 unx      116 b- defN 21-Oct-22 15:15 pip/_internal/cli/status_codes.py
+-rw-r--r--  2.0 unx     3736 b- defN 21-Oct-22 15:15 pip/_internal/commands/__init__.py
+-rw-r--r--  2.0 unx     7524 b- defN 21-Oct-22 15:15 pip/_internal/commands/cache.py
+-rw-r--r--  2.0 unx     1685 b- defN 21-Oct-22 15:15 pip/_internal/commands/check.py
+-rw-r--r--  2.0 unx     2958 b- defN 21-Oct-22 15:15 pip/_internal/commands/completion.py
+-rw-r--r--  2.0 unx     8944 b- defN 21-Oct-22 15:15 pip/_internal/commands/configuration.py
+-rw-r--r--  2.0 unx     6629 b- defN 21-Oct-22 15:15 pip/_internal/commands/debug.py
+-rw-r--r--  2.0 unx     4904 b- defN 21-Oct-22 15:15 pip/_internal/commands/download.py
+-rw-r--r--  2.0 unx     2951 b- defN 21-Oct-22 15:15 pip/_internal/commands/freeze.py
+-rw-r--r--  2.0 unx     1703 b- defN 21-Oct-22 15:15 pip/_internal/commands/hash.py
+-rw-r--r--  2.0 unx     1132 b- defN 21-Oct-22 15:15 pip/_internal/commands/help.py
+-rw-r--r--  2.0 unx     4762 b- defN 21-Oct-22 15:15 pip/_internal/commands/index.py
+-rw-r--r--  2.0 unx    27851 b- defN 21-Oct-22 15:15 pip/_internal/commands/install.py
+-rw-r--r--  2.0 unx    12203 b- defN 21-Oct-22 15:15 pip/_internal/commands/list.py
+-rw-r--r--  2.0 unx     5697 b- defN 21-Oct-22 15:15 pip/_internal/commands/search.py
+-rw-r--r--  2.0 unx     8064 b- defN 21-Oct-22 15:15 pip/_internal/commands/show.py
+-rw-r--r--  2.0 unx     3526 b- defN 21-Oct-22 15:15 pip/_internal/commands/uninstall.py
+-rw-r--r--  2.0 unx     6168 b- defN 21-Oct-22 15:15 pip/_internal/commands/wheel.py
+-rw-r--r--  2.0 unx      858 b- defN 21-Oct-22 15:15 pip/_internal/distributions/__init__.py
+-rw-r--r--  2.0 unx     1172 b- defN 21-Oct-22 15:15 pip/_internal/distributions/base.py
+-rw-r--r--  2.0 unx      767 b- defN 21-Oct-22 15:15 pip/_internal/distributions/installed.py
+-rw-r--r--  2.0 unx     5598 b- defN 21-Oct-22 15:15 pip/_internal/distributions/sdist.py
+-rw-r--r--  2.0 unx     1115 b- defN 21-Oct-22 15:15 pip/_internal/distributions/wheel.py
+-rw-r--r--  2.0 unx       30 b- defN 21-Oct-22 15:15 pip/_internal/index/__init__.py
+-rw-r--r--  2.0 unx    17534 b- defN 21-Oct-22 15:15 pip/_internal/index/collector.py
+-rw-r--r--  2.0 unx    36344 b- defN 21-Oct-22 15:15 pip/_internal/index/package_finder.py
+-rw-r--r--  2.0 unx     6557 b- defN 21-Oct-22 15:15 pip/_internal/index/sources.py
+-rw-r--r--  2.0 unx    14444 b- defN 21-Oct-22 15:15 pip/_internal/locations/__init__.py
+-rw-r--r--  2.0 unx     5871 b- defN 21-Oct-22 15:15 pip/_internal/locations/_distutils.py
+-rw-r--r--  2.0 unx     7918 b- defN 21-Oct-22 15:15 pip/_internal/locations/_sysconfig.py
+-rw-r--r--  2.0 unx     1579 b- defN 21-Oct-22 15:15 pip/_internal/locations/base.py
+-rw-r--r--  2.0 unx     1660 b- defN 21-Oct-22 15:15 pip/_internal/metadata/__init__.py
+-rw-r--r--  2.0 unx    11103 b- defN 21-Oct-22 15:15 pip/_internal/metadata/base.py
+-rw-r--r--  2.0 unx     5089 b- defN 21-Oct-22 15:15 pip/_internal/metadata/pkg_resources.py
+-rw-r--r--  2.0 unx       63 b- defN 21-Oct-22 15:15 pip/_internal/models/__init__.py
+-rw-r--r--  2.0 unx      990 b- defN 21-Oct-22 15:15 pip/_internal/models/candidate.py
+-rw-r--r--  2.0 unx     6350 b- defN 21-Oct-22 15:15 pip/_internal/models/direct_url.py
+-rw-r--r--  2.0 unx     2520 b- defN 21-Oct-22 15:15 pip/_internal/models/format_control.py
+-rw-r--r--  2.0 unx     1030 b- defN 21-Oct-22 15:15 pip/_internal/models/index.py
+-rw-r--r--  2.0 unx     9817 b- defN 21-Oct-22 15:15 pip/_internal/models/link.py
+-rw-r--r--  2.0 unx      738 b- defN 21-Oct-22 15:15 pip/_internal/models/scheme.py
+-rw-r--r--  2.0 unx     4520 b- defN 21-Oct-22 15:15 pip/_internal/models/search_scope.py
+-rw-r--r--  2.0 unx     1907 b- defN 21-Oct-22 15:15 pip/_internal/models/selection_prefs.py
+-rw-r--r--  2.0 unx     3858 b- defN 21-Oct-22 15:15 pip/_internal/models/target_python.py
+-rw-r--r--  2.0 unx     3500 b- defN 21-Oct-22 15:15 pip/_internal/models/wheel.py
+-rw-r--r--  2.0 unx       50 b- defN 21-Oct-22 15:15 pip/_internal/network/__init__.py
+-rw-r--r--  2.0 unx    12190 b- defN 21-Oct-22 15:15 pip/_internal/network/auth.py
+-rw-r--r--  2.0 unx     2100 b- defN 21-Oct-22 15:15 pip/_internal/network/cache.py
+-rw-r--r--  2.0 unx     6016 b- defN 21-Oct-22 15:15 pip/_internal/network/download.py
+-rw-r--r--  2.0 unx     7627 b- defN 21-Oct-22 15:15 pip/_internal/network/lazy_wheel.py
+-rw-r--r--  2.0 unx    16729 b- defN 21-Oct-22 15:15 pip/_internal/network/session.py
+-rw-r--r--  2.0 unx     4059 b- defN 21-Oct-22 15:15 pip/_internal/network/utils.py
+-rw-r--r--  2.0 unx     1791 b- defN 21-Oct-22 15:15 pip/_internal/network/xmlrpc.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_internal/operations/__init__.py
+-rw-r--r--  2.0 unx     5109 b- defN 21-Oct-22 15:15 pip/_internal/operations/check.py
+-rw-r--r--  2.0 unx     9770 b- defN 21-Oct-22 15:15 pip/_internal/operations/freeze.py
+-rw-r--r--  2.0 unx    23838 b- defN 21-Oct-22 15:15 pip/_internal/operations/prepare.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_internal/operations/build/__init__.py
+-rw-r--r--  2.0 unx     1119 b- defN 21-Oct-22 15:15 pip/_internal/operations/build/metadata.py
+-rw-r--r--  2.0 unx     1177 b- defN 21-Oct-22 15:15 pip/_internal/operations/build/metadata_editable.py
+-rw-r--r--  2.0 unx     1945 b- defN 21-Oct-22 15:15 pip/_internal/operations/build/metadata_legacy.py
+-rw-r--r--  2.0 unx     1063 b- defN 21-Oct-22 15:15 pip/_internal/operations/build/wheel.py
+-rw-r--r--  2.0 unx     1405 b- defN 21-Oct-22 15:15 pip/_internal/operations/build/wheel_editable.py
+-rw-r--r--  2.0 unx     3047 b- defN 21-Oct-22 15:15 pip/_internal/operations/build/wheel_legacy.py
+-rw-r--r--  2.0 unx       51 b- defN 21-Oct-22 15:15 pip/_internal/operations/install/__init__.py
+-rw-r--r--  2.0 unx     1298 b- defN 21-Oct-22 15:15 pip/_internal/operations/install/editable_legacy.py
+-rw-r--r--  2.0 unx     4158 b- defN 21-Oct-22 15:15 pip/_internal/operations/install/legacy.py
+-rw-r--r--  2.0 unx    27412 b- defN 21-Oct-22 15:15 pip/_internal/operations/install/wheel.py
+-rw-r--r--  2.0 unx     2793 b- defN 21-Oct-22 15:15 pip/_internal/req/__init__.py
+-rw-r--r--  2.0 unx    15285 b- defN 21-Oct-22 15:15 pip/_internal/req/constructors.py
+-rw-r--r--  2.0 unx    17421 b- defN 21-Oct-22 15:15 pip/_internal/req/req_file.py
+-rw-r--r--  2.0 unx    33804 b- defN 21-Oct-22 15:15 pip/_internal/req/req_install.py
+-rw-r--r--  2.0 unx     7584 b- defN 21-Oct-22 15:15 pip/_internal/req/req_set.py
+-rw-r--r--  2.0 unx     4117 b- defN 21-Oct-22 15:15 pip/_internal/req/req_tracker.py
+-rw-r--r--  2.0 unx    23748 b- defN 21-Oct-22 15:15 pip/_internal/req/req_uninstall.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_internal/resolution/__init__.py
+-rw-r--r--  2.0 unx      583 b- defN 21-Oct-22 15:15 pip/_internal/resolution/base.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_internal/resolution/legacy/__init__.py
+-rw-r--r--  2.0 unx    18312 b- defN 21-Oct-22 15:15 pip/_internal/resolution/legacy/resolver.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/__init__.py
+-rw-r--r--  2.0 unx     5220 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/base.py
+-rw-r--r--  2.0 unx    18210 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/candidates.py
+-rw-r--r--  2.0 unx    26806 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/factory.py
+-rw-r--r--  2.0 unx     5705 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/found_candidates.py
+-rw-r--r--  2.0 unx     9205 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/provider.py
+-rw-r--r--  2.0 unx     2526 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/reporter.py
+-rw-r--r--  2.0 unx     5455 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/requirements.py
+-rw-r--r--  2.0 unx     9580 b- defN 21-Oct-22 15:15 pip/_internal/resolution/resolvelib/resolver.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_internal/utils/__init__.py
+-rw-r--r--  2.0 unx     1015 b- defN 21-Oct-22 15:15 pip/_internal/utils/_log.py
+-rw-r--r--  2.0 unx     1665 b- defN 21-Oct-22 15:15 pip/_internal/utils/appdirs.py
+-rw-r--r--  2.0 unx     1884 b- defN 21-Oct-22 15:15 pip/_internal/utils/compat.py
+-rw-r--r--  2.0 unx     5377 b- defN 21-Oct-22 15:15 pip/_internal/utils/compatibility_tags.py
+-rw-r--r--  2.0 unx      242 b- defN 21-Oct-22 15:15 pip/_internal/utils/datetime.py
+-rw-r--r--  2.0 unx     3627 b- defN 21-Oct-22 15:15 pip/_internal/utils/deprecation.py
+-rw-r--r--  2.0 unx     3206 b- defN 21-Oct-22 15:15 pip/_internal/utils/direct_url_helpers.py
+-rw-r--r--  2.0 unx     1249 b- defN 21-Oct-22 15:15 pip/_internal/utils/distutils_args.py
+-rw-r--r--  2.0 unx     2203 b- defN 21-Oct-22 15:15 pip/_internal/utils/egg_link.py
+-rw-r--r--  2.0 unx     1169 b- defN 21-Oct-22 15:15 pip/_internal/utils/encoding.py
+-rw-r--r--  2.0 unx     1055 b- defN 21-Oct-22 15:15 pip/_internal/utils/entrypoints.py
+-rw-r--r--  2.0 unx     5893 b- defN 21-Oct-22 15:15 pip/_internal/utils/filesystem.py
+-rw-r--r--  2.0 unx      716 b- defN 21-Oct-22 15:15 pip/_internal/utils/filetypes.py
+-rw-r--r--  2.0 unx     3110 b- defN 21-Oct-22 15:15 pip/_internal/utils/glibc.py
+-rw-r--r--  2.0 unx     4811 b- defN 21-Oct-22 15:15 pip/_internal/utils/hashes.py
+-rw-r--r--  2.0 unx      795 b- defN 21-Oct-22 15:15 pip/_internal/utils/inject_securetransport.py
+-rw-r--r--  2.0 unx    11532 b- defN 21-Oct-22 15:15 pip/_internal/utils/logging.py
+-rw-r--r--  2.0 unx    20432 b- defN 21-Oct-22 15:15 pip/_internal/utils/misc.py
+-rw-r--r--  2.0 unx     1193 b- defN 21-Oct-22 15:15 pip/_internal/utils/models.py
+-rw-r--r--  2.0 unx     2952 b- defN 21-Oct-22 15:15 pip/_internal/utils/packaging.py
+-rw-r--r--  2.0 unx     3196 b- defN 21-Oct-22 15:15 pip/_internal/utils/parallel.py
+-rw-r--r--  2.0 unx      987 b- defN 21-Oct-22 15:15 pip/_internal/utils/pkg_resources.py
+-rw-r--r--  2.0 unx     4697 b- defN 21-Oct-22 15:15 pip/_internal/utils/setuptools_build.py
+-rw-r--r--  2.0 unx    10058 b- defN 21-Oct-22 15:15 pip/_internal/utils/subprocess.py
+-rw-r--r--  2.0 unx     7662 b- defN 21-Oct-22 15:15 pip/_internal/utils/temp_dir.py
+-rw-r--r--  2.0 unx     8906 b- defN 21-Oct-22 15:15 pip/_internal/utils/unpacking.py
+-rw-r--r--  2.0 unx     1759 b- defN 21-Oct-22 15:15 pip/_internal/utils/urls.py
+-rw-r--r--  2.0 unx     3459 b- defN 21-Oct-22 15:15 pip/_internal/utils/virtualenv.py
+-rw-r--r--  2.0 unx     6163 b- defN 21-Oct-22 15:15 pip/_internal/utils/wheel.py
+-rw-r--r--  2.0 unx      596 b- defN 21-Oct-22 15:15 pip/_internal/vcs/__init__.py
+-rw-r--r--  2.0 unx     2857 b- defN 21-Oct-22 15:15 pip/_internal/vcs/bazaar.py
+-rw-r--r--  2.0 unx    17804 b- defN 21-Oct-22 15:15 pip/_internal/vcs/git.py
+-rw-r--r--  2.0 unx     4945 b- defN 21-Oct-22 15:15 pip/_internal/vcs/mercurial.py
+-rw-r--r--  2.0 unx    11596 b- defN 21-Oct-22 15:15 pip/_internal/vcs/subversion.py
+-rw-r--r--  2.0 unx    22414 b- defN 21-Oct-22 15:15 pip/_internal/vcs/versioncontrol.py
+-rw-r--r--  2.0 unx     4708 b- defN 21-Oct-22 15:15 pip/_vendor/__init__.py
+-rw-r--r--  2.0 unx    48414 b- defN 21-Oct-22 15:15 pip/_vendor/distro.py
+-rw-r--r--  2.0 unx   273394 b- defN 21-Oct-22 15:15 pip/_vendor/pyparsing.py
+-rw-r--r--  2.0 unx    34549 b- defN 21-Oct-22 15:15 pip/_vendor/six.py
+-rw-r--r--  2.0 unx      432 b- defN 21-Oct-22 15:15 pip/_vendor/vendor.txt
+-rw-r--r--  2.0 unx      302 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/__init__.py
+-rw-r--r--  2.0 unx     1295 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/_cmd.py
+-rw-r--r--  2.0 unx     4882 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/adapter.py
+-rw-r--r--  2.0 unx      805 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/cache.py
+-rw-r--r--  2.0 unx      695 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/compat.py
+-rw-r--r--  2.0 unx    14149 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/controller.py
+-rw-r--r--  2.0 unx     2533 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/filewrapper.py
+-rw-r--r--  2.0 unx     4070 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/heuristics.py
+-rw-r--r--  2.0 unx     7091 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/serialize.py
+-rw-r--r--  2.0 unx      690 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/wrapper.py
+-rw-r--r--  2.0 unx       86 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/caches/__init__.py
+-rw-r--r--  2.0 unx     4153 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/caches/file_cache.py
+-rw-r--r--  2.0 unx      856 b- defN 21-Oct-22 15:15 pip/_vendor/cachecontrol/caches/redis_cache.py
+-rw-r--r--  2.0 unx       62 b- defN 21-Oct-22 15:15 pip/_vendor/certifi/__init__.py
+-rw-r--r--  2.0 unx      255 b- defN 21-Oct-22 15:15 pip/_vendor/certifi/__main__.py
+-rw-r--r--  2.0 unx   259465 b- defN 21-Oct-22 15:15 pip/_vendor/certifi/cacert.pem
+-rw-r--r--  2.0 unx     2840 b- defN 21-Oct-22 15:15 pip/_vendor/certifi/core.py
+-rw-r--r--  2.0 unx     3271 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/__init__.py
+-rw-r--r--  2.0 unx    31254 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/big5freq.py
+-rw-r--r--  2.0 unx     1757 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/big5prober.py
+-rw-r--r--  2.0 unx     9411 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/chardistribution.py
+-rw-r--r--  2.0 unx     3839 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/charsetgroupprober.py
+-rw-r--r--  2.0 unx     5110 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/charsetprober.py
+-rw-r--r--  2.0 unx     3590 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/codingstatemachine.py
+-rw-r--r--  2.0 unx     1200 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/compat.py
+-rw-r--r--  2.0 unx     1855 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/cp949prober.py
+-rw-r--r--  2.0 unx     1661 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/enums.py
+-rw-r--r--  2.0 unx     3950 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/escprober.py
+-rw-r--r--  2.0 unx    10510 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/escsm.py
+-rw-r--r--  2.0 unx     3749 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/eucjpprober.py
+-rw-r--r--  2.0 unx    13546 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/euckrfreq.py
+-rw-r--r--  2.0 unx     1748 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/euckrprober.py
+-rw-r--r--  2.0 unx    31621 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/euctwfreq.py
+-rw-r--r--  2.0 unx     1747 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/euctwprober.py
+-rw-r--r--  2.0 unx    20715 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/gb2312freq.py
+-rw-r--r--  2.0 unx     1754 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/gb2312prober.py
+-rw-r--r--  2.0 unx    13838 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/hebrewprober.py
+-rw-r--r--  2.0 unx    25777 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/jisfreq.py
+-rw-r--r--  2.0 unx    19643 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/jpcntx.py
+-rw-r--r--  2.0 unx   105697 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/langbulgarianmodel.py
+-rw-r--r--  2.0 unx    99571 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/langgreekmodel.py
+-rw-r--r--  2.0 unx    98776 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/langhebrewmodel.py
+-rw-r--r--  2.0 unx   102498 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/langhungarianmodel.py
+-rw-r--r--  2.0 unx   131180 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/langrussianmodel.py
+-rw-r--r--  2.0 unx   103312 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/langthaimodel.py
+-rw-r--r--  2.0 unx    95946 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/langturkishmodel.py
+-rw-r--r--  2.0 unx     5370 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/latin1prober.py
+-rw-r--r--  2.0 unx     3413 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/mbcharsetprober.py
+-rw-r--r--  2.0 unx     2012 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/mbcsgroupprober.py
+-rw-r--r--  2.0 unx    25481 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/mbcssm.py
+-rw-r--r--  2.0 unx     6136 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/sbcharsetprober.py
+-rw-r--r--  2.0 unx     4309 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/sbcsgroupprober.py
+-rw-r--r--  2.0 unx     3774 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/sjisprober.py
+-rw-r--r--  2.0 unx    12503 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/universaldetector.py
+-rw-r--r--  2.0 unx     2766 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/utf8prober.py
+-rw-r--r--  2.0 unx      242 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/version.py
+-rw-r--r--  2.0 unx        1 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/cli/__init__.py
+-rw-r--r--  2.0 unx     2747 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/cli/chardetect.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/metadata/__init__.py
+-rw-r--r--  2.0 unx    19474 b- defN 21-Oct-22 15:15 pip/_vendor/chardet/metadata/languages.py
+-rw-r--r--  2.0 unx      239 b- defN 21-Oct-22 15:15 pip/_vendor/colorama/__init__.py
+-rw-r--r--  2.0 unx     2522 b- defN 21-Oct-22 15:15 pip/_vendor/colorama/ansi.py
+-rw-r--r--  2.0 unx    10517 b- defN 21-Oct-22 15:15 pip/_vendor/colorama/ansitowin32.py
+-rw-r--r--  2.0 unx     1915 b- defN 21-Oct-22 15:15 pip/_vendor/colorama/initialise.py
+-rw-r--r--  2.0 unx     5404 b- defN 21-Oct-22 15:15 pip/_vendor/colorama/win32.py
+-rw-r--r--  2.0 unx     6438 b- defN 21-Oct-22 15:15 pip/_vendor/colorama/winterm.py
+-rw-r--r--  2.0 unx      581 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/__init__.py
+-rw-r--r--  2.0 unx    41495 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/compat.py
+-rw-r--r--  2.0 unx    51059 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/database.py
+-rw-r--r--  2.0 unx    20739 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/index.py
+-rw-r--r--  2.0 unx    51965 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/locators.py
+-rw-r--r--  2.0 unx    14811 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/manifest.py
+-rw-r--r--  2.0 unx     4989 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/markers.py
+-rw-r--r--  2.0 unx    39109 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/metadata.py
+-rw-r--r--  2.0 unx    10820 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/resources.py
+-rw-r--r--  2.0 unx    17720 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/scripts.py
+-rw-r--r--  2.0 unx    96768 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/t32.exe
+-rw-r--r--  2.0 unx   180736 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/t64-arm.exe
+-rw-r--r--  2.0 unx   105984 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/t64.exe
+-rw-r--r--  2.0 unx    67766 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/util.py
+-rw-r--r--  2.0 unx    23513 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/version.py
+-rw-r--r--  2.0 unx    90112 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/w32.exe
+-rw-r--r--  2.0 unx   166400 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/w64-arm.exe
+-rw-r--r--  2.0 unx    99840 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/w64.exe
+-rw-r--r--  2.0 unx    42943 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/wheel.py
+-rw-r--r--  2.0 unx      274 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/_backport/__init__.py
+-rw-r--r--  2.0 unx      971 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/_backport/misc.py
+-rw-r--r--  2.0 unx    25707 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/_backport/shutil.py
+-rw-r--r--  2.0 unx     2617 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/_backport/sysconfig.cfg
+-rw-r--r--  2.0 unx    26854 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/_backport/sysconfig.py
+-rw-r--r--  2.0 unx    92628 b- defN 21-Oct-22 15:15 pip/_vendor/distlib/_backport/tarfile.py
+-rw-r--r--  2.0 unx     1160 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/__init__.py
+-rw-r--r--  2.0 unx    16728 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/_ihatexml.py
+-rw-r--r--  2.0 unx    32353 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/_inputstream.py
+-rw-r--r--  2.0 unx    77040 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/_tokenizer.py
+-rw-r--r--  2.0 unx     4931 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/_utils.py
+-rw-r--r--  2.0 unx    83464 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/constants.py
+-rw-r--r--  2.0 unx   117186 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/html5parser.py
+-rw-r--r--  2.0 unx    15759 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/serializer.py
+-rw-r--r--  2.0 unx      109 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/_trie/__init__.py
+-rw-r--r--  2.0 unx     1013 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/_trie/_base.py
+-rw-r--r--  2.0 unx     1775 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/_trie/py.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/filters/__init__.py
+-rw-r--r--  2.0 unx      919 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/filters/alphabeticalattributes.py
+-rw-r--r--  2.0 unx      286 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/filters/base.py
+-rw-r--r--  2.0 unx     2945 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/filters/inject_meta_charset.py
+-rw-r--r--  2.0 unx     3643 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/filters/lint.py
+-rw-r--r--  2.0 unx    10588 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/filters/optionaltags.py
+-rw-r--r--  2.0 unx    26897 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/filters/sanitizer.py
+-rw-r--r--  2.0 unx     1214 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/filters/whitespace.py
+-rw-r--r--  2.0 unx      679 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treeadapters/__init__.py
+-rw-r--r--  2.0 unx     1715 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treeadapters/genshi.py
+-rw-r--r--  2.0 unx     1776 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treeadapters/sax.py
+-rw-r--r--  2.0 unx     3592 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treebuilders/__init__.py
+-rw-r--r--  2.0 unx    14565 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treebuilders/base.py
+-rw-r--r--  2.0 unx     8925 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treebuilders/dom.py
+-rw-r--r--  2.0 unx    12836 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treebuilders/etree.py
+-rw-r--r--  2.0 unx    14766 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treebuilders/etree_lxml.py
+-rw-r--r--  2.0 unx     5719 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treewalkers/__init__.py
+-rw-r--r--  2.0 unx     7476 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treewalkers/base.py
+-rw-r--r--  2.0 unx     1413 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treewalkers/dom.py
+-rw-r--r--  2.0 unx     4551 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treewalkers/etree.py
+-rw-r--r--  2.0 unx     6357 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treewalkers/etree_lxml.py
+-rw-r--r--  2.0 unx     2309 b- defN 21-Oct-22 15:15 pip/_vendor/html5lib/treewalkers/genshi.py
+-rw-r--r--  2.0 unx      849 b- defN 21-Oct-22 15:15 pip/_vendor/idna/__init__.py
+-rw-r--r--  2.0 unx     3453 b- defN 21-Oct-22 15:15 pip/_vendor/idna/codec.py
+-rw-r--r--  2.0 unx      360 b- defN 21-Oct-22 15:15 pip/_vendor/idna/compat.py
+-rw-r--r--  2.0 unx    12826 b- defN 21-Oct-22 15:15 pip/_vendor/idna/core.py
+-rw-r--r--  2.0 unx    42350 b- defN 21-Oct-22 15:15 pip/_vendor/idna/idnadata.py
+-rw-r--r--  2.0 unx     1933 b- defN 21-Oct-22 15:15 pip/_vendor/idna/intranges.py
+-rw-r--r--  2.0 unx       21 b- defN 21-Oct-22 15:15 pip/_vendor/idna/package_data.py
+-rw-r--r--  2.0 unx   201849 b- defN 21-Oct-22 15:15 pip/_vendor/idna/uts46data.py
+-rw-r--r--  2.0 unx     1118 b- defN 21-Oct-22 15:15 pip/_vendor/msgpack/__init__.py
+-rw-r--r--  2.0 unx       20 b- defN 21-Oct-22 15:15 pip/_vendor/msgpack/_version.py
+-rw-r--r--  2.0 unx     1081 b- defN 21-Oct-22 15:15 pip/_vendor/msgpack/exceptions.py
+-rw-r--r--  2.0 unx     6088 b- defN 21-Oct-22 15:15 pip/_vendor/msgpack/ext.py
+-rw-r--r--  2.0 unx    38026 b- defN 21-Oct-22 15:15 pip/_vendor/msgpack/fallback.py
+-rw-r--r--  2.0 unx      661 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/__about__.py
+-rw-r--r--  2.0 unx      497 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/__init__.py
+-rw-r--r--  2.0 unx    11488 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/_manylinux.py
+-rw-r--r--  2.0 unx     4378 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/_musllinux.py
+-rw-r--r--  2.0 unx     1629 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/_structures.py
+-rw-r--r--  2.0 unx     8487 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/markers.py
+-rw-r--r--  2.0 unx     4676 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/requirements.py
+-rw-r--r--  2.0 unx    30964 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/specifiers.py
+-rw-r--r--  2.0 unx    15714 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/tags.py
+-rw-r--r--  2.0 unx     4200 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/utils.py
+-rw-r--r--  2.0 unx    14665 b- defN 21-Oct-22 15:15 pip/_vendor/packaging/version.py
+-rw-r--r--  2.0 unx      130 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/__init__.py
+-rw-r--r--  2.0 unx     3457 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/build.py
+-rw-r--r--  2.0 unx     6084 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/check.py
+-rw-r--r--  2.0 unx     4098 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/colorlog.py
+-rw-r--r--  2.0 unx     1253 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/compat.py
+-rw-r--r--  2.0 unx     1129 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/dirtools.py
+-rw-r--r--  2.0 unx     6100 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/envbuild.py
+-rw-r--r--  2.0 unx     2463 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/meta.py
+-rw-r--r--  2.0 unx    13429 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/wrappers.py
+-rw-r--r--  2.0 unx      563 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/in_process/__init__.py
+-rw-r--r--  2.0 unx    11201 b- defN 21-Oct-22 15:15 pip/_vendor/pep517/in_process/_in_process.py
+-rw-r--r--  2.0 unx   108287 b- defN 21-Oct-22 15:15 pip/_vendor/pkg_resources/__init__.py
+-rw-r--r--  2.0 unx      562 b- defN 21-Oct-22 15:15 pip/_vendor/pkg_resources/py31compat.py
+-rw-r--r--  2.0 unx    12859 b- defN 21-Oct-22 15:15 pip/_vendor/platformdirs/__init__.py
+-rw-r--r--  2.0 unx     1140 b- defN 21-Oct-22 15:15 pip/_vendor/platformdirs/__main__.py
+-rw-r--r--  2.0 unx     3994 b- defN 21-Oct-22 15:15 pip/_vendor/platformdirs/android.py
+-rw-r--r--  2.0 unx     4922 b- defN 21-Oct-22 15:15 pip/_vendor/platformdirs/api.py
+-rw-r--r--  2.0 unx     2619 b- defN 21-Oct-22 15:15 pip/_vendor/platformdirs/macos.py
+-rw-r--r--  2.0 unx     6905 b- defN 21-Oct-22 15:15 pip/_vendor/platformdirs/unix.py
+-rw-r--r--  2.0 unx       80 b- defN 21-Oct-22 15:15 pip/_vendor/platformdirs/version.py
+-rw-r--r--  2.0 unx     6416 b- defN 21-Oct-22 15:15 pip/_vendor/platformdirs/windows.py
+-rw-r--r--  2.0 unx     5294 b- defN 21-Oct-22 15:15 pip/_vendor/progress/__init__.py
+-rw-r--r--  2.0 unx     2942 b- defN 21-Oct-22 15:15 pip/_vendor/progress/bar.py
+-rw-r--r--  2.0 unx     2655 b- defN 21-Oct-22 15:15 pip/_vendor/progress/colors.py
+-rw-r--r--  2.0 unx     1613 b- defN 21-Oct-22 15:15 pip/_vendor/progress/counter.py
+-rw-r--r--  2.0 unx     1461 b- defN 21-Oct-22 15:15 pip/_vendor/progress/spinner.py
+-rw-r--r--  2.0 unx     5113 b- defN 21-Oct-22 15:15 pip/_vendor/requests/__init__.py
+-rw-r--r--  2.0 unx      441 b- defN 21-Oct-22 15:15 pip/_vendor/requests/__version__.py
+-rw-r--r--  2.0 unx     1096 b- defN 21-Oct-22 15:15 pip/_vendor/requests/_internal_utils.py
+-rw-r--r--  2.0 unx    21548 b- defN 21-Oct-22 15:15 pip/_vendor/requests/adapters.py
+-rw-r--r--  2.0 unx     6402 b- defN 21-Oct-22 15:15 pip/_vendor/requests/api.py
+-rw-r--r--  2.0 unx    10207 b- defN 21-Oct-22 15:15 pip/_vendor/requests/auth.py
+-rw-r--r--  2.0 unx      465 b- defN 21-Oct-22 15:15 pip/_vendor/requests/certs.py
+-rw-r--r--  2.0 unx     2045 b- defN 21-Oct-22 15:15 pip/_vendor/requests/compat.py
+-rw-r--r--  2.0 unx    18430 b- defN 21-Oct-22 15:15 pip/_vendor/requests/cookies.py
+-rw-r--r--  2.0 unx     3250 b- defN 21-Oct-22 15:15 pip/_vendor/requests/exceptions.py
+-rw-r--r--  2.0 unx     3972 b- defN 21-Oct-22 15:15 pip/_vendor/requests/help.py
+-rw-r--r--  2.0 unx      757 b- defN 21-Oct-22 15:15 pip/_vendor/requests/hooks.py
+-rw-r--r--  2.0 unx    34924 b- defN 21-Oct-22 15:15 pip/_vendor/requests/models.py
+-rw-r--r--  2.0 unx      695 b- defN 21-Oct-22 15:15 pip/_vendor/requests/packages.py
+-rw-r--r--  2.0 unx    30168 b- defN 21-Oct-22 15:15 pip/_vendor/requests/sessions.py
+-rw-r--r--  2.0 unx     4188 b- defN 21-Oct-22 15:15 pip/_vendor/requests/status_codes.py
+-rw-r--r--  2.0 unx     3005 b- defN 21-Oct-22 15:15 pip/_vendor/requests/structures.py
+-rw-r--r--  2.0 unx    31394 b- defN 21-Oct-22 15:15 pip/_vendor/requests/utils.py
+-rw-r--r--  2.0 unx      537 b- defN 21-Oct-22 15:15 pip/_vendor/resolvelib/__init__.py
+-rw-r--r--  2.0 unx     5872 b- defN 21-Oct-22 15:15 pip/_vendor/resolvelib/providers.py
+-rw-r--r--  2.0 unx     1364 b- defN 21-Oct-22 15:15 pip/_vendor/resolvelib/reporters.py
+-rw-r--r--  2.0 unx    17540 b- defN 21-Oct-22 15:15 pip/_vendor/resolvelib/resolvers.py
+-rw-r--r--  2.0 unx     4794 b- defN 21-Oct-22 15:15 pip/_vendor/resolvelib/structs.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_vendor/resolvelib/compat/__init__.py
+-rw-r--r--  2.0 unx      156 b- defN 21-Oct-22 15:15 pip/_vendor/resolvelib/compat/collections_abc.py
+-rw-r--r--  2.0 unx    18257 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/__init__.py
+-rw-r--r--  2.0 unx     3314 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/_asyncio.py
+-rw-r--r--  2.0 unx     1944 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/_utils.py
+-rw-r--r--  2.0 unx     1496 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/after.py
+-rw-r--r--  2.0 unx     1376 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/before.py
+-rw-r--r--  2.0 unx     1908 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/before_sleep.py
+-rw-r--r--  2.0 unx     1383 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/nap.py
+-rw-r--r--  2.0 unx     6645 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/retry.py
+-rw-r--r--  2.0 unx     2790 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/stop.py
+-rw-r--r--  2.0 unx     2145 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/tornadoweb.py
+-rw-r--r--  2.0 unx     6691 b- defN 21-Oct-22 15:15 pip/_vendor/tenacity/wait.py
+-rw-r--r--  2.0 unx      230 b- defN 21-Oct-22 15:15 pip/_vendor/tomli/__init__.py
+-rw-r--r--  2.0 unx    22415 b- defN 21-Oct-22 15:15 pip/_vendor/tomli/_parser.py
+-rw-r--r--  2.0 unx     2681 b- defN 21-Oct-22 15:15 pip/_vendor/tomli/_re.py
+-rw-r--r--  2.0 unx     2763 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/__init__.py
+-rw-r--r--  2.0 unx    10811 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/_collections.py
+-rw-r--r--  2.0 unx       63 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/_version.py
+-rw-r--r--  2.0 unx    20080 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/connection.py
+-rw-r--r--  2.0 unx    37587 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/connectionpool.py
+-rw-r--r--  2.0 unx     8217 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/exceptions.py
+-rw-r--r--  2.0 unx     8579 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/fields.py
+-rw-r--r--  2.0 unx     2440 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/filepost.py
+-rw-r--r--  2.0 unx    19763 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/poolmanager.py
+-rw-r--r--  2.0 unx     5985 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/request.py
+-rw-r--r--  2.0 unx    28203 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/response.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/__init__.py
+-rw-r--r--  2.0 unx      957 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/_appengine_environ.py
+-rw-r--r--  2.0 unx    11034 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/appengine.py
+-rw-r--r--  2.0 unx     4538 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/ntlmpool.py
+-rw-r--r--  2.0 unx    16900 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/pyopenssl.py
+-rw-r--r--  2.0 unx    34449 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/securetransport.py
+-rw-r--r--  2.0 unx     7097 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/socks.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/_securetransport/__init__.py
+-rw-r--r--  2.0 unx    17649 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/_securetransport/bindings.py
+-rw-r--r--  2.0 unx    13922 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/contrib/_securetransport/low_level.py
+-rw-r--r--  2.0 unx      108 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/packages/__init__.py
+-rw-r--r--  2.0 unx    34666 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/packages/six.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/packages/backports/__init__.py
+-rw-r--r--  2.0 unx     1417 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/packages/backports/makefile.py
+-rw-r--r--  2.0 unx      927 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/packages/ssl_match_hostname/__init__.py
+-rw-r--r--  2.0 unx     5679 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/packages/ssl_match_hostname/_implementation.py
+-rw-r--r--  2.0 unx     1155 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/__init__.py
+-rw-r--r--  2.0 unx     4920 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/connection.py
+-rw-r--r--  2.0 unx     1605 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/proxy.py
+-rw-r--r--  2.0 unx      498 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/queue.py
+-rw-r--r--  2.0 unx     4123 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/request.py
+-rw-r--r--  2.0 unx     3510 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/response.py
+-rw-r--r--  2.0 unx    21391 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/retry.py
+-rw-r--r--  2.0 unx    17177 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/ssl_.py
+-rw-r--r--  2.0 unx     6931 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/ssltransport.py
+-rw-r--r--  2.0 unx    10003 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/timeout.py
+-rw-r--r--  2.0 unx    14047 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/url.py
+-rw-r--r--  2.0 unx     5404 b- defN 21-Oct-22 15:15 pip/_vendor/urllib3/util/wait.py
+-rw-r--r--  2.0 unx    10579 b- defN 21-Oct-22 15:15 pip/_vendor/webencodings/__init__.py
+-rw-r--r--  2.0 unx     8979 b- defN 21-Oct-22 15:15 pip/_vendor/webencodings/labels.py
+-rw-r--r--  2.0 unx     1305 b- defN 21-Oct-22 15:15 pip/_vendor/webencodings/mklabels.py
+-rw-r--r--  2.0 unx     6563 b- defN 21-Oct-22 15:15 pip/_vendor/webencodings/tests.py
+-rw-r--r--  2.0 unx     4307 b- defN 21-Oct-22 15:15 pip/_vendor/webencodings/x_user_defined.py
+-rw-r--r--  2.0 unx     1090 b- defN 21-Oct-22 15:15 pip-21.3.1.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx     4216 b- defN 21-Oct-22 15:15 pip-21.3.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 21-Oct-22 15:15 pip-21.3.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx      125 b- defN 21-Oct-22 15:15 pip-21.3.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        4 b- defN 21-Oct-22 15:15 pip-21.3.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    37837 b- defN 21-Oct-22 15:15 pip-21.3.1.dist-info/RECORD
+415 files, 5797679 bytes uncompressed, 1663581 bytes compressed:  71.3%
```

#### zipnote «TEMP»/diffoscope_2t9ypn17_/tmpf7xjhxm3_.zip

```diff
@@ -240,20 +240,26 @@
 
 Filename: pip/_internal/operations/build/__init__.py
 Comment: 
 
 Filename: pip/_internal/operations/build/metadata.py
 Comment: 
 
+Filename: pip/_internal/operations/build/metadata_editable.py
+Comment: 
+
 Filename: pip/_internal/operations/build/metadata_legacy.py
 Comment: 
 
 Filename: pip/_internal/operations/build/wheel.py
 Comment: 
 
+Filename: pip/_internal/operations/build/wheel_editable.py
+Comment: 
+
 Filename: pip/_internal/operations/build/wheel_legacy.py
 Comment: 
 
 Filename: pip/_internal/operations/install/__init__.py
 Comment: 
 
 Filename: pip/_internal/operations/install/editable_legacy.py
@@ -348,14 +354,17 @@
 
 Filename: pip/_internal/utils/direct_url_helpers.py
 Comment: 
 
 Filename: pip/_internal/utils/distutils_args.py
 Comment: 
 
+Filename: pip/_internal/utils/egg_link.py
+Comment: 
+
 Filename: pip/_internal/utils/encoding.py
 Comment: 
 
 Filename: pip/_internal/utils/entrypoints.py
 Comment: 
 
 Filename: pip/_internal/utils/filesystem.py
@@ -429,17 +438,14 @@
 
 Filename: pip/_internal/vcs/versioncontrol.py
 Comment: 
 
 Filename: pip/_vendor/__init__.py
 Comment: 
 
-Filename: pip/_vendor/appdirs.py
-Comment: 
-
 Filename: pip/_vendor/distro.py
 Comment: 
 
 Filename: pip/_vendor/pyparsing.py
 Comment: 
 
 Filename: pip/_vendor/six.py
@@ -675,26 +681,32 @@
 
 Filename: pip/_vendor/distlib/scripts.py
 Comment: 
 
 Filename: pip/_vendor/distlib/t32.exe
 Comment: 
 
+Filename: pip/_vendor/distlib/t64-arm.exe
+Comment: 
+
 Filename: pip/_vendor/distlib/t64.exe
 Comment: 
 
 Filename: pip/_vendor/distlib/util.py
 Comment: 
 
 Filename: pip/_vendor/distlib/version.py
 Comment: 
 
 Filename: pip/_vendor/distlib/w32.exe
 Comment: 
 
+Filename: pip/_vendor/distlib/w64-arm.exe
+Comment: 
+
 Filename: pip/_vendor/distlib/w64.exe
 Comment: 
 
 Filename: pip/_vendor/distlib/wheel.py
 Comment: 
 
 Filename: pip/_vendor/distlib/_backport/__init__.py
@@ -921,20 +933,47 @@
 
 Filename: pip/_vendor/pkg_resources/__init__.py
 Comment: 
 
 Filename: pip/_vendor/pkg_resources/py31compat.py
 Comment: 
 
+Filename: pip/_vendor/platformdirs/__init__.py
+Comment: 
+
+Filename: pip/_vendor/platformdirs/__main__.py
+Comment: 
+
+Filename: pip/_vendor/platformdirs/android.py
+Comment: 
+
+Filename: pip/_vendor/platformdirs/api.py
+Comment: 
+
+Filename: pip/_vendor/platformdirs/macos.py
+Comment: 
+
+Filename: pip/_vendor/platformdirs/unix.py
+Comment: 
+
+Filename: pip/_vendor/platformdirs/version.py
+Comment: 
+
+Filename: pip/_vendor/platformdirs/windows.py
+Comment: 
+
 Filename: pip/_vendor/progress/__init__.py
 Comment: 
 
 Filename: pip/_vendor/progress/bar.py
 Comment: 
 
+Filename: pip/_vendor/progress/colors.py
+Comment: 
+
 Filename: pip/_vendor/progress/counter.py
 Comment: 
 
 Filename: pip/_vendor/progress/spinner.py
 Comment: 
 
 Filename: pip/_vendor/requests/__init__.py
@@ -1182,26 +1221,26 @@
 
 Filename: pip/_vendor/webencodings/tests.py
 Comment: 
 
 Filename: pip/_vendor/webencodings/x_user_defined.py
 Comment: 
 
-Filename: pip-21.2.4.dist-info/LICENSE.txt
+Filename: pip-21.3.1.dist-info/LICENSE.txt
 Comment: 
 
-Filename: pip-21.2.4.dist-info/METADATA
+Filename: pip-21.3.1.dist-info/METADATA
 Comment: 
 
-Filename: pip-21.2.4.dist-info/WHEEL
+Filename: pip-21.3.1.dist-info/WHEEL
 Comment: 
 
-Filename: pip-21.2.4.dist-info/entry_points.txt
+Filename: pip-21.3.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: pip-21.2.4.dist-info/top_level.txt
+Filename: pip-21.3.1.dist-info/top_level.txt
 Comment: 
 
-Filename: pip-21.2.4.dist-info/RECORD
+Filename: pip-21.3.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

#### pip/__init__.py

```diff
@@ -1,10 +1,10 @@
 from typing import List, Optional
 
-__version__ = "21.2.4"
+__version__ = "21.3.1"
 
 
 def main(args: Optional[List[str]] = None) -> int:
     """This is an internal API only meant for use by pip's own console scripts.
 
     For additional details, see https://github.com/pypa/pip/issues/7498.
     """
```

#### pip/_internal/build_env.py

```diff
@@ -27,23 +27,21 @@
 if TYPE_CHECKING:
     from pip._internal.index.package_finder import PackageFinder
 
 logger = logging.getLogger(__name__)
 
 
 class _Prefix:
-
-    def __init__(self, path):
-        # type: (str) -> None
+    def __init__(self, path: str) -> None:
         self.path = path
         self.setup = False
         self.bin_dir = get_paths(
-            'nt' if os.name == 'nt' else 'posix_prefix',
-            vars={'base': path, 'platbase': path}
-        )['scripts']
+            "nt" if os.name == "nt" else "posix_prefix",
+            vars={"base": path, "platbase": path},
+        )["scripts"]
         self.lib_dirs = get_prefixed_libs(path)
 
 
 @contextlib.contextmanager
 def _create_standalone_pip() -> Iterator[str]:
     """Create a "standalone pip" zip file.
 
@@ -66,46 +64,43 @@
         with zipfile.ZipFile(pip_zip, "w", **kwargs) as zf:
             for child in source.rglob("*"):
                 zf.write(child, child.relative_to(source.parent).as_posix())
         yield os.path.join(pip_zip, "pip")
 
 
 class BuildEnvironment:
-    """Creates and manages an isolated environment to install build deps
-    """
+    """Creates and manages an isolated environment to install build deps"""
 
-    def __init__(self):
-        # type: () -> None
-        temp_dir = TempDirectory(
-            kind=tempdir_kinds.BUILD_ENV, globally_managed=True
-        )
+    def __init__(self) -> None:
+        temp_dir = TempDirectory(kind=tempdir_kinds.BUILD_ENV, globally_managed=True)
 
         self._prefixes = OrderedDict(
             (name, _Prefix(os.path.join(temp_dir.path, name)))
-            for name in ('normal', 'overlay')
+            for name in ("normal", "overlay")
         )
 
-        self._bin_dirs = []  # type: List[str]
-        self._lib_dirs = []  # type: List[str]
+        self._bin_dirs: List[str] = []
+        self._lib_dirs: List[str] = []
         for prefix in reversed(list(self._prefixes.values())):
             self._bin_dirs.append(prefix.bin_dir)
             self._lib_dirs.extend(prefix.lib_dirs)
 
         # Customize site to:
         # - ensure .pth files are honored
         # - prevent access to system site packages
         system_sites = {
             os.path.normcase(site) for site in (get_purelib(), get_platlib())
         }
-        self._site_dir = os.path.join(temp_dir.path, 'site')
+        self._site_dir = os.path.join(temp_dir.path, "site")
         if not os.path.exists(self._site_dir):
             os.mkdir(self._site_dir)
-        with open(os.path.join(self._site_dir, 'sitecustomize.py'), 'w') as fp:
-            fp.write(textwrap.dedent(
-                '''
+        with open(os.path.join(self._site_dir, "sitecustomize.py"), "w") as fp:
+            fp.write(
+                textwrap.dedent(
+                    """
                 import os, site, sys
 
                 # First, drop system-sites related paths.
                 original_sys_path = sys.path[:]
                 known_paths = set()
                 for path in {system_sites!r}:
                     site.addsitedir(path, known_paths=known_paths)
@@ -120,55 +115,57 @@
                 sys.path = original_sys_path
 
                 # Second, add lib directories.
                 # ensuring .pth file are processed.
                 for path in {lib_dirs!r}:
                     assert not path in sys.path
                     site.addsitedir(path)
-                '''
-            ).format(system_sites=system_sites, lib_dirs=self._lib_dirs))
+                """
+                ).format(system_sites=system_sites, lib_dirs=self._lib_dirs)
+            )
 
-    def __enter__(self):
-        # type: () -> None
+    def __enter__(self) -> None:
         self._save_env = {
             name: os.environ.get(name, None)
-            for name in ('PATH', 'PYTHONNOUSERSITE', 'PYTHONPATH')
+            for name in ("PATH", "PYTHONNOUSERSITE", "PYTHONPATH")
         }
 
         path = self._bin_dirs[:]
-        old_path = self._save_env['PATH']
+        old_path = self._save_env["PATH"]
         if old_path:
             path.extend(old_path.split(os.pathsep))
 
         pythonpath = [self._site_dir]
 
-        os.environ.update({
-            'PATH': os.pathsep.join(path),
-            'PYTHONNOUSERSITE': '1',
-            'PYTHONPATH': os.pathsep.join(pythonpath),
-        })
+        os.environ.update(
+            {
+                "PATH": os.pathsep.join(path),
+                "PYTHONNOUSERSITE": "1",
+                "PYTHONPATH": os.pathsep.join(pythonpath),
+            }
+        )
 
     def __exit__(
         self,
-        exc_type,  # type: Optional[Type[BaseException]]
-        exc_val,  # type: Optional[BaseException]
-        exc_tb  # type: Optional[TracebackType]
-    ):
-        # type: (...) -> None
+        exc_type: Optional[Type[BaseException]],
+        exc_val: Optional[BaseException],
+        exc_tb: Optional[TracebackType],
+    ) -> None:
         for varname, old_value in self._save_env.items():
             if old_value is None:
                 os.environ.pop(varname, None)
             else:
                 os.environ[varname] = old_value
 
-    def check_requirements(self, reqs):
-        # type: (Iterable[str]) -> Tuple[Set[Tuple[str, str]], Set[str]]
+    def check_requirements(
+        self, reqs: Iterable[str]
+    ) -> Tuple[Set[Tuple[str, str]], Set[str]]:
         """Return 2 sets:
-            - conflicting requirements: set of (installed, wanted) reqs tuples
-            - missing requirements: set of reqs
+        - conflicting requirements: set of (installed, wanted) reqs tuples
+        - missing requirements: set of reqs
         """
         missing = set()
         conflicting = set()
         if reqs:
             env = get_environment(self._lib_dirs)
             for req_str in reqs:
                 req = Requirement(req_str)
@@ -183,20 +180,19 @@
                 if dist.version not in req.specifier:
                     conflicting.add((installed_req_str, req_str))
                 # FIXME: Consider direct URL?
         return conflicting, missing
 
     def install_requirements(
         self,
-        finder,  # type: PackageFinder
-        requirements,  # type: Iterable[str]
-        prefix_as_string,  # type: str
-        message  # type: str
-    ):
-        # type: (...) -> None
+        finder: "PackageFinder",
+        requirements: Iterable[str],
+        prefix_as_string: str,
+        message: str,
+    ) -> None:
         prefix = self._prefixes[prefix_as_string]
         assert not prefix.setup
         prefix.setup = True
         if not requirements:
             return
         with contextlib.ExitStack() as ctx:
             # TODO: Remove this block when dropping 3.6 support. Python 3.6
@@ -219,76 +215,79 @@
     def _install_requirements(
         pip_runnable: str,
         finder: "PackageFinder",
         requirements: Iterable[str],
         prefix: _Prefix,
         message: str,
     ) -> None:
-        args = [
-            sys.executable, pip_runnable, 'install',
-            '--ignore-installed', '--no-user', '--prefix', prefix.path,
-            '--no-warn-script-location',
-        ]  # type: List[str]
+        args: List[str] = [
+            sys.executable,
+            pip_runnable,
+            "install",
+            "--ignore-installed",
+            "--no-user",
+            "--prefix",
+            prefix.path,
+            "--no-warn-script-location",
+        ]
         if logger.getEffectiveLevel() <= logging.DEBUG:
-            args.append('-v')
-        for format_control in ('no_binary', 'only_binary'):
+            args.append("-v")
+        for format_control in ("no_binary", "only_binary"):
             formats = getattr(finder.format_control, format_control)
-            args.extend(('--' + format_control.replace('_', '-'),
-                         ','.join(sorted(formats or {':none:'}))))
+            args.extend(
+                (
+                    "--" + format_control.replace("_", "-"),
+                    ",".join(sorted(formats or {":none:"})),
+                )
+            )
 
         index_urls = finder.index_urls
         if index_urls:
-            args.extend(['-i', index_urls[0]])
+            args.extend(["-i", index_urls[0]])
             for extra_index in index_urls[1:]:
-                args.extend(['--extra-index-url', extra_index])
+                args.extend(["--extra-index-url", extra_index])
         else:
-            args.append('--no-index')
+            args.append("--no-index")
         for link in finder.find_links:
-            args.extend(['--find-links', link])
+            args.extend(["--find-links", link])
 
         for host in finder.trusted_hosts:
-            args.extend(['--trusted-host', host])
+            args.extend(["--trusted-host", host])
         if finder.allow_all_prereleases:
-            args.append('--pre')
+            args.append("--pre")
         if finder.prefer_binary:
-            args.append('--prefer-binary')
-        args.append('--')
+            args.append("--prefer-binary")
+        args.append("--")
         args.extend(requirements)
         extra_environ = {"_PIP_STANDALONE_CERT": where()}
         with open_spinner(message) as spinner:
             call_subprocess(args, spinner=spinner, extra_environ=extra_environ)
 
 
 class NoOpBuildEnvironment(BuildEnvironment):
-    """A no-op drop-in replacement for BuildEnvironment
-    """
+    """A no-op drop-in replacement for BuildEnvironment"""
 
-    def __init__(self):
-        # type: () -> None
+    def __init__(self) -> None:
         pass
 
-    def __enter__(self):
-        # type: () -> None
+    def __enter__(self) -> None:
         pass
 
     def __exit__(
         self,
-        exc_type,  # type: Optional[Type[BaseException]]
-        exc_val,  # type: Optional[BaseException]
-        exc_tb  # type: Optional[TracebackType]
-    ):
-        # type: (...) -> None
+        exc_type: Optional[Type[BaseException]],
+        exc_val: Optional[BaseException],
+        exc_tb: Optional[TracebackType],
+    ) -> None:
         pass
 
-    def cleanup(self):
-        # type: () -> None
+    def cleanup(self) -> None:
         pass
 
     def install_requirements(
         self,
-        finder,  # type: PackageFinder
-        requirements,  # type: Iterable[str]
-        prefix_as_string,  # type: str
-        message  # type: str
-    ):
-        # type: (...) -> None
+        finder: "PackageFinder",
+        requirements: Iterable[str],
+        prefix_as_string: str,
+        message: str,
+    ) -> None:
         raise NotImplementedError()
```

#### pip/_internal/cache.py

```diff
@@ -16,47 +16,45 @@
 from pip._internal.models.wheel import Wheel
 from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
 from pip._internal.utils.urls import path_to_url
 
 logger = logging.getLogger(__name__)
 
 
-def _hash_dict(d):
-    # type: (Dict[str, str]) -> str
+def _hash_dict(d: Dict[str, str]) -> str:
     """Return a stable sha224 of a dictionary."""
     s = json.dumps(d, sort_keys=True, separators=(",", ":"), ensure_ascii=True)
     return hashlib.sha224(s.encode("ascii")).hexdigest()
 
 
 class Cache:
     """An abstract class - provides cache directories for data from links
 
 
-        :param cache_dir: The root of the cache.
-        :param format_control: An object of FormatControl class to limit
-            binaries being read from the cache.
-        :param allowed_formats: which formats of files the cache should store.
-            ('binary' and 'source' are the only allowed values)
+    :param cache_dir: The root of the cache.
+    :param format_control: An object of FormatControl class to limit
+        binaries being read from the cache.
+    :param allowed_formats: which formats of files the cache should store.
+        ('binary' and 'source' are the only allowed values)
     """
 
-    def __init__(self, cache_dir, format_control, allowed_formats):
-        # type: (str, FormatControl, Set[str]) -> None
+    def __init__(
+        self, cache_dir: str, format_control: FormatControl, allowed_formats: Set[str]
+    ) -> None:
         super().__init__()
         assert not cache_dir or os.path.isabs(cache_dir)
         self.cache_dir = cache_dir or None
         self.format_control = format_control
         self.allowed_formats = allowed_formats
 
         _valid_formats = {"source", "binary"}
         assert self.allowed_formats.union(_valid_formats) == _valid_formats
 
-    def _get_cache_path_parts(self, link):
-        # type: (Link) -> List[str]
-        """Get parts of part that must be os.path.joined with cache_dir
-        """
+    def _get_cache_path_parts(self, link: Link) -> List[str]:
+        """Get parts of part that must be os.path.joined with cache_dir"""
 
         # We want to generate an url to use as our cache key, we don't want to
         # just re-use the URL because it might have other items in the fragment
         # and we don't care about those.
         key_parts = {"url": link.url_without_fragment}
         if link.hash_name is not None and link.hash is not None:
             key_parts[link.hash_name] = link.hash
@@ -80,66 +78,53 @@
         # We want to nest the directories some to prevent having a ton of top
         # level directories where we might run out of sub directories on some
         # FS.
         parts = [hashed[:2], hashed[2:4], hashed[4:6], hashed[6:]]
 
         return parts
 
-    def _get_candidates(self, link, canonical_package_name):
-        # type: (Link, str) -> List[Any]
-        can_not_cache = (
-            not self.cache_dir or
-            not canonical_package_name or
-            not link
-        )
+    def _get_candidates(self, link: Link, canonical_package_name: str) -> List[Any]:
+        can_not_cache = not self.cache_dir or not canonical_package_name or not link
         if can_not_cache:
             return []
 
-        formats = self.format_control.get_allowed_formats(
-            canonical_package_name
-        )
+        formats = self.format_control.get_allowed_formats(canonical_package_name)
         if not self.allowed_formats.intersection(formats):
             return []
 
         candidates = []
         path = self.get_path_for_link(link)
         if os.path.isdir(path):
             for candidate in os.listdir(path):
                 candidates.append((candidate, path))
         return candidates
 
-    def get_path_for_link(self, link):
-        # type: (Link) -> str
-        """Return a directory to store cached items in for link.
-        """
+    def get_path_for_link(self, link: Link) -> str:
+        """Return a directory to store cached items in for link."""
         raise NotImplementedError()
 
     def get(
         self,
-        link,            # type: Link
-        package_name,    # type: Optional[str]
-        supported_tags,  # type: List[Tag]
-    ):
-        # type: (...) -> Link
+        link: Link,
+        package_name: Optional[str],
+        supported_tags: List[Tag],
+    ) -> Link:
         """Returns a link to a cached item if it exists, otherwise returns the
         passed link.
         """
         raise NotImplementedError()
 
 
 class SimpleWheelCache(Cache):
-    """A cache of wheels for future installs.
-    """
+    """A cache of wheels for future installs."""
 
-    def __init__(self, cache_dir, format_control):
-        # type: (str, FormatControl) -> None
+    def __init__(self, cache_dir: str, format_control: FormatControl) -> None:
         super().__init__(cache_dir, format_control, {"binary"})
 
-    def get_path_for_link(self, link):
-        # type: (Link) -> str
+    def get_path_for_link(self, link: Link) -> str:
         """Return a directory to store cached wheels for link
 
         Because there are M wheels for any one sdist, we provide a directory
         to cache them in, and then consult that directory when looking up
         cache hits.
 
         We only insert things into the cache if they have plausible version
@@ -153,37 +138,36 @@
         parts = self._get_cache_path_parts(link)
         assert self.cache_dir
         # Store wheels within the root cache_dir
         return os.path.join(self.cache_dir, "wheels", *parts)
 
     def get(
         self,
-        link,            # type: Link
-        package_name,    # type: Optional[str]
-        supported_tags,  # type: List[Tag]
-    ):
-        # type: (...) -> Link
+        link: Link,
+        package_name: Optional[str],
+        supported_tags: List[Tag],
+    ) -> Link:
         candidates = []
 
         if not package_name:
             return link
 
         canonical_package_name = canonicalize_name(package_name)
-        for wheel_name, wheel_dir in self._get_candidates(
-            link, canonical_package_name
-        ):
+        for wheel_name, wheel_dir in self._get_candidates(link, canonical_package_name):
             try:
                 wheel = Wheel(wheel_name)
             except InvalidWheelFilename:
                 continue
             if canonicalize_name(wheel.name) != canonical_package_name:
                 logger.debug(
                     "Ignoring cached wheel %s for %s as it "
                     "does not match the expected distribution name %s.",
-                    wheel_name, link, package_name,
+                    wheel_name,
+                    link,
+                    package_name,
                 )
                 continue
             if not wheel.supported(supported_tags):
                 # Built for a different python/arch/etc
                 continue
             candidates.append(
                 (
@@ -197,77 +181,70 @@
             return link
 
         _, wheel_name, wheel_dir = min(candidates)
         return Link(path_to_url(os.path.join(wheel_dir, wheel_name)))
 
 
 class EphemWheelCache(SimpleWheelCache):
-    """A SimpleWheelCache that creates it's own temporary cache directory
-    """
+    """A SimpleWheelCache that creates it's own temporary cache directory"""
 
-    def __init__(self, format_control):
-        # type: (FormatControl) -> None
+    def __init__(self, format_control: FormatControl) -> None:
         self._temp_dir = TempDirectory(
             kind=tempdir_kinds.EPHEM_WHEEL_CACHE,
             globally_managed=True,
         )
 
         super().__init__(self._temp_dir.path, format_control)
 
 
 class CacheEntry:
     def __init__(
         self,
-        link,  # type: Link
-        persistent,  # type: bool
+        link: Link,
+        persistent: bool,
     ):
         self.link = link
         self.persistent = persistent
 
 
 class WheelCache(Cache):
     """Wraps EphemWheelCache and SimpleWheelCache into a single Cache
 
     This Cache allows for gracefully degradation, using the ephem wheel cache
     when a certain link is not found in the simple wheel cache first.
     """
 
-    def __init__(self, cache_dir, format_control):
-        # type: (str, FormatControl) -> None
-        super().__init__(cache_dir, format_control, {'binary'})
+    def __init__(self, cache_dir: str, format_control: FormatControl) -> None:
+        super().__init__(cache_dir, format_control, {"binary"})
         self._wheel_cache = SimpleWheelCache(cache_dir, format_control)
         self._ephem_cache = EphemWheelCache(format_control)
 
-    def get_path_for_link(self, link):
-        # type: (Link) -> str
+    def get_path_for_link(self, link: Link) -> str:
         return self._wheel_cache.get_path_for_link(link)
 
-    def get_ephem_path_for_link(self, link):
-        # type: (Link) -> str
+    def get_ephem_path_for_link(self, link: Link) -> str:
         return self._ephem_cache.get_path_for_link(link)
 
     def get(
         self,
-        link,            # type: Link
-        package_name,    # type: Optional[str]
-        supported_tags,  # type: List[Tag]
-    ):
-        # type: (...) -> Link
+        link: Link,
+        package_name: Optional[str],
+        supported_tags: List[Tag],
+    ) -> Link:
         cache_entry = self.get_cache_entry(link, package_name, supported_tags)
         if cache_entry is None:
             return link
         return cache_entry.link
 
     def get_cache_entry(
         self,
-        link,            # type: Link
-        package_name,    # type: Optional[str]
-        supported_tags,  # type: List[Tag]
-    ):
-        # type: (...) -> Optional[CacheEntry]
+        link: Link,
+        package_name: Optional[str],
+        supported_tags: List[Tag],
+    ) -> Optional[CacheEntry]:
         """Returns a CacheEntry with a link to a cached item if it exists or
         None. The cache entry indicates if the item was found in the persistent
         or ephemeral cache.
         """
         retval = self._wheel_cache.get(
             link=link,
             package_name=package_name,
```

#### pip/_internal/configuration.py

```diff
@@ -9,85 +9,78 @@
   Name combined with it's section (section.name)
 - variant
   A single word describing where the configuration key-value pair came from
 """
 
 import configparser
 import locale
-import logging
 import os
 import sys
 from typing import Any, Dict, Iterable, List, NewType, Optional, Tuple
 
 from pip._internal.exceptions import (
     ConfigurationError,
     ConfigurationFileCouldNotBeLoaded,
 )
 from pip._internal.utils import appdirs
 from pip._internal.utils.compat import WINDOWS
+from pip._internal.utils.logging import getLogger
 from pip._internal.utils.misc import ensure_dir, enum
 
 RawConfigParser = configparser.RawConfigParser  # Shorthand
 Kind = NewType("Kind", str)
 
-CONFIG_BASENAME = 'pip.ini' if WINDOWS else 'pip.conf'
+CONFIG_BASENAME = "pip.ini" if WINDOWS else "pip.conf"
 ENV_NAMES_IGNORED = "version", "help"
 
 # The kinds of configurations there are.
 kinds = enum(
-    USER="user",        # User Specific
-    GLOBAL="global",    # System Wide
-    SITE="site",        # [Virtual] Environment Specific
-    ENV="env",          # from PIP_CONFIG_FILE
+    USER="user",  # User Specific
+    GLOBAL="global",  # System Wide
+    SITE="site",  # [Virtual] Environment Specific
+    ENV="env",  # from PIP_CONFIG_FILE
     ENV_VAR="env-var",  # from Environment Variables
 )
 OVERRIDE_ORDER = kinds.GLOBAL, kinds.USER, kinds.SITE, kinds.ENV, kinds.ENV_VAR
 VALID_LOAD_ONLY = kinds.USER, kinds.GLOBAL, kinds.SITE
 
-logger = logging.getLogger(__name__)
+logger = getLogger(__name__)
 
 
 # NOTE: Maybe use the optionx attribute to normalize keynames.
-def _normalize_name(name):
-    # type: (str) -> str
-    """Make a name consistent regardless of source (environment or file)
-    """
-    name = name.lower().replace('_', '-')
-    if name.startswith('--'):
+def _normalize_name(name: str) -> str:
+    """Make a name consistent regardless of source (environment or file)"""
+    name = name.lower().replace("_", "-")
+    if name.startswith("--"):
         name = name[2:]  # only prefer long opts
     return name
 
 
-def _disassemble_key(name):
-    # type: (str) -> List[str]
+def _disassemble_key(name: str) -> List[str]:
     if "." not in name:
         error_message = (
             "Key does not contain dot separated section and key. "
             "Perhaps you wanted to use 'global.{}' instead?"
         ).format(name)
         raise ConfigurationError(error_message)
     return name.split(".", 1)
 
 
-def get_configuration_files():
-    # type: () -> Dict[Kind, List[str]]
+def get_configuration_files() -> Dict[Kind, List[str]]:
     global_config_files = [
-        os.path.join(path, CONFIG_BASENAME)
-        for path in appdirs.site_config_dirs('pip')
+        os.path.join(path, CONFIG_BASENAME) for path in appdirs.site_config_dirs("pip")
     ]
 
     site_config_file = os.path.join(sys.prefix, CONFIG_BASENAME)
     legacy_config_file = os.path.join(
-        os.path.expanduser('~'),
-        'pip' if WINDOWS else '.pip',
+        os.path.expanduser("~"),
+        "pip" if WINDOWS else ".pip",
         CONFIG_BASENAME,
     )
-    new_config_file = os.path.join(
-        appdirs.user_config_dir("pip"), CONFIG_BASENAME
-    )
+    new_config_file = os.path.join(appdirs.user_config_dir("pip"), CONFIG_BASENAME)
     return {
         kinds.GLOBAL: global_config_files,
         kinds.SITE: [site_config_file],
         kinds.USER: [legacy_config_file, new_config_file],
     }
 
 
@@ -101,76 +94,65 @@
     section "section".
 
     This allows for a clean interface wherein the both the section and the
     key-name are preserved in an easy to manage form in the configuration files
     and the data stored is also nice.
     """
 
-    def __init__(self, isolated, load_only=None):
-        # type: (bool, Optional[Kind]) -> None
+    def __init__(self, isolated: bool, load_only: Optional[Kind] = None) -> None:
         super().__init__()
 
         if load_only is not None and load_only not in VALID_LOAD_ONLY:
             raise ConfigurationError(
                 "Got invalid value for load_only - should be one of {}".format(
                     ", ".join(map(repr, VALID_LOAD_ONLY))
                 )
             )
         self.isolated = isolated
         self.load_only = load_only
 
         # Because we keep track of where we got the data from
-        self._parsers = {
+        self._parsers: Dict[Kind, List[Tuple[str, RawConfigParser]]] = {
             variant: [] for variant in OVERRIDE_ORDER
-        }  # type: Dict[Kind, List[Tuple[str, RawConfigParser]]]
-        self._config = {
+        }
+        self._config: Dict[Kind, Dict[str, Any]] = {
             variant: {} for variant in OVERRIDE_ORDER
-        }  # type: Dict[Kind, Dict[str, Any]]
-        self._modified_parsers = []  # type: List[Tuple[str, RawConfigParser]]
+        }
+        self._modified_parsers: List[Tuple[str, RawConfigParser]] = []
 
-    def load(self):
-        # type: () -> None
-        """Loads configuration from configuration files and environment
-        """
+    def load(self) -> None:
+        """Loads configuration from configuration files and environment"""
         self._load_config_files()
         if not self.isolated:
             self._load_environment_vars()
 
-    def get_file_to_edit(self):
-        # type: () -> Optional[str]
-        """Returns the file with highest priority in configuration
-        """
-        assert self.load_only is not None, \
-            "Need to be specified a file to be editing"
+    def get_file_to_edit(self) -> Optional[str]:
+        """Returns the file with highest priority in configuration"""
+        assert self.load_only is not None, "Need to be specified a file to be editing"
 
         try:
             return self._get_parser_to_modify()[0]
         except IndexError:
             return None
 
-    def items(self):
-        # type: () -> Iterable[Tuple[str, Any]]
+    def items(self) -> Iterable[Tuple[str, Any]]:
         """Returns key-value pairs like dict.items() representing the loaded
         configuration
         """
         return self._dictionary.items()
 
-    def get_value(self, key):
-        # type: (str) -> Any
-        """Get a value from the configuration.
-        """
+    def get_value(self, key: str) -> Any:
+        """Get a value from the configuration."""
         try:
             return self._dictionary[key]
         except KeyError:
             raise ConfigurationError(f"No such key - {key}")
 
-    def set_value(self, key, value):
-        # type: (str, Any) -> None
-        """Modify a value in the configuration.
-        """
+    def set_value(self, key: str, value: Any) -> None:
+        """Modify a value in the configuration."""
         self._ensure_have_load_only()
 
         assert self.load_only
         fname, parser = self._get_parser_to_modify()
 
         if parser is not None:
             section, name = _disassemble_key(key)
@@ -179,45 +161,43 @@
             if not parser.has_section(section):
                 parser.add_section(section)
             parser.set(section, name, value)
 
         self._config[self.load_only][key] = value
         self._mark_as_modified(fname, parser)
 
-    def unset_value(self, key):
-        # type: (str) -> None
+    def unset_value(self, key: str) -> None:
         """Unset a value in the configuration."""
         self._ensure_have_load_only()
 
         assert self.load_only
         if key not in self._config[self.load_only]:
             raise ConfigurationError(f"No such key - {key}")
 
         fname, parser = self._get_parser_to_modify()
 
         if parser is not None:
             section, name = _disassemble_key(key)
-            if not (parser.has_section(section)
-                    and parser.remove_option(section, name)):
+            if not (
+                parser.has_section(section) and parser.remove_option(section, name)
+            ):
                 # The option was not removed.
                 raise ConfigurationError(
                     "Fatal Internal error [id=1]. Please report as a bug."
                 )
 
             # The section may be empty after the option was removed.
             if not parser.items(section):
                 parser.remove_section(section)
             self._mark_as_modified(fname, parser)
 
         del self._config[self.load_only][key]
 
-    def save(self):
-        # type: () -> None
-        """Save the current in-memory state.
-        """
+    def save(self) -> None:
+        """Save the current in-memory state."""
         self._ensure_have_load_only()
 
         for fname, parser in self._modified_parsers:
             logger.info("Writing to %s", fname)
 
             # Ensure directory exists.
             ensure_dir(os.path.dirname(fname))
@@ -225,74 +205,65 @@
             with open(fname, "w") as f:
                 parser.write(f)
 
     #
     # Private routines
     #
 
-    def _ensure_have_load_only(self):
-        # type: () -> None
+    def _ensure_have_load_only(self) -> None:
         if self.load_only is None:
             raise ConfigurationError("Needed a specific file to be modifying.")
         logger.debug("Will be working with %s variant only", self.load_only)
 
     @property
-    def _dictionary(self):
-        # type: () -> Dict[str, Any]
-        """A dictionary representing the loaded configuration.
-        """
+    def _dictionary(self) -> Dict[str, Any]:
+        """A dictionary representing the loaded configuration."""
         # NOTE: Dictionaries are not populated if not loaded. So, conditionals
         #       are not needed here.
         retval = {}
 
         for variant in OVERRIDE_ORDER:
             retval.update(self._config[variant])
 
         return retval
 
-    def _load_config_files(self):
-        # type: () -> None
-        """Loads configuration from configuration files
-        """
+    def _load_config_files(self) -> None:
+        """Loads configuration from configuration files"""
         config_files = dict(self.iter_config_files())
         if config_files[kinds.ENV][0:1] == [os.devnull]:
             logger.debug(
                 "Skipping loading configuration files due to "
                 "environment's PIP_CONFIG_FILE being os.devnull"
             )
             return
 
         for variant, files in config_files.items():
             for fname in files:
                 # If there's specific variant set in `load_only`, load only
                 # that variant, not the others.
                 if self.load_only is not None and variant != self.load_only:
-                    logger.debug(
-                        "Skipping file '%s' (variant: %s)", fname, variant
-                    )
+                    logger.debug("Skipping file '%s' (variant: %s)", fname, variant)
                     continue
 
                 parser = self._load_file(variant, fname)
 
                 # Keeping track of the parsers used
                 self._parsers[variant].append((fname, parser))
 
-    def _load_file(self, variant, fname):
-        # type: (Kind, str) -> RawConfigParser
-        logger.debug("For variant '%s', will try loading '%s'", variant, fname)
+    def _load_file(self, variant: Kind, fname: str) -> RawConfigParser:
+        logger.verbose("For variant '%s', will try loading '%s'", variant, fname)
         parser = self._construct_parser(fname)
 
         for section in parser.sections():
             items = parser.items(section)
             self._config[variant].update(self._normalized_keys(section, items))
 
         return parser
 
-    def _construct_parser(self, fname):
-        # type: (str) -> RawConfigParser
+    def _construct_parser(self, fname: str) -> RawConfigParser:
         parser = configparser.RawConfigParser()
         # If there is no such file, don't bother reading it but create the
         # parser anyway, to hold the data.
         # Doing this is useful when modifying and saving files, where we don't
         # need to construct a parser.
         if os.path.exists(fname):
             try:
@@ -306,55 +277,52 @@
                     fname=fname,
                 )
             except configparser.Error as error:
                 # See https://github.com/pypa/pip/issues/4893
                 raise ConfigurationFileCouldNotBeLoaded(error=error)
         return parser
 
-    def _load_environment_vars(self):
-        # type: () -> None
-        """Loads configuration from environment variables
-        """
+    def _load_environment_vars(self) -> None:
+        """Loads configuration from environment variables"""
         self._config[kinds.ENV_VAR].update(
             self._normalized_keys(":env:", self.get_environ_vars())
         )
 
-    def _normalized_keys(self, section, items):
-        # type: (str, Iterable[Tuple[str, Any]]) -> Dict[str, Any]
+    def _normalized_keys(
+        self, section: str, items: Iterable[Tuple[str, Any]]
+    ) -> Dict[str, Any]:
         """Normalizes items to construct a dictionary with normalized keys.
 
         This routine is where the names become keys and are made the same
         regardless of source - configuration files or environment.
         """
         normalized = {}
         for name, val in items:
             key = section + "." + _normalize_name(name)
             normalized[key] = val
         return normalized
 
-    def get_environ_vars(self):
-        # type: () -> Iterable[Tuple[str, str]]
+    def get_environ_vars(self) -> Iterable[Tuple[str, str]]:
         """Returns a generator with all environmental vars with prefix PIP_"""
         for key, val in os.environ.items():
             if key.startswith("PIP_"):
                 name = key[4:].lower()
                 if name not in ENV_NAMES_IGNORED:
                     yield name, val
 
     # XXX: This is patched in the tests.
-    def iter_config_files(self):
-        # type: () -> Iterable[Tuple[Kind, List[str]]]
+    def iter_config_files(self) -> Iterable[Tuple[Kind, List[str]]]:
         """Yields variant and configuration files associated with it.
 
         This should be treated like items of a dictionary.
         """
         # SMELL: Move the conditions out of this function
 
         # environment variables have the lowest priority
-        config_file = os.environ.get('PIP_CONFIG_FILE', None)
+        config_file = os.environ.get("PIP_CONFIG_FILE", None)
         if config_file is not None:
             yield kinds.ENV, [config_file]
         else:
             yield kinds.ENV, []
 
         config_files = get_configuration_files()
 
@@ -368,36 +336,32 @@
         if should_load_user_config:
             # The legacy config file is overridden by the new config file
             yield kinds.USER, config_files[kinds.USER]
 
         # finally virtualenv configuration first trumping others
         yield kinds.SITE, config_files[kinds.SITE]
 
-    def get_values_in_config(self, variant):
-        # type: (Kind) -> Dict[str, Any]
+    def get_values_in_config(self, variant: Kind) -> Dict[str, Any]:
         """Get values present in a config file"""
         return self._config[variant]
 
-    def _get_parser_to_modify(self):
-        # type: () -> Tuple[str, RawConfigParser]
+    def _get_parser_to_modify(self) -> Tuple[str, RawConfigParser]:
         # Determine which parser to modify
         assert self.load_only
         parsers = self._parsers[self.load_only]
         if not parsers:
             # This should not happen if everything works correctly.
             raise ConfigurationError(
                 "Fatal Internal error [id=2]. Please report as a bug."
             )
 
         # Use the highest priority parser.
         return parsers[-1]
 
     # XXX: This is patched in the tests.
-    def _mark_as_modified(self, fname, parser):
-        # type: (str, RawConfigParser) -> None
+    def _mark_as_modified(self, fname: str, parser: RawConfigParser) -> None:
         file_parser_tuple = (fname, parser)
         if file_parser_tuple not in self._modified_parsers:
             self._modified_parsers.append(file_parser_tuple)
 
-    def __repr__(self):
-        # type: () -> str
+    def __repr__(self) -> str:
         return f"{self.__class__.__name__}({self._dictionary!r})"
```

#### pip/_internal/exceptions.py

```diff
@@ -1,19 +1,20 @@
 """Exceptions used throughout package"""
 
 import configparser
 from itertools import chain, groupby, repeat
-from typing import TYPE_CHECKING, Dict, List, Optional
+from typing import TYPE_CHECKING, Dict, List, Optional, Union
 
 from pip._vendor.pkg_resources import Distribution
 from pip._vendor.requests.models import Request, Response
 
 if TYPE_CHECKING:
     from hashlib import _Hash
 
+    from pip._internal.metadata import BaseDistribution
     from pip._internal.req.req_install import InstallRequirement
 
 
 class PipError(Exception):
     """Base pip exception"""
 
 
@@ -34,46 +35,45 @@
     Raised when accessing "METADATA" or "PKG-INFO" metadata for a
     pip._vendor.pkg_resources.Distribution object and
     `dist.has_metadata('METADATA')` returns True but
     `dist.get_metadata('METADATA')` returns None (and similarly for
     "PKG-INFO").
     """
 
-    def __init__(self, dist, metadata_name):
-        # type: (Distribution, str) -> None
+    def __init__(
+        self,
+        dist: Union[Distribution, "BaseDistribution"],
+        metadata_name: str,
+    ) -> None:
         """
         :param dist: A Distribution object.
         :param metadata_name: The name of the metadata being accessed
             (can be "METADATA" or "PKG-INFO").
         """
         self.dist = dist
         self.metadata_name = metadata_name
 
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         # Use `dist` in the error message because its stringification
         # includes more information, like the version and location.
-        return (
-            'None {} metadata found for distribution: {}'.format(
-                self.metadata_name, self.dist,
-            )
+        return "None {} metadata found for distribution: {}".format(
+            self.metadata_name,
+            self.dist,
         )
 
 
 class UserInstallationInvalid(InstallationError):
     """A --user install is requested on an environment without user site."""
 
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         return "User base directory is not specified"
 
 
 class InvalidSchemeCombination(InstallationError):
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         before = ", ".join(str(a) for a in self.args[:-1])
         return f"Cannot set {before} and {self.args[-1]} together"
 
 
 class DistributionNotFound(InstallationError):
     """Raised when a distribution cannot be found to satisfy a requirement"""
 
@@ -98,30 +98,33 @@
 class PreviousBuildDirError(PipError):
     """Raised when there's a previous conflicting build directory"""
 
 
 class NetworkConnectionError(PipError):
     """HTTP connection error"""
 
-    def __init__(self, error_msg, response=None, request=None):
-        # type: (str, Response, Request) -> None
+    def __init__(
+        self, error_msg: str, response: Response = None, request: Request = None
+    ) -> None:
         """
         Initialize NetworkConnectionError with  `request` and `response`
         objects.
         """
         self.response = response
         self.request = request
         self.error_msg = error_msg
-        if (self.response is not None and not self.request and
-                hasattr(response, 'request')):
+        if (
+            self.response is not None
+            and not self.request
+            and hasattr(response, "request")
+        ):
             self.request = self.response.request
         super().__init__(error_msg, response, request)
 
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         return str(self.error_msg)
 
 
 class InvalidWheelFilename(InstallationError):
     """Invalid wheel filename."""
 
 
@@ -132,75 +135,67 @@
 class MetadataInconsistent(InstallationError):
     """Built metadata contains inconsistent information.
 
     This is raised when the metadata contains values (e.g. name and version)
     that do not match the information previously obtained from sdist filename
     or user-supplied ``#egg=`` value.
     """
-    def __init__(self, ireq, field, f_val, m_val):
-        # type: (InstallRequirement, str, str, str) -> None
+
+    def __init__(
+        self, ireq: "InstallRequirement", field: str, f_val: str, m_val: str
+    ) -> None:
         self.ireq = ireq
         self.field = field
         self.f_val = f_val
         self.m_val = m_val
 
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         template = (
             "Requested {} has inconsistent {}: "
             "filename has {!r}, but metadata has {!r}"
         )
         return template.format(self.ireq, self.field, self.f_val, self.m_val)
 
 
 class InstallationSubprocessError(InstallationError):
     """A subprocess call failed during installation."""
-    def __init__(self, returncode, description):
-        # type: (int, str) -> None
+
+    def __init__(self, returncode: int, description: str) -> None:
         self.returncode = returncode
         self.description = description
 
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         return (
             "Command errored out with exit status {}: {} "
             "Check the logs for full command output."
         ).format(self.returncode, self.description)
 
 
 class HashErrors(InstallationError):
     """Multiple HashError instances rolled into one for reporting"""
 
-    def __init__(self):
-        # type: () -> None
-        self.errors = []  # type: List[HashError]
+    def __init__(self) -> None:
+        self.errors: List["HashError"] = []
 
-    def append(self, error):
-        # type: (HashError) -> None
+    def append(self, error: "HashError") -> None:
         self.errors.append(error)
 
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         lines = []
         self.errors.sort(key=lambda e: e.order)
         for cls, errors_of_cls in groupby(self.errors, lambda e: e.__class__):
             lines.append(cls.head)
             lines.extend(e.body() for e in errors_of_cls)
         if lines:
-            return '\n'.join(lines)
-        return ''
+            return "\n".join(lines)
+        return ""
 
-    def __nonzero__(self):
-        # type: () -> bool
+    def __bool__(self) -> bool:
         return bool(self.errors)
 
-    def __bool__(self):
-        # type: () -> bool
-        return self.__nonzero__()
-
 
 class HashError(InstallationError):
     """
     A failure to verify a package against known-good hashes
 
     :cvar order: An int sorting hash exception classes by difficulty of
         recovery (lower being harder), so the user doesn't bother fretting
@@ -210,188 +205,198 @@
     :cvar head: A section heading for display above potentially many
         exceptions of this kind
     :ivar req: The InstallRequirement that triggered this error. This is
         pasted on after the exception is instantiated, because it's not
         typically available earlier.
 
     """
-    req = None  # type: Optional[InstallRequirement]
-    head = ''
-    order = -1  # type: int
 
-    def body(self):
-        # type: () -> str
+    req: Optional["InstallRequirement"] = None
+    head = ""
+    order: int = -1
+
+    def body(self) -> str:
         """Return a summary of me for display under the heading.
 
         This default implementation simply prints a description of the
         triggering requirement.
 
         :param req: The InstallRequirement that provoked this error, with
             its link already populated by the resolver's _populate_link().
 
         """
-        return f'    {self._requirement_name()}'
+        return f"    {self._requirement_name()}"
 
-    def __str__(self):
-        # type: () -> str
-        return f'{self.head}\n{self.body()}'
+    def __str__(self) -> str:
+        return f"{self.head}\n{self.body()}"
 
-    def _requirement_name(self):
-        # type: () -> str
+    def _requirement_name(self) -> str:
         """Return a description of the requirement that triggered me.
 
         This default implementation returns long description of the req, with
         line numbers
 
         """
-        return str(self.req) if self.req else 'unknown package'
+        return str(self.req) if self.req else "unknown package"
 
 
 class VcsHashUnsupported(HashError):
     """A hash was provided for a version-control-system-based requirement, but
     we don't have a method for hashing those."""
 
     order = 0
-    head = ("Can't verify hashes for these requirements because we don't "
-            "have a way to hash version control repositories:")
+    head = (
+        "Can't verify hashes for these requirements because we don't "
+        "have a way to hash version control repositories:"
+    )
 
 
 class DirectoryUrlHashUnsupported(HashError):
     """A hash was provided for a version-control-system-based requirement, but
     we don't have a method for hashing those."""
 
     order = 1
-    head = ("Can't verify hashes for these file:// requirements because they "
-            "point to directories:")
+    head = (
+        "Can't verify hashes for these file:// requirements because they "
+        "point to directories:"
+    )
 
 
 class HashMissing(HashError):
     """A hash was needed for a requirement but is absent."""
 
     order = 2
-    head = ('Hashes are required in --require-hashes mode, but they are '
-            'missing from some requirements. Here is a list of those '
-            'requirements along with the hashes their downloaded archives '
-            'actually had. Add lines like these to your requirements files to '
-            'prevent tampering. (If you did not enable --require-hashes '
-            'manually, note that it turns on automatically when any package '
-            'has a hash.)')
+    head = (
+        "Hashes are required in --require-hashes mode, but they are "
+        "missing from some requirements. Here is a list of those "
+        "requirements along with the hashes their downloaded archives "
+        "actually had. Add lines like these to your requirements files to "
+        "prevent tampering. (If you did not enable --require-hashes "
+        "manually, note that it turns on automatically when any package "
+        "has a hash.)"
+    )
 
-    def __init__(self, gotten_hash):
-        # type: (str) -> None
+    def __init__(self, gotten_hash: str) -> None:
         """
         :param gotten_hash: The hash of the (possibly malicious) archive we
             just downloaded
         """
         self.gotten_hash = gotten_hash
 
-    def body(self):
-        # type: () -> str
+    def body(self) -> str:
         # Dodge circular import.
         from pip._internal.utils.hashes import FAVORITE_HASH
 
         package = None
         if self.req:
             # In the case of URL-based requirements, display the original URL
             # seen in the requirements file rather than the package name,
             # so the output can be directly copied into the requirements file.
-            package = (self.req.original_link if self.req.original_link
-                       # In case someone feeds something downright stupid
-                       # to InstallRequirement's constructor.
-                       else getattr(self.req, 'req', None))
-        return '    {} --hash={}:{}'.format(package or 'unknown package',
-                                            FAVORITE_HASH,
-                                            self.gotten_hash)
+            package = (
+                self.req.original_link
+                if self.req.original_link
+                # In case someone feeds something downright stupid
+                # to InstallRequirement's constructor.
+                else getattr(self.req, "req", None)
+            )
+        return "    {} --hash={}:{}".format(
+            package or "unknown package", FAVORITE_HASH, self.gotten_hash
+        )
 
 
 class HashUnpinned(HashError):
     """A requirement had a hash specified but was not pinned to a specific
     version."""
 
     order = 3
-    head = ('In --require-hashes mode, all requirements must have their '
-            'versions pinned with ==. These do not:')
+    head = (
+        "In --require-hashes mode, all requirements must have their "
+        "versions pinned with ==. These do not:"
+    )
 
 
 class HashMismatch(HashError):
     """
     Distribution file hash values don't match.
 
     :ivar package_name: The name of the package that triggered the hash
         mismatch. Feel free to write to this after the exception is raise to
         improve its error message.
 
     """
+
     order = 4
-    head = ('THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS '
-            'FILE. If you have updated the package versions, please update '
-            'the hashes. Otherwise, examine the package contents carefully; '
-            'someone may have tampered with them.')
+    head = (
+        "THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS "
+        "FILE. If you have updated the package versions, please update "
+        "the hashes. Otherwise, examine the package contents carefully; "
+        "someone may have tampered with them."
+    )
 
-    def __init__(self, allowed, gots):
-        # type: (Dict[str, List[str]], Dict[str, _Hash]) -> None
+    def __init__(self, allowed: Dict[str, List[str]], gots: Dict[str, "_Hash"]) -> None:
         """
         :param allowed: A dict of algorithm names pointing to lists of allowed
             hex digests
         :param gots: A dict of algorithm names pointing to hashes we
             actually got from the files under suspicion
         """
         self.allowed = allowed
         self.gots = gots
 
-    def body(self):
-        # type: () -> str
-        return '    {}:\n{}'.format(self._requirement_name(),
-                                    self._hash_comparison())
+    def body(self) -> str:
+        return "    {}:\n{}".format(self._requirement_name(), self._hash_comparison())
 
-    def _hash_comparison(self):
-        # type: () -> str
+    def _hash_comparison(self) -> str:
         """
         Return a comparison of actual and expected hash values.
 
         Example::
 
                Expected sha256 abcdeabcdeabcdeabcdeabcdeabcdeabcdeabcdeabcde
                             or 123451234512345123451234512345123451234512345
                     Got        bcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdef
 
         """
-        def hash_then_or(hash_name):
-            # type: (str) -> chain[str]
+
+        def hash_then_or(hash_name: str) -> "chain[str]":
             # For now, all the decent hashes have 6-char names, so we can get
             # away with hard-coding space literals.
-            return chain([hash_name], repeat('    or'))
+            return chain([hash_name], repeat("    or"))
 
-        lines = []  # type: List[str]
+        lines: List[str] = []
         for hash_name, expecteds in self.allowed.items():
             prefix = hash_then_or(hash_name)
-            lines.extend(('        Expected {} {}'.format(next(prefix), e))
-                         for e in expecteds)
-            lines.append('             Got        {}\n'.format(
-                         self.gots[hash_name].hexdigest()))
-        return '\n'.join(lines)
+            lines.extend(
+                ("        Expected {} {}".format(next(prefix), e)) for e in expecteds
+            )
+            lines.append(
+                "             Got        {}\n".format(self.gots[hash_name].hexdigest())
+            )
+        return "\n".join(lines)
 
 
 class UnsupportedPythonVersion(InstallationError):
     """Unsupported python version according to Requires-Python package
     metadata."""
 
 
 class ConfigurationFileCouldNotBeLoaded(ConfigurationError):
-    """When there are errors while loading a configuration file
-    """
+    """When there are errors while loading a configuration file"""
 
-    def __init__(self, reason="could not be loaded", fname=None, error=None):
-        # type: (str, Optional[str], Optional[configparser.Error]) -> None
+    def __init__(
+        self,
+        reason: str = "could not be loaded",
+        fname: Optional[str] = None,
+        error: Optional[configparser.Error] = None,
+    ) -> None:
         super().__init__(error)
         self.reason = reason
         self.fname = fname
         self.error = error
 
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         if self.fname is not None:
             message_part = f" in {self.fname}."
         else:
             assert self.error is not None
             message_part = f".\n{self.error}\n"
         return f"Configuration file {self.reason}{message_part}"
```

#### pip/_internal/main.py

```diff
@@ -1,12 +1,11 @@
 from typing import List, Optional
 
 
-def main(args=None):
-    # type: (Optional[List[str]]) -> int
+def main(args: Optional[List[str]] = None) -> int:
     """This is preserved for old console scripts that may still be referencing
     it.
 
     For additional details, see https://github.com/pypa/pip/issues/7498.
     """
     from pip._internal.utils.entrypoints import _wrapper
```

#### pip/_internal/pyproject.py

```diff
@@ -4,39 +4,30 @@
 
 from pip._vendor import tomli
 from pip._vendor.packaging.requirements import InvalidRequirement, Requirement
 
 from pip._internal.exceptions import InstallationError
 
 
-def _is_list_of_str(obj):
-    # type: (Any) -> bool
-    return (
-        isinstance(obj, list) and
-        all(isinstance(item, str) for item in obj)
-    )
+def _is_list_of_str(obj: Any) -> bool:
+    return isinstance(obj, list) and all(isinstance(item, str) for item in obj)
 
 
-def make_pyproject_path(unpacked_source_directory):
-    # type: (str) -> str
-    return os.path.join(unpacked_source_directory, 'pyproject.toml')
+def make_pyproject_path(unpacked_source_directory: str) -> str:
+    return os.path.join(unpacked_source_directory, "pyproject.toml")
 
 
-BuildSystemDetails = namedtuple('BuildSystemDetails', [
-    'requires', 'backend', 'check', 'backend_path'
-])
+BuildSystemDetails = namedtuple(
+    "BuildSystemDetails", ["requires", "backend", "check", "backend_path"]
+)
 
 
 def load_pyproject_toml(
-    use_pep517,  # type: Optional[bool]
-    pyproject_toml,  # type: str
-    setup_py,  # type: str
-    req_name  # type: str
-):
-    # type: (...) -> Optional[BuildSystemDetails]
+    use_pep517: Optional[bool], pyproject_toml: str, setup_py: str, req_name: str
+) -> Optional[BuildSystemDetails]:
     """Load the pyproject.toml file.
 
     Parameters:
         use_pep517 - Has the user requested PEP 517 processing? None
                      means the user hasn't explicitly specified.
         pyproject_toml - Location of the project's pyproject.toml file
         setup_py - Location of the project's setup.py file
@@ -53,14 +44,20 @@
             directory paths to import the backend from (backend-path),
                 relative to the project root.
         )
     """
     has_pyproject = os.path.isfile(pyproject_toml)
     has_setup = os.path.isfile(setup_py)
 
+    if not has_pyproject and not has_setup:
+        raise InstallationError(
+            f"{req_name} does not appear to be a Python project: "
+            f"neither 'setup.py' nor 'pyproject.toml' found."
+        )
+
     if has_pyproject:
         with open(pyproject_toml, encoding="utf-8") as f:
             pp_toml = tomli.load(f)
         build_system = pp_toml.get("build-system")
     else:
         build_system = None
 
@@ -78,17 +75,15 @@
             )
         use_pep517 = True
     elif build_system and "build-backend" in build_system:
         if use_pep517 is not None and not use_pep517:
             raise InstallationError(
                 "Disabling PEP 517 processing is invalid: "
                 "project specifies a build backend of {} "
-                "in pyproject.toml".format(
-                    build_system["build-backend"]
-                )
+                "in pyproject.toml".format(build_system["build-backend"])
             )
         use_pep517 = True
 
     # If we haven't worked out whether to use PEP 517 yet,
     # and the user hasn't explicitly stated a preference,
     # we do so if the project has a pyproject.toml file.
     elif use_pep517 is None:
@@ -128,27 +123,32 @@
         "{package} has a pyproject.toml file that does not comply "
         "with PEP 518: {reason}"
     )
 
     # Specifying the build-system table but not the requires key is invalid
     if "requires" not in build_system:
         raise InstallationError(
-            error_template.format(package=req_name, reason=(
-                "it has a 'build-system' table but not "
-                "'build-system.requires' which is mandatory in the table"
-            ))
+            error_template.format(
+                package=req_name,
+                reason=(
+                    "it has a 'build-system' table but not "
+                    "'build-system.requires' which is mandatory in the table"
+                ),
+            )
         )
 
     # Error out if requires is not a list of strings
     requires = build_system["requires"]
     if not _is_list_of_str(requires):
-        raise InstallationError(error_template.format(
-            package=req_name,
-            reason="'build-system.requires' is not a list of strings.",
-        ))
+        raise InstallationError(
+            error_template.format(
+                package=req_name,
+                reason="'build-system.requires' is not a list of strings.",
+            )
+        )
 
     # Each requirement must be valid as per PEP 508
     for requirement in requires:
         try:
             Requirement(requirement)
         except InvalidRequirement:
             raise InstallationError(
@@ -159,15 +159,15 @@
                         "requirement: {!r}".format(requirement)
                     ),
                 )
             )
 
     backend = build_system.get("build-backend")
     backend_path = build_system.get("backend-path", [])
-    check = []  # type: List[str]
+    check: List[str] = []
     if backend is None:
         # If the user didn't specify a backend, we assume they want to use
         # the setuptools backend. But we can't be sure they have included
         # a version of setuptools which supplies the backend, or wheel
         # (which is needed by the backend) in their requirements. So we
         # make a note to check that those requirements are present once
         # we have set up the environment.
```

#### pip/_internal/self_outdated_check.py

```diff
@@ -19,25 +19,23 @@
 
 SELFCHECK_DATE_FMT = "%Y-%m-%dT%H:%M:%SZ"
 
 
 logger = logging.getLogger(__name__)
 
 
-def _get_statefile_name(key):
-    # type: (str) -> str
+def _get_statefile_name(key: str) -> str:
     key_bytes = key.encode()
     name = hashlib.sha224(key_bytes).hexdigest()
     return name
 
 
 class SelfCheckState:
-    def __init__(self, cache_dir):
-        # type: (str) -> None
-        self.state = {}  # type: Dict[str, Any]
+    def __init__(self, cache_dir: str) -> None:
+        self.state: Dict[str, Any] = {}
         self.statefile_path = None
 
         # Try to load the existing state
         if cache_dir:
             self.statefile_path = os.path.join(
                 cache_dir, "selfcheck", _get_statefile_name(self.key)
             )
@@ -46,20 +44,18 @@
                     self.state = json.load(statefile)
             except (OSError, ValueError, KeyError):
                 # Explicitly suppressing exceptions, since we don't want to
                 # error out if the cache file is invalid.
                 pass
 
     @property
-    def key(self):
-        # type: () -> str
+    def key(self) -> str:
         return sys.prefix
 
-    def save(self, pypi_version, current_time):
-        # type: (str, datetime.datetime) -> None
+    def save(self, pypi_version: str, current_time: datetime.datetime) -> None:
         # If we do not have a path to cache in, don't bother saving.
         if not self.statefile_path:
             return
 
         # Check to make sure that we own the directory
         if not check_path_owner(os.path.dirname(self.statefile_path)):
             return
@@ -86,27 +82,25 @@
             # overwrite whatever is there, no need to check.
             replace(f.name, self.statefile_path)
         except OSError:
             # Best effort.
             pass
 
 
-def was_installed_by_pip(pkg):
-    # type: (str) -> bool
+def was_installed_by_pip(pkg: str) -> bool:
     """Checks whether pkg was installed by pip
 
     This is used not to display the upgrade message when pip is in fact
     installed by system package manager, such as dnf on Fedora.
     """
     dist = get_default_environment().get_distribution(pkg)
     return dist is not None and "pip" == dist.installer
 
 
-def pip_self_version_check(session, options):
-    # type: (PipSession, optparse.Values) -> None
+def pip_self_version_check(session: PipSession, options: optparse.Values) -> None:
     """Check for an update for pip.
 
     Limit the frequency of checks to once per week. State is stored either in
     the active virtualenv or in the user's USER_CACHE_DIR keyed off the prefix
     of the pip script path.
     """
     installed_dist = get_default_environment().get_distribution("pip")
@@ -119,16 +113,15 @@
     try:
         state = SelfCheckState(cache_dir=options.cache_dir)
 
         current_time = datetime.datetime.utcnow()
         # Determine if we need to refresh the state
         if "last_check" in state.state and "pypi_version" in state.state:
             last_check = datetime.datetime.strptime(
-                state.state["last_check"],
-                SELFCHECK_DATE_FMT
+                state.state["last_check"], SELFCHECK_DATE_FMT
             )
             if (current_time - last_check).total_seconds() < 7 * 24 * 60 * 60:
                 pypi_version = state.state["pypi_version"]
 
         # Refresh the version if we need to or just see if we need to warn
         if pypi_version is None:
             # Lets use PackageFinder to see what the latest pip version is
@@ -156,17 +149,17 @@
 
             # save that we've performed a check
             state.save(pypi_version, current_time)
 
         remote_version = parse_version(pypi_version)
 
         local_version_is_older = (
-            pip_version < remote_version and
-            pip_version.base_version != remote_version.base_version and
-            was_installed_by_pip('pip')
+            pip_version < remote_version
+            and pip_version.base_version != remote_version.base_version
+            and was_installed_by_pip("pip")
         )
 
         # Determine if our pypi_version is older
         if not local_version_is_older:
             return
 
         # We cannot tell how the current pip is available in the current
@@ -174,14 +167,16 @@
         # that's always available. This does not accommodate spaces in
         # `sys.executable`.
         pip_cmd = f"{sys.executable} -m pip"
         logger.warning(
             "You are using pip version %s; however, version %s is "
             "available.\nYou should consider upgrading via the "
             "'%s install --upgrade pip' command.",
-            pip_version, pypi_version, pip_cmd
+            pip_version,
+            pypi_version,
+            pip_cmd,
         )
     except Exception:
         logger.debug(
             "There was an error checking the latest version of pip",
             exc_info=True,
         )
```

#### pip/_internal/wheel_builder.py

```diff
@@ -8,116 +8,116 @@
 from typing import Any, Callable, Iterable, List, Optional, Tuple
 
 from pip._vendor.packaging.utils import canonicalize_name, canonicalize_version
 from pip._vendor.packaging.version import InvalidVersion, Version
 
 from pip._internal.cache import WheelCache
 from pip._internal.exceptions import InvalidWheelFilename, UnsupportedWheel
-from pip._internal.metadata import get_wheel_distribution
+from pip._internal.metadata import FilesystemWheel, get_wheel_distribution
 from pip._internal.models.link import Link
 from pip._internal.models.wheel import Wheel
 from pip._internal.operations.build.wheel import build_wheel_pep517
+from pip._internal.operations.build.wheel_editable import build_wheel_editable
 from pip._internal.operations.build.wheel_legacy import build_wheel_legacy
 from pip._internal.req.req_install import InstallRequirement
 from pip._internal.utils.logging import indent_log
 from pip._internal.utils.misc import ensure_dir, hash_file, is_wheel_installed
 from pip._internal.utils.setuptools_build import make_setuptools_clean_args
 from pip._internal.utils.subprocess import call_subprocess
 from pip._internal.utils.temp_dir import TempDirectory
 from pip._internal.utils.urls import path_to_url
 from pip._internal.vcs import vcs
 
 logger = logging.getLogger(__name__)
 
-_egg_info_re = re.compile(r'([a-z0-9_.]+)-([a-z0-9_.!+-]+)', re.IGNORECASE)
+_egg_info_re = re.compile(r"([a-z0-9_.]+)-([a-z0-9_.!+-]+)", re.IGNORECASE)
 
 BinaryAllowedPredicate = Callable[[InstallRequirement], bool]
 BuildResult = Tuple[List[InstallRequirement], List[InstallRequirement]]
 
 
-def _contains_egg_info(s):
-    # type: (str) -> bool
+def _contains_egg_info(s: str) -> bool:
     """Determine whether the string looks like an egg_info.
 
     :param s: The string to parse. E.g. foo-2.1
     """
     return bool(_egg_info_re.search(s))
 
 
 def _should_build(
-    req,  # type: InstallRequirement
-    need_wheel,  # type: bool
-    check_binary_allowed,  # type: BinaryAllowedPredicate
-):
-    # type: (...) -> bool
+    req: InstallRequirement,
+    need_wheel: bool,
+    check_binary_allowed: BinaryAllowedPredicate,
+) -> bool:
     """Return whether an InstallRequirement should be built into a wheel."""
     if req.constraint:
         # never build requirements that are merely constraints
         return False
     if req.is_wheel:
         if need_wheel:
             logger.info(
-                'Skipping %s, due to already being wheel.', req.name,
+                "Skipping %s, due to already being wheel.",
+                req.name,
             )
         return False
 
     if need_wheel:
         # i.e. pip wheel, not pip install
         return True
 
     # From this point, this concerns the pip install command only
     # (need_wheel=False).
 
-    if req.editable or not req.source_dir:
+    if not req.source_dir:
         return False
 
+    if req.editable:
+        # we only build PEP 660 editable requirements
+        return req.supports_pyproject_editable()
+
     if req.use_pep517:
         return True
 
     if not check_binary_allowed(req):
         logger.info(
-            "Skipping wheel build for %s, due to binaries "
-            "being disabled for it.", req.name,
+            "Skipping wheel build for %s, due to binaries being disabled for it.",
+            req.name,
         )
         return False
 
     if not is_wheel_installed():
         # we don't build legacy requirements if wheel is not installed
         logger.info(
             "Using legacy 'setup.py install' for %s, "
-            "since package 'wheel' is not installed.", req.name,
+            "since package 'wheel' is not installed.",
+            req.name,
         )
         return False
 
     return True
 
 
 def should_build_for_wheel_command(
-    req,  # type: InstallRequirement
-):
-    # type: (...) -> bool
-    return _should_build(
-        req, need_wheel=True, check_binary_allowed=_always_true
-    )
+    req: InstallRequirement,
+) -> bool:
+    return _should_build(req, need_wheel=True, check_binary_allowed=_always_true)
 
 
 def should_build_for_install_command(
-    req,  # type: InstallRequirement
-    check_binary_allowed,  # type: BinaryAllowedPredicate
-):
-    # type: (...) -> bool
+    req: InstallRequirement,
+    check_binary_allowed: BinaryAllowedPredicate,
+) -> bool:
     return _should_build(
         req, need_wheel=False, check_binary_allowed=check_binary_allowed
     )
 
 
 def _should_cache(
-    req,  # type: InstallRequirement
-):
-    # type: (...) -> Optional[bool]
+    req: InstallRequirement,
+) -> Optional[bool]:
     """
     Return whether a built InstallRequirement can be stored in the persistent
     wheel cache, assuming the wheel cache is available, and _should_build()
     has determined a wheel needs to be built.
     """
     if req.editable or not req.source_dir:
         # never cache editable requirements
@@ -140,128 +140,135 @@
         return True
 
     # Otherwise, do not cache.
     return False
 
 
 def _get_cache_dir(
-    req,  # type: InstallRequirement
-    wheel_cache,  # type: WheelCache
-):
-    # type: (...) -> str
+    req: InstallRequirement,
+    wheel_cache: WheelCache,
+) -> str:
     """Return the persistent or temporary cache directory where the built
     wheel need to be stored.
     """
     cache_available = bool(wheel_cache.cache_dir)
     assert req.link
     if cache_available and _should_cache(req):
         cache_dir = wheel_cache.get_path_for_link(req.link)
     else:
         cache_dir = wheel_cache.get_ephem_path_for_link(req.link)
     return cache_dir
 
 
-def _always_true(_):
-    # type: (Any) -> bool
+def _always_true(_: Any) -> bool:
     return True
 
 
-def _verify_one(req, wheel_path):
-    # type: (InstallRequirement, str) -> None
+def _verify_one(req: InstallRequirement, wheel_path: str) -> None:
     canonical_name = canonicalize_name(req.name or "")
     w = Wheel(os.path.basename(wheel_path))
     if canonicalize_name(w.name) != canonical_name:
         raise InvalidWheelFilename(
             "Wheel has unexpected file name: expected {!r}, "
             "got {!r}".format(canonical_name, w.name),
         )
-    dist = get_wheel_distribution(wheel_path, canonical_name)
+    dist = get_wheel_distribution(FilesystemWheel(wheel_path), canonical_name)
     dist_verstr = str(dist.version)
     if canonicalize_version(dist_verstr) != canonicalize_version(w.version):
         raise InvalidWheelFilename(
             "Wheel has unexpected file name: expected {!r}, "
             "got {!r}".format(dist_verstr, w.version),
         )
     metadata_version_value = dist.metadata_version
     if metadata_version_value is None:
         raise UnsupportedWheel("Missing Metadata-Version")
     try:
         metadata_version = Version(metadata_version_value)
     except InvalidVersion:
         msg = f"Invalid Metadata-Version: {metadata_version_value}"
         raise UnsupportedWheel(msg)
-    if (metadata_version >= Version("1.2")
-            and not isinstance(dist.version, Version)):
+    if metadata_version >= Version("1.2") and not isinstance(dist.version, Version):
         raise UnsupportedWheel(
             "Metadata 1.2 mandates PEP 440 version, "
             "but {!r} is not".format(dist_verstr)
         )
 
 
 def _build_one(
-    req,  # type: InstallRequirement
-    output_dir,  # type: str
-    verify,  # type: bool
-    build_options,  # type: List[str]
-    global_options,  # type: List[str]
-):
-    # type: (...) -> Optional[str]
+    req: InstallRequirement,
+    output_dir: str,
+    verify: bool,
+    build_options: List[str],
+    global_options: List[str],
+    editable: bool,
+) -> Optional[str]:
     """Build one wheel.
 
     :return: The filename of the built wheel, or None if the build failed.
     """
+    artifact = "editable" if editable else "wheel"
     try:
         ensure_dir(output_dir)
     except OSError as e:
         logger.warning(
-            "Building wheel for %s failed: %s",
-            req.name, e,
+            "Building %s for %s failed: %s",
+            artifact,
+            req.name,
+            e,
         )
         return None
 
     # Install build deps into temporary directory (PEP 518)
     with req.build_env:
         wheel_path = _build_one_inside_env(
-            req, output_dir, build_options, global_options
+            req, output_dir, build_options, global_options, editable
         )
     if wheel_path and verify:
         try:
             _verify_one(req, wheel_path)
         except (InvalidWheelFilename, UnsupportedWheel) as e:
-            logger.warning("Built wheel for %s is invalid: %s", req.name, e)
+            logger.warning("Built %s for %s is invalid: %s", artifact, req.name, e)
             return None
     return wheel_path
 
 
 def _build_one_inside_env(
-    req,  # type: InstallRequirement
-    output_dir,  # type: str
-    build_options,  # type: List[str]
-    global_options,  # type: List[str]
-):
-    # type: (...) -> Optional[str]
+    req: InstallRequirement,
+    output_dir: str,
+    build_options: List[str],
+    global_options: List[str],
+    editable: bool,
+) -> Optional[str]:
     with TempDirectory(kind="wheel") as temp_dir:
         assert req.name
         if req.use_pep517:
             assert req.metadata_directory
             assert req.pep517_backend
             if global_options:
                 logger.warning(
-                    'Ignoring --global-option when building %s using PEP 517', req.name
+                    "Ignoring --global-option when building %s using PEP 517", req.name
                 )
             if build_options:
                 logger.warning(
-                    'Ignoring --build-option when building %s using PEP 517', req.name
+                    "Ignoring --build-option when building %s using PEP 517", req.name
+                )
+            if editable:
+                wheel_path = build_wheel_editable(
+                    name=req.name,
+                    backend=req.pep517_backend,
+                    metadata_directory=req.metadata_directory,
+                    tempd=temp_dir.path,
+                )
+            else:
+                wheel_path = build_wheel_pep517(
+                    name=req.name,
+                    backend=req.pep517_backend,
+                    metadata_directory=req.metadata_directory,
+                    tempd=temp_dir.path,
                 )
-            wheel_path = build_wheel_pep517(
-                name=req.name,
-                backend=req.pep517_backend,
-                metadata_directory=req.metadata_directory,
-                tempd=temp_dir.path,
-            )
         else:
             wheel_path = build_wheel_legacy(
                 name=req.name,
                 setup_py_path=req.setup_py_path,
                 source_dir=req.unpacked_source_directory,
                 global_options=global_options,
                 build_options=build_options,
@@ -270,91 +277,99 @@
 
         if wheel_path is not None:
             wheel_name = os.path.basename(wheel_path)
             dest_path = os.path.join(output_dir, wheel_name)
             try:
                 wheel_hash, length = hash_file(wheel_path)
                 shutil.move(wheel_path, dest_path)
-                logger.info('Created wheel for %s: '
-                            'filename=%s size=%d sha256=%s',
-                            req.name, wheel_name, length,
-                            wheel_hash.hexdigest())
-                logger.info('Stored in directory: %s', output_dir)
+                logger.info(
+                    "Created wheel for %s: filename=%s size=%d sha256=%s",
+                    req.name,
+                    wheel_name,
+                    length,
+                    wheel_hash.hexdigest(),
+                )
+                logger.info("Stored in directory: %s", output_dir)
                 return dest_path
             except Exception as e:
                 logger.warning(
                     "Building wheel for %s failed: %s",
-                    req.name, e,
+                    req.name,
+                    e,
                 )
         # Ignore return, we can't do anything else useful.
         if not req.use_pep517:
             _clean_one_legacy(req, global_options)
         return None
 
 
-def _clean_one_legacy(req, global_options):
-    # type: (InstallRequirement, List[str]) -> bool
+def _clean_one_legacy(req: InstallRequirement, global_options: List[str]) -> bool:
     clean_args = make_setuptools_clean_args(
         req.setup_py_path,
         global_options=global_options,
     )
 
-    logger.info('Running setup.py clean for %s', req.name)
+    logger.info("Running setup.py clean for %s", req.name)
     try:
         call_subprocess(clean_args, cwd=req.source_dir)
         return True
     except Exception:
-        logger.error('Failed cleaning build dir for %s', req.name)
+        logger.error("Failed cleaning build dir for %s", req.name)
         return False
 
 
 def build(
-    requirements,  # type: Iterable[InstallRequirement]
-    wheel_cache,  # type: WheelCache
-    verify,  # type: bool
-    build_options,  # type: List[str]
-    global_options,  # type: List[str]
-):
-    # type: (...) -> BuildResult
+    requirements: Iterable[InstallRequirement],
+    wheel_cache: WheelCache,
+    verify: bool,
+    build_options: List[str],
+    global_options: List[str],
+) -> BuildResult:
     """Build wheels.
 
     :return: The list of InstallRequirement that succeeded to build and
         the list of InstallRequirement that failed to build.
     """
     if not requirements:
         return [], []
 
     # Build the wheels.
     logger.info(
-        'Building wheels for collected packages: %s',
-        ', '.join(req.name for req in requirements),  # type: ignore
+        "Building wheels for collected packages: %s",
+        ", ".join(req.name for req in requirements),  # type: ignore
     )
 
     with indent_log():
         build_successes, build_failures = [], []
         for req in requirements:
+            assert req.name
             cache_dir = _get_cache_dir(req, wheel_cache)
             wheel_file = _build_one(
-                req, cache_dir, verify, build_options, global_options
+                req,
+                cache_dir,
+                verify,
+                build_options,
+                global_options,
+                req.editable and req.permit_editable_wheels,
             )
             if wheel_file:
                 # Update the link for this.
                 req.link = Link(path_to_url(wheel_file))
                 req.local_file_path = req.link.file_path
                 assert req.link.is_wheel
                 build_successes.append(req)
             else:
                 build_failures.append(req)
 
     # notify success/failure
     if build_successes:
         logger.info(
-            'Successfully built %s',
-            ' '.join([req.name for req in build_successes]),  # type: ignore
+            "Successfully built %s",
+            " ".join([req.name for req in build_successes]),  # type: ignore
         )
     if build_failures:
         logger.info(
-            'Failed to build %s',
-            ' '.join([req.name for req in build_failures]),  # type: ignore
+            "Failed to build %s",
+            " ".join([req.name for req in build_failures]),  # type: ignore
         )
     # Return a list of requirements that failed to build
     return build_successes, build_failures
```

#### pip/_internal/cli/base_command.py

```diff
@@ -1,17 +1,18 @@
 """Base Command class, and related routines"""
 
+import functools
 import logging
 import logging.config
 import optparse
 import os
 import sys
 import traceback
 from optparse import Values
-from typing import Any, List, Optional, Tuple
+from typing import Any, Callable, List, Optional, Tuple
 
 from pip._internal.cli import cmdoptions
 from pip._internal.cli.command_context import CommandContextMixIn
 from pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter
 from pip._internal.cli.status_codes import (
     ERROR,
     PREVIOUS_BUILD_DIR_ERROR,
@@ -22,15 +23,14 @@
     BadCommand,
     CommandError,
     InstallationError,
     NetworkConnectionError,
     PreviousBuildDirError,
     UninstallationError,
 )
-from pip._internal.utils.deprecation import deprecated
 from pip._internal.utils.filesystem import check_path_owner
 from pip._internal.utils.logging import BrokenStdoutLoggingError, setup_logging
 from pip._internal.utils.misc import get_prog, normalize_path
 from pip._internal.utils.temp_dir import TempDirectoryTypeRegistry as TempDirRegistry
 from pip._internal.utils.temp_dir import global_tempdir_manager, tempdir_registry
 from pip._internal.utils.virtualenv import running_under_virtualenv
 
@@ -81,18 +81,18 @@
         This is a no-op so that commands by default do not do the pip version
         check.
         """
         # Make sure we do the pip version check if the index_group options
         # are present.
         assert not hasattr(options, "no_index")
 
-    def run(self, options: Values, args: List[Any]) -> int:
+    def run(self, options: Values, args: List[str]) -> int:
         raise NotImplementedError
 
-    def parse_args(self, args: List[str]) -> Tuple[Any, Any]:
+    def parse_args(self, args: List[str]) -> Tuple[Values, List[str]]:
         # factored out for testability
         return self.parser.parse_args(args)
 
     def main(self, args: List[str]) -> int:
         try:
             with self.main_context():
                 return self._main(args)
@@ -144,71 +144,71 @@
                     "has been disabled. Check the permissions and owner of "
                     "that directory. If executing pip with sudo, you should "
                     "use sudo's -H flag.",
                     options.cache_dir,
                 )
                 options.cache_dir = None
 
-        if getattr(options, "build_dir", None):
-            deprecated(
-                reason=(
-                    "The -b/--build/--build-dir/--build-directory "
-                    "option is deprecated and has no effect anymore."
-                ),
-                replacement=(
-                    "use the TMPDIR/TEMP/TMP environment variable, "
-                    "possibly combined with --no-clean"
-                ),
-                gone_in="21.3",
-                issue=8333,
-            )
-
         if "2020-resolver" in options.features_enabled:
             logger.warning(
                 "--use-feature=2020-resolver no longer has any effect, "
                 "since it is now the default dependency resolver in pip. "
                 "This will become an error in pip 21.0."
             )
 
-        try:
-            status = self.run(options, args)
-            assert isinstance(status, int)
-            return status
-        except PreviousBuildDirError as exc:
-            logger.critical(str(exc))
-            logger.debug("Exception information:", exc_info=True)
-
-            return PREVIOUS_BUILD_DIR_ERROR
-        except (
-            InstallationError,
-            UninstallationError,
-            BadCommand,
-            NetworkConnectionError,
-        ) as exc:
-            logger.critical(str(exc))
-            logger.debug("Exception information:", exc_info=True)
-
-            return ERROR
-        except CommandError as exc:
-            logger.critical("%s", exc)
-            logger.debug("Exception information:", exc_info=True)
-
-            return ERROR
-        except BrokenStdoutLoggingError:
-            # Bypass our logger and write any remaining messages to stderr
-            # because stdout no longer works.
-            print("ERROR: Pipe to stdout was broken", file=sys.stderr)
-            if level_number <= logging.DEBUG:
-                traceback.print_exc(file=sys.stderr)
-
-            return ERROR
-        except KeyboardInterrupt:
-            logger.critical("Operation cancelled by user")
-            logger.debug("Exception information:", exc_info=True)
-
-            return ERROR
-        except BaseException:
-            logger.critical("Exception:", exc_info=True)
+        def intercepts_unhandled_exc(
+            run_func: Callable[..., int]
+        ) -> Callable[..., int]:
+            @functools.wraps(run_func)
+            def exc_logging_wrapper(*args: Any) -> int:
+                try:
+                    status = run_func(*args)
+                    assert isinstance(status, int)
+                    return status
+                except PreviousBuildDirError as exc:
+                    logger.critical(str(exc))
+                    logger.debug("Exception information:", exc_info=True)
+
+                    return PREVIOUS_BUILD_DIR_ERROR
+                except (
+                    InstallationError,
+                    UninstallationError,
+                    BadCommand,
+                    NetworkConnectionError,
+                ) as exc:
+                    logger.critical(str(exc))
+                    logger.debug("Exception information:", exc_info=True)
+
+                    return ERROR
+                except CommandError as exc:
+                    logger.critical("%s", exc)
+                    logger.debug("Exception information:", exc_info=True)
+
+                    return ERROR
+                except BrokenStdoutLoggingError:
+                    # Bypass our logger and write any remaining messages to
+                    # stderr because stdout no longer works.
+                    print("ERROR: Pipe to stdout was broken", file=sys.stderr)
+                    if level_number <= logging.DEBUG:
+                        traceback.print_exc(file=sys.stderr)
+
+                    return ERROR
+                except KeyboardInterrupt:
+                    logger.critical("Operation cancelled by user")
+                    logger.debug("Exception information:", exc_info=True)
+
+                    return ERROR
+                except BaseException:
+                    logger.critical("Exception:", exc_info=True)
 
-            return UNKNOWN_ERROR
+                    return UNKNOWN_ERROR
+
+            return exc_logging_wrapper
+
+        try:
+            if not options.debug_mode:
+                run = intercepts_unhandled_exc(self.run)
+            else:
+                run = self.run
+            return run(options, args)
         finally:
             self.handle_pip_version_check(options)
```

#### pip/_internal/cli/cmdoptions.py

```diff
@@ -147,14 +147,26 @@
     "-h",
     "--help",
     dest="help",
     action="help",
     help="Show help.",
 )
 
+debug_mode: Callable[..., Option] = partial(
+    Option,
+    "--debug",
+    dest="debug_mode",
+    action="store_true",
+    default=False,
+    help=(
+        "Let unhandled exceptions propagate outside the main subroutine, "
+        "instead of logging them to stderr."
+    ),
+)
+
 isolated_mode: Callable[..., Option] = partial(
     Option,
     "--isolated",
     dest="isolated_mode",
     action="store_true",
     default=False,
     help=(
@@ -715,26 +727,14 @@
     "--no-dependencies",
     dest="ignore_dependencies",
     action="store_true",
     default=False,
     help="Don't install package dependencies.",
 )
 
-build_dir: Callable[..., Option] = partial(
-    PipOption,
-    "-b",
-    "--build",
-    "--build-dir",
-    "--build-directory",
-    dest="build_dir",
-    type="path",
-    metavar="dir",
-    help=SUPPRESS_HELP,
-)
-
 ignore_requires_python: Callable[..., Option] = partial(
     Option,
     "--ignore-requires-python",
     dest="ignore_requires_python",
     action="store_true",
     help="Ignore the Requires-Python information.",
 )
@@ -957,27 +957,28 @@
 use_deprecated_feature: Callable[..., Option] = partial(
     Option,
     "--use-deprecated",
     dest="deprecated_features_enabled",
     metavar="feature",
     action="append",
     default=[],
-    choices=["legacy-resolver"],
+    choices=["legacy-resolver", "out-of-tree-build"],
     help=("Enable deprecated functionality, that will be removed in the future."),
 )
 
 
 ##########
 # groups #
 ##########
 
 general_group: Dict[str, Any] = {
     "name": "General Options",
     "options": [
         help_,
+        debug_mode,
         isolated_mode,
         require_virtualenv,
         verbose,
         version,
         quiet,
         log,
         no_input,
```

#### pip/_internal/cli/req_command.py

```diff
@@ -30,14 +30,15 @@
     install_req_from_req_string,
 )
 from pip._internal.req.req_file import parse_requirements
 from pip._internal.req.req_install import InstallRequirement
 from pip._internal.req.req_tracker import RequirementTracker
 from pip._internal.resolution.base import BaseResolver
 from pip._internal.self_outdated_check import pip_self_version_check
+from pip._internal.utils.deprecation import deprecated
 from pip._internal.utils.temp_dir import (
     TempDirectory,
     TempDirectoryTypeRegistry,
     tempdir_kinds,
 )
 from pip._internal.utils.virtualenv import running_under_virtualenv
 
@@ -168,17 +169,18 @@
     # On Windows, there are no "system managed" Python packages. Installing as
     # Administrator via pip is the correct way of updating system environments.
     #
     # We choose sys.platform over utils.compat.WINDOWS here to enable Mypy platform
     # checks: https://mypy.readthedocs.io/en/stable/common_issues.html
     if sys.platform == "win32" or sys.platform == "cygwin":
         return
-    if sys.platform == "darwin" or sys.platform == "linux":
-        if os.getuid() != 0:
-            return
+
+    if os.getuid() != 0:
+        return
+
     logger.warning(
         "Running pip as the 'root' user can result in broken permissions and "
         "conflicting behaviour with the system package manager. "
         "It is recommended to use a virtual environment instead: "
         "https://pip.pypa.io/warnings/venv"
     )
 
@@ -256,27 +258,41 @@
         else:
             lazy_wheel = False
             if "fast-deps" in options.features_enabled:
                 logger.warning(
                     "fast-deps has no effect when used with the legacy resolver."
                 )
 
+        in_tree_build = "out-of-tree-build" not in options.deprecated_features_enabled
+        if "in-tree-build" in options.features_enabled:
+            deprecated(
+                reason="In-tree builds are now the default.",
+                replacement="to remove the --use-feature=in-tree-build flag",
+                gone_in="22.1",
+            )
+        if "out-of-tree-build" in options.deprecated_features_enabled:
+            deprecated(
+                reason="Out-of-tree builds are deprecated.",
+                replacement=None,
+                gone_in="22.1",
+            )
+
         return RequirementPreparer(
             build_dir=temp_build_dir_path,
             src_dir=options.src_dir,
             download_dir=download_dir,
             build_isolation=options.build_isolation,
             req_tracker=req_tracker,
             session=session,
             progress_bar=options.progress_bar,
             finder=finder,
             require_hashes=options.require_hashes,
             use_user_site=use_user_site,
             lazy_wheel=lazy_wheel,
-            in_tree_build="in-tree-build" in options.features_enabled,
+            in_tree_build=in_tree_build,
         )
 
     @classmethod
     def make_resolver(
         cls,
         preparer: RequirementPreparer,
         finder: PackageFinder,
```

#### pip/_internal/commands/__init__.py

```diff
@@ -1,93 +1,108 @@
 """
 Package containing all pip commands
 """
 
 import importlib
-from collections import OrderedDict, namedtuple
+from collections import namedtuple
 from typing import Any, Dict, Optional
 
 from pip._internal.cli.base_command import Command
 
-CommandInfo = namedtuple('CommandInfo', 'module_path, class_name, summary')
+CommandInfo = namedtuple("CommandInfo", "module_path, class_name, summary")
 
-# The ordering matters for help display.
-#    Also, even though the module path starts with the same
-# "pip._internal.commands" prefix in each case, we include the full path
-# because it makes testing easier (specifically when modifying commands_dict
-# in test setup / teardown by adding info for a FakeCommand class defined
-# in a test-related module).
-#    Finally, we need to pass an iterable of pairs here rather than a dict
-# so that the ordering won't be lost when using Python 2.7.
-commands_dict: Dict[str, CommandInfo] = OrderedDict([
-    ('install', CommandInfo(
-        'pip._internal.commands.install', 'InstallCommand',
-        'Install packages.',
-    )),
-    ('download', CommandInfo(
-        'pip._internal.commands.download', 'DownloadCommand',
-        'Download packages.',
-    )),
-    ('uninstall', CommandInfo(
-        'pip._internal.commands.uninstall', 'UninstallCommand',
-        'Uninstall packages.',
-    )),
-    ('freeze', CommandInfo(
-        'pip._internal.commands.freeze', 'FreezeCommand',
-        'Output installed packages in requirements format.',
-    )),
-    ('list', CommandInfo(
-        'pip._internal.commands.list', 'ListCommand',
-        'List installed packages.',
-    )),
-    ('show', CommandInfo(
-        'pip._internal.commands.show', 'ShowCommand',
-        'Show information about installed packages.',
-    )),
-    ('check', CommandInfo(
-        'pip._internal.commands.check', 'CheckCommand',
-        'Verify installed packages have compatible dependencies.',
-    )),
-    ('config', CommandInfo(
-        'pip._internal.commands.configuration', 'ConfigurationCommand',
-        'Manage local and global configuration.',
-    )),
-    ('search', CommandInfo(
-        'pip._internal.commands.search', 'SearchCommand',
-        'Search PyPI for packages.',
-    )),
-    ('cache', CommandInfo(
-        'pip._internal.commands.cache', 'CacheCommand',
+# This dictionary does a bunch of heavy lifting for help output:
+# - Enables avoiding additional (costly) imports for presenting `--help`.
+# - The ordering matters for help display.
+#
+# Even though the module path starts with the same "pip._internal.commands"
+# prefix, the full path makes testing easier (specifically when modifying
+# `commands_dict` in test setup / teardown).
+commands_dict: Dict[str, CommandInfo] = {
+    "install": CommandInfo(
+        "pip._internal.commands.install",
+        "InstallCommand",
+        "Install packages.",
+    ),
+    "download": CommandInfo(
+        "pip._internal.commands.download",
+        "DownloadCommand",
+        "Download packages.",
+    ),
+    "uninstall": CommandInfo(
+        "pip._internal.commands.uninstall",
+        "UninstallCommand",
+        "Uninstall packages.",
+    ),
+    "freeze": CommandInfo(
+        "pip._internal.commands.freeze",
+        "FreezeCommand",
+        "Output installed packages in requirements format.",
+    ),
+    "list": CommandInfo(
+        "pip._internal.commands.list",
+        "ListCommand",
+        "List installed packages.",
+    ),
+    "show": CommandInfo(
+        "pip._internal.commands.show",
+        "ShowCommand",
+        "Show information about installed packages.",
+    ),
+    "check": CommandInfo(
+        "pip._internal.commands.check",
+        "CheckCommand",
+        "Verify installed packages have compatible dependencies.",
+    ),
+    "config": CommandInfo(
+        "pip._internal.commands.configuration",
+        "ConfigurationCommand",
+        "Manage local and global configuration.",
+    ),
+    "search": CommandInfo(
+        "pip._internal.commands.search",
+        "SearchCommand",
+        "Search PyPI for packages.",
+    ),
+    "cache": CommandInfo(
+        "pip._internal.commands.cache",
+        "CacheCommand",
         "Inspect and manage pip's wheel cache.",
-    )),
-    ('index', CommandInfo(
-        'pip._internal.commands.index', 'IndexCommand',
+    ),
+    "index": CommandInfo(
+        "pip._internal.commands.index",
+        "IndexCommand",
         "Inspect information available from package indexes.",
-    )),
-    ('wheel', CommandInfo(
-        'pip._internal.commands.wheel', 'WheelCommand',
-        'Build wheels from your requirements.',
-    )),
-    ('hash', CommandInfo(
-        'pip._internal.commands.hash', 'HashCommand',
-        'Compute hashes of package archives.',
-    )),
-    ('completion', CommandInfo(
-        'pip._internal.commands.completion', 'CompletionCommand',
-        'A helper command used for command completion.',
-    )),
-    ('debug', CommandInfo(
-        'pip._internal.commands.debug', 'DebugCommand',
-        'Show information useful for debugging.',
-    )),
-    ('help', CommandInfo(
-        'pip._internal.commands.help', 'HelpCommand',
-        'Show help for commands.',
-    )),
-])
+    ),
+    "wheel": CommandInfo(
+        "pip._internal.commands.wheel",
+        "WheelCommand",
+        "Build wheels from your requirements.",
+    ),
+    "hash": CommandInfo(
+        "pip._internal.commands.hash",
+        "HashCommand",
+        "Compute hashes of package archives.",
+    ),
+    "completion": CommandInfo(
+        "pip._internal.commands.completion",
+        "CompletionCommand",
+        "A helper command used for command completion.",
+    ),
+    "debug": CommandInfo(
+        "pip._internal.commands.debug",
+        "DebugCommand",
+        "Show information useful for debugging.",
+    ),
+    "help": CommandInfo(
+        "pip._internal.commands.help",
+        "HelpCommand",
+        "Show help for commands.",
+    ),
+}
 
 
 def create_command(name: str, **kwargs: Any) -> Command:
     """
     Create an instance of the Command class with the given name.
     """
     module_path, class_name, summary = commands_dict[name]
```

#### pip/_internal/commands/cache.py

```diff
@@ -35,36 +35,35 @@
         %prog remove <pattern>
         %prog purge
     """
 
     def add_options(self) -> None:
 
         self.cmd_opts.add_option(
-            '--format',
-            action='store',
-            dest='list_format',
+            "--format",
+            action="store",
+            dest="list_format",
             default="human",
-            choices=('human', 'abspath'),
-            help="Select the output format among: human (default) or abspath"
+            choices=("human", "abspath"),
+            help="Select the output format among: human (default) or abspath",
         )
 
         self.parser.insert_option_group(0, self.cmd_opts)
 
-    def run(self, options: Values, args: List[Any]) -> int:
+    def run(self, options: Values, args: List[str]) -> int:
         handlers = {
             "dir": self.get_cache_dir,
             "info": self.get_cache_info,
             "list": self.list_cache_items,
             "remove": self.remove_cache_items,
             "purge": self.purge_cache,
         }
 
         if not options.cache_dir:
-            logger.error("pip cache commands can not "
-                         "function since cache is disabled.")
+            logger.error("pip cache commands can not function since cache is disabled.")
             return ERROR
 
         # Determine action
         if not args or args[0] not in handlers:
             logger.error(
                 "Need an action (%s) to perform.",
                 ", ".join(sorted(handlers)),
@@ -80,124 +79,132 @@
             logger.error(e.args[0])
             return ERROR
 
         return SUCCESS
 
     def get_cache_dir(self, options: Values, args: List[Any]) -> None:
         if args:
-            raise CommandError('Too many arguments')
+            raise CommandError("Too many arguments")
 
         logger.info(options.cache_dir)
 
     def get_cache_info(self, options: Values, args: List[Any]) -> None:
         if args:
-            raise CommandError('Too many arguments')
+            raise CommandError("Too many arguments")
 
         num_http_files = len(self._find_http_files(options))
-        num_packages = len(self._find_wheels(options, '*'))
+        num_packages = len(self._find_wheels(options, "*"))
 
-        http_cache_location = self._cache_dir(options, 'http')
-        wheels_cache_location = self._cache_dir(options, 'wheels')
+        http_cache_location = self._cache_dir(options, "http")
+        wheels_cache_location = self._cache_dir(options, "wheels")
         http_cache_size = filesystem.format_directory_size(http_cache_location)
-        wheels_cache_size = filesystem.format_directory_size(
-            wheels_cache_location
-        )
+        wheels_cache_size = filesystem.format_directory_size(wheels_cache_location)
 
-        message = textwrap.dedent("""
-            Package index page cache location: {http_cache_location}
-            Package index page cache size: {http_cache_size}
-            Number of HTTP files: {num_http_files}
-            Wheels location: {wheels_cache_location}
-            Wheels size: {wheels_cache_size}
-            Number of wheels: {package_count}
-        """).format(
-            http_cache_location=http_cache_location,
-            http_cache_size=http_cache_size,
-            num_http_files=num_http_files,
-            wheels_cache_location=wheels_cache_location,
-            package_count=num_packages,
-            wheels_cache_size=wheels_cache_size,
-        ).strip()
+        message = (
+            textwrap.dedent(
+                """
+                    Package index page cache location: {http_cache_location}
+                    Package index page cache size: {http_cache_size}
+                    Number of HTTP files: {num_http_files}
+                    Wheels location: {wheels_cache_location}
+                    Wheels size: {wheels_cache_size}
+                    Number of wheels: {package_count}
+                """
+            )
+            .format(
+                http_cache_location=http_cache_location,
+                http_cache_size=http_cache_size,
+                num_http_files=num_http_files,
+                wheels_cache_location=wheels_cache_location,
+                package_count=num_packages,
+                wheels_cache_size=wheels_cache_size,
+            )
+            .strip()
+        )
 
         logger.info(message)
 
     def list_cache_items(self, options: Values, args: List[Any]) -> None:
         if len(args) > 1:
-            raise CommandError('Too many arguments')
+            raise CommandError("Too many arguments")
 
         if args:
             pattern = args[0]
         else:
-            pattern = '*'
+            pattern = "*"
 
         files = self._find_wheels(options, pattern)
-        if options.list_format == 'human':
+        if options.list_format == "human":
             self.format_for_human(files)
         else:
             self.format_for_abspath(files)
 
     def format_for_human(self, files: List[str]) -> None:
         if not files:
-            logger.info('Nothing cached.')
+            logger.info("Nothing cached.")
             return
 
         results = []
         for filename in files:
             wheel = os.path.basename(filename)
             size = filesystem.format_file_size(filename)
-            results.append(f' - {wheel} ({size})')
-        logger.info('Cache contents:\n')
-        logger.info('\n'.join(sorted(results)))
+            results.append(f" - {wheel} ({size})")
+        logger.info("Cache contents:\n")
+        logger.info("\n".join(sorted(results)))
 
     def format_for_abspath(self, files: List[str]) -> None:
         if not files:
             return
 
         results = []
         for filename in files:
             results.append(filename)
 
-        logger.info('\n'.join(sorted(results)))
+        logger.info("\n".join(sorted(results)))
 
     def remove_cache_items(self, options: Values, args: List[Any]) -> None:
         if len(args) > 1:
-            raise CommandError('Too many arguments')
+            raise CommandError("Too many arguments")
 
         if not args:
-            raise CommandError('Please provide a pattern')
+            raise CommandError("Please provide a pattern")
 
         files = self._find_wheels(options, args[0])
 
-        # Only fetch http files if no specific pattern given
-        if args[0] == '*':
+        no_matching_msg = "No matching packages"
+        if args[0] == "*":
+            # Only fetch http files if no specific pattern given
             files += self._find_http_files(options)
+        else:
+            # Add the pattern to the log message
+            no_matching_msg += ' for pattern "{}"'.format(args[0])
 
         if not files:
-            raise CommandError('No matching packages')
+            logger.warning(no_matching_msg)
 
         for filename in files:
             os.unlink(filename)
             logger.verbose("Removed %s", filename)
         logger.info("Files removed: %s", len(files))
 
     def purge_cache(self, options: Values, args: List[Any]) -> None:
         if args:
-            raise CommandError('Too many arguments')
+            raise CommandError("Too many arguments")
 
-        return self.remove_cache_items(options, ['*'])
+        return self.remove_cache_items(options, ["*"])
 
     def _cache_dir(self, options: Values, subdir: str) -> str:
         return os.path.join(options.cache_dir, subdir)
 
     def _find_http_files(self, options: Values) -> List[str]:
-        http_dir = self._cache_dir(options, 'http')
-        return filesystem.find_files(http_dir, '*')
+        http_dir = self._cache_dir(options, "http")
+        return filesystem.find_files(http_dir, "*")
 
     def _find_wheels(self, options: Values, pattern: str) -> List[str]:
-        wheel_dir = self._cache_dir(options, 'wheels')
+        wheel_dir = self._cache_dir(options, "wheels")
 
         # The wheel filename format, as specified in PEP 427, is:
         #     {distribution}-{version}(-{build})?-{python}-{abi}-{platform}.whl
         #
         # Additionally, non-alphanumeric values in the distribution are
         # normalized to underscores (_), meaning hyphens can never occur
         # before `-{version}`.
```

#### pip/_internal/commands/check.py

```diff
@@ -1,10 +1,10 @@
 import logging
 from optparse import Values
-from typing import Any, List
+from typing import List
 
 from pip._internal.cli.base_command import Command
 from pip._internal.cli.status_codes import ERROR, SUCCESS
 from pip._internal.operations.check import (
     check_package_set,
     create_package_set_from_installed,
 )
@@ -15,33 +15,39 @@
 
 class CheckCommand(Command):
     """Verify installed packages have compatible dependencies."""
 
     usage = """
       %prog [options]"""
 
-    def run(self, options: Values, args: List[Any]) -> int:
+    def run(self, options: Values, args: List[str]) -> int:
 
         package_set, parsing_probs = create_package_set_from_installed()
         missing, conflicting = check_package_set(package_set)
 
         for project_name in missing:
             version = package_set[project_name].version
             for dependency in missing[project_name]:
                 write_output(
                     "%s %s requires %s, which is not installed.",
-                    project_name, version, dependency[0],
+                    project_name,
+                    version,
+                    dependency[0],
                 )
 
         for project_name in conflicting:
             version = package_set[project_name].version
             for dep_name, dep_version, req in conflicting[project_name]:
                 write_output(
                     "%s %s has requirement %s, but you have %s %s.",
-                    project_name, version, req, dep_name, dep_version,
+                    project_name,
+                    version,
+                    req,
+                    dep_name,
+                    dep_version,
                 )
 
         if missing or conflicting or parsing_probs:
             return ERROR
         else:
             write_output("No broken requirements found.")
             return SUCCESS
```

#### pip/_internal/commands/completion.py

```diff
@@ -8,35 +8,35 @@
 from pip._internal.utils.misc import get_prog
 
 BASE_COMPLETION = """
 # pip {shell} completion start{script}# pip {shell} completion end
 """
 
 COMPLETION_SCRIPTS = {
-    'bash': """
+    "bash": """
         _pip_completion()
         {{
             COMPREPLY=( $( COMP_WORDS="${{COMP_WORDS[*]}}" \\
                            COMP_CWORD=$COMP_CWORD \\
                            PIP_AUTO_COMPLETE=1 $1 2>/dev/null ) )
         }}
         complete -o default -F _pip_completion {prog}
     """,
-    'zsh': """
+    "zsh": """
         function _pip_completion {{
           local words cword
           read -Ac words
           read -cn cword
           reply=( $( COMP_WORDS="$words[*]" \\
                      COMP_CWORD=$(( cword-1 )) \\
                      PIP_AUTO_COMPLETE=1 $words[1] 2>/dev/null ))
         }}
         compctl -K _pip_completion {prog}
     """,
-    'fish': """
+    "fish": """
         function __fish_complete_pip
             set -lx COMP_WORDS (commandline -o) ""
             set -lx COMP_CWORD ( \\
                 math (contains -i -- (commandline -t) $COMP_WORDS)-1 \\
             )
             set -lx PIP_AUTO_COMPLETE 1
             string split \\  -- (eval $COMP_WORDS[1])
@@ -49,43 +49,48 @@
 class CompletionCommand(Command):
     """A helper command to be used for command completion."""
 
     ignore_require_venv = True
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(
-            '--bash', '-b',
-            action='store_const',
-            const='bash',
-            dest='shell',
-            help='Emit completion code for bash')
+            "--bash",
+            "-b",
+            action="store_const",
+            const="bash",
+            dest="shell",
+            help="Emit completion code for bash",
+        )
         self.cmd_opts.add_option(
-            '--zsh', '-z',
-            action='store_const',
-            const='zsh',
-            dest='shell',
-            help='Emit completion code for zsh')
+            "--zsh",
+            "-z",
+            action="store_const",
+            const="zsh",
+            dest="shell",
+            help="Emit completion code for zsh",
+        )
         self.cmd_opts.add_option(
-            '--fish', '-f',
-            action='store_const',
-            const='fish',
-            dest='shell',
-            help='Emit completion code for fish')
+            "--fish",
+            "-f",
+            action="store_const",
+            const="fish",
+            dest="shell",
+            help="Emit completion code for fish",
+        )
 
         self.parser.insert_option_group(0, self.cmd_opts)
 
     def run(self, options: Values, args: List[str]) -> int:
         """Prints the completion code of the given shell"""
         shells = COMPLETION_SCRIPTS.keys()
-        shell_options = ['--' + shell for shell in sorted(shells)]
+        shell_options = ["--" + shell for shell in sorted(shells)]
         if options.shell in shells:
             script = textwrap.dedent(
-                COMPLETION_SCRIPTS.get(options.shell, '').format(
-                    prog=get_prog())
+                COMPLETION_SCRIPTS.get(options.shell, "").format(prog=get_prog())
             )
             print(BASE_COMPLETION.format(script=script, shell=options.shell))
             return SUCCESS
         else:
             sys.stderr.write(
-                'ERROR: You must pass {}\n' .format(' or '.join(shell_options))
+                "ERROR: You must pass {}\n".format(" or ".join(shell_options))
             )
             return SUCCESS
```

#### pip/_internal/commands/configuration.py

```diff
@@ -30,15 +30,15 @@
     - get: Get the value associated with name
     - set: Set the name=value
     - unset: Unset the value associated with name
     - debug: List the configuration files and values defined under them
 
     If none of --user, --global and --site are passed, a virtual
     environment configuration file is used if one is active and the file
-    exists. Otherwise, all modifications happen on the to the user file by
+    exists. Otherwise, all modifications happen to the user file by
     default.
     """
 
     ignore_require_venv = True
     usage = """
         %prog [<file-option>] list
         %prog [<file-option>] [--editor <editor-path>] edit
@@ -47,46 +47,46 @@
         %prog [<file-option>] set name value
         %prog [<file-option>] unset name
         %prog [<file-option>] debug
     """
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(
-            '--editor',
-            dest='editor',
-            action='store',
+            "--editor",
+            dest="editor",
+            action="store",
             default=None,
             help=(
-                'Editor to use to edit the file. Uses VISUAL or EDITOR '
-                'environment variables if not provided.'
-            )
+                "Editor to use to edit the file. Uses VISUAL or EDITOR "
+                "environment variables if not provided."
+            ),
         )
 
         self.cmd_opts.add_option(
-            '--global',
-            dest='global_file',
-            action='store_true',
+            "--global",
+            dest="global_file",
+            action="store_true",
             default=False,
-            help='Use the system-wide configuration file only'
+            help="Use the system-wide configuration file only",
         )
 
         self.cmd_opts.add_option(
-            '--user',
-            dest='user_file',
-            action='store_true',
+            "--user",
+            dest="user_file",
+            action="store_true",
             default=False,
-            help='Use the user configuration file only'
+            help="Use the user configuration file only",
         )
 
         self.cmd_opts.add_option(
-            '--site',
-            dest='site_file',
-            action='store_true',
+            "--site",
+            dest="site_file",
+            action="store_true",
             default=False,
-            help='Use the current environment configuration file only'
+            help="Use the current environment configuration file only",
         )
 
         self.parser.insert_option_group(0, self.cmd_opts)
 
     def run(self, options: Values, args: List[str]) -> int:
         handlers = {
             "list": self.list_values,
@@ -129,19 +129,23 @@
         except PipError as e:
             logger.error(e.args[0])
             return ERROR
 
         return SUCCESS
 
     def _determine_file(self, options: Values, need_value: bool) -> Optional[Kind]:
-        file_options = [key for key, value in (
-            (kinds.USER, options.user_file),
-            (kinds.GLOBAL, options.global_file),
-            (kinds.SITE, options.site_file),
-        ) if value]
+        file_options = [
+            key
+            for key, value in (
+                (kinds.USER, options.user_file),
+                (kinds.GLOBAL, options.global_file),
+                (kinds.SITE, options.site_file),
+            )
+            if value
+        ]
 
         if not file_options:
             if not need_value:
                 return None
             # Default to user, unless there's a site file.
             elif any(
                 os.path.exists(site_config_file)
@@ -190,55 +194,51 @@
         # Iterate over config files and print if they exist, and the
         # key-value pairs present in them if they do
         for variant, files in sorted(self.configuration.iter_config_files()):
             write_output("%s:", variant)
             for fname in files:
                 with indent_log():
                     file_exists = os.path.exists(fname)
-                    write_output("%s, exists: %r",
-                                 fname, file_exists)
+                    write_output("%s, exists: %r", fname, file_exists)
                     if file_exists:
                         self.print_config_file_values(variant)
 
     def print_config_file_values(self, variant: Kind) -> None:
         """Get key-value pairs from the file of a variant"""
-        for name, value in self.configuration.\
-                get_values_in_config(variant).items():
+        for name, value in self.configuration.get_values_in_config(variant).items():
             with indent_log():
                 write_output("%s: %s", name, value)
 
     def print_env_var_values(self) -> None:
         """Get key-values pairs present as environment variables"""
-        write_output("%s:", 'env_var')
+        write_output("%s:", "env_var")
         with indent_log():
             for key, value in sorted(self.configuration.get_environ_vars()):
-                env_var = f'PIP_{key.upper()}'
+                env_var = f"PIP_{key.upper()}"
                 write_output("%s=%r", env_var, value)
 
     def open_in_editor(self, options: Values, args: List[str]) -> None:
         editor = self._determine_editor(options)
 
         fname = self.configuration.get_file_to_edit()
         if fname is None:
             raise PipError("Could not determine appropriate file.")
 
         try:
             subprocess.check_call([editor, fname])
         except subprocess.CalledProcessError as e:
             raise PipError(
-                "Editor Subprocess exited with exit code {}"
-                .format(e.returncode)
+                "Editor Subprocess exited with exit code {}".format(e.returncode)
             )
 
     def _get_n_args(self, args: List[str], example: str, n: int) -> Any:
-        """Helper to make sure the command got the right number of arguments
-        """
+        """Helper to make sure the command got the right number of arguments"""
         if len(args) != n:
             msg = (
-                'Got unexpected number of arguments, expected {}. '
+                "Got unexpected number of arguments, expected {}. "
                 '(example: "{} config {}")'
             ).format(n, get_prog(), example)
             raise PipError(msg)
 
         if n == 1:
             return args[0]
         else:
```

#### pip/_internal/commands/debug.py

```diff
@@ -20,60 +20,54 @@
 from pip._internal.utils.logging import indent_log
 from pip._internal.utils.misc import get_pip_version
 
 logger = logging.getLogger(__name__)
 
 
 def show_value(name: str, value: Any) -> None:
-    logger.info('%s: %s', name, value)
+    logger.info("%s: %s", name, value)
 
 
 def show_sys_implementation() -> None:
-    logger.info('sys.implementation:')
+    logger.info("sys.implementation:")
     implementation_name = sys.implementation.name
     with indent_log():
-        show_value('name', implementation_name)
+        show_value("name", implementation_name)
 
 
 def create_vendor_txt_map() -> Dict[str, str]:
     vendor_txt_path = os.path.join(
-        os.path.dirname(pip_location),
-        '_vendor',
-        'vendor.txt'
+        os.path.dirname(pip_location), "_vendor", "vendor.txt"
     )
 
     with open(vendor_txt_path) as f:
         # Purge non version specifying lines.
         # Also, remove any space prefix or suffixes (including comments).
-        lines = [line.strip().split(' ', 1)[0]
-                 for line in f.readlines() if '==' in line]
+        lines = [
+            line.strip().split(" ", 1)[0] for line in f.readlines() if "==" in line
+        ]
 
     # Transform into "module" -> version dict.
-    return dict(line.split('==', 1) for line in lines)  # type: ignore
+    return dict(line.split("==", 1) for line in lines)  # type: ignore
 
 
 def get_module_from_module_name(module_name: str) -> ModuleType:
     # Module name can be uppercase in vendor.txt for some reason...
     module_name = module_name.lower()
     # PATCH: setuptools is actually only pkg_resources.
-    if module_name == 'setuptools':
-        module_name = 'pkg_resources'
+    if module_name == "setuptools":
+        module_name = "pkg_resources"
 
-    __import__(
-        f'pip._vendor.{module_name}',
-        globals(),
-        locals(),
-        level=0
-    )
+    __import__(f"pip._vendor.{module_name}", globals(), locals(), level=0)
     return getattr(pip._vendor, module_name)
 
 
 def get_vendor_version_from_module(module_name: str) -> Optional[str]:
     module = get_module_from_module_name(module_name)
-    version = getattr(module, '__version__', None)
+    version = getattr(module, "__version__", None)
 
     if not version:
         # Try to find version in debundled module info.
         env = get_environment([os.path.dirname(module.__file__)])
         dist = env.get_distribution(module_name)
         if dist:
             version = str(dist.version)
@@ -82,84 +76,87 @@
 
 
 def show_actual_vendor_versions(vendor_txt_versions: Dict[str, str]) -> None:
     """Log the actual version and print extra info if there is
     a conflict or if the actual version could not be imported.
     """
     for module_name, expected_version in vendor_txt_versions.items():
-        extra_message = ''
+        extra_message = ""
         actual_version = get_vendor_version_from_module(module_name)
         if not actual_version:
-            extra_message = ' (Unable to locate actual module version, using'\
-                            ' vendor.txt specified version)'
+            extra_message = (
+                " (Unable to locate actual module version, using"
+                " vendor.txt specified version)"
+            )
             actual_version = expected_version
         elif parse_version(actual_version) != parse_version(expected_version):
-            extra_message = ' (CONFLICT: vendor.txt suggests version should'\
-                            ' be {})'.format(expected_version)
-        logger.info('%s==%s%s', module_name, actual_version, extra_message)
+            extra_message = (
+                " (CONFLICT: vendor.txt suggests version should"
+                " be {})".format(expected_version)
+            )
+        logger.info("%s==%s%s", module_name, actual_version, extra_message)
 
 
 def show_vendor_versions() -> None:
-    logger.info('vendored library versions:')
+    logger.info("vendored library versions:")
 
     vendor_txt_versions = create_vendor_txt_map()
     with indent_log():
         show_actual_vendor_versions(vendor_txt_versions)
 
 
 def show_tags(options: Values) -> None:
     tag_limit = 10
 
     target_python = make_target_python(options)
     tags = target_python.get_tags()
 
     # Display the target options that were explicitly provided.
     formatted_target = target_python.format_given()
-    suffix = ''
+    suffix = ""
     if formatted_target:
-        suffix = f' (target: {formatted_target})'
+        suffix = f" (target: {formatted_target})"
 
-    msg = 'Compatible tags: {}{}'.format(len(tags), suffix)
+    msg = "Compatible tags: {}{}".format(len(tags), suffix)
     logger.info(msg)
 
     if options.verbose < 1 and len(tags) > tag_limit:
         tags_limited = True
         tags = tags[:tag_limit]
     else:
         tags_limited = False
 
     with indent_log():
         for tag in tags:
             logger.info(str(tag))
 
         if tags_limited:
             msg = (
-                '...\n'
-                '[First {tag_limit} tags shown. Pass --verbose to show all.]'
+                "...\n[First {tag_limit} tags shown. Pass --verbose to show all.]"
             ).format(tag_limit=tag_limit)
             logger.info(msg)
 
 
 def ca_bundle_info(config: Configuration) -> str:
     levels = set()
     for key, _ in config.items():
-        levels.add(key.split('.')[0])
+        levels.add(key.split(".")[0])
 
     if not levels:
         return "Not specified"
 
-    levels_that_override_global = ['install', 'wheel', 'download']
+    levels_that_override_global = ["install", "wheel", "download"]
     global_overriding_level = [
         level for level in levels if level in levels_that_override_global
     ]
     if not global_overriding_level:
-        return 'global'
+        return "global"
 
-    if 'global' in levels:
-        levels.remove('global')
+    if "global" in levels:
+        levels.remove("global")
     return ", ".join(levels)
 
 
 class DebugCommand(Command):
     """
     Display debug information.
     """
@@ -176,28 +173,29 @@
     def run(self, options: Values, args: List[str]) -> int:
         logger.warning(
             "This command is only meant for debugging. "
             "Do not use this with automation for parsing and getting these "
             "details, since the output and options of this command may "
             "change without notice."
         )
-        show_value('pip version', get_pip_version())
-        show_value('sys.version', sys.version)
-        show_value('sys.executable', sys.executable)
-        show_value('sys.getdefaultencoding', sys.getdefaultencoding())
-        show_value('sys.getfilesystemencoding', sys.getfilesystemencoding())
+        show_value("pip version", get_pip_version())
+        show_value("sys.version", sys.version)
+        show_value("sys.executable", sys.executable)
+        show_value("sys.getdefaultencoding", sys.getdefaultencoding())
+        show_value("sys.getfilesystemencoding", sys.getfilesystemencoding())
         show_value(
-            'locale.getpreferredencoding', locale.getpreferredencoding(),
+            "locale.getpreferredencoding",
+            locale.getpreferredencoding(),
         )
-        show_value('sys.platform', sys.platform)
+        show_value("sys.platform", sys.platform)
         show_sys_implementation()
 
         show_value("'cert' config value", ca_bundle_info(self.parser.config))
-        show_value("REQUESTS_CA_BUNDLE", os.environ.get('REQUESTS_CA_BUNDLE'))
-        show_value("CURL_CA_BUNDLE", os.environ.get('CURL_CA_BUNDLE'))
+        show_value("REQUESTS_CA_BUNDLE", os.environ.get("REQUESTS_CA_BUNDLE"))
+        show_value("CURL_CA_BUNDLE", os.environ.get("CURL_CA_BUNDLE"))
         show_value("pip._vendor.certifi.where()", where())
         show_value("pip._vendor.DEBUNDLED", pip._vendor.DEBUNDLED)
 
         show_vendor_versions()
 
         show_tags(options)
```

#### pip/_internal/commands/download.py

```diff
@@ -33,15 +33,14 @@
       %prog [options] <vcs project url> ...
       %prog [options] <local project path> ...
       %prog [options] <archive url/path> ..."""
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(cmdoptions.constraints())
         self.cmd_opts.add_option(cmdoptions.requirements())
-        self.cmd_opts.add_option(cmdoptions.build_dir())
         self.cmd_opts.add_option(cmdoptions.no_deps())
         self.cmd_opts.add_option(cmdoptions.global_options())
         self.cmd_opts.add_option(cmdoptions.no_binary())
         self.cmd_opts.add_option(cmdoptions.only_binary())
         self.cmd_opts.add_option(cmdoptions.prefer_binary())
         self.cmd_opts.add_option(cmdoptions.src())
         self.cmd_opts.add_option(cmdoptions.pre())
@@ -49,19 +48,22 @@
         self.cmd_opts.add_option(cmdoptions.progress_bar())
         self.cmd_opts.add_option(cmdoptions.no_build_isolation())
         self.cmd_opts.add_option(cmdoptions.use_pep517())
         self.cmd_opts.add_option(cmdoptions.no_use_pep517())
         self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
 
         self.cmd_opts.add_option(
-            '-d', '--dest', '--destination-dir', '--destination-directory',
-            dest='download_dir',
-            metavar='dir',
+            "-d",
+            "--dest",
+            "--destination-dir",
+            "--destination-directory",
+            dest="download_dir",
+            metavar="dir",
             default=os.curdir,
-            help=("Download packages into <dir>."),
+            help="Download packages into <dir>.",
         )
 
         cmdoptions.add_target_python_options(self.cmd_opts)
 
         index_opts = cmdoptions.make_option_group(
             cmdoptions.index_group,
             self.parser,
@@ -119,21 +121,19 @@
             options=options,
             ignore_requires_python=options.ignore_requires_python,
             py_version_info=options.python_version,
         )
 
         self.trace_basic_info(finder)
 
-        requirement_set = resolver.resolve(
-            reqs, check_supported_wheels=True
-        )
+        requirement_set = resolver.resolve(reqs, check_supported_wheels=True)
 
         downloaded: List[str] = []
         for req in requirement_set.requirements.values():
             if req.satisfied_by is None:
                 assert req.name is not None
                 preparer.save_linked_requirement(req)
                 downloaded.append(req.name)
         if downloaded:
-            write_output('Successfully downloaded %s', ' '.join(downloaded))
+            write_output("Successfully downloaded %s", " ".join(downloaded))
 
         return SUCCESS
```

#### pip/_internal/commands/freeze.py

```diff
@@ -4,15 +4,15 @@
 
 from pip._internal.cli import cmdoptions
 from pip._internal.cli.base_command import Command
 from pip._internal.cli.status_codes import SUCCESS
 from pip._internal.operations.freeze import freeze
 from pip._internal.utils.compat import stdlib_pkgs
 
-DEV_PKGS = {'pip', 'setuptools', 'distribute', 'wheel'}
+DEV_PKGS = {"pip", "setuptools", "distribute", "wheel"}
 
 
 class FreezeCommand(Command):
     """
     Output installed packages in requirements format.
 
     packages are listed in a case-insensitive sorted order.
@@ -20,47 +20,60 @@
 
     usage = """
       %prog [options]"""
     log_streams = ("ext://sys.stderr", "ext://sys.stderr")
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(
-            '-r', '--requirement',
-            dest='requirements',
-            action='append',
+            "-r",
+            "--requirement",
+            dest="requirements",
+            action="append",
             default=[],
-            metavar='file',
-            help="Use the order in the given requirements file and its "
-                 "comments when generating output. This option can be "
-                 "used multiple times.")
+            metavar="file",
+            help=(
+                "Use the order in the given requirements file and its "
+                "comments when generating output. This option can be "
+                "used multiple times."
+            ),
+        )
         self.cmd_opts.add_option(
-            '-l', '--local',
-            dest='local',
-            action='store_true',
+            "-l",
+            "--local",
+            dest="local",
+            action="store_true",
             default=False,
-            help='If in a virtualenv that has global access, do not output '
-                 'globally-installed packages.')
+            help=(
+                "If in a virtualenv that has global access, do not output "
+                "globally-installed packages."
+            ),
+        )
         self.cmd_opts.add_option(
-            '--user',
-            dest='user',
-            action='store_true',
+            "--user",
+            dest="user",
+            action="store_true",
             default=False,
-            help='Only output packages installed in user-site.')
+            help="Only output packages installed in user-site.",
+        )
         self.cmd_opts.add_option(cmdoptions.list_path())
         self.cmd_opts.add_option(
-            '--all',
-            dest='freeze_all',
-            action='store_true',
-            help='Do not skip these packages in the output:'
-                 ' {}'.format(', '.join(DEV_PKGS)))
+            "--all",
+            dest="freeze_all",
+            action="store_true",
+            help=(
+                "Do not skip these packages in the output:"
+                " {}".format(", ".join(DEV_PKGS))
+            ),
+        )
         self.cmd_opts.add_option(
-            '--exclude-editable',
-            dest='exclude_editable',
-            action='store_true',
-            help='Exclude editable package from output.')
+            "--exclude-editable",
+            dest="exclude_editable",
+            action="store_true",
+            help="Exclude editable package from output.",
+        )
         self.cmd_opts.add_option(cmdoptions.list_exclude())
 
         self.parser.insert_option_group(0, self.cmd_opts)
 
     def run(self, options: Values, args: List[str]) -> int:
         skip = set(stdlib_pkgs)
         if not options.freeze_all:
@@ -76,9 +89,9 @@
             local_only=options.local,
             user_only=options.user,
             paths=options.path,
             isolated=options.isolated_mode,
             skip=skip,
             exclude_editable=options.exclude_editable,
         ):
-            sys.stdout.write(line + '\n')
+            sys.stdout.write(line + "\n")
         return SUCCESS
```

#### pip/_internal/commands/hash.py

```diff
@@ -16,40 +16,44 @@
     """
     Compute a hash of a local package archive.
 
     These can be used with --hash in a requirements file to do repeatable
     installs.
     """
 
-    usage = '%prog [options] <file> ...'
+    usage = "%prog [options] <file> ..."
     ignore_require_venv = True
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(
-            '-a', '--algorithm',
-            dest='algorithm',
+            "-a",
+            "--algorithm",
+            dest="algorithm",
             choices=STRONG_HASHES,
-            action='store',
+            action="store",
             default=FAVORITE_HASH,
-            help='The hash algorithm to use: one of {}'.format(
-                 ', '.join(STRONG_HASHES)))
+            help="The hash algorithm to use: one of {}".format(
+                ", ".join(STRONG_HASHES)
+            ),
+        )
         self.parser.insert_option_group(0, self.cmd_opts)
 
     def run(self, options: Values, args: List[str]) -> int:
         if not args:
             self.parser.print_usage(sys.stderr)
             return ERROR
 
         algorithm = options.algorithm
         for path in args:
-            write_output('%s:\n--hash=%s:%s',
-                         path, algorithm, _hash_of_file(path, algorithm))
+            write_output(
+                "%s:\n--hash=%s:%s", path, algorithm, _hash_of_file(path, algorithm)
+            )
         return SUCCESS
 
 
 def _hash_of_file(path: str, algorithm: str) -> str:
     """Return the hash digest of a file."""
-    with open(path, 'rb') as archive:
+    with open(path, "rb") as archive:
         hash = hashlib.new(algorithm)
         for chunk in read_chunks(archive):
             hash.update(chunk)
     return hash.hexdigest()
```

#### pip/_internal/commands/help.py

```diff
@@ -29,13 +29,13 @@
         if cmd_name not in commands_dict:
             guess = get_similar_commands(cmd_name)
 
             msg = [f'unknown command "{cmd_name}"']
             if guess:
                 msg.append(f'maybe you meant "{guess}"')
 
-            raise CommandError(' - '.join(msg))
+            raise CommandError(" - ".join(msg))
 
         command = create_command(cmd_name)
         command.parser.print_help()
 
         return SUCCESS
```

#### pip/_internal/commands/index.py

```diff
@@ -40,15 +40,15 @@
             cmdoptions.index_group,
             self.parser,
         )
 
         self.parser.insert_option_group(0, index_opts)
         self.parser.insert_option_group(0, self.cmd_opts)
 
-    def run(self, options: Values, args: List[Any]) -> int:
+    def run(self, options: Values, args: List[str]) -> int:
         handlers = {
             "versions": self.get_available_package_versions,
         }
 
         logger.warning(
             "pip index is currently an experimental command. "
             "It may be removed/changed in a future release "
@@ -97,43 +97,42 @@
             link_collector=link_collector,
             selection_prefs=selection_prefs,
             target_python=target_python,
         )
 
     def get_available_package_versions(self, options: Values, args: List[Any]) -> None:
         if len(args) != 1:
-            raise CommandError('You need to specify exactly one argument')
+            raise CommandError("You need to specify exactly one argument")
 
         target_python = cmdoptions.make_target_python(options)
         query = args[0]
 
         with self._build_session(options) as session:
             finder = self._build_package_finder(
                 options=options,
                 session=session,
                 target_python=target_python,
                 ignore_requires_python=options.ignore_requires_python,
             )
 
             versions: Iterable[Union[LegacyVersion, Version]] = (
-                candidate.version
-                for candidate in finder.find_all_candidates(query)
+                candidate.version for candidate in finder.find_all_candidates(query)
             )
 
             if not options.pre:
                 # Remove prereleases
-                versions = (version for version in versions
-                            if not version.is_prerelease)
+                versions = (
+                    version for version in versions if not version.is_prerelease
+                )
             versions = set(versions)
 
             if not versions:
                 raise DistributionNotFound(
-                    'No matching distribution found for {}'.format(query))
+                    "No matching distribution found for {}".format(query)
+                )
 
-            formatted_versions = [str(ver) for ver in sorted(
-                versions, reverse=True)]
+            formatted_versions = [str(ver) for ver in sorted(versions, reverse=True)]
             latest = formatted_versions[0]
 
-        write_output('{} ({})'.format(query, latest))
-        write_output('Available versions: {}'.format(
-            ', '.join(formatted_versions)))
+        write_output("{} ({})".format(query, latest))
+        write_output("Available versions: {}".format(", ".join(formatted_versions)))
         print_dist_installation_info(query, latest)
```

#### pip/_internal/commands/install.py

```diff
@@ -82,95 +82,111 @@
         self.cmd_opts.add_option(cmdoptions.requirements())
         self.cmd_opts.add_option(cmdoptions.constraints())
         self.cmd_opts.add_option(cmdoptions.no_deps())
         self.cmd_opts.add_option(cmdoptions.pre())
 
         self.cmd_opts.add_option(cmdoptions.editable())
         self.cmd_opts.add_option(
-            '-t', '--target',
-            dest='target_dir',
-            metavar='dir',
+            "-t",
+            "--target",
+            dest="target_dir",
+            metavar="dir",
             default=None,
-            help='Install packages into <dir>. '
-                 'By default this will not replace existing files/folders in '
-                 '<dir>. Use --upgrade to replace existing packages in <dir> '
-                 'with new versions.'
+            help=(
+                "Install packages into <dir>. "
+                "By default this will not replace existing files/folders in "
+                "<dir>. Use --upgrade to replace existing packages in <dir> "
+                "with new versions."
+            ),
         )
         cmdoptions.add_target_python_options(self.cmd_opts)
 
         self.cmd_opts.add_option(
-            '--user',
-            dest='use_user_site',
-            action='store_true',
-            help="Install to the Python user install directory for your "
-                 "platform. Typically ~/.local/, or %APPDATA%\\Python on "
-                 "Windows. (See the Python documentation for site.USER_BASE "
-                 "for full details.)")
-        self.cmd_opts.add_option(
-            '--no-user',
-            dest='use_user_site',
-            action='store_false',
-            help=SUPPRESS_HELP)
-        self.cmd_opts.add_option(
-            '--root',
-            dest='root_path',
-            metavar='dir',
+            "--user",
+            dest="use_user_site",
+            action="store_true",
+            help=(
+                "Install to the Python user install directory for your "
+                "platform. Typically ~/.local/, or %APPDATA%\\Python on "
+                "Windows. (See the Python documentation for site.USER_BASE "
+                "for full details.)"
+            ),
+        )
+        self.cmd_opts.add_option(
+            "--no-user",
+            dest="use_user_site",
+            action="store_false",
+            help=SUPPRESS_HELP,
+        )
+        self.cmd_opts.add_option(
+            "--root",
+            dest="root_path",
+            metavar="dir",
             default=None,
-            help="Install everything relative to this alternate root "
-                 "directory.")
+            help="Install everything relative to this alternate root directory.",
+        )
         self.cmd_opts.add_option(
-            '--prefix',
-            dest='prefix_path',
-            metavar='dir',
+            "--prefix",
+            dest="prefix_path",
+            metavar="dir",
             default=None,
-            help="Installation prefix where lib, bin and other top-level "
-                 "folders are placed")
-
-        self.cmd_opts.add_option(cmdoptions.build_dir())
+            help=(
+                "Installation prefix where lib, bin and other top-level "
+                "folders are placed"
+            ),
+        )
 
         self.cmd_opts.add_option(cmdoptions.src())
 
         self.cmd_opts.add_option(
-            '-U', '--upgrade',
-            dest='upgrade',
-            action='store_true',
-            help='Upgrade all specified packages to the newest available '
-                 'version. The handling of dependencies depends on the '
-                 'upgrade-strategy used.'
+            "-U",
+            "--upgrade",
+            dest="upgrade",
+            action="store_true",
+            help=(
+                "Upgrade all specified packages to the newest available "
+                "version. The handling of dependencies depends on the "
+                "upgrade-strategy used."
+            ),
         )
 
         self.cmd_opts.add_option(
-            '--upgrade-strategy',
-            dest='upgrade_strategy',
-            default='only-if-needed',
-            choices=['only-if-needed', 'eager'],
-            help='Determines how dependency upgrading should be handled '
-                 '[default: %default]. '
-                 '"eager" - dependencies are upgraded regardless of '
-                 'whether the currently installed version satisfies the '
-                 'requirements of the upgraded package(s). '
-                 '"only-if-needed" -  are upgraded only when they do not '
-                 'satisfy the requirements of the upgraded package(s).'
+            "--upgrade-strategy",
+            dest="upgrade_strategy",
+            default="only-if-needed",
+            choices=["only-if-needed", "eager"],
+            help=(
+                "Determines how dependency upgrading should be handled "
+                "[default: %default]. "
+                '"eager" - dependencies are upgraded regardless of '
+                "whether the currently installed version satisfies the "
+                "requirements of the upgraded package(s). "
+                '"only-if-needed" -  are upgraded only when they do not '
+                "satisfy the requirements of the upgraded package(s)."
+            ),
         )
 
         self.cmd_opts.add_option(
-            '--force-reinstall',
-            dest='force_reinstall',
-            action='store_true',
-            help='Reinstall all packages even if they are already '
-                 'up-to-date.')
-
-        self.cmd_opts.add_option(
-            '-I', '--ignore-installed',
-            dest='ignore_installed',
-            action='store_true',
-            help='Ignore the installed packages, overwriting them. '
-                 'This can break your system if the existing package '
-                 'is of a different version or was installed '
-                 'with a different package manager!'
+            "--force-reinstall",
+            dest="force_reinstall",
+            action="store_true",
+            help="Reinstall all packages even if they are already up-to-date.",
+        )
+
+        self.cmd_opts.add_option(
+            "-I",
+            "--ignore-installed",
+            dest="ignore_installed",
+            action="store_true",
+            help=(
+                "Ignore the installed packages, overwriting them. "
+                "This can break your system if the existing package "
+                "is of a different version or was installed "
+                "with a different package manager!"
+            ),
         )
 
         self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
         self.cmd_opts.add_option(cmdoptions.no_build_isolation())
         self.cmd_opts.add_option(cmdoptions.use_pep517())
         self.cmd_opts.add_option(cmdoptions.no_use_pep517())
 
@@ -245,19 +261,22 @@
         )
 
         target_temp_dir: Optional[TempDirectory] = None
         target_temp_dir_path: Optional[str] = None
         if options.target_dir:
             options.ignore_installed = True
             options.target_dir = os.path.abspath(options.target_dir)
-            if (os.path.exists(options.target_dir) and not
-                    os.path.isdir(options.target_dir)):
+            if (
+                # fmt: off
+                os.path.exists(options.target_dir) and
+                not os.path.isdir(options.target_dir)
+                # fmt: on
+            ):
                 raise CommandError(
-                    "Target path exists but is not a directory, will not "
-                    "continue."
+                    "Target path exists but is not a directory, will not continue."
                 )
 
             # Create a target directory for using with the target option
             target_temp_dir = TempDirectory(kind="target")
             target_temp_dir_path = target_temp_dir.path
             self.enter_context(target_temp_dir)
 
@@ -281,17 +300,21 @@
             kind="install",
             globally_managed=True,
         )
 
         try:
             reqs = self.get_requirements(args, options, finder, session)
 
-            reject_location_related_install_options(
-                reqs, options.install_options
-            )
+            # Only when installing is it permitted to use PEP 660.
+            # In other circumstances (pip wheel, pip download) we generate
+            # regular (i.e. non editable) metadata and wheels.
+            for req in reqs:
+                req.permit_editable_wheels = True
+
+            reject_location_related_install_options(reqs, options.install_options)
 
             preparer = self.make_requirement_preparer(
                 temp_build_dir=directory,
                 options=options,
                 req_tracker=req_tracker,
                 session=session,
                 finder=finder,
@@ -320,67 +343,58 @@
                 pip_req = requirement_set.get_requirement("pip")
             except KeyError:
                 modifying_pip = False
             else:
                 # If we're not replacing an already installed pip,
                 # we're not modifying it.
                 modifying_pip = pip_req.satisfied_by is None
-            protect_pip_from_modification_on_windows(
-                modifying_pip=modifying_pip
-            )
+            protect_pip_from_modification_on_windows(modifying_pip=modifying_pip)
 
-            check_binary_allowed = get_check_binary_allowed(
-                finder.format_control
-            )
+            check_binary_allowed = get_check_binary_allowed(finder.format_control)
 
             reqs_to_build = [
-                r for r in requirement_set.requirements.values()
-                if should_build_for_install_command(
-                    r, check_binary_allowed
-                )
+                r
+                for r in requirement_set.requirements.values()
+                if should_build_for_install_command(r, check_binary_allowed)
             ]
 
             _, build_failures = build(
                 reqs_to_build,
                 wheel_cache=wheel_cache,
                 verify=True,
                 build_options=[],
                 global_options=[],
             )
 
-            # If we're using PEP 517, we cannot do a direct install
+            # If we're using PEP 517, we cannot do a legacy setup.py install
             # so we fail here.
             pep517_build_failure_names: List[str] = [
-                r.name   # type: ignore
-                for r in build_failures if r.use_pep517
+                r.name for r in build_failures if r.use_pep517  # type: ignore
             ]
             if pep517_build_failure_names:
                 raise InstallationError(
-                    "Could not build wheels for {} which use"
-                    " PEP 517 and cannot be installed directly".format(
+                    "Could not build wheels for {}, which is required to "
+                    "install pyproject.toml-based projects".format(
                         ", ".join(pep517_build_failure_names)
                     )
                 )
 
             # For now, we just warn about failures building legacy
-            # requirements, as we'll fall through to a direct
-            # install for those.
+            # requirements, as we'll fall through to a setup.py install for
+            # those.
             for r in build_failures:
                 if not r.use_pep517:
                     r.legacy_install_reason = 8368
 
-            to_install = resolver.get_installation_order(
-                requirement_set
-            )
+            to_install = resolver.get_installation_order(requirement_set)
 
             # Check for conflicts in the package set we're installing.
             conflicts: Optional[ConflictDetails] = None
             should_warn_about_conflicts = (
-                not options.ignore_dependencies and
-                options.warn_about_conflicts
+                not options.ignore_dependencies and options.warn_about_conflicts
             )
             if should_warn_about_conflicts:
                 conflicts = self._determine_conflicts(to_install)
 
             # Don't warn about script install locations if
             # --target or --prefix has been specified
             warn_script_location = options.warn_script_location
@@ -404,15 +418,15 @@
                 home=target_temp_dir_path,
                 root=options.root_path,
                 prefix=options.prefix_path,
                 isolated=options.isolated_mode,
             )
             env = get_environment(lib_locations)
 
-            installed.sort(key=operator.attrgetter('name'))
+            installed.sort(key=operator.attrgetter("name"))
             items = []
             for result in installed:
                 item = result.name
                 try:
                     installed_dist = env.get_distribution(item)
                     if installed_dist is not None:
                         item = f"{item}-{installed_dist.version}"
@@ -422,24 +436,27 @@
 
             if conflicts is not None:
                 self._warn_about_conflicts(
                     conflicts,
                     resolver_variant=self.determine_resolver_variant(options),
                 )
 
-            installed_desc = ' '.join(items)
+            installed_desc = " ".join(items)
             if installed_desc:
                 write_output(
-                    'Successfully installed %s', installed_desc,
+                    "Successfully installed %s",
+                    installed_desc,
                 )
         except OSError as error:
-            show_traceback = (self.verbosity >= 1)
+            show_traceback = self.verbosity >= 1
 
             message = create_os_error_message(
-                error, show_traceback, options.use_user_site,
+                error,
+                show_traceback,
+                options.use_user_site,
             )
             logger.error(message, exc_info=show_traceback)  # noqa
 
             return ERROR
 
         if options.target_dir:
             assert target_temp_dir
@@ -457,15 +474,15 @@
 
         # Checking both purelib and platlib directories for installed
         # packages to be moved to target directory
         lib_dir_list = []
 
         # Checking both purelib and platlib directories for installed
         # packages to be moved to target directory
-        scheme = get_scheme('', home=target_temp_dir.path)
+        scheme = get_scheme("", home=target_temp_dir.path)
         purelib_dir = scheme.purelib
         platlib_dir = scheme.platlib
         data_dir = scheme.data
 
         if os.path.exists(purelib_dir):
             lib_dir_list.append(purelib_dir)
         if os.path.exists(platlib_dir) and platlib_dir != purelib_dir:
@@ -479,37 +496,34 @@
                     ddir = os.path.join(data_dir, item)
                     if any(s.startswith(ddir) for s in lib_dir_list[:-1]):
                         continue
                 target_item_dir = os.path.join(target_dir, item)
                 if os.path.exists(target_item_dir):
                     if not upgrade:
                         logger.warning(
-                            'Target directory %s already exists. Specify '
-                            '--upgrade to force replacement.',
-                            target_item_dir
+                            "Target directory %s already exists. Specify "
+                            "--upgrade to force replacement.",
+                            target_item_dir,
                         )
                         continue
                     if os.path.islink(target_item_dir):
                         logger.warning(
-                            'Target directory %s already exists and is '
-                            'a link. pip will not automatically replace '
-                            'links, please remove if replacement is '
-                            'desired.',
-                            target_item_dir
+                            "Target directory %s already exists and is "
+                            "a link. pip will not automatically replace "
+                            "links, please remove if replacement is "
+                            "desired.",
+                            target_item_dir,
                         )
                         continue
                     if os.path.isdir(target_item_dir):
                         shutil.rmtree(target_item_dir)
                     else:
                         os.remove(target_item_dir)
 
-                shutil.move(
-                    os.path.join(lib_dir, item),
-                    target_item_dir
-                )
+                shutil.move(os.path.join(lib_dir, item), target_item_dir)
 
     def _determine_conflicts(
         self, to_install: List[InstallRequirement]
     ) -> Optional[ConflictDetails]:
         try:
             return check_install_conflicts(to_install)
         except Exception:
@@ -563,43 +577,43 @@
                     "{dep_name} {dep_version} which is incompatible."
                 ).format(
                     name=project_name,
                     version=version,
                     requirement=req,
                     dep_name=dep_name,
                     dep_version=dep_version,
-                    you=("you" if resolver_variant == "2020-resolver" else "you'll")
+                    you=("you" if resolver_variant == "2020-resolver" else "you'll"),
                 )
                 parts.append(message)
 
         logger.critical("\n".join(parts))
 
 
 def get_lib_location_guesses(
-        user: bool = False,
-        home: Optional[str] = None,
-        root: Optional[str] = None,
-        isolated: bool = False,
-        prefix: Optional[str] = None
+    user: bool = False,
+    home: Optional[str] = None,
+    root: Optional[str] = None,
+    isolated: bool = False,
+    prefix: Optional[str] = None,
 ) -> List[str]:
     scheme = get_scheme(
-        '',
+        "",
         user=user,
         home=home,
         root=root,
         isolated=isolated,
         prefix=prefix,
     )
     return [scheme.purelib, scheme.platlib]
 
 
 def site_packages_writable(root: Optional[str], isolated: bool) -> bool:
     return all(
-        test_writable_dir(d) for d in set(
-            get_lib_location_guesses(root=root, isolated=isolated))
+        test_writable_dir(d)
+        for d in set(get_lib_location_guesses(root=root, isolated=isolated))
     )
 
 
 def decide_user_install(
     use_user_site: Optional[bool],
     prefix_path: Optional[str] = None,
     target_dir: Optional[str] = None,
@@ -649,25 +663,28 @@
 
     # If we have permission for a non-user install, do that,
     # otherwise do a user install.
     if site_packages_writable(root=root_path, isolated=isolated_mode):
         logger.debug("Non-user install because site-packages writeable")
         return False
 
-    logger.info("Defaulting to user installation because normal site-packages "
-                "is not writeable")
+    logger.info(
+        "Defaulting to user installation because normal site-packages "
+        "is not writeable"
+    )
     return True
 
 
 def reject_location_related_install_options(
     requirements: List[InstallRequirement], options: Optional[List[str]]
 ) -> None:
     """If any location-changing --install-option arguments were passed for
     requirements or on the command-line, then show a deprecation warning.
     """
+
     def format_options(option_names: Iterable[str]) -> List[str]:
         return ["--{}".format(name.replace("_", "-")) for name in option_names]
 
     offenders = []
 
     for requirement in requirements:
         install_options = requirement.install_options
@@ -679,28 +696,24 @@
                 )
             )
 
     if options:
         location_options = parse_distutils_args(options)
         if location_options:
             offenders.append(
-                "{!r} from command line".format(
-                    format_options(location_options.keys())
-                )
+                "{!r} from command line".format(format_options(location_options.keys()))
             )
 
     if not offenders:
         return
 
     raise CommandError(
         "Location-changing options found in --install-option: {}."
         " This is unsupported, use pip-level options like --user,"
-        " --prefix, --root, and --target instead.".format(
-            "; ".join(offenders)
-        )
+        " --prefix, --root, and --target instead.".format("; ".join(offenders))
     )
 
 
 def create_os_error_message(
     error: OSError, show_traceback: bool, using_user_site: bool
 ) -> str:
     """Format an error message for an OSError
@@ -723,26 +736,33 @@
     # Suggest useful actions to the user:
     #  (1) using user site-packages or (2) verifying the permissions
     if error.errno == errno.EACCES:
         user_option_part = "Consider using the `--user` option"
         permissions_part = "Check the permissions"
 
         if not running_under_virtualenv() and not using_user_site:
-            parts.extend([
-                user_option_part, " or ",
-                permissions_part.lower(),
-            ])
+            parts.extend(
+                [
+                    user_option_part,
+                    " or ",
+                    permissions_part.lower(),
+                ]
+            )
         else:
             parts.append(permissions_part)
         parts.append(".\n")
 
     # Suggest the user to enable Long Paths if path length is
     # more than 260
-    if (WINDOWS and error.errno == errno.ENOENT and error.filename and
-            len(error.filename) > 260):
+    if (
+        WINDOWS
+        and error.errno == errno.ENOENT
+        and error.filename
+        and len(error.filename) > 260
+    ):
         parts.append(
             "HINT: This error might have occurred since "
             "this system does not have Windows Long Path "
             "support enabled. You can find information on "
             "how to enable this at "
             "https://pip.pypa.io/warnings/enable-long-paths\n"
         )
```

#### pip/_internal/commands/list.py

```diff
@@ -10,26 +10,28 @@
 from pip._internal.cli.status_codes import SUCCESS
 from pip._internal.exceptions import CommandError
 from pip._internal.index.collector import LinkCollector
 from pip._internal.index.package_finder import PackageFinder
 from pip._internal.metadata import BaseDistribution, get_environment
 from pip._internal.models.selection_prefs import SelectionPreferences
 from pip._internal.network.session import PipSession
-from pip._internal.utils.misc import stdlib_pkgs, tabulate, write_output
+from pip._internal.utils.compat import stdlib_pkgs
+from pip._internal.utils.misc import tabulate, write_output
 from pip._internal.utils.parallel import map_multithread
 
 if TYPE_CHECKING:
     from pip._internal.metadata.base import DistributionVersion
 
     class _DistWithLatestInfo(BaseDistribution):
         """Give the distribution object a couple of extra fields.
 
         These will be populated during ``get_outdated()``. This is dirty but
         makes the rest of the code much cleaner.
         """
+
         latest_version: DistributionVersion
         latest_filetype: str
 
     _ProcessedDists = Sequence[_DistWithLatestInfo]
 
 
 logger = logging.getLogger(__name__)
@@ -44,85 +46,93 @@
 
     ignore_require_venv = True
     usage = """
       %prog [options]"""
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(
-            '-o', '--outdated',
-            action='store_true',
+            "-o",
+            "--outdated",
+            action="store_true",
             default=False,
-            help='List outdated packages')
+            help="List outdated packages",
+        )
         self.cmd_opts.add_option(
-            '-u', '--uptodate',
-            action='store_true',
+            "-u",
+            "--uptodate",
+            action="store_true",
             default=False,
-            help='List uptodate packages')
+            help="List uptodate packages",
+        )
         self.cmd_opts.add_option(
-            '-e', '--editable',
-            action='store_true',
+            "-e",
+            "--editable",
+            action="store_true",
             default=False,
-            help='List editable projects.')
+            help="List editable projects.",
+        )
         self.cmd_opts.add_option(
-            '-l', '--local',
-            action='store_true',
+            "-l",
+            "--local",
+            action="store_true",
             default=False,
-            help=('If in a virtualenv that has global access, do not list '
-                  'globally-installed packages.'),
+            help=(
+                "If in a virtualenv that has global access, do not list "
+                "globally-installed packages."
+            ),
         )
         self.cmd_opts.add_option(
-            '--user',
-            dest='user',
-            action='store_true',
+            "--user",
+            dest="user",
+            action="store_true",
             default=False,
-            help='Only output packages installed in user-site.')
+            help="Only output packages installed in user-site.",
+        )
         self.cmd_opts.add_option(cmdoptions.list_path())
         self.cmd_opts.add_option(
-            '--pre',
-            action='store_true',
+            "--pre",
+            action="store_true",
             default=False,
-            help=("Include pre-release and development versions. By default, "
-                  "pip only finds stable versions."),
+            help=(
+                "Include pre-release and development versions. By default, "
+                "pip only finds stable versions."
+            ),
         )
 
         self.cmd_opts.add_option(
-            '--format',
-            action='store',
-            dest='list_format',
+            "--format",
+            action="store",
+            dest="list_format",
             default="columns",
-            choices=('columns', 'freeze', 'json'),
-            help="Select the output format among: columns (default), freeze, "
-                 "or json",
+            choices=("columns", "freeze", "json"),
+            help="Select the output format among: columns (default), freeze, or json",
         )
 
         self.cmd_opts.add_option(
-            '--not-required',
-            action='store_true',
-            dest='not_required',
-            help="List packages that are not dependencies of "
-                 "installed packages.",
+            "--not-required",
+            action="store_true",
+            dest="not_required",
+            help="List packages that are not dependencies of installed packages.",
         )
 
         self.cmd_opts.add_option(
-            '--exclude-editable',
-            action='store_false',
-            dest='include_editable',
-            help='Exclude editable package from output.',
+            "--exclude-editable",
+            action="store_false",
+            dest="include_editable",
+            help="Exclude editable package from output.",
         )
         self.cmd_opts.add_option(
-            '--include-editable',
-            action='store_true',
-            dest='include_editable',
-            help='Include editable package from output.',
+            "--include-editable",
+            action="store_true",
+            dest="include_editable",
+            help="Include editable package from output.",
             default=True,
         )
         self.cmd_opts.add_option(cmdoptions.list_exclude())
-        index_opts = cmdoptions.make_option_group(
-            cmdoptions.index_group, self.parser
-        )
+        index_opts = cmdoptions.make_option_group(cmdoptions.index_group, self.parser)
 
         self.parser.insert_option_group(0, index_opts)
         self.parser.insert_option_group(0, self.cmd_opts)
 
     def _build_package_finder(
         self, options: Values, session: PipSession
     ) -> PackageFinder:
@@ -140,16 +150,15 @@
         return PackageFinder.create(
             link_collector=link_collector,
             selection_prefs=selection_prefs,
         )
 
     def run(self, options: Values, args: List[str]) -> int:
         if options.outdated and options.uptodate:
-            raise CommandError(
-                "Options --outdated and --uptodate cannot be combined.")
+            raise CommandError("Options --outdated and --uptodate cannot be combined.")
 
         cmdoptions.check_list_path_option(options)
 
         skip = set(stdlib_pkgs)
         if options.excludes:
             skip.update(canonicalize_name(n) for n in options.excludes)
 
@@ -179,23 +188,25 @@
         self.output_package_listing(packages, options)
         return SUCCESS
 
     def get_outdated(
         self, packages: "_ProcessedDists", options: Values
     ) -> "_ProcessedDists":
         return [
-            dist for dist in self.iter_packages_latest_infos(packages, options)
+            dist
+            for dist in self.iter_packages_latest_infos(packages, options)
             if dist.latest_version > dist.version
         ]
 
     def get_uptodate(
         self, packages: "_ProcessedDists", options: Values
     ) -> "_ProcessedDists":
         return [
-            dist for dist in self.iter_packages_latest_infos(packages, options)
+            dist
+            for dist in self.iter_packages_latest_infos(packages, options)
             if dist.latest_version == dist.version
         ]
 
     def get_not_required(
         self, packages: "_ProcessedDists", options: Values
     ) -> "_ProcessedDists":
         dep_keys = {
@@ -212,34 +223,37 @@
     def iter_packages_latest_infos(
         self, packages: "_ProcessedDists", options: Values
     ) -> Iterator["_DistWithLatestInfo"]:
         with self._build_session(options) as session:
             finder = self._build_package_finder(options, session)
 
             def latest_info(
-                dist: "_DistWithLatestInfo"
+                dist: "_DistWithLatestInfo",
             ) -> Optional["_DistWithLatestInfo"]:
                 all_candidates = finder.find_all_candidates(dist.canonical_name)
                 if not options.pre:
                     # Remove prereleases
-                    all_candidates = [candidate for candidate in all_candidates
-                                      if not candidate.version.is_prerelease]
+                    all_candidates = [
+                        candidate
+                        for candidate in all_candidates
+                        if not candidate.version.is_prerelease
+                    ]
 
                 evaluator = finder.make_candidate_evaluator(
                     project_name=dist.canonical_name,
                 )
                 best_candidate = evaluator.sort_best_candidate(all_candidates)
                 if best_candidate is None:
                     return None
 
                 remote_version = best_candidate.version
                 if best_candidate.link.is_wheel:
-                    typ = 'wheel'
+                    typ = "wheel"
                 else:
-                    typ = 'sdist'
+                    typ = "sdist"
                 dist.latest_version = remote_version
                 dist.latest_filetype = typ
                 return dist
 
             for dist in map_multithread(latest_info, packages):
                 if dist is not None:
                     yield dist
@@ -247,91 +261,101 @@
     def output_package_listing(
         self, packages: "_ProcessedDists", options: Values
     ) -> None:
         packages = sorted(
             packages,
             key=lambda dist: dist.canonical_name,
         )
-        if options.list_format == 'columns' and packages:
+        if options.list_format == "columns" and packages:
             data, header = format_for_columns(packages, options)
             self.output_package_listing_columns(data, header)
-        elif options.list_format == 'freeze':
+        elif options.list_format == "freeze":
             for dist in packages:
                 if options.verbose >= 1:
-                    write_output("%s==%s (%s)", dist.raw_name,
-                                 dist.version, dist.location)
+                    write_output(
+                        "%s==%s (%s)", dist.raw_name, dist.version, dist.location
+                    )
                 else:
                     write_output("%s==%s", dist.raw_name, dist.version)
-        elif options.list_format == 'json':
+        elif options.list_format == "json":
             write_output(format_for_json(packages, options))
 
     def output_package_listing_columns(
         self, data: List[List[str]], header: List[str]
     ) -> None:
         # insert the header first: we need to know the size of column names
         if len(data) > 0:
             data.insert(0, header)
 
         pkg_strings, sizes = tabulate(data)
 
         # Create and add a separator.
         if len(data) > 0:
-            pkg_strings.insert(1, " ".join(map(lambda x: '-' * x, sizes)))
+            pkg_strings.insert(1, " ".join(map(lambda x: "-" * x, sizes)))
 
         for val in pkg_strings:
             write_output(val)
 
 
 def format_for_columns(
     pkgs: "_ProcessedDists", options: Values
 ) -> Tuple[List[List[str]], List[str]]:
     """
     Convert the package data into something usable
     by output_package_listing_columns.
     """
+    header = ["Package", "Version"]
+
     running_outdated = options.outdated
-    # Adjust the header for the `pip list --outdated` case.
     if running_outdated:
-        header = ["Package", "Version", "Latest", "Type"]
-    else:
-        header = ["Package", "Version"]
+        header.extend(["Latest", "Type"])
 
-    data = []
-    if options.verbose >= 1 or any(x.editable for x in pkgs):
+    has_editables = any(x.editable for x in pkgs)
+    if has_editables:
+        header.append("Editable project location")
+
+    if options.verbose >= 1:
         header.append("Location")
     if options.verbose >= 1:
         header.append("Installer")
 
+    data = []
     for proj in pkgs:
         # if we're working on the 'outdated' list, separate out the
         # latest_version and type
         row = [proj.raw_name, str(proj.version)]
 
         if running_outdated:
             row.append(str(proj.latest_version))
             row.append(proj.latest_filetype)
 
-        if options.verbose >= 1 or proj.editable:
+        if has_editables:
+            row.append(proj.editable_project_location or "")
+
+        if options.verbose >= 1:
             row.append(proj.location or "")
         if options.verbose >= 1:
             row.append(proj.installer)
 
         data.append(row)
 
     return data, header
 
 
 def format_for_json(packages: "_ProcessedDists", options: Values) -> str:
     data = []
     for dist in packages:
         info = {
-            'name': dist.raw_name,
-            'version': str(dist.version),
+            "name": dist.raw_name,
+            "version": str(dist.version),
         }
         if options.verbose >= 1:
-            info['location'] = dist.location or ""
-            info['installer'] = dist.installer
+            info["location"] = dist.location or ""
+            info["installer"] = dist.installer
         if options.outdated:
-            info['latest_version'] = str(dist.latest_version)
-            info['latest_filetype'] = dist.latest_filetype
+            info["latest_version"] = str(dist.latest_version)
+            info["latest_filetype"] = dist.latest_filetype
+        editable_project_location = dist.editable_project_location
+        if editable_project_location:
+            info["editable_project_location"] = editable_project_location
         data.append(info)
     return json.dumps(data)
```

#### pip/_internal/commands/search.py

```diff
@@ -23,37 +23,40 @@
     from typing import TypedDict
 
     class TransformedHit(TypedDict):
         name: str
         summary: str
         versions: List[str]
 
+
 logger = logging.getLogger(__name__)
 
 
 class SearchCommand(Command, SessionCommandMixin):
     """Search for PyPI packages whose name or summary contains <query>."""
 
     usage = """
       %prog [options] <query>"""
     ignore_require_venv = True
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(
-            '-i', '--index',
-            dest='index',
-            metavar='URL',
+            "-i",
+            "--index",
+            dest="index",
+            metavar="URL",
             default=PyPI.pypi_url,
-            help='Base URL of Python Package Index (default %default)')
+            help="Base URL of Python Package Index (default %default)",
+        )
 
         self.parser.insert_option_group(0, self.cmd_opts)
 
     def run(self, options: Values, args: List[str]) -> int:
         if not args:
-            raise CommandError('Missing required argument (search query).')
+            raise CommandError("Missing required argument (search query).")
         query = args
         pypi_hits = self.search(query, options)
         hits = transform_hits(pypi_hits)
 
         terminal_width = None
         if sys.stdout.isatty():
             terminal_width = shutil.get_terminal_size()[0]
@@ -67,15 +70,15 @@
         index_url = options.index
 
         session = self.get_default_session(options)
 
         transport = PipXmlrpcTransport(index_url, session)
         pypi = xmlrpc.client.ServerProxy(index_url, transport)
         try:
-            hits = pypi.search({'name': query, 'summary': query}, 'or')
+            hits = pypi.search({"name": query, "summary": query}, "or")
         except xmlrpc.client.Fault as fault:
             message = "XMLRPC request failed [code: {code}]\n{string}".format(
                 code=fault.faultCode,
                 string=fault.faultString,
             )
             raise CommandError(message)
         assert isinstance(hits, list)
@@ -86,77 +89,84 @@
     """
     The list from pypi is really a list of versions. We want a list of
     packages with the list of versions stored inline. This converts the
     list from pypi into one we can use.
     """
     packages: Dict[str, "TransformedHit"] = OrderedDict()
     for hit in hits:
-        name = hit['name']
-        summary = hit['summary']
-        version = hit['version']
+        name = hit["name"]
+        summary = hit["summary"]
+        version = hit["version"]
 
         if name not in packages.keys():
             packages[name] = {
-                'name': name,
-                'summary': summary,
-                'versions': [version],
+                "name": name,
+                "summary": summary,
+                "versions": [version],
             }
         else:
-            packages[name]['versions'].append(version)
+            packages[name]["versions"].append(version)
 
             # if this is the highest version, replace summary and score
-            if version == highest_version(packages[name]['versions']):
-                packages[name]['summary'] = summary
+            if version == highest_version(packages[name]["versions"]):
+                packages[name]["summary"] = summary
 
     return list(packages.values())
 
 
 def print_dist_installation_info(name: str, latest: str) -> None:
     env = get_default_environment()
     dist = env.get_distribution(name)
     if dist is not None:
         with indent_log():
             if dist.version == latest:
-                write_output('INSTALLED: %s (latest)', dist.version)
+                write_output("INSTALLED: %s (latest)", dist.version)
             else:
-                write_output('INSTALLED: %s', dist.version)
+                write_output("INSTALLED: %s", dist.version)
                 if parse_version(latest).pre:
-                    write_output('LATEST:    %s (pre-release; install'
-                                 ' with "pip install --pre")', latest)
+                    write_output(
+                        "LATEST:    %s (pre-release; install"
+                        " with `pip install --pre`)",
+                        latest,
+                    )
                 else:
-                    write_output('LATEST:    %s', latest)
+                    write_output("LATEST:    %s", latest)
 
 
 def print_results(
     hits: List["TransformedHit"],
     name_column_width: Optional[int] = None,
     terminal_width: Optional[int] = None,
 ) -> None:
     if not hits:
         return
     if name_column_width is None:
-        name_column_width = max([
-            len(hit['name']) + len(highest_version(hit.get('versions', ['-'])))
-            for hit in hits
-        ]) + 4
+        name_column_width = (
+            max(
+                [
+                    len(hit["name"]) + len(highest_version(hit.get("versions", ["-"])))
+                    for hit in hits
+                ]
+            )
+            + 4
+        )
 
     for hit in hits:
-        name = hit['name']
-        summary = hit['summary'] or ''
-        latest = highest_version(hit.get('versions', ['-']))
+        name = hit["name"]
+        summary = hit["summary"] or ""
+        latest = highest_version(hit.get("versions", ["-"]))
         if terminal_width is not None:
             target_width = terminal_width - name_column_width - 5
             if target_width > 10:
                 # wrap and indent summary to fit terminal
                 summary_lines = textwrap.wrap(summary, target_width)
-                summary = ('\n' + ' ' * (name_column_width + 3)).join(
-                    summary_lines)
+                summary = ("\n" + " " * (name_column_width + 3)).join(summary_lines)
 
-        name_latest = f'{name} ({latest})'
-        line = f'{name_latest:{name_column_width}} - {summary}'
+        name_latest = f"{name} ({latest})"
+        line = f"{name_latest:{name_column_width}} - {summary}"
         try:
             write_output(line)
             print_dist_installation_info(name, latest)
         except UnicodeEncodeError:
             pass
```

#### pip/_internal/commands/show.py

```diff
@@ -23,31 +23,34 @@
 
     usage = """
       %prog [options] <package> ..."""
     ignore_require_venv = True
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(
-            '-f', '--files',
-            dest='files',
-            action='store_true',
+            "-f",
+            "--files",
+            dest="files",
+            action="store_true",
             default=False,
-            help='Show the full list of installed files for each package.')
+            help="Show the full list of installed files for each package.",
+        )
 
         self.parser.insert_option_group(0, self.cmd_opts)
 
     def run(self, options: Values, args: List[str]) -> int:
         if not args:
-            logger.warning('ERROR: Please provide a package name or names.')
+            logger.warning("ERROR: Please provide a package name or names.")
             return ERROR
         query = args
 
         results = search_packages_info(query)
         if not print_results(
-                results, list_files=options.files, verbose=options.verbose):
+            results, list_files=options.files, verbose=options.verbose
+        ):
             return ERROR
         return SUCCESS
 
 
 class _PackageInfo(NamedTuple):
     name: str
     version: str
@@ -62,15 +65,15 @@
     author: str
     author_email: str
     license: str
     entry_points: List[str]
     files: Optional[List[str]]
 
 
-def _covert_legacy_entry(entry: Tuple[str, ...], info: Tuple[str, ...]) -> str:
+def _convert_legacy_entry(entry: Tuple[str, ...], info: Tuple[str, ...]) -> str:
     """Convert a legacy installed-files.txt path into modern RECORD path.
 
     The legacy format stores paths relative to the info directory, while the
     modern format stores paths relative to the package root, e.g. the
     site-packages directory.
 
     :param entry: Path parts of the installed-files.txt entry.
@@ -98,71 +101,69 @@
     Gather details from installed distributions. Print distribution name,
     version, location, and installed files. Installed files requires a
     pip generated 'installed-files.txt' in the distributions '.egg-info'
     directory.
     """
     env = get_default_environment()
 
-    installed = {
-        dist.canonical_name: dist
-        for dist in env.iter_distributions()
-    }
+    installed = {dist.canonical_name: dist for dist in env.iter_distributions()}
     query_names = [canonicalize_name(name) for name in query]
     missing = sorted(
         [name for name, pkg in zip(query, query_names) if pkg not in installed]
     )
     if missing:
-        logger.warning('Package(s) not found: %s', ', '.join(missing))
+        logger.warning("Package(s) not found: %s", ", ".join(missing))
 
-    def _get_requiring_packages(current_dist: BaseDistribution) -> List[str]:
-        return [
+    def _get_requiring_packages(current_dist: BaseDistribution) -> Iterator[str]:
+        return (
             dist.metadata["Name"] or "UNKNOWN"
             for dist in installed.values()
-            if current_dist.canonical_name in {
-                canonicalize_name(d.name) for d in dist.iter_dependencies()
-            }
-        ]
+            if current_dist.canonical_name
+            in {canonicalize_name(d.name) for d in dist.iter_dependencies()}
+        )
 
     def _files_from_record(dist: BaseDistribution) -> Optional[Iterator[str]]:
         try:
-            text = dist.read_text('RECORD')
+            text = dist.read_text("RECORD")
         except FileNotFoundError:
             return None
         # This extra Path-str cast normalizes entries.
         return (str(pathlib.Path(row[0])) for row in csv.reader(text.splitlines()))
 
     def _files_from_legacy(dist: BaseDistribution) -> Optional[Iterator[str]]:
         try:
-            text = dist.read_text('installed-files.txt')
+            text = dist.read_text("installed-files.txt")
         except FileNotFoundError:
             return None
         paths = (p for p in text.splitlines(keepends=False) if p)
         root = dist.location
         info = dist.info_directory
         if root is None or info is None:
             return paths
         try:
             info_rel = pathlib.Path(info).relative_to(root)
         except ValueError:  # info is not relative to root.
             return paths
         if not info_rel.parts:  # info *is* root.
             return paths
         return (
-            _covert_legacy_entry(pathlib.Path(p).parts, info_rel.parts)
-            for p in paths
+            _convert_legacy_entry(pathlib.Path(p).parts, info_rel.parts) for p in paths
         )
 
     for query_name in query_names:
         try:
             dist = installed[query_name]
         except KeyError:
             continue
 
+        requires = sorted((req.name for req in dist.iter_dependencies()), key=str.lower)
+        required_by = sorted(_get_requiring_packages(dist), key=str.lower)
+
         try:
-            entry_points_text = dist.read_text('entry_points.txt')
+            entry_points_text = dist.read_text("entry_points.txt")
             entry_points = entry_points_text.splitlines(keepends=False)
         except FileNotFoundError:
             entry_points = []
 
         files_iter = _files_from_record(dist) or _files_from_legacy(dist)
         if files_iter is None:
             files: Optional[List[str]] = None
@@ -171,16 +172,16 @@
 
         metadata = dist.metadata
 
         yield _PackageInfo(
             name=dist.raw_name,
             version=str(dist.version),
             location=dist.location or "",
-            requires=[req.name for req in dist.iter_dependencies()],
-            required_by=_get_requiring_packages(dist),
+            requires=requires,
+            required_by=required_by,
             installer=dist.installer,
             metadata_version=dist.metadata_version or "",
             classifiers=metadata.get_all("Classifier", []),
             summary=metadata.get("Summary", ""),
             homepage=metadata.get("Home-page", ""),
             author=metadata.get("Author", ""),
             author_email=metadata.get("Author-email", ""),
@@ -208,16 +209,16 @@
         write_output("Version: %s", dist.version)
         write_output("Summary: %s", dist.summary)
         write_output("Home-page: %s", dist.homepage)
         write_output("Author: %s", dist.author)
         write_output("Author-email: %s", dist.author_email)
         write_output("License: %s", dist.license)
         write_output("Location: %s", dist.location)
-        write_output("Requires: %s", ', '.join(dist.requires))
-        write_output("Required-by: %s", ', '.join(dist.required_by))
+        write_output("Requires: %s", ", ".join(dist.requires))
+        write_output("Required-by: %s", ", ".join(dist.required_by))
 
         if verbose:
             write_output("Metadata-Version: %s", dist.metadata_version)
             write_output("Installer: %s", dist.installer)
             write_output("Classifiers:")
             for classifier in dist.classifiers:
                 write_output("  %s", classifier)
```

#### pip/_internal/commands/uninstall.py

```diff
@@ -31,70 +31,75 @@
 
     usage = """
       %prog [options] <package> ...
       %prog [options] -r <requirements file> ..."""
 
     def add_options(self) -> None:
         self.cmd_opts.add_option(
-            '-r', '--requirement',
-            dest='requirements',
-            action='append',
+            "-r",
+            "--requirement",
+            dest="requirements",
+            action="append",
             default=[],
-            metavar='file',
-            help='Uninstall all the packages listed in the given requirements '
-                 'file.  This option can be used multiple times.',
+            metavar="file",
+            help=(
+                "Uninstall all the packages listed in the given requirements "
+                "file.  This option can be used multiple times."
+            ),
         )
         self.cmd_opts.add_option(
-            '-y', '--yes',
-            dest='yes',
-            action='store_true',
-            help="Don't ask for confirmation of uninstall deletions.")
+            "-y",
+            "--yes",
+            dest="yes",
+            action="store_true",
+            help="Don't ask for confirmation of uninstall deletions.",
+        )
 
         self.parser.insert_option_group(0, self.cmd_opts)
 
     def run(self, options: Values, args: List[str]) -> int:
         session = self.get_default_session(options)
 
         reqs_to_uninstall = {}
         for name in args:
             req = install_req_from_line(
-                name, isolated=options.isolated_mode,
+                name,
+                isolated=options.isolated_mode,
             )
             if req.name:
                 reqs_to_uninstall[canonicalize_name(req.name)] = req
             else:
                 logger.warning(
                     "Invalid requirement: %r ignored -"
                     " the uninstall command expects named"
                     " requirements.",
                     name,
                 )
         for filename in options.requirements:
             for parsed_req in parse_requirements(
-                    filename,
-                    options=options,
-                    session=session):
+                filename, options=options, session=session
+            ):
                 req = install_req_from_parsed_requirement(
-                    parsed_req,
-                    isolated=options.isolated_mode
+                    parsed_req, isolated=options.isolated_mode
                 )
                 if req.name:
                     reqs_to_uninstall[canonicalize_name(req.name)] = req
         if not reqs_to_uninstall:
             raise InstallationError(
-                f'You must give at least one requirement to {self.name} (see '
+                f"You must give at least one requirement to {self.name} (see "
                 f'"pip help {self.name}")'
             )
 
         protect_pip_from_modification_on_windows(
             modifying_pip="pip" in reqs_to_uninstall
         )
 
         for req in reqs_to_uninstall.values():
             uninstall_pathset = req.uninstall(
-                auto_confirm=options.yes, verbose=self.verbosity > 0,
+                auto_confirm=options.yes,
+                verbose=self.verbosity > 0,
             )
             if uninstall_pathset:
                 uninstall_pathset.commit()
 
         warn_if_run_as_root()
         return SUCCESS
```

#### pip/_internal/commands/wheel.py

```diff
@@ -39,53 +39,57 @@
       %prog [options] [-e] <vcs project url> ...
       %prog [options] [-e] <local project path> ...
       %prog [options] <archive url/path> ..."""
 
     def add_options(self) -> None:
 
         self.cmd_opts.add_option(
-            '-w', '--wheel-dir',
-            dest='wheel_dir',
-            metavar='dir',
+            "-w",
+            "--wheel-dir",
+            dest="wheel_dir",
+            metavar="dir",
             default=os.curdir,
-            help=("Build wheels into <dir>, where the default is the "
-                  "current working directory."),
+            help=(
+                "Build wheels into <dir>, where the default is the "
+                "current working directory."
+            ),
         )
         self.cmd_opts.add_option(cmdoptions.no_binary())
         self.cmd_opts.add_option(cmdoptions.only_binary())
         self.cmd_opts.add_option(cmdoptions.prefer_binary())
         self.cmd_opts.add_option(cmdoptions.no_build_isolation())
         self.cmd_opts.add_option(cmdoptions.use_pep517())
         self.cmd_opts.add_option(cmdoptions.no_use_pep517())
         self.cmd_opts.add_option(cmdoptions.constraints())
         self.cmd_opts.add_option(cmdoptions.editable())
         self.cmd_opts.add_option(cmdoptions.requirements())
         self.cmd_opts.add_option(cmdoptions.src())
         self.cmd_opts.add_option(cmdoptions.ignore_requires_python())
         self.cmd_opts.add_option(cmdoptions.no_deps())
-        self.cmd_opts.add_option(cmdoptions.build_dir())
         self.cmd_opts.add_option(cmdoptions.progress_bar())
 
         self.cmd_opts.add_option(
-            '--no-verify',
-            dest='no_verify',
-            action='store_true',
+            "--no-verify",
+            dest="no_verify",
+            action="store_true",
             default=False,
             help="Don't verify if built wheel is valid.",
         )
 
         self.cmd_opts.add_option(cmdoptions.build_options())
         self.cmd_opts.add_option(cmdoptions.global_options())
 
         self.cmd_opts.add_option(
-            '--pre',
-            action='store_true',
+            "--pre",
+            action="store_true",
             default=False,
-            help=("Include pre-release and development versions. By default, "
-                  "pip only finds stable versions."),
+            help=(
+                "Include pre-release and development versions. By default, "
+                "pip only finds stable versions."
+            ),
         )
 
         self.cmd_opts.add_option(cmdoptions.require_hashes())
 
         index_opts = cmdoptions.make_option_group(
             cmdoptions.index_group,
             self.parser,
@@ -133,17 +137,15 @@
             wheel_cache=wheel_cache,
             ignore_requires_python=options.ignore_requires_python,
             use_pep517=options.use_pep517,
         )
 
         self.trace_basic_info(finder)
 
-        requirement_set = resolver.resolve(
-            reqs, check_supported_wheels=True
-        )
+        requirement_set = resolver.resolve(reqs, check_supported_wheels=True)
 
         reqs_to_build: List[InstallRequirement] = []
         for req in requirement_set.requirements.values():
             if req.is_wheel:
                 preparer.save_linked_requirement(req)
             elif should_build_for_wheel_command(req):
                 reqs_to_build.append(req)
@@ -161,16 +163,15 @@
             assert req.local_file_path
             # copy from cache to target directory
             try:
                 shutil.copy(req.local_file_path, options.wheel_dir)
             except OSError as e:
                 logger.warning(
                     "Building wheel for %s failed: %s",
-                    req.name, e,
+                    req.name,
+                    e,
                 )
                 build_failures.append(req)
         if len(build_failures) != 0:
-            raise CommandError(
-                "Failed to build one or more wheels"
-            )
+            raise CommandError("Failed to build one or more wheels")
 
         return SUCCESS
```

#### pip/_internal/distributions/base.py

```diff
@@ -1,13 +1,11 @@
 import abc
-from typing import Optional
-
-from pip._vendor.pkg_resources import Distribution
 
 from pip._internal.index.package_finder import PackageFinder
+from pip._internal.metadata.base import BaseDistribution
 from pip._internal.req import InstallRequirement
 
 
 class AbstractDistribution(metaclass=abc.ABCMeta):
     """A base class for handling installable artifacts.
 
     The requirements for anything installable are as follows:
@@ -24,15 +22,15 @@
     """
 
     def __init__(self, req: InstallRequirement) -> None:
         super().__init__()
         self.req = req
 
     @abc.abstractmethod
-    def get_pkg_resources_distribution(self) -> Optional[Distribution]:
+    def get_metadata_distribution(self) -> BaseDistribution:
         raise NotImplementedError()
 
     @abc.abstractmethod
     def prepare_distribution_metadata(
         self, finder: PackageFinder, build_isolation: bool
     ) -> None:
         raise NotImplementedError()
```

#### pip/_internal/distributions/installed.py

```diff
@@ -1,22 +1,22 @@
-from typing import Optional
-
-from pip._vendor.pkg_resources import Distribution
-
 from pip._internal.distributions.base import AbstractDistribution
 from pip._internal.index.package_finder import PackageFinder
+from pip._internal.metadata import BaseDistribution
 
 
 class InstalledDistribution(AbstractDistribution):
     """Represents an installed package.
 
     This does not need any preparation as the required information has already
     been computed.
     """
 
-    def get_pkg_resources_distribution(self) -> Optional[Distribution]:
-        return self.req.satisfied_by
+    def get_metadata_distribution(self) -> BaseDistribution:
+        from pip._internal.metadata.pkg_resources import Distribution as _Dist
+
+        assert self.req.satisfied_by is not None, "not actually installed"
+        return _Dist(self.req.satisfied_by)
 
     def prepare_distribution_metadata(
         self, finder: PackageFinder, build_isolation: bool
     ) -> None:
         pass
```

#### pip/_internal/distributions/sdist.py

```diff
@@ -1,95 +1,129 @@
 import logging
-from typing import Set, Tuple
-
-from pip._vendor.pkg_resources import Distribution
+from typing import Iterable, Set, Tuple
 
 from pip._internal.build_env import BuildEnvironment
 from pip._internal.distributions.base import AbstractDistribution
 from pip._internal.exceptions import InstallationError
 from pip._internal.index.package_finder import PackageFinder
+from pip._internal.metadata import BaseDistribution
 from pip._internal.utils.subprocess import runner_with_spinner_message
 
 logger = logging.getLogger(__name__)
 
 
 class SourceDistribution(AbstractDistribution):
     """Represents a source distribution.
 
     The preparation step for these needs metadata for the packages to be
     generated, either using PEP 517 or using the legacy `setup.py egg_info`.
     """
 
-    def get_pkg_resources_distribution(self) -> Distribution:
-        return self.req.get_dist()
+    def get_metadata_distribution(self) -> BaseDistribution:
+        from pip._internal.metadata.pkg_resources import Distribution as _Dist
+
+        return _Dist(self.req.get_dist())
 
     def prepare_distribution_metadata(
         self, finder: PackageFinder, build_isolation: bool
     ) -> None:
         # Load pyproject.toml, to determine whether PEP 517 is to be used
         self.req.load_pyproject_toml()
 
         # Set up the build isolation, if this requirement should be isolated
         should_isolate = self.req.use_pep517 and build_isolation
         if should_isolate:
-            self._setup_isolation(finder)
+            # Setup an isolated environment and install the build backend static
+            # requirements in it.
+            self._prepare_build_backend(finder)
+            # Check that if the requirement is editable, it either supports PEP 660 or
+            # has a setup.py or a setup.cfg. This cannot be done earlier because we need
+            # to setup the build backend to verify it supports build_editable, nor can
+            # it be done later, because we want to avoid installing build requirements
+            # needlessly. Doing it here also works around setuptools generating
+            # UNKNOWN.egg-info when running get_requires_for_build_wheel on a directory
+            # without setup.py nor setup.cfg.
+            self.req.isolated_editable_sanity_check()
+            # Install the dynamic build requirements.
+            self._install_build_reqs(finder)
 
         self.req.prepare_metadata()
 
-    def _setup_isolation(self, finder: PackageFinder) -> None:
-        def _raise_conflicts(
-            conflicting_with: str, conflicting_reqs: Set[Tuple[str, str]]
-        ) -> None:
-            format_string = (
-                "Some build dependencies for {requirement} "
-                "conflict with {conflicting_with}: {description}."
-            )
-            error_message = format_string.format(
-                requirement=self.req,
-                conflicting_with=conflicting_with,
-                description=", ".join(
-                    f"{installed} is incompatible with {wanted}"
-                    for installed, wanted in sorted(conflicting)
-                ),
-            )
-            raise InstallationError(error_message)
-
+    def _prepare_build_backend(self, finder: PackageFinder) -> None:
         # Isolate in a BuildEnvironment and install the build-time
         # requirements.
         pyproject_requires = self.req.pyproject_requires
         assert pyproject_requires is not None
 
         self.req.build_env = BuildEnvironment()
         self.req.build_env.install_requirements(
             finder, pyproject_requires, "overlay", "Installing build dependencies"
         )
         conflicting, missing = self.req.build_env.check_requirements(
             self.req.requirements_to_check
         )
         if conflicting:
-            _raise_conflicts("PEP 517/518 supported requirements", conflicting)
+            self._raise_conflicts("PEP 517/518 supported requirements", conflicting)
         if missing:
             logger.warning(
                 "Missing build requirements in pyproject.toml for %s.",
                 self.req,
             )
             logger.warning(
                 "The project does not specify a build backend, and "
                 "pip cannot fall back to setuptools without %s.",
                 " and ".join(map(repr, sorted(missing))),
             )
-        # Install any extra build dependencies that the backend requests.
-        # This must be done in a second pass, as the pyproject.toml
-        # dependencies must be installed before we can call the backend.
+
+    def _get_build_requires_wheel(self) -> Iterable[str]:
         with self.req.build_env:
             runner = runner_with_spinner_message("Getting requirements to build wheel")
             backend = self.req.pep517_backend
             assert backend is not None
             with backend.subprocess_runner(runner):
-                reqs = backend.get_requires_for_build_wheel()
+                return backend.get_requires_for_build_wheel()
+
+    def _get_build_requires_editable(self) -> Iterable[str]:
+        with self.req.build_env:
+            runner = runner_with_spinner_message(
+                "Getting requirements to build editable"
+            )
+            backend = self.req.pep517_backend
+            assert backend is not None
+            with backend.subprocess_runner(runner):
+                return backend.get_requires_for_build_editable()
 
-        conflicting, missing = self.req.build_env.check_requirements(reqs)
+    def _install_build_reqs(self, finder: PackageFinder) -> None:
+        # Install any extra build dependencies that the backend requests.
+        # This must be done in a second pass, as the pyproject.toml
+        # dependencies must be installed before we can call the backend.
+        if (
+            self.req.editable
+            and self.req.permit_editable_wheels
+            and self.req.supports_pyproject_editable()
+        ):
+            build_reqs = self._get_build_requires_editable()
+        else:
+            build_reqs = self._get_build_requires_wheel()
+        conflicting, missing = self.req.build_env.check_requirements(build_reqs)
         if conflicting:
-            _raise_conflicts("the backend dependencies", conflicting)
+            self._raise_conflicts("the backend dependencies", conflicting)
         self.req.build_env.install_requirements(
             finder, missing, "normal", "Installing backend dependencies"
         )
+
+    def _raise_conflicts(
+        self, conflicting_with: str, conflicting_reqs: Set[Tuple[str, str]]
+    ) -> None:
+        format_string = (
+            "Some build dependencies for {requirement} "
+            "conflict with {conflicting_with}: {description}."
+        )
+        error_message = format_string.format(
+            requirement=self.req,
+            conflicting_with=conflicting_with,
+            description=", ".join(
+                f"{installed} is incompatible with {wanted}"
+                for installed, wanted in sorted(conflicting_reqs)
+            ),
+        )
+        raise InstallationError(error_message)
```

#### pip/_internal/distributions/wheel.py

```diff
@@ -1,34 +1,31 @@
-from zipfile import ZipFile
-
-from pip._vendor.pkg_resources import Distribution
+from pip._vendor.packaging.utils import canonicalize_name
 
 from pip._internal.distributions.base import AbstractDistribution
 from pip._internal.index.package_finder import PackageFinder
-from pip._internal.utils.wheel import pkg_resources_distribution_for_wheel
+from pip._internal.metadata import (
+    BaseDistribution,
+    FilesystemWheel,
+    get_wheel_distribution,
+)
 
 
 class WheelDistribution(AbstractDistribution):
     """Represents a wheel distribution.
 
     This does not need any preparation as wheels can be directly unpacked.
     """
 
-    def get_pkg_resources_distribution(self) -> Distribution:
+    def get_metadata_distribution(self) -> BaseDistribution:
         """Loads the metadata from the wheel file into memory and returns a
         Distribution that uses it, not relying on the wheel file or
         requirement.
         """
-        # Set as part of preparation during download.
-        assert self.req.local_file_path
-        # Wheels are never unnamed.
-        assert self.req.name
-
-        with ZipFile(self.req.local_file_path, allowZip64=True) as z:
-            return pkg_resources_distribution_for_wheel(
-                z, self.req.name, self.req.local_file_path
-            )
+        assert self.req.local_file_path, "Set as part of preparation during download"
+        assert self.req.name, "Wheels are never unnamed"
+        wheel = FilesystemWheel(self.req.local_file_path)
+        return get_wheel_distribution(wheel, canonicalize_name(self.req.name))
 
     def prepare_distribution_metadata(
         self, finder: PackageFinder, build_isolation: bool
     ) -> None:
         pass
```

#### pip/_internal/index/collector.py

```diff
@@ -1,15 +1,14 @@
 """
 The main purpose of this module is to expose LinkCollector.collect_sources().
 """
 
 import cgi
 import collections
 import functools
-import html
 import itertools
 import logging
 import os
 import re
 import urllib.parse
 import urllib.request
 import xml.etree.ElementTree
@@ -48,15 +47,15 @@
 
 def _match_vcs_scheme(url: str) -> Optional[str]:
     """Look for VCS schemes in the URL.
 
     Returns the matched VCS scheme, or None if there's no match.
     """
     for scheme in vcs.schemes:
-        if url.lower().startswith(scheme) and url[len(scheme)] in '+:':
+        if url.lower().startswith(scheme) and url[len(scheme)] in "+:":
             return scheme
     return None
 
 
 class _NotHTML(Exception):
     def __init__(self, content_type: str, request_desc: str) -> None:
         super().__init__(content_type, request_desc)
@@ -81,15 +80,15 @@
 def _ensure_html_response(url: str, session: PipSession) -> None:
     """Send a HEAD request to the URL, and ensure the response contains HTML.
 
     Raises `_NotHTTP` if the URL is not available for a HEAD request, or
     `_NotHTML` if the content type is not text/html.
     """
     scheme, netloc, path, query, fragment = urllib.parse.urlsplit(url)
-    if scheme not in {'http', 'https'}:
+    if scheme not in {"http", "https"}:
         raise _NotHTTP()
 
     resp = session.head(url, allow_redirects=True)
     raise_for_status(resp)
 
     _ensure_html_header(resp)
 
@@ -106,15 +105,15 @@
     2. Actually perform the request. Raise HTTP exceptions on network failures.
     3. Check the Content-Type header to make sure we got HTML, and raise
        `_NotHTML` otherwise.
     """
     if is_archive_file(Link(url).filename):
         _ensure_html_response(url, session=session)
 
-    logger.debug('Getting page %s', redact_auth_from_url(url))
+    logger.debug("Getting page %s", redact_auth_from_url(url))
 
     resp = session.get(
         url,
         headers={
             "Accept": "text/html",
             # We don't want to blindly returned cached data for
             # /simple/, because authors generally expecting that
@@ -141,20 +140,19 @@
     # or not. However we can check after we've downloaded it.
     _ensure_html_header(resp)
 
     return resp
 
 
 def _get_encoding_from_headers(headers: ResponseHeaders) -> Optional[str]:
-    """Determine if we have any encoding information in our headers.
-    """
+    """Determine if we have any encoding information in our headers."""
     if headers and "Content-Type" in headers:
         content_type, params = cgi.parse_header(headers["Content-Type"])
         if "charset" in params:
-            return params['charset']
+            return params["charset"]
     return None
 
 
 def _determine_base_url(document: HTMLElement, page_url: str) -> str:
     """Determine the HTML document's base URL.
 
     This looks for a ``<base>`` tag in the HTML document. If present, its href
@@ -191,15 +189,15 @@
     # should not be quoted. On Linux where drive letters do not
     # exist, the colon should be quoted. We rely on urllib.request
     # to do the right thing here.
     return urllib.request.pathname2url(urllib.request.url2pathname(part))
 
 
 # percent-encoded:                   /
-_reserved_chars_re = re.compile('(@|%2F)', re.IGNORECASE)
+_reserved_chars_re = re.compile("(@|%2F)", re.IGNORECASE)
 
 
 def _clean_url_path(path: str, is_local_path: bool) -> str:
     """
     Clean the path portion of a URL.
     """
     if is_local_path:
@@ -208,20 +206,20 @@
         clean_func = _clean_url_path_part
 
     # Split on the reserved characters prior to cleaning so that
     # revision strings in VCS URLs are properly preserved.
     parts = _reserved_chars_re.split(path)
 
     cleaned_parts = []
-    for to_clean, reserved in pairwise(itertools.chain(parts, [''])):
+    for to_clean, reserved in pairwise(itertools.chain(parts, [""])):
         cleaned_parts.append(clean_func(to_clean))
         # Normalize %xx escapes (e.g. %2f -> %2F)
         cleaned_parts.append(reserved.upper())
 
-    return ''.join(cleaned_parts)
+    return "".join(cleaned_parts)
 
 
 def _clean_link(url: str) -> str:
     """
     Make sure a link is fully quoted.
     For example, if ' ' occurs in the URL, it will be replaced with "%20",
     and without double-quoting other characters.
@@ -244,20 +242,16 @@
     Convert an anchor element in a simple repository page to a Link.
     """
     href = anchor.get("href")
     if not href:
         return None
 
     url = _clean_link(urllib.parse.urljoin(base_url, href))
-    pyrequire = anchor.get('data-requires-python')
-    pyrequire = html.unescape(pyrequire) if pyrequire else None
-
-    yanked_reason = anchor.get('data-yanked')
-    if yanked_reason:
-        yanked_reason = html.unescape(yanked_reason)
+    pyrequire = anchor.get("data-requires-python")
+    yanked_reason = anchor.get("data-yanked")
 
     link = Link(
         url,
         comes_from=page_url,
         requires_python=pyrequire,
         yanked_reason=yanked_reason,
     )
@@ -267,16 +261,15 @@
 
 class CacheablePageContent:
     def __init__(self, page: "HTMLPage") -> None:
         assert page.cache_link_parsing
         self.page = page
 
     def __eq__(self, other: object) -> bool:
-        return (isinstance(other, type(self)) and
-                self.page.url == other.page.url)
+        return isinstance(other, type(self)) and self.page.url == other.page.url
 
     def __hash__(self) -> int:
         return hash(self.page.url)
 
 
 def with_cached_html_pages(
     fn: Callable[["HTMLPage"], Iterable[Link]],
@@ -349,85 +342,91 @@
     def __str__(self) -> str:
         return redact_auth_from_url(self.url)
 
 
 def _handle_get_page_fail(
     link: Link,
     reason: Union[str, Exception],
-    meth: Optional[Callable[..., None]] = None
+    meth: Optional[Callable[..., None]] = None,
 ) -> None:
     if meth is None:
         meth = logger.debug
     meth("Could not fetch URL %s: %s - skipping", link, reason)
 
 
 def _make_html_page(response: Response, cache_link_parsing: bool = True) -> HTMLPage:
     encoding = _get_encoding_from_headers(response.headers)
     return HTMLPage(
         response.content,
         encoding=encoding,
         url=response.url,
-        cache_link_parsing=cache_link_parsing)
+        cache_link_parsing=cache_link_parsing,
+    )
 
 
 def _get_html_page(
     link: Link, session: Optional[PipSession] = None
 ) -> Optional["HTMLPage"]:
     if session is None:
         raise TypeError(
             "_get_html_page() missing 1 required keyword argument: 'session'"
         )
 
-    url = link.url.split('#', 1)[0]
+    url = link.url.split("#", 1)[0]
 
     # Check for VCS schemes that do not support lookup as web pages.
     vcs_scheme = _match_vcs_scheme(url)
     if vcs_scheme:
-        logger.warning('Cannot look at %s URL %s because it does not support '
-                       'lookup as web pages.', vcs_scheme, link)
+        logger.warning(
+            "Cannot look at %s URL %s because it does not support lookup as web pages.",
+            vcs_scheme,
+            link,
+        )
         return None
 
     # Tack index.html onto file:// URLs that point to directories
     scheme, _, path, _, _, _ = urllib.parse.urlparse(url)
-    if (scheme == 'file' and os.path.isdir(urllib.request.url2pathname(path))):
+    if scheme == "file" and os.path.isdir(urllib.request.url2pathname(path)):
         # add trailing slash if not present so urljoin doesn't trim
         # final segment
-        if not url.endswith('/'):
-            url += '/'
-        url = urllib.parse.urljoin(url, 'index.html')
-        logger.debug(' file: URL is directory, getting %s', url)
+        if not url.endswith("/"):
+            url += "/"
+        url = urllib.parse.urljoin(url, "index.html")
+        logger.debug(" file: URL is directory, getting %s", url)
 
     try:
         resp = _get_html_response(url, session=session)
     except _NotHTTP:
         logger.warning(
-            'Skipping page %s because it looks like an archive, and cannot '
-            'be checked by a HTTP HEAD request.', link,
+            "Skipping page %s because it looks like an archive, and cannot "
+            "be checked by a HTTP HEAD request.",
+            link,
         )
     except _NotHTML as exc:
         logger.warning(
-            'Skipping page %s because the %s request got Content-Type: %s.'
-            'The only supported Content-Type is text/html',
-            link, exc.request_desc, exc.content_type,
+            "Skipping page %s because the %s request got Content-Type: %s."
+            "The only supported Content-Type is text/html",
+            link,
+            exc.request_desc,
+            exc.content_type,
         )
     except NetworkConnectionError as exc:
         _handle_get_page_fail(link, exc)
     except RetryError as exc:
         _handle_get_page_fail(link, exc)
     except SSLError as exc:
         reason = "There was a problem confirming the ssl certificate: "
         reason += str(exc)
         _handle_get_page_fail(link, reason, meth=logger.info)
     except requests.ConnectionError as exc:
         _handle_get_page_fail(link, f"connection error: {exc}")
     except requests.Timeout:
         _handle_get_page_fail(link, "timed out")
     else:
-        return _make_html_page(resp,
-                               cache_link_parsing=link.cache_link_parsing)
+        return _make_html_page(resp, cache_link_parsing=link.cache_link_parsing)
     return None
 
 
 class CollectedSources(NamedTuple):
     find_links: Sequence[Optional[LinkSource]]
     index_urls: Sequence[Optional[LinkSource]]
 
@@ -447,39 +446,42 @@
         search_scope: SearchScope,
     ) -> None:
         self.search_scope = search_scope
         self.session = session
 
     @classmethod
     def create(
-        cls, session: PipSession,
+        cls,
+        session: PipSession,
         options: Values,
-        suppress_no_index: bool = False
+        suppress_no_index: bool = False,
     ) -> "LinkCollector":
         """
         :param session: The Session to use to make requests.
         :param suppress_no_index: Whether to ignore the --no-index option
             when constructing the SearchScope object.
         """
         index_urls = [options.index_url] + options.extra_index_urls
         if options.no_index and not suppress_no_index:
             logger.debug(
-                'Ignoring indexes: %s',
-                ','.join(redact_auth_from_url(url) for url in index_urls),
+                "Ignoring indexes: %s",
+                ",".join(redact_auth_from_url(url) for url in index_urls),
             )
             index_urls = []
 
         # Make sure find_links is a list before passing to create().
         find_links = options.find_links or []
 
         search_scope = SearchScope.create(
-            find_links=find_links, index_urls=index_urls,
+            find_links=find_links,
+            index_urls=index_urls,
         )
         link_collector = LinkCollector(
-            session=session, search_scope=search_scope,
+            session=session,
+            search_scope=search_scope,
         )
         return link_collector
 
     @property
     def find_links(self) -> List[str]:
         return self.search_scope.find_links
```

#### pip/_internal/index/package_finder.py

```diff
@@ -35,23 +35,21 @@
 from pip._internal.utils.hashes import Hashes
 from pip._internal.utils.logging import indent_log
 from pip._internal.utils.misc import build_netloc
 from pip._internal.utils.packaging import check_requires_python
 from pip._internal.utils.unpacking import SUPPORTED_EXTENSIONS
 from pip._internal.utils.urls import url_to_path
 
-__all__ = ['FormatControl', 'BestCandidateResult', 'PackageFinder']
+__all__ = ["FormatControl", "BestCandidateResult", "PackageFinder"]
 
 
 logger = getLogger(__name__)
 
 BuildTag = Union[Tuple[()], Tuple[int, str]]
-CandidateSortingKey = (
-    Tuple[int, int, int, _BaseVersion, Optional[int], BuildTag]
-)
+CandidateSortingKey = Tuple[int, int, int, _BaseVersion, Optional[int], BuildTag]
 
 
 def _check_link_requires_python(
     link: Link,
     version_info: Tuple[int, int, int],
     ignore_requires_python: bool = False,
 ) -> bool:
@@ -62,47 +60,52 @@
     :param version_info: A 3-tuple of ints representing the Python
         major-minor-micro version to check.
     :param ignore_requires_python: Whether to ignore the "Requires-Python"
         value if the given Python version isn't compatible.
     """
     try:
         is_compatible = check_requires_python(
-            link.requires_python, version_info=version_info,
+            link.requires_python,
+            version_info=version_info,
         )
     except specifiers.InvalidSpecifier:
         logger.debug(
             "Ignoring invalid Requires-Python (%r) for link: %s",
-            link.requires_python, link,
+            link.requires_python,
+            link,
         )
     else:
         if not is_compatible:
-            version = '.'.join(map(str, version_info))
+            version = ".".join(map(str, version_info))
             if not ignore_requires_python:
                 logger.verbose(
-                    'Link requires a different Python (%s not in: %r): %s',
-                    version, link.requires_python, link,
+                    "Link requires a different Python (%s not in: %r): %s",
+                    version,
+                    link.requires_python,
+                    link,
                 )
                 return False
 
             logger.debug(
-                'Ignoring failed Requires-Python check (%s not in: %r) '
-                'for link: %s',
-                version, link.requires_python, link,
+                "Ignoring failed Requires-Python check (%s not in: %r) for link: %s",
+                version,
+                link.requires_python,
+                link,
             )
 
     return True
 
 
 class LinkEvaluator:
 
     """
     Responsible for evaluating links for a particular project.
     """
 
-    _py_version_re = re.compile(r'-py([123]\.?[0-9]?)$')
+    _py_version_re = re.compile(r"-py([123]\.?[0-9]?)$")
 
     # Don't include an allow_yanked default value to make sure each call
     # site considers whether yanked releases are allowed. This also causes
     # that decision to be made explicit in the calling code, which helps
     # people when reading the code.
     def __init__(
         self,
@@ -148,87 +151,87 @@
         :return: A tuple (is_candidate, result), where `result` is (1) a
             version string if `is_candidate` is True, and (2) if
             `is_candidate` is False, an optional string to log the reason
             the link fails to qualify.
         """
         version = None
         if link.is_yanked and not self._allow_yanked:
-            reason = link.yanked_reason or '<none given>'
-            return (False, f'yanked for reason: {reason}')
+            reason = link.yanked_reason or "<none given>"
+            return (False, f"yanked for reason: {reason}")
 
         if link.egg_fragment:
             egg_info = link.egg_fragment
             ext = link.ext
         else:
             egg_info, ext = link.splitext()
             if not ext:
-                return (False, 'not a file')
+                return (False, "not a file")
             if ext not in SUPPORTED_EXTENSIONS:
-                return (False, f'unsupported archive format: {ext}')
+                return (False, f"unsupported archive format: {ext}")
             if "binary" not in self._formats and ext == WHEEL_EXTENSION:
-                reason = 'No binaries permitted for {}'.format(
-                    self.project_name)
+                reason = "No binaries permitted for {}".format(self.project_name)
                 return (False, reason)
-            if "macosx10" in link.path and ext == '.zip':
-                return (False, 'macosx10 one')
+            if "macosx10" in link.path and ext == ".zip":
+                return (False, "macosx10 one")
             if ext == WHEEL_EXTENSION:
                 try:
                     wheel = Wheel(link.filename)
                 except InvalidWheelFilename:
-                    return (False, 'invalid wheel filename')
+                    return (False, "invalid wheel filename")
                 if canonicalize_name(wheel.name) != self._canonical_name:
-                    reason = 'wrong project name (not {})'.format(
-                        self.project_name)
+                    reason = "wrong project name (not {})".format(self.project_name)
                     return (False, reason)
 
                 supported_tags = self._target_python.get_tags()
                 if not wheel.supported(supported_tags):
                     # Include the wheel's tags in the reason string to
                     # simplify troubleshooting compatibility issues.
                     file_tags = wheel.get_formatted_file_tags()
                     reason = (
                         "none of the wheel's tags ({}) are compatible "
                         "(run pip debug --verbose to show compatible tags)".format(
-                            ', '.join(file_tags)
+                            ", ".join(file_tags)
                         )
                     )
                     return (False, reason)
 
                 version = wheel.version
 
         # This should be up by the self.ok_binary check, but see issue 2700.
         if "source" not in self._formats and ext != WHEEL_EXTENSION:
-            reason = f'No sources permitted for {self.project_name}'
+            reason = f"No sources permitted for {self.project_name}"
             return (False, reason)
 
         if not version:
             version = _extract_version_from_fragment(
-                egg_info, self._canonical_name,
+                egg_info,
+                self._canonical_name,
             )
         if not version:
-            reason = f'Missing project version for {self.project_name}'
+            reason = f"Missing project version for {self.project_name}"
             return (False, reason)
 
         match = self._py_version_re.search(version)
         if match:
-            version = version[:match.start()]
+            version = version[: match.start()]
             py_version = match.group(1)
             if py_version != self._target_python.py_version:
-                return (False, 'Python version is incorrect')
+                return (False, "Python version is incorrect")
 
         supports_python = _check_link_requires_python(
-            link, version_info=self._target_python.py_version_info,
+            link,
+            version_info=self._target_python.py_version_info,
             ignore_requires_python=self._ignore_requires_python,
         )
         if not supports_python:
             # Return None for the reason text to suppress calling
             # _log_skipped_link().
             return (False, None)
 
-        logger.debug('Found link %s, version: %s', link, version)
+        logger.debug("Found link %s, version: %s", link, version)
 
         return (True, version)
 
 
 def filter_unallowed_hashes(
     candidates: List[InstallationCandidate],
     hashes: Hashes,
@@ -247,16 +250,16 @@
     with no hash specified.  Returning all candidates in the case of no
     matches lets pip report the hash of the candidate that would otherwise
     have been installed (e.g. permitting the user to more easily update
     their requirements file with the desired hash).
     """
     if not hashes:
         logger.debug(
-            'Given no hashes to check %s links for project %r: '
-            'discarding no candidates',
+            "Given no hashes to check %s links for project %r: "
+            "discarding no candidates",
             len(candidates),
             project_name,
         )
         # Make sure we're not returning back the given value.
         return list(candidates)
 
     matches_or_no_digest = []
@@ -278,30 +281,30 @@
     if match_count:
         filtered = matches_or_no_digest
     else:
         # Make sure we're not returning back the given value.
         filtered = list(candidates)
 
     if len(filtered) == len(candidates):
-        discard_message = 'discarding no candidates'
+        discard_message = "discarding no candidates"
     else:
-        discard_message = 'discarding {} non-matches:\n  {}'.format(
+        discard_message = "discarding {} non-matches:\n  {}".format(
             len(non_matches),
-            '\n  '.join(str(candidate.link) for candidate in non_matches)
+            "\n  ".join(str(candidate.link) for candidate in non_matches),
         )
 
     logger.debug(
-        'Checked %s links for project %r against %s hashes '
-        '(%s matches, %s no digest): %s',
+        "Checked %s links for project %r against %s hashes "
+        "(%s matches, %s no digest): %s",
         len(candidates),
         project_name,
         hashes.digest_count,
         match_count,
         len(matches_or_no_digest) - match_count,
-        discard_message
+        discard_message,
     )
 
     return filtered
 
 
 class CandidatePreferences:
 
@@ -350,21 +353,19 @@
 
         self._applicable_candidates = applicable_candidates
         self._candidates = candidates
 
         self.best_candidate = best_candidate
 
     def iter_all(self) -> Iterable[InstallationCandidate]:
-        """Iterate through all candidates.
-        """
+        """Iterate through all candidates."""
         return iter(self._candidates)
 
     def iter_applicable(self) -> Iterable[InstallationCandidate]:
-        """Iterate through the applicable candidates.
-        """
+        """Iterate through the applicable candidates."""
         return iter(self._applicable_candidates)
 
 
 class CandidateEvaluator:
 
     """
     Responsible for filtering and sorting candidates for installation based
@@ -440,31 +441,30 @@
         """
         Return the applicable candidates from a list of candidates.
         """
         # Using None infers from the specifier instead.
         allow_prereleases = self._allow_all_prereleases or None
         specifier = self._specifier
         versions = {
-            str(v) for v in specifier.filter(
+            str(v)
+            for v in specifier.filter(
                 # We turn the version object into a str here because otherwise
                 # when we're debundled but setuptools isn't, Python will see
                 # packaging.version.Version and
                 # pkg_resources._vendor.packaging.version.Version as different
                 # types. This way we'll use a str as a common data interchange
                 # format. If we stop using the pkg_resources provided specifier
                 # and start using our own, we can drop the cast to str().
                 (str(c.version) for c in candidates),
                 prereleases=allow_prereleases,
             )
         }
 
         # Again, converting version to str to deal with debundling.
-        applicable_candidates = [
-            c for c in candidates if str(c.version) in versions
-        ]
+        applicable_candidates = [c for c in candidates if str(c.version) in versions]
 
         filtered_applicable_candidates = filter_unallowed_hashes(
             candidates=applicable_candidates,
             hashes=self._hashes,
             project_name=self._project_name,
         )
 
@@ -505,35 +505,41 @@
         build_tag: BuildTag = ()
         binary_preference = 0
         link = candidate.link
         if link.is_wheel:
             # can raise InvalidWheelFilename
             wheel = Wheel(link.filename)
             try:
-                pri = -(wheel.find_most_preferred_tag(
-                    valid_tags, self._wheel_tag_preferences
-                ))
+                pri = -(
+                    wheel.find_most_preferred_tag(
+                        valid_tags, self._wheel_tag_preferences
+                    )
+                )
             except ValueError:
                 raise UnsupportedWheel(
                     "{} is not a supported wheel for this platform. It "
                     "can't be sorted.".format(wheel.filename)
                 )
             if self._prefer_binary:
                 binary_preference = 1
             if wheel.build_tag is not None:
-                match = re.match(r'^(\d+)(.*)$', wheel.build_tag)
+                match = re.match(r"^(\d+)(.*)$", wheel.build_tag)
                 build_tag_groups = match.groups()
                 build_tag = (int(build_tag_groups[0]), build_tag_groups[1])
         else:  # sdist
             pri = -(support_num)
         has_allowed_hash = int(link.is_hash_allowed(self._hashes))
         yank_value = -1 * int(link.is_yanked)  # -1 for yanked.
         return (
-            has_allowed_hash, yank_value, binary_preference, candidate.version,
-            pri, build_tag,
+            has_allowed_hash,
+            yank_value,
+            binary_preference,
+            candidate.version,
+            pri,
+            build_tag,
         )
 
     def sort_best_candidate(
         self,
         candidates: List[InstallationCandidate],
     ) -> Optional[InstallationCandidate]:
         """
@@ -709,15 +715,15 @@
                     no_eggs.append(link)
         return no_eggs + eggs
 
     def _log_skipped_link(self, link: Link, reason: str) -> None:
         if link not in self._logged_links:
             # Put the link at the end so the reason is more visible and because
             # the link string is usually very long.
-            logger.debug('Skipping link: %s: %s', reason, link)
+            logger.debug("Skipping link: %s: %s", reason, link)
             self._logged_links.add(link)
 
     def get_install_candidate(
         self, link_evaluator: LinkEvaluator, link: Link
     ) -> Optional[InstallationCandidate]:
         """
         If the link is a candidate for install, convert it to an
@@ -749,15 +755,16 @@
 
         return candidates
 
     def process_project_url(
         self, project_url: Link, link_evaluator: LinkEvaluator
     ) -> List[InstallationCandidate]:
         logger.debug(
-            'Fetching project page and analyzing links: %s', project_url,
+            "Fetching project page and analyzing links: %s",
+            project_url,
         )
         html_page = self._link_collector.fetch_page(project_url)
         if html_page is None:
             return []
 
         page_links = list(parse_links(html_page))
 
@@ -817,16 +824,15 @@
 
     def make_candidate_evaluator(
         self,
         project_name: str,
         specifier: Optional[specifiers.BaseSpecifier] = None,
         hashes: Optional[Hashes] = None,
     ) -> CandidateEvaluator:
-        """Create a CandidateEvaluator object to use.
-        """
+        """Create a CandidateEvaluator object to use."""
         candidate_prefs = self._candidate_prefs
         return CandidateEvaluator.create(
             project_name=project_name,
             target_python=self._target_python,
             prefer_binary=candidate_prefs.prefer_binary,
             allow_all_prereleases=candidate_prefs.allow_all_prereleases,
             specifier=specifier,
@@ -863,79 +869,84 @@
 
         Expects req, an InstallRequirement and upgrade, a boolean
         Returns a InstallationCandidate if found,
         Raises DistributionNotFound or BestVersionAlreadyInstalled otherwise
         """
         hashes = req.hashes(trust_internet=False)
         best_candidate_result = self.find_best_candidate(
-            req.name, specifier=req.specifier, hashes=hashes,
+            req.name,
+            specifier=req.specifier,
+            hashes=hashes,
         )
         best_candidate = best_candidate_result.best_candidate
 
         installed_version: Optional[_BaseVersion] = None
         if req.satisfied_by is not None:
             installed_version = parse_version(req.satisfied_by.version)
 
         def _format_versions(cand_iter: Iterable[InstallationCandidate]) -> str:
             # This repeated parse_version and str() conversion is needed to
             # handle different vendoring sources from pip and pkg_resources.
             # If we stop using the pkg_resources provided specifier and start
             # using our own, we can drop the cast to str().
-            return ", ".join(sorted(
-                {str(c.version) for c in cand_iter},
-                key=parse_version,
-            )) or "none"
+            return (
+                ", ".join(
+                    sorted(
+                        {str(c.version) for c in cand_iter},
+                        key=parse_version,
+                    )
+                )
+                or "none"
+            )
 
         if installed_version is None and best_candidate is None:
             logger.critical(
-                'Could not find a version that satisfies the requirement %s '
-                '(from versions: %s)',
+                "Could not find a version that satisfies the requirement %s "
+                "(from versions: %s)",
                 req,
                 _format_versions(best_candidate_result.iter_all()),
             )
 
             raise DistributionNotFound(
-                'No matching distribution found for {}'.format(
-                    req)
+                "No matching distribution found for {}".format(req)
             )
 
         best_installed = False
         if installed_version and (
-                best_candidate is None or
-                best_candidate.version <= installed_version):
+            best_candidate is None or best_candidate.version <= installed_version
+        ):
             best_installed = True
 
         if not upgrade and installed_version is not None:
             if best_installed:
                 logger.debug(
-                    'Existing installed version (%s) is most up-to-date and '
-                    'satisfies requirement',
+                    "Existing installed version (%s) is most up-to-date and "
+                    "satisfies requirement",
                     installed_version,
                 )
             else:
                 logger.debug(
-                    'Existing installed version (%s) satisfies requirement '
-                    '(most up-to-date version is %s)',
+                    "Existing installed version (%s) satisfies requirement "
+                    "(most up-to-date version is %s)",
                     installed_version,
                     best_candidate.version,
                 )
             return None
 
         if best_installed:
             # We have an existing version, and its the best version
             logger.debug(
-                'Installed version (%s) is most up-to-date (past versions: '
-                '%s)',
+                "Installed version (%s) is most up-to-date (past versions: %s)",
                 installed_version,
                 _format_versions(best_candidate_result.iter_applicable()),
             )
             raise BestVersionAlreadyInstalled
 
         logger.debug(
-            'Using version %s (newest of versions: %s)',
+            "Using version %s (newest of versions: %s)",
             best_candidate.version,
             _format_versions(best_candidate_result.iter_applicable()),
         )
         return best_candidate
 
 
 def _find_name_version_sep(fragment: str, canonical_name: str) -> int:
```

#### pip/_internal/locations/__init__.py

```diff
@@ -41,14 +41,16 @@
 if os.environ.get("_PIP_LOCATIONS_NO_WARN_ON_MISMATCH"):
     _MISMATCH_LEVEL = logging.DEBUG
 else:
     _MISMATCH_LEVEL = logging.WARNING
 
 _PLATLIBDIR: str = getattr(sys, "platlibdir", "lib")
 
+_USE_SYSCONFIG = sys.version_info >= (3, 10)
+
 
 def _looks_like_bpo_44860() -> bool:
     """The resolution to bpo-44860 will change this incorrect platlib.
 
     See <https://bugs.python.org/issue44860>.
     """
     from distutils.command.install import INSTALL_SCHEMES  # type: ignore
@@ -58,14 +60,16 @@
     except KeyError:
         return False
     return unix_user_platlib == "$usersite"
 
 
 def _looks_like_red_hat_patched_platlib_purelib(scheme: Dict[str, str]) -> bool:
     platlib = scheme["platlib"]
+    if "/$platlibdir/" in platlib and hasattr(sys, "platlibdir"):
+        platlib = platlib.replace("/$platlibdir/", f"/{sys.platlibdir}/")
     if "/lib64/" not in platlib:
         return False
     unpatched = platlib.replace("/lib64/", "/lib/")
     return unpatched.replace("$platbase/", "$base/") == scheme["purelib"]
 
 
 @functools.lru_cache(maxsize=None)
@@ -186,23 +190,26 @@
     dist_name: str,
     user: bool = False,
     home: Optional[str] = None,
     root: Optional[str] = None,
     isolated: bool = False,
     prefix: Optional[str] = None,
 ) -> Scheme:
-    old = _distutils.get_scheme(
+    new = _sysconfig.get_scheme(
         dist_name,
         user=user,
         home=home,
         root=root,
         isolated=isolated,
         prefix=prefix,
     )
-    new = _sysconfig.get_scheme(
+    if _USE_SYSCONFIG:
+        return new
+
+    old = _distutils.get_scheme(
         dist_name,
         user=user,
         home=home,
         root=root,
         isolated=isolated,
         prefix=prefix,
     )
@@ -292,14 +299,26 @@
         # part of the path. This is incorrect and will be fixed in MSYS.
         skip_msys2_mingw_bug = (
             WINDOWS and k in ("platlib", "purelib") and _looks_like_msys2_mingw_scheme()
         )
         if skip_msys2_mingw_bug:
             continue
 
+        # CPython's POSIX install script invokes pip (via ensurepip) against the
+        # interpreter located in the source tree, not the install site. This
+        # triggers special logic in sysconfig that's not present in distutils.
+        # https://github.com/python/cpython/blob/8c21941ddaf/Lib/sysconfig.py#L178-L194
+        skip_cpython_build = (
+            sysconfig.is_python_build(check_home=True)
+            and not WINDOWS
+            and k in ("headers", "include", "platinclude")
+        )
+        if skip_cpython_build:
+            continue
+
         warning_contexts.append((old_v, new_v, f"scheme.{k}"))
 
     if not warning_contexts:
         return old
 
     # Check if this path mismatch is caused by distutils config files. Those
     # files will no longer work once we switch to sysconfig, so this raises a
@@ -311,34 +330,39 @@
         root,
         isolated,
         prefix,
         ignore_config_files=True,
     )
     if any(default_old[k] != getattr(old, k) for k in SCHEME_KEYS):
         deprecated(
-            "Configuring installation scheme with distutils config files "
-            "is deprecated and will no longer work in the near future. If you "
-            "are using a Homebrew or Linuxbrew Python, please see discussion "
-            "at https://github.com/Homebrew/homebrew-core/issues/76621",
+            reason=(
+                "Configuring installation scheme with distutils config files "
+                "is deprecated and will no longer work in the near future. If you "
+                "are using a Homebrew or Linuxbrew Python, please see discussion "
+                "at https://github.com/Homebrew/homebrew-core/issues/76621"
+            ),
             replacement=None,
             gone_in=None,
         )
         return old
 
     # Post warnings about this mismatch so user can report them back.
     for old_v, new_v, key in warning_contexts:
         _warn_mismatched(old_v, new_v, key=key)
     _log_context(user=user, home=home, root=root, prefix=prefix)
 
     return old
 
 
 def get_bin_prefix() -> str:
-    old = _distutils.get_bin_prefix()
     new = _sysconfig.get_bin_prefix()
+    if _USE_SYSCONFIG:
+        return new
+
+    old = _distutils.get_bin_prefix()
     if _warn_if_mismatch(pathlib.Path(old), pathlib.Path(new), key="bin_prefix"):
         _log_context()
     return old
 
 
 def get_bin_user() -> str:
     return _sysconfig.get_scheme("", user=True).scripts
@@ -359,38 +383,54 @@
     if value == "/usr/lib/python3/dist-packages":
         return True
     return False
 
 
 def get_purelib() -> str:
     """Return the default pure-Python lib location."""
-    old = _distutils.get_purelib()
     new = _sysconfig.get_purelib()
+    if _USE_SYSCONFIG:
+        return new
+
+    old = _distutils.get_purelib()
     if _looks_like_deb_system_dist_packages(old):
         return old
     if _warn_if_mismatch(pathlib.Path(old), pathlib.Path(new), key="purelib"):
         _log_context()
     return old
 
 
 def get_platlib() -> str:
     """Return the default platform-shared lib location."""
-    old = _distutils.get_platlib()
     new = _sysconfig.get_platlib()
+    if _USE_SYSCONFIG:
+        return new
+
+    old = _distutils.get_platlib()
     if _looks_like_deb_system_dist_packages(old):
         return old
     if _warn_if_mismatch(pathlib.Path(old), pathlib.Path(new), key="platlib"):
         _log_context()
     return old
 
 
+def _deduplicated(v1: str, v2: str) -> List[str]:
+    """Deduplicate values from a list."""
+    if v1 == v2:
+        return [v1]
+    return [v1, v2]
+
+
 def get_prefixed_libs(prefix: str) -> List[str]:
     """Return the lib locations under ``prefix``."""
-    old_pure, old_plat = _distutils.get_prefixed_libs(prefix)
     new_pure, new_plat = _sysconfig.get_prefixed_libs(prefix)
+    if _USE_SYSCONFIG:
+        return _deduplicated(new_pure, new_plat)
+
+    old_pure, old_plat = _distutils.get_prefixed_libs(prefix)
 
     warned = [
         _warn_if_mismatch(
             pathlib.Path(old_pure),
             pathlib.Path(new_pure),
             key="prefixed-purelib",
         ),
@@ -399,10 +439,8 @@
             pathlib.Path(new_plat),
             key="prefixed-platlib",
         ),
     ]
     if any(warned):
         _log_context(prefix=prefix)
 
-    if old_pure == old_plat:
-        return [old_pure]
-    return [old_pure, old_plat]
+    return _deduplicated(old_pure, old_plat)
```

#### pip/_internal/metadata/__init__.py

```diff
@@ -1,14 +1,17 @@
 from typing import List, Optional
 
-from .base import BaseDistribution, BaseEnvironment
+from .base import BaseDistribution, BaseEnvironment, FilesystemWheel, MemoryWheel, Wheel
 
 __all__ = [
     "BaseDistribution",
     "BaseEnvironment",
+    "FilesystemWheel",
+    "MemoryWheel",
+    "Wheel",
     "get_default_environment",
     "get_environment",
     "get_wheel_distribution",
 ]
 
 
 def get_default_environment() -> BaseEnvironment:
@@ -31,18 +34,18 @@
     the state of installed distributions when this function is called.
     """
     from .pkg_resources import Environment
 
     return Environment.from_paths(paths)
 
 
-def get_wheel_distribution(wheel_path: str, canonical_name: str) -> BaseDistribution:
+def get_wheel_distribution(wheel: Wheel, canonical_name: str) -> BaseDistribution:
     """Get the representation of the specified wheel's distribution metadata.
 
     This returns a Distribution instance from the chosen backend based on
     the given wheel's ``.dist-info`` directory.
 
     :param canonical_name: Normalized project name of the given wheel.
     """
     from .pkg_resources import Distribution
 
-    return Distribution.from_wheel(wheel_path, canonical_name)
+    return Distribution.from_wheel(wheel, canonical_name)
```

#### pip/_internal/metadata/base.py

```diff
@@ -1,36 +1,40 @@
 import email.message
 import json
 import logging
 import re
+import zipfile
 from typing import (
+    IO,
     TYPE_CHECKING,
     Collection,
     Container,
     Iterable,
     Iterator,
     List,
     Optional,
     Union,
 )
 
 from pip._vendor.packaging.requirements import Requirement
+from pip._vendor.packaging.specifiers import InvalidSpecifier, SpecifierSet
+from pip._vendor.packaging.utils import NormalizedName
 from pip._vendor.packaging.version import LegacyVersion, Version
 
 from pip._internal.models.direct_url import (
     DIRECT_URL_METADATA_NAME,
     DirectUrl,
     DirectUrlValidationError,
 )
-from pip._internal.utils.misc import stdlib_pkgs  # TODO: Move definition here.
+from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
+from pip._internal.utils.egg_link import egg_link_path_from_sys_path
+from pip._internal.utils.urls import url_to_path
 
 if TYPE_CHECKING:
     from typing import Protocol
-
-    from pip._vendor.packaging.utils import NormalizedName
 else:
     Protocol = object
 
 DistributionVersion = Union[LegacyVersion, Version]
 
 logger = logging.getLogger(__name__)
 
@@ -46,14 +50,20 @@
 
     @property
     def group(self) -> str:
         raise NotImplementedError()
 
 
 class BaseDistribution(Protocol):
+    def __repr__(self) -> str:
+        return f"{self.raw_name} {self.version} ({self.location})"
+
+    def __str__(self) -> str:
+        return f"{self.raw_name} {self.version}"
+
     @property
     def location(self) -> Optional[str]:
         """Where the distribution is loaded from.
 
         A string value is not necessarily a filesystem path, since distributions
         can be loaded from other sources, e.g. arbitrary zip archives. ``None``
         means the distribution is created in-memory.
@@ -61,14 +71,36 @@
         Do not canonicalize this value with e.g. ``pathlib.Path.resolve()``. If
         this is a symbolic link, we want to preserve the relative path between
         it and files in the distribution.
         """
         raise NotImplementedError()
 
     @property
+    def editable_project_location(self) -> Optional[str]:
+        """The project location for editable distributions.
+
+        This is the directory where pyproject.toml or setup.py is located.
+        None if the distribution is not installed in editable mode.
+        """
+        # TODO: this property is relatively costly to compute, memoize it ?
+        direct_url = self.direct_url
+        if direct_url:
+            if direct_url.is_local_editable():
+                return url_to_path(direct_url.url)
+        else:
+            # Search for an .egg-link file by walking sys.path, as it was
+            # done before by dist_is_editable().
+            egg_link_path = egg_link_path_from_sys_path(self.raw_name)
+            if egg_link_path:
+                # TODO: get project location from second line of egg_link file
+                #       (https://github.com/pypa/pip/issues/10243)
+                return self.location
+        return None
+
+    @property
     def info_directory(self) -> Optional[str]:
         """Location of the .[egg|dist]-info directory.
 
         Similarly to ``location``, a string value is not necessarily a
         filesystem path. ``None`` means the distribution is created in-memory.
 
         For a modern .dist-info installation on disk, this should be something
@@ -77,15 +109,15 @@
         Do not canonicalize this value with e.g. ``pathlib.Path.resolve()``. If
         this is a symbolic link, we want to preserve the relative path between
         it and other files in the distribution.
         """
         raise NotImplementedError()
 
     @property
-    def canonical_name(self) -> "NormalizedName":
+    def canonical_name(self) -> NormalizedName:
         raise NotImplementedError()
 
     @property
     def version(self) -> DistributionVersion:
         raise NotImplementedError()
 
     @property
@@ -116,15 +148,15 @@
 
     @property
     def installer(self) -> str:
         raise NotImplementedError()
 
     @property
     def editable(self) -> bool:
-        raise NotImplementedError()
+        return bool(self.editable_project_location)
 
     @property
     def local(self) -> bool:
         raise NotImplementedError()
 
     @property
     def in_usersite(self) -> bool:
@@ -155,18 +187,50 @@
         """Value of "Metadata-Version:" in distribution metadata, if available."""
         return self.metadata.get("Metadata-Version")
 
     @property
     def raw_name(self) -> str:
         """Value of "Name:" in distribution metadata."""
         # The metadata should NEVER be missing the Name: key, but if it somehow
-        # does not, fall back to the known canonical name.
+        # does, fall back to the known canonical name.
         return self.metadata.get("Name", self.canonical_name)
 
+    @property
+    def requires_python(self) -> SpecifierSet:
+        """Value of "Requires-Python:" in distribution metadata.
+
+        If the key does not exist or contains an invalid value, an empty
+        SpecifierSet should be returned.
+        """
+        value = self.metadata.get("Requires-Python")
+        if value is None:
+            return SpecifierSet()
+        try:
+            # Convert to str to satisfy the type checker; this can be a Header object.
+            spec = SpecifierSet(str(value))
+        except InvalidSpecifier as e:
+            message = "Package %r has an invalid Requires-Python: %s"
+            logger.warning(message, self.raw_name, e)
+            return SpecifierSet()
+        return spec
+
     def iter_dependencies(self, extras: Collection[str] = ()) -> Iterable[Requirement]:
+        """Dependencies of this distribution.
+
+        For modern .dist-info distributions, this is the collection of
+        "Requires-Dist:" entries in distribution metadata.
+        """
+        raise NotImplementedError()
+
+    def iter_provided_extras(self) -> Iterable[str]:
+        """Extras provided by this distribution.
+
+        For modern .dist-info distributions, this is the collection of
+        "Provides-Extra:" entries in distribution metadata.
+        """
         raise NotImplementedError()
 
 
 class BaseEnvironment:
     """An environment containing distributions to introspect."""
 
     @classmethod
@@ -236,7 +300,31 @@
         if not include_editables:
             it = (d for d in it if not d.editable)
         if editables_only:
             it = (d for d in it if d.editable)
         if user_only:
             it = (d for d in it if d.in_usersite)
         return (d for d in it if d.canonical_name not in skip)
+
+
+class Wheel(Protocol):
+    location: str
+
+    def as_zipfile(self) -> zipfile.ZipFile:
+        raise NotImplementedError()
+
+
+class FilesystemWheel(Wheel):
+    def __init__(self, location: str) -> None:
+        self.location = location
+
+    def as_zipfile(self) -> zipfile.ZipFile:
+        return zipfile.ZipFile(self.location, allowZip64=True)
+
+
+class MemoryWheel(Wheel):
+    def __init__(self, location: str, stream: IO[bytes]) -> None:
+        self.location = location
+        self.stream = stream
+
+    def as_zipfile(self) -> zipfile.ZipFile:
+        return zipfile.ZipFile(self.stream, allowZip64=True)
```

#### pip/_internal/metadata/pkg_resources.py

```diff
@@ -1,33 +1,27 @@
 import email.message
 import logging
-import zipfile
-from typing import (
-    TYPE_CHECKING,
-    Collection,
-    Iterable,
-    Iterator,
-    List,
-    NamedTuple,
-    Optional,
-)
+from typing import Collection, Iterable, Iterator, List, NamedTuple, Optional
 
 from pip._vendor import pkg_resources
 from pip._vendor.packaging.requirements import Requirement
-from pip._vendor.packaging.utils import canonicalize_name
+from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
 from pip._vendor.packaging.version import parse as parse_version
 
 from pip._internal.utils import misc  # TODO: Move definition here.
 from pip._internal.utils.packaging import get_installer, get_metadata
 from pip._internal.utils.wheel import pkg_resources_distribution_for_wheel
 
-from .base import BaseDistribution, BaseEntryPoint, BaseEnvironment, DistributionVersion
-
-if TYPE_CHECKING:
-    from pip._vendor.packaging.utils import NormalizedName
+from .base import (
+    BaseDistribution,
+    BaseEntryPoint,
+    BaseEnvironment,
+    DistributionVersion,
+    Wheel,
+)
 
 logger = logging.getLogger(__name__)
 
 
 class EntryPoint(NamedTuple):
     name: str
     value: str
@@ -35,44 +29,40 @@
 
 
 class Distribution(BaseDistribution):
     def __init__(self, dist: pkg_resources.Distribution) -> None:
         self._dist = dist
 
     @classmethod
-    def from_wheel(cls, path: str, name: str) -> "Distribution":
-        with zipfile.ZipFile(path, allowZip64=True) as zf:
-            dist = pkg_resources_distribution_for_wheel(zf, name, path)
+    def from_wheel(cls, wheel: Wheel, name: str) -> "Distribution":
+        with wheel.as_zipfile() as zf:
+            dist = pkg_resources_distribution_for_wheel(zf, name, wheel.location)
         return cls(dist)
 
     @property
     def location(self) -> Optional[str]:
         return self._dist.location
 
     @property
     def info_directory(self) -> Optional[str]:
         return self._dist.egg_info
 
     @property
-    def canonical_name(self) -> "NormalizedName":
+    def canonical_name(self) -> NormalizedName:
         return canonicalize_name(self._dist.project_name)
 
     @property
     def version(self) -> DistributionVersion:
         return parse_version(self._dist.version)
 
     @property
     def installer(self) -> str:
         return get_installer(self._dist)
 
     @property
-    def editable(self) -> bool:
-        return misc.dist_is_editable(self._dist)
-
-    @property
     def local(self) -> bool:
         return misc.dist_is_local(self._dist)
 
     @property
     def in_usersite(self) -> bool:
         return misc.dist_in_usersite(self._dist)
 
@@ -96,14 +86,17 @@
         return get_metadata(self._dist)
 
     def iter_dependencies(self, extras: Collection[str] = ()) -> Iterable[Requirement]:
         if extras:  # pkg_resources raises on invalid extras, so we sanitize.
             extras = frozenset(extras).intersection(self._dist.extras)
         return self._dist.requires(extras)
 
+    def iter_provided_extras(self) -> Iterable[str]:
+        return self._dist.extras
+
 
 class Environment(BaseEnvironment):
     def __init__(self, ws: pkg_resources.WorkingSet) -> None:
         self._ws = ws
 
     @classmethod
     def default(cls) -> BaseEnvironment:
```

#### pip/_internal/models/candidate.py

```diff
@@ -1,31 +1,34 @@
 from pip._vendor.packaging.version import parse as parse_version
 
 from pip._internal.models.link import Link
 from pip._internal.utils.models import KeyBasedCompareMixin
 
 
 class InstallationCandidate(KeyBasedCompareMixin):
-    """Represents a potential "candidate" for installation.
-    """
+    """Represents a potential "candidate" for installation."""
 
     __slots__ = ["name", "version", "link"]
 
     def __init__(self, name: str, version: str, link: Link) -> None:
         self.name = name
         self.version = parse_version(version)
         self.link = link
 
         super().__init__(
             key=(self.name, self.version, self.link),
-            defining_class=InstallationCandidate
+            defining_class=InstallationCandidate,
         )
 
     def __repr__(self) -> str:
         return "<InstallationCandidate({!r}, {!r}, {!r})>".format(
-            self.name, self.version, self.link,
+            self.name,
+            self.version,
+            self.link,
         )
 
     def __str__(self) -> str:
-        return '{!r} candidate (version {} at {})'.format(
-            self.name, self.version, self.link,
+        return "{!r} candidate (version {} at {})".format(
+            self.name,
+            self.version,
+            self.link,
         )
```

#### pip/_internal/models/direct_url.py

```diff
@@ -133,27 +133,24 @@
     ) -> None:
         self.editable = editable
 
     @classmethod
     def _from_dict(cls, d: Optional[Dict[str, Any]]) -> Optional["DirInfo"]:
         if d is None:
             return None
-        return cls(
-            editable=_get_required(d, bool, "editable", default=False)
-        )
+        return cls(editable=_get_required(d, bool, "editable", default=False))
 
     def _to_dict(self) -> Dict[str, Any]:
         return _filter_none(editable=self.editable or None)
 
 
 InfoType = Union[ArchiveInfo, DirInfo, VcsInfo]
 
 
 class DirectUrl:
-
     def __init__(
         self,
         url: str,
         info: InfoType,
         subdirectory: Optional[str] = None,
     ) -> None:
         self.url = url
@@ -161,17 +158,17 @@
         self.subdirectory = subdirectory
 
     def _remove_auth_from_netloc(self, netloc: str) -> str:
         if "@" not in netloc:
             return netloc
         user_pass, netloc_no_user_pass = netloc.split("@", 1)
         if (
-            isinstance(self.info, VcsInfo) and
-            self.info.vcs == "git" and
-            user_pass == "git"
+            isinstance(self.info, VcsInfo)
+            and self.info.vcs == "git"
+            and user_pass == "git"
         ):
             return netloc
         if ENV_VAR_RE.match(user_pass):
             return netloc
         return netloc_no_user_pass
 
     @property
@@ -214,7 +211,10 @@
 
     @classmethod
     def from_json(cls, s: str) -> "DirectUrl":
         return cls.from_dict(json.loads(s))
 
     def to_json(self) -> str:
         return json.dumps(self.to_dict(), sort_keys=True)
+
+    def is_local_editable(self) -> bool:
+        return isinstance(self.info, DirInfo) and self.info.editable
```

#### pip/_internal/models/format_control.py

```diff
@@ -2,23 +2,22 @@
 
 from pip._vendor.packaging.utils import canonicalize_name
 
 from pip._internal.exceptions import CommandError
 
 
 class FormatControl:
-    """Helper for managing formats from which a package can be installed.
-    """
+    """Helper for managing formats from which a package can be installed."""
 
     __slots__ = ["no_binary", "only_binary"]
 
     def __init__(
         self,
         no_binary: Optional[Set[str]] = None,
-        only_binary: Optional[Set[str]] = None
+        only_binary: Optional[Set[str]] = None,
     ) -> None:
         if no_binary is None:
             no_binary = set()
         if only_binary is None:
             only_binary = set()
 
         self.no_binary = no_binary
@@ -27,58 +26,55 @@
     def __eq__(self, other: object) -> bool:
         if not isinstance(other, self.__class__):
             return NotImplemented
 
         if self.__slots__ != other.__slots__:
             return False
 
-        return all(
-            getattr(self, k) == getattr(other, k)
-            for k in self.__slots__
-        )
+        return all(getattr(self, k) == getattr(other, k) for k in self.__slots__)
 
     def __repr__(self) -> str:
         return "{}({}, {})".format(
-            self.__class__.__name__,
-            self.no_binary,
-            self.only_binary
+            self.__class__.__name__, self.no_binary, self.only_binary
         )
 
     @staticmethod
     def handle_mutual_excludes(value: str, target: Set[str], other: Set[str]) -> None:
-        if value.startswith('-'):
+        if value.startswith("-"):
             raise CommandError(
                 "--no-binary / --only-binary option requires 1 argument."
             )
-        new = value.split(',')
-        while ':all:' in new:
+        new = value.split(",")
+        while ":all:" in new:
             other.clear()
             target.clear()
-            target.add(':all:')
-            del new[:new.index(':all:') + 1]
+            target.add(":all:")
+            del new[: new.index(":all:") + 1]
             # Without a none, we want to discard everything as :all: covers it
-            if ':none:' not in new:
+            if ":none:" not in new:
                 return
         for name in new:
-            if name == ':none:':
+            if name == ":none:":
                 target.clear()
                 continue
             name = canonicalize_name(name)
             other.discard(name)
             target.add(name)
 
     def get_allowed_formats(self, canonical_name: str) -> FrozenSet[str]:
         result = {"binary", "source"}
         if canonical_name in self.only_binary:
-            result.discard('source')
+            result.discard("source")
         elif canonical_name in self.no_binary:
-            result.discard('binary')
-        elif ':all:' in self.only_binary:
-            result.discard('source')
-        elif ':all:' in self.no_binary:
-            result.discard('binary')
+            result.discard("binary")
+        elif ":all:" in self.only_binary:
+            result.discard("source")
+        elif ":all:" in self.no_binary:
+            result.discard("binary")
         return frozenset(result)
 
     def disallow_binaries(self) -> None:
         self.handle_mutual_excludes(
-            ':all:', self.no_binary, self.only_binary,
+            ":all:",
+            self.no_binary,
+            self.only_binary,
         )
```

#### pip/_internal/models/index.py

```diff
@@ -1,32 +1,28 @@
 import urllib.parse
 
 
 class PackageIndex:
-    """Represents a Package Index and provides easier access to endpoints
-    """
+    """Represents a Package Index and provides easier access to endpoints"""
 
-    __slots__ = ['url', 'netloc', 'simple_url', 'pypi_url',
-                 'file_storage_domain']
+    __slots__ = ["url", "netloc", "simple_url", "pypi_url", "file_storage_domain"]
 
     def __init__(self, url: str, file_storage_domain: str) -> None:
         super().__init__()
         self.url = url
         self.netloc = urllib.parse.urlsplit(url).netloc
-        self.simple_url = self._url_for_path('simple')
-        self.pypi_url = self._url_for_path('pypi')
+        self.simple_url = self._url_for_path("simple")
+        self.pypi_url = self._url_for_path("pypi")
 
         # This is part of a temporary hack used to block installs of PyPI
         # packages which depend on external urls only necessary until PyPI can
         # block such packages themselves
         self.file_storage_domain = file_storage_domain
 
     def _url_for_path(self, path: str) -> str:
         return urllib.parse.urljoin(self.url, path)
 
 
-PyPI = PackageIndex(
-    'https://pypi.org/', file_storage_domain='files.pythonhosted.org'
-)
+PyPI = PackageIndex("https://pypi.org/", file_storage_domain="files.pythonhosted.org")
 TestPyPI = PackageIndex(
-    'https://test.pypi.org/', file_storage_domain='test-files.pythonhosted.org'
+    "https://test.pypi.org/", file_storage_domain="test-files.pythonhosted.org"
 )
```

#### pip/_internal/models/link.py

```diff
@@ -22,16 +22,15 @@
 logger = logging.getLogger(__name__)
 
 
 _SUPPORTED_HASHES = ("sha1", "sha224", "sha384", "sha256", "sha512", "md5")
 
 
 class Link(KeyBasedCompareMixin):
-    """Represents a parsed link from a Package Index's simple URL
-    """
+    """Represents a parsed link from a Package Index's simple URL"""
 
     __slots__ = [
         "_parsed_url",
         "_url",
         "comes_from",
         "requires_python",
         "yanked_reason",
@@ -64,15 +63,15 @@
                                    whether resources retrieved from this link
                                    should be cached. PyPI index urls should
                                    generally have this set to False, for
                                    example.
         """
 
         # url can be a UNC windows share
-        if url.startswith('\\\\'):
+        if url.startswith("\\\\"):
             url = path_to_url(url)
 
         self._parsed_url = urllib.parse.urlsplit(url)
         # Store the url as a private attribute to prevent accidentally
         # trying to set a new value.
         self._url = url
 
@@ -82,42 +81,43 @@
 
         super().__init__(key=url, defining_class=Link)
 
         self.cache_link_parsing = cache_link_parsing
 
     def __str__(self) -> str:
         if self.requires_python:
-            rp = f' (requires-python:{self.requires_python})'
+            rp = f" (requires-python:{self.requires_python})"
         else:
-            rp = ''
+            rp = ""
         if self.comes_from:
-            return '{} (from {}){}'.format(
-                redact_auth_from_url(self._url), self.comes_from, rp)
+            return "{} (from {}){}".format(
+                redact_auth_from_url(self._url), self.comes_from, rp
+            )
         else:
             return redact_auth_from_url(str(self._url))
 
     def __repr__(self) -> str:
-        return f'<Link {self}>'
+        return f"<Link {self}>"
 
     @property
     def url(self) -> str:
         return self._url
 
     @property
     def filename(self) -> str:
-        path = self.path.rstrip('/')
+        path = self.path.rstrip("/")
         name = posixpath.basename(path)
         if not name:
             # Make sure we don't leak auth information if the netloc
             # includes a username and password.
             netloc, user_pass = split_auth_from_netloc(self.netloc)
             return netloc
 
         name = urllib.parse.unquote(name)
-        assert name, f'URL {self._url!r} produced no filename'
+        assert name, f"URL {self._url!r} produced no filename"
         return name
 
     @property
     def file_path(self) -> str:
         return url_to_path(self.url)
 
     @property
@@ -132,45 +132,45 @@
         return self._parsed_url.netloc
 
     @property
     def path(self) -> str:
         return urllib.parse.unquote(self._parsed_url.path)
 
     def splitext(self) -> Tuple[str, str]:
-        return splitext(posixpath.basename(self.path.rstrip('/')))
+        return splitext(posixpath.basename(self.path.rstrip("/")))
 
     @property
     def ext(self) -> str:
         return self.splitext()[1]
 
     @property
     def url_without_fragment(self) -> str:
         scheme, netloc, path, query, fragment = self._parsed_url
-        return urllib.parse.urlunsplit((scheme, netloc, path, query, ''))
+        return urllib.parse.urlunsplit((scheme, netloc, path, query, ""))
 
-    _egg_fragment_re = re.compile(r'[#&]egg=([^&]*)')
+    _egg_fragment_re = re.compile(r"[#&]egg=([^&]*)")
 
     @property
     def egg_fragment(self) -> Optional[str]:
         match = self._egg_fragment_re.search(self._url)
         if not match:
             return None
         return match.group(1)
 
-    _subdirectory_fragment_re = re.compile(r'[#&]subdirectory=([^&]*)')
+    _subdirectory_fragment_re = re.compile(r"[#&]subdirectory=([^&]*)")
 
     @property
     def subdirectory_fragment(self) -> Optional[str]:
         match = self._subdirectory_fragment_re.search(self._url)
         if not match:
             return None
         return match.group(1)
 
     _hash_re = re.compile(
-        r'({choices})=([a-f0-9]+)'.format(choices="|".join(_SUPPORTED_HASHES))
+        r"({choices})=([a-f0-9]+)".format(choices="|".join(_SUPPORTED_HASHES))
     )
 
     @property
     def hash(self) -> Optional[str]:
         match = self._hash_re.search(self._url)
         if match:
             return match.group(2)
@@ -181,19 +181,19 @@
         match = self._hash_re.search(self._url)
         if match:
             return match.group(1)
         return None
 
     @property
     def show_url(self) -> str:
-        return posixpath.basename(self._url.split('#', 1)[0].split('?', 1)[0])
+        return posixpath.basename(self._url.split("#", 1)[0].split("?", 1)[0])
 
     @property
     def is_file(self) -> bool:
-        return self.scheme == 'file'
+        return self.scheme == "file"
 
     def is_existing_dir(self) -> bool:
         return self.is_file and os.path.isdir(self.file_path)
 
     @property
     def is_wheel(self) -> bool:
         return self.ext == WHEEL_EXTENSION
```

#### pip/_internal/models/scheme.py

```diff
@@ -2,15 +2,15 @@
 For types associated with installation schemes.
 
 For a general overview of available schemes and their context, see
 https://docs.python.org/3/install/index.html#alternate-installation.
 """
 
 
-SCHEME_KEYS = ['platlib', 'purelib', 'headers', 'scripts', 'data']
+SCHEME_KEYS = ["platlib", "purelib", "headers", "scripts", "data"]
 
 
 class Scheme:
     """A Scheme holds paths which are used as the base directories for
     artifacts associated with a Python package.
     """
```

#### pip/_internal/models/search_scope.py

```diff
@@ -34,30 +34,30 @@
         # Build find_links. If an argument starts with ~, it may be
         # a local file relative to a home directory. So try normalizing
         # it and if it exists, use the normalized version.
         # This is deliberately conservative - it might be fine just to
         # blindly normalize anything starting with a ~...
         built_find_links: List[str] = []
         for link in find_links:
-            if link.startswith('~'):
+            if link.startswith("~"):
                 new_link = normalize_path(link)
                 if os.path.exists(new_link):
                     link = new_link
             built_find_links.append(link)
 
         # If we don't have TLS enabled, then WARN if anyplace we're looking
         # relies on TLS.
         if not has_tls():
             for link in itertools.chain(index_urls, built_find_links):
                 parsed = urllib.parse.urlparse(link)
-                if parsed.scheme == 'https':
+                if parsed.scheme == "https":
                     logger.warning(
-                        'pip is configured with locations that require '
-                        'TLS/SSL, however the ssl module in Python is not '
-                        'available.'
+                        "pip is configured with locations that require "
+                        "TLS/SSL, however the ssl module in Python is not "
+                        "available."
                     )
                     break
 
         return cls(
             find_links=built_find_links,
             index_urls=index_urls,
         )
@@ -84,43 +84,46 @@
                 # URL is generally invalid if scheme and netloc is missing
                 # there are issues with Python and URL parsing, so this test
                 # is a bit crude. See bpo-20271, bpo-23505. Python doesn't
                 # always parse invalid URLs correctly - it should raise
                 # exceptions for malformed URLs
                 if not purl.scheme and not purl.netloc:
                     logger.warning(
-                        'The index url "%s" seems invalid, '
-                        'please provide a scheme.', redacted_index_url)
+                        'The index url "%s" seems invalid, please provide a scheme.',
+                        redacted_index_url,
+                    )
 
                 redacted_index_urls.append(redacted_index_url)
 
-            lines.append('Looking in indexes: {}'.format(
-                ', '.join(redacted_index_urls)))
+            lines.append(
+                "Looking in indexes: {}".format(", ".join(redacted_index_urls))
+            )
 
         if self.find_links:
             lines.append(
-                'Looking in links: {}'.format(', '.join(
-                    redact_auth_from_url(url) for url in self.find_links))
+                "Looking in links: {}".format(
+                    ", ".join(redact_auth_from_url(url) for url in self.find_links)
+                )
             )
-        return '\n'.join(lines)
+        return "\n".join(lines)
 
     def get_index_urls_locations(self, project_name: str) -> List[str]:
         """Returns the locations found via self.index_urls
 
         Checks the url_name on the main (first in the list) index and
         use this url_name to produce all locations
         """
 
         def mkurl_pypi_url(url: str) -> str:
             loc = posixpath.join(
-                url,
-                urllib.parse.quote(canonicalize_name(project_name)))
+                url, urllib.parse.quote(canonicalize_name(project_name))
+            )
             # For maximum compatibility with easy_install, ensure the path
             # ends in a trailing slash.  Although this isn't in the spec
             # (and PyPI can handle it without the slash) some other index
             # implementations might break if they relied on easy_install's
             # behavior.
-            if not loc.endswith('/'):
-                loc = loc + '/'
+            if not loc.endswith("/"):
+                loc = loc + "/"
             return loc
 
         return [mkurl_pypi_url(url) for url in self.index_urls]
```

#### pip/_internal/models/selection_prefs.py

```diff
@@ -5,16 +5,21 @@
 
 class SelectionPreferences:
     """
     Encapsulates the candidate selection preferences for downloading
     and installing files.
     """
 
-    __slots__ = ['allow_yanked', 'allow_all_prereleases', 'format_control',
-                 'prefer_binary', 'ignore_requires_python']
+    __slots__ = [
+        "allow_yanked",
+        "allow_all_prereleases",
+        "format_control",
+        "prefer_binary",
+        "ignore_requires_python",
+    ]
 
     # Don't include an allow_yanked default value to make sure each call
     # site considers whether yanked releases are allowed. This also causes
     # that decision to be made explicit in the calling code, which helps
     # people when reading the code.
     def __init__(
         self,
```

#### pip/_internal/models/target_python.py

```diff
@@ -49,15 +49,15 @@
         self._given_py_version_info = py_version_info
 
         if py_version_info is None:
             py_version_info = sys.version_info[:3]
         else:
             py_version_info = normalize_version_info(py_version_info)
 
-        py_version = '.'.join(map(str, py_version_info[:2]))
+        py_version = ".".join(map(str, py_version_info[:2]))
 
         self.abis = abis
         self.implementation = implementation
         self.platforms = platforms
         self.py_version = py_version
         self.py_version_info = py_version_info
 
@@ -66,27 +66,26 @@
 
     def format_given(self) -> str:
         """
         Format the given, non-None attributes for display.
         """
         display_version = None
         if self._given_py_version_info is not None:
-            display_version = '.'.join(
+            display_version = ".".join(
                 str(part) for part in self._given_py_version_info
             )
 
         key_values = [
-            ('platforms', self.platforms),
-            ('version_info', display_version),
-            ('abis', self.abis),
-            ('implementation', self.implementation),
+            ("platforms", self.platforms),
+            ("version_info", display_version),
+            ("abis", self.abis),
+            ("implementation", self.implementation),
         ]
-        return ' '.join(
-            f'{key}={value!r}' for key, value in key_values
-            if value is not None
+        return " ".join(
+            f"{key}={value!r}" for key, value in key_values if value is not None
         )
 
     def get_tags(self) -> List[Tag]:
         """
         Return the supported PEP 425 tags to check wheel candidates against.
 
         The tags are returned in order of preference (most preferred first).
```

#### pip/_internal/models/wheel.py

```diff
@@ -12,40 +12,37 @@
 class Wheel:
     """A wheel file"""
 
     wheel_file_re = re.compile(
         r"""^(?P<namever>(?P<name>.+?)-(?P<ver>.*?))
         ((-(?P<build>\d[^-]*?))?-(?P<pyver>.+?)-(?P<abi>.+?)-(?P<plat>.+?)
         \.whl|\.dist-info)$""",
-        re.VERBOSE
+        re.VERBOSE,
     )
 
     def __init__(self, filename: str) -> None:
         """
         :raises InvalidWheelFilename: when the filename is invalid for a wheel
         """
         wheel_info = self.wheel_file_re.match(filename)
         if not wheel_info:
-            raise InvalidWheelFilename(
-                f"{filename} is not a valid wheel filename."
-            )
+            raise InvalidWheelFilename(f"{filename} is not a valid wheel filename.")
         self.filename = filename
-        self.name = wheel_info.group('name').replace('_', '-')
+        self.name = wheel_info.group("name").replace("_", "-")
         # we'll assume "_" means "-" due to wheel naming scheme
         # (https://github.com/pypa/pip/issues/1150)
-        self.version = wheel_info.group('ver').replace('_', '-')
-        self.build_tag = wheel_info.group('build')
-        self.pyversions = wheel_info.group('pyver').split('.')
-        self.abis = wheel_info.group('abi').split('.')
-        self.plats = wheel_info.group('plat').split('.')
+        self.version = wheel_info.group("ver").replace("_", "-")
+        self.build_tag = wheel_info.group("build")
+        self.pyversions = wheel_info.group("pyver").split(".")
+        self.abis = wheel_info.group("abi").split(".")
+        self.plats = wheel_info.group("plat").split(".")
 
         # All the tag combinations from this file
         self.file_tags = {
-            Tag(x, y, z) for x in self.pyversions
-            for y in self.abis for z in self.plats
+            Tag(x, y, z) for x in self.pyversions for y in self.abis for z in self.plats
         }
 
     def get_formatted_file_tags(self) -> List[str]:
         """Return the wheel's tags as a sorted list of strings."""
         return sorted(str(tag) for tag in self.file_tags)
 
     def support_index_min(self, tags: List[Tag]) -> int:
```

#### pip/_internal/network/auth.py

```diff
@@ -24,21 +24,21 @@
 logger = getLogger(__name__)
 
 Credentials = Tuple[str, str, str]
 
 try:
     import keyring
 except ImportError:
-    keyring = None
+    keyring = None  # type: ignore[assignment]
 except Exception as exc:
     logger.warning(
         "Keyring is skipped due to an exception: %s",
         str(exc),
     )
-    keyring = None
+    keyring = None  # type: ignore[assignment]
 
 
 def get_keyring_auth(url: Optional[str], username: Optional[str]) -> Optional[AuthInfo]:
     """Return the tuple auth for a given url from keyring."""
     global keyring
     if not url or not keyring:
         return None
@@ -62,15 +62,15 @@
                 return username, password
 
     except Exception as exc:
         logger.warning(
             "Keyring is skipped due to an exception: %s",
             str(exc),
         )
-        keyring = None
+        keyring = None  # type: ignore[assignment]
     return None
 
 
 class MultiDomainBasicAuth(AuthBase):
     def __init__(
         self, prompting: bool = True, index_urls: Optional[List[str]] = None
     ) -> None:
@@ -175,17 +175,24 @@
         function may return a different username and password.
         """
         url, netloc, _ = split_auth_netloc_from_url(original_url)
 
         # Try to get credentials from original url
         username, password = self._get_new_credentials(original_url)
 
-        # If credentials not found, use any stored credentials for this netloc
-        if username is None and password is None:
-            username, password = self.passwords.get(netloc, (None, None))
+        # If credentials not found, use any stored credentials for this netloc.
+        # Do this if either the username or the password is missing.
+        # This accounts for the situation in which the user has specified
+        # the username in the index url, but the password comes from keyring.
+        if (username is None or password is None) and netloc in self.passwords:
+            un, pw = self.passwords[netloc]
+            # It is possible that the cached credentials are for a different username,
+            # in which case the cache should be ignored.
+            if username is None or username == un:
+                username, password = un, pw
 
         if username is not None or password is not None:
             # Convert the username and password if they're None, so that
             # this netloc will show up as "cached" in the conditional above.
             # Further, HTTPBasicAuth doesn't accept None, so it makes sense to
             # cache the value that is going to be used.
             username = username or ""
```

#### pip/_internal/network/lazy_wheel.py

```diff
@@ -4,41 +4,41 @@
 
 from bisect import bisect_left, bisect_right
 from contextlib import contextmanager
 from tempfile import NamedTemporaryFile
 from typing import Any, Dict, Iterator, List, Optional, Tuple
 from zipfile import BadZipfile, ZipFile
 
-from pip._vendor.pkg_resources import Distribution
+from pip._vendor.packaging.utils import canonicalize_name
 from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response
 
+from pip._internal.metadata import BaseDistribution, MemoryWheel, get_wheel_distribution
 from pip._internal.network.session import PipSession
 from pip._internal.network.utils import HEADERS, raise_for_status, response_chunks
-from pip._internal.utils.wheel import pkg_resources_distribution_for_wheel
 
 
 class HTTPRangeRequestUnsupported(Exception):
     pass
 
 
-def dist_from_wheel_url(name: str, url: str, session: PipSession) -> Distribution:
-    """Return a pkg_resources.Distribution from the given wheel URL.
+def dist_from_wheel_url(name: str, url: str, session: PipSession) -> BaseDistribution:
+    """Return a distribution object from the given wheel URL.
 
     This uses HTTP range requests to only fetch the potion of the wheel
     containing metadata, just enough for the object to be constructed.
     If such requests are not supported, HTTPRangeRequestUnsupported
     is raised.
     """
-    with LazyZipOverHTTP(url, session) as wheel:
+    with LazyZipOverHTTP(url, session) as zf:
         # For read-only ZIP files, ZipFile only needs methods read,
         # seek, seekable and tell, not the whole IO protocol.
-        zip_file = ZipFile(wheel)  # type: ignore
+        wheel = MemoryWheel(zf.name, zf)  # type: ignore
         # After context manager exit, wheel.name
         # is an invalid file by intention.
-        return pkg_resources_distribution_for_wheel(zip_file, name, wheel.name)
+        return get_wheel_distribution(wheel, canonicalize_name(name))
 
 
 class LazyZipOverHTTP:
     """File-like object mapped to a ZIP file over HTTP.
 
     This uses HTTP range requests to lazily fetch the file's content,
     which is supposed to be fed to ZipFile.  If such requests are not
```

#### pip/_internal/network/session.py

```diff
@@ -1,22 +1,13 @@
 """PipSession and supporting code, containing all pip-specific
 network request configuration and behavior.
 """
 
-# When mypy runs on Windows the call to distro.linux_distribution() is skipped
-# resulting in the failure:
-#
-#     error: unused 'type: ignore' comment
-#
-# If the upstream module adds typing, this comment should be removed. See
-# https://github.com/nir0s/distro/pull/269
-#
-# mypy: warn-unused-ignores=False
-
 import email.utils
+import io
 import ipaddress
 import json
 import logging
 import mimetypes
 import os
 import platform
 import shutil
@@ -124,17 +115,16 @@
     elif data["implementation"]["name"] == "IronPython":
         # Complete Guess
         data["implementation"]["version"] = platform.python_version()
 
     if sys.platform.startswith("linux"):
         from pip._vendor import distro
 
-        # https://github.com/nir0s/distro/pull/269
-        linux_distribution = distro.linux_distribution()  # type: ignore
-        distro_infos = dict(
+        linux_distribution = distro.name(), distro.version(), distro.codename()
+        distro_infos: Dict[str, Any] = dict(
             filter(
                 lambda x: x[1],
                 zip(["name", "version", "id"], linux_distribution),
             )
         )
         libc = dict(
             filter(
@@ -214,16 +204,19 @@
         resp = Response()
         resp.status_code = 200
         resp.url = request.url
 
         try:
             stats = os.stat(pathname)
         except OSError as exc:
+            # format the exception raised as a io.BytesIO object,
+            # to return a better error message:
             resp.status_code = 404
-            resp.raw = exc
+            resp.reason = type(exc).__name__
+            resp.raw = io.BytesIO(f"{resp.reason}: {exc}".encode("utf8"))
         else:
             modified = email.utils.formatdate(stats.st_mtime, usegmt=True)
             content_type = mimetypes.guess_type(pathname)[0] or "text/plain"
             resp.headers = CaseInsensitiveDict(
                 {
                     "Content-Type": content_type,
                     "Content-Length": stats.st_size,
@@ -365,16 +358,23 @@
                 msg += f" (from {source})"
             logger.info(msg)
 
         host_port = parse_netloc(host)
         if host_port not in self.pip_trusted_origins:
             self.pip_trusted_origins.append(host_port)
 
+        self.mount(
+            build_url_from_netloc(host, scheme="http") + "/", self._trusted_host_adapter
+        )
         self.mount(build_url_from_netloc(host) + "/", self._trusted_host_adapter)
         if not host_port[1]:
+            self.mount(
+                build_url_from_netloc(host, scheme="http") + ":",
+                self._trusted_host_adapter,
+            )
             # Mount wildcard ports for the same host.
             self.mount(build_url_from_netloc(host) + ":", self._trusted_host_adapter)
 
     def iter_secure_origins(self) -> Iterator[SecureOrigin]:
         yield from SECURE_ORIGINS
         for host, port in self.pip_trusted_origins:
             yield ("*", host, "*" if port is None else port)
```

#### pip/_internal/operations/check.py

```diff
@@ -1,39 +1,36 @@
 """Validation of dependencies of packages
 """
 
 import logging
-from typing import TYPE_CHECKING, Callable, Dict, List, NamedTuple, Optional, Set, Tuple
+from typing import Callable, Dict, List, NamedTuple, Optional, Set, Tuple
 
 from pip._vendor.packaging.requirements import Requirement
-from pip._vendor.packaging.utils import canonicalize_name
+from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
 
 from pip._internal.distributions import make_distribution_for_install_requirement
 from pip._internal.metadata import get_default_environment
 from pip._internal.metadata.base import DistributionVersion
 from pip._internal.req.req_install import InstallRequirement
 
-if TYPE_CHECKING:
-    from pip._vendor.packaging.utils import NormalizedName
-
 logger = logging.getLogger(__name__)
 
 
 class PackageDetails(NamedTuple):
     version: DistributionVersion
     dependencies: List[Requirement]
 
 
 # Shorthands
-PackageSet = Dict['NormalizedName', PackageDetails]
-Missing = Tuple['NormalizedName', Requirement]
-Conflicting = Tuple['NormalizedName', DistributionVersion, Requirement]
+PackageSet = Dict[NormalizedName, PackageDetails]
+Missing = Tuple[NormalizedName, Requirement]
+Conflicting = Tuple[NormalizedName, DistributionVersion, Requirement]
 
-MissingDict = Dict['NormalizedName', List[Missing]]
-ConflictingDict = Dict['NormalizedName', List[Conflicting]]
+MissingDict = Dict[NormalizedName, List[Missing]]
+ConflictingDict = Dict[NormalizedName, List[Conflicting]]
 CheckResult = Tuple[MissingDict, ConflictingDict]
 ConflictDetails = Tuple[PackageSet, CheckResult]
 
 
 def create_package_set_from_installed() -> Tuple[PackageSet, bool]:
     """Converts a list of distributions into a PackageSet."""
     package_set = {}
@@ -47,29 +44,30 @@
         except (OSError, ValueError) as e:
             # Don't crash on unreadable or broken metadata.
             logger.warning("Error parsing requirements for %s: %s", name, e)
             problems = True
     return package_set, problems
 
 
-def check_package_set(package_set, should_ignore=None):
-    # type: (PackageSet, Optional[Callable[[str], bool]]) -> CheckResult
+def check_package_set(
+    package_set: PackageSet, should_ignore: Optional[Callable[[str], bool]] = None
+) -> CheckResult:
     """Check if a package set is consistent
 
     If should_ignore is passed, it should be a callable that takes a
     package name and returns a boolean.
     """
 
     missing = {}
     conflicting = {}
 
     for package_name, package_detail in package_set.items():
         # Info about dependencies of package_name
-        missing_deps = set()  # type: Set[Missing]
-        conflicting_deps = set()  # type: Set[Conflicting]
+        missing_deps: Set[Missing] = set()
+        conflicting_deps: Set[Conflicting] = set()
 
         if should_ignore and should_ignore(package_name):
             continue
 
         for req in package_detail.dependencies:
             name = canonicalize_name(req.name)
 
@@ -91,16 +89,15 @@
             missing[package_name] = sorted(missing_deps, key=str)
         if conflicting_deps:
             conflicting[package_name] = sorted(conflicting_deps, key=str)
 
     return missing, conflicting
 
 
-def check_install_conflicts(to_install):
-    # type: (List[InstallRequirement]) -> ConflictDetails
+def check_install_conflicts(to_install: List[InstallRequirement]) -> ConflictDetails:
     """For checking if the dependency graph would be consistent after \
     installing given requirements
     """
     # Start from the current state
     package_set, _ = create_package_set_from_installed()
     # Install packages
     would_be_installed = _simulate_installation_of(to_install, package_set)
@@ -108,41 +105,40 @@
     # Only warn about directly-dependent packages; create a whitelist of them
     whitelist = _create_whitelist(would_be_installed, package_set)
 
     return (
         package_set,
         check_package_set(
             package_set, should_ignore=lambda name: name not in whitelist
-        )
+        ),
     )
 
 
-def _simulate_installation_of(to_install, package_set):
-    # type: (List[InstallRequirement], PackageSet) -> Set[NormalizedName]
-    """Computes the version of packages after installing to_install.
-    """
+def _simulate_installation_of(
+    to_install: List[InstallRequirement], package_set: PackageSet
+) -> Set[NormalizedName]:
+    """Computes the version of packages after installing to_install."""
     # Keep track of packages that were installed
     installed = set()
 
     # Modify it as installing requirement_set would (assuming no errors)
     for inst_req in to_install:
         abstract_dist = make_distribution_for_install_requirement(inst_req)
-        dist = abstract_dist.get_pkg_resources_distribution()
-
-        assert dist is not None
-        name = canonicalize_name(dist.project_name)
-        package_set[name] = PackageDetails(dist.parsed_version, dist.requires())
+        dist = abstract_dist.get_metadata_distribution()
+        name = dist.canonical_name
+        package_set[name] = PackageDetails(dist.version, list(dist.iter_dependencies()))
 
         installed.add(name)
 
     return installed
 
 
-def _create_whitelist(would_be_installed, package_set):
-    # type: (Set[NormalizedName], PackageSet) -> Set[NormalizedName]
+def _create_whitelist(
+    would_be_installed: Set[NormalizedName], package_set: PackageSet
+) -> Set[NormalizedName]:
     packages_affected = set(would_be_installed)
 
     for package_name in package_set:
         if package_name in packages_affected:
             continue
 
         for req in package_set[package_name].dependencies:
```

#### pip/_internal/operations/freeze.py

```diff
@@ -1,23 +1,12 @@
 import collections
 import logging
 import os
-from typing import (
-    Container,
-    Dict,
-    Iterable,
-    Iterator,
-    List,
-    NamedTuple,
-    Optional,
-    Set,
-    Union,
-)
+from typing import Container, Dict, Iterable, Iterator, List, NamedTuple, Optional, Set
 
-from pip._vendor.packaging.requirements import Requirement
 from pip._vendor.packaging.utils import canonicalize_name
 from pip._vendor.packaging.version import Version
 
 from pip._internal.exceptions import BadCommand, InstallationError
 from pip._internal.metadata import BaseDistribution, get_environment
 from pip._internal.req.constructors import (
     install_req_from_editable,
@@ -26,30 +15,28 @@
 from pip._internal.req.req_file import COMMENT_RE
 from pip._internal.utils.direct_url_helpers import direct_url_as_pep440_direct_reference
 
 logger = logging.getLogger(__name__)
 
 
 class _EditableInfo(NamedTuple):
-    requirement: Optional[str]
-    editable: bool
+    requirement: str
     comments: List[str]
 
 
 def freeze(
-    requirement=None,  # type: Optional[List[str]]
-    local_only=False,  # type: bool
-    user_only=False,  # type: bool
-    paths=None,  # type: Optional[List[str]]
-    isolated=False,  # type: bool
-    exclude_editable=False,  # type: bool
-    skip=()  # type: Container[str]
-):
-    # type: (...) -> Iterator[str]
-    installations = {}  # type: Dict[str, FrozenRequirement]
+    requirement: Optional[List[str]] = None,
+    local_only: bool = False,
+    user_only: bool = False,
+    paths: Optional[List[str]] = None,
+    isolated: bool = False,
+    exclude_editable: bool = False,
+    skip: Container[str] = (),
+) -> Iterator[str]:
+    installations: Dict[str, FrozenRequirement] = {}
 
     dists = get_environment(paths).iter_installed_distributions(
         local_only=local_only,
         skip=(),
         user_only=user_only,
     )
     for dist in dists:
@@ -59,219 +46,209 @@
         installations[req.canonical_name] = req
 
     if requirement:
         # the options that don't get turned into an InstallRequirement
         # should only be emitted once, even if the same option is in multiple
         # requirements files, so we need to keep track of what has been emitted
         # so that we don't emit it again if it's seen again
-        emitted_options = set()  # type: Set[str]
+        emitted_options: Set[str] = set()
         # keep track of which files a requirement is in so that we can
         # give an accurate warning if a requirement appears multiple times.
-        req_files = collections.defaultdict(list)  # type: Dict[str, List[str]]
+        req_files: Dict[str, List[str]] = collections.defaultdict(list)
         for req_file_path in requirement:
             with open(req_file_path) as req_file:
                 for line in req_file:
-                    if (not line.strip() or
-                            line.strip().startswith('#') or
-                            line.startswith((
-                                '-r', '--requirement',
-                                '-f', '--find-links',
-                                '-i', '--index-url',
-                                '--pre',
-                                '--trusted-host',
-                                '--process-dependency-links',
-                                '--extra-index-url',
-                                '--use-feature'))):
+                    if (
+                        not line.strip()
+                        or line.strip().startswith("#")
+                        or line.startswith(
+                            (
+                                "-r",
+                                "--requirement",
+                                "-f",
+                                "--find-links",
+                                "-i",
+                                "--index-url",
+                                "--pre",
+                                "--trusted-host",
+                                "--process-dependency-links",
+                                "--extra-index-url",
+                                "--use-feature",
+                            )
+                        )
+                    ):
                         line = line.rstrip()
                         if line not in emitted_options:
                             emitted_options.add(line)
                             yield line
                         continue
 
-                    if line.startswith('-e') or line.startswith('--editable'):
-                        if line.startswith('-e'):
+                    if line.startswith("-e") or line.startswith("--editable"):
+                        if line.startswith("-e"):
                             line = line[2:].strip()
                         else:
-                            line = line[len('--editable'):].strip().lstrip('=')
+                            line = line[len("--editable") :].strip().lstrip("=")
                         line_req = install_req_from_editable(
                             line,
                             isolated=isolated,
                         )
                     else:
                         line_req = install_req_from_line(
-                            COMMENT_RE.sub('', line).strip(),
+                            COMMENT_RE.sub("", line).strip(),
                             isolated=isolated,
                         )
 
                     if not line_req.name:
                         logger.info(
                             "Skipping line in requirement file [%s] because "
                             "it's not clear what it would install: %s",
-                            req_file_path, line.strip(),
+                            req_file_path,
+                            line.strip(),
                         )
                         logger.info(
                             "  (add #egg=PackageName to the URL to avoid"
                             " this warning)"
                         )
                     else:
-                        line_req_canonical_name = canonicalize_name(
-                            line_req.name)
+                        line_req_canonical_name = canonicalize_name(line_req.name)
                         if line_req_canonical_name not in installations:
                             # either it's not installed, or it is installed
                             # but has been processed already
                             if not req_files[line_req.name]:
                                 logger.warning(
                                     "Requirement file [%s] contains %s, but "
                                     "package %r is not installed",
                                     req_file_path,
-                                    COMMENT_RE.sub('', line).strip(),
-                                    line_req.name
+                                    COMMENT_RE.sub("", line).strip(),
+                                    line_req.name,
                                 )
                             else:
                                 req_files[line_req.name].append(req_file_path)
                         else:
-                            yield str(installations[
-                                line_req_canonical_name]).rstrip()
+                            yield str(installations[line_req_canonical_name]).rstrip()
                             del installations[line_req_canonical_name]
                             req_files[line_req.name].append(req_file_path)
 
         # Warn about requirements that were included multiple times (in a
         # single requirements file or in different requirements files).
         for name, files in req_files.items():
             if len(files) > 1:
-                logger.warning("Requirement %s included multiple times [%s]",
-                               name, ', '.join(sorted(set(files))))
+                logger.warning(
+                    "Requirement %s included multiple times [%s]",
+                    name,
+                    ", ".join(sorted(set(files))),
+                )
 
-        yield(
-            '## The following requirements were added by '
-            'pip freeze:'
-        )
-    for installation in sorted(
-            installations.values(), key=lambda x: x.name.lower()):
+        yield ("## The following requirements were added by pip freeze:")
+    for installation in sorted(installations.values(), key=lambda x: x.name.lower()):
         if installation.canonical_name not in skip:
             yield str(installation).rstrip()
 
 
 def _format_as_name_version(dist: BaseDistribution) -> str:
     if isinstance(dist.version, Version):
         return f"{dist.raw_name}=={dist.version}"
     return f"{dist.raw_name}==={dist.version}"
 
 
 def _get_editable_info(dist: BaseDistribution) -> _EditableInfo:
     """
-    Compute and return values (req, editable, comments) for use in
+    Compute and return values (req, comments) for use in
     FrozenRequirement.from_dist().
     """
-    if not dist.editable:
-        return _EditableInfo(requirement=None, editable=False, comments=[])
-    if dist.location is None:
-        display = _format_as_name_version(dist)
-        logger.warning("Editable requirement not found on disk: %s", display)
-        return _EditableInfo(
-            requirement=None,
-            editable=True,
-            comments=[f"# Editable install not found ({display})"],
-        )
-
-    location = os.path.normcase(os.path.abspath(dist.location))
+    editable_project_location = dist.editable_project_location
+    assert editable_project_location
+    location = os.path.normcase(os.path.abspath(editable_project_location))
 
     from pip._internal.vcs import RemoteNotFoundError, RemoteNotValidError, vcs
 
     vcs_backend = vcs.get_backend_for_dir(location)
 
     if vcs_backend is None:
         display = _format_as_name_version(dist)
         logger.debug(
-            'No VCS found for editable requirement "%s" in: %r', display,
+            'No VCS found for editable requirement "%s" in: %r',
+            display,
             location,
         )
         return _EditableInfo(
             requirement=location,
-            editable=True,
-            comments=[f'# Editable install with no version control ({display})'],
+            comments=[f"# Editable install with no version control ({display})"],
         )
 
     vcs_name = type(vcs_backend).__name__
 
     try:
         req = vcs_backend.get_src_requirement(location, dist.raw_name)
     except RemoteNotFoundError:
         display = _format_as_name_version(dist)
         return _EditableInfo(
             requirement=location,
-            editable=True,
-            comments=[f'# Editable {vcs_name} install with no remote ({display})'],
+            comments=[f"# Editable {vcs_name} install with no remote ({display})"],
         )
     except RemoteNotValidError as ex:
         display = _format_as_name_version(dist)
         return _EditableInfo(
             requirement=location,
-            editable=True,
             comments=[
                 f"# Editable {vcs_name} install ({display}) with either a deleted "
                 f"local remote or invalid URI:",
                 f"# '{ex.url}'",
             ],
         )
-
     except BadCommand:
         logger.warning(
-            'cannot determine version of editable source in %s '
-            '(%s command not found in path)',
+            "cannot determine version of editable source in %s "
+            "(%s command not found in path)",
             location,
             vcs_backend.name,
         )
-        return _EditableInfo(requirement=None, editable=True, comments=[])
-
+        return _EditableInfo(requirement=location, comments=[])
     except InstallationError as exc:
-        logger.warning(
-            "Error when trying to get requirement for VCS system %s, "
-            "falling back to uneditable format", exc
-        )
+        logger.warning("Error when trying to get requirement for VCS system %s", exc)
     else:
-        return _EditableInfo(requirement=req, editable=True, comments=[])
+        return _EditableInfo(requirement=req, comments=[])
 
-    logger.warning('Could not determine repository location of %s', location)
+    logger.warning("Could not determine repository location of %s", location)
 
     return _EditableInfo(
-        requirement=None,
-        editable=False,
-        comments=['## !! Could not determine repository location'],
+        requirement=location,
+        comments=["## !! Could not determine repository location"],
     )
 
 
 class FrozenRequirement:
-    def __init__(self, name, req, editable, comments=()):
-        # type: (str, Union[str, Requirement], bool, Iterable[str]) -> None
+    def __init__(
+        self,
+        name: str,
+        req: str,
+        editable: bool,
+        comments: Iterable[str] = (),
+    ) -> None:
         self.name = name
         self.canonical_name = canonicalize_name(name)
         self.req = req
         self.editable = editable
         self.comments = comments
 
     @classmethod
     def from_dist(cls, dist: BaseDistribution) -> "FrozenRequirement":
-        # TODO `get_requirement_info` is taking care of editable requirements.
-        # TODO This should be refactored when we will add detection of
-        #      editable that provide .dist-info metadata.
-        req, editable, comments = _get_editable_info(dist)
-        if req is None and not editable:
-            # if PEP 610 metadata is present, attempt to use it
+        editable = dist.editable
+        if editable:
+            req, comments = _get_editable_info(dist)
+        else:
+            comments = []
             direct_url = dist.direct_url
             if direct_url:
-                req = direct_url_as_pep440_direct_reference(
-                    direct_url, dist.raw_name
-                )
-                comments = []
-        if req is None:
-            # name==version requirement
-            req = _format_as_name_version(dist)
+                # if PEP 610 metadata is present, use it
+                req = direct_url_as_pep440_direct_reference(direct_url, dist.raw_name)
+            else:
+                # name==version requirement
+                req = _format_as_name_version(dist)
 
         return cls(dist.raw_name, req, editable, comments=comments)
 
-    def __str__(self):
-        # type: () -> str
+    def __str__(self) -> str:
         req = self.req
         if self.editable:
-            req = f'-e {req}'
-        return '\n'.join(list(self.comments) + [str(req)]) + '\n'
+            req = f"-e {req}"
+        return "\n".join(list(self.comments) + [str(req)]) + "\n"
```

#### pip/_internal/operations/prepare.py

```diff
@@ -4,114 +4,105 @@
 # The following comment should be removed at some point in the future.
 # mypy: strict-optional=False
 
 import logging
 import mimetypes
 import os
 import shutil
-from typing import Dict, Iterable, List, Optional, Tuple
+from typing import Dict, Iterable, List, Optional
 
 from pip._vendor.packaging.utils import canonicalize_name
-from pip._vendor.pkg_resources import Distribution
 
 from pip._internal.distributions import make_distribution_for_install_requirement
 from pip._internal.distributions.installed import InstalledDistribution
 from pip._internal.exceptions import (
     DirectoryUrlHashUnsupported,
     HashMismatch,
     HashUnpinned,
     InstallationError,
     NetworkConnectionError,
     PreviousBuildDirError,
     VcsHashUnsupported,
 )
 from pip._internal.index.package_finder import PackageFinder
+from pip._internal.metadata import BaseDistribution
 from pip._internal.models.link import Link
 from pip._internal.models.wheel import Wheel
 from pip._internal.network.download import BatchDownloader, Downloader
 from pip._internal.network.lazy_wheel import (
     HTTPRangeRequestUnsupported,
     dist_from_wheel_url,
 )
 from pip._internal.network.session import PipSession
 from pip._internal.req.req_install import InstallRequirement
 from pip._internal.req.req_tracker import RequirementTracker
-from pip._internal.utils.deprecation import deprecated
 from pip._internal.utils.filesystem import copy2_fixed
 from pip._internal.utils.hashes import Hashes, MissingHashes
 from pip._internal.utils.logging import indent_log
 from pip._internal.utils.misc import display_path, hide_url, is_installable_dir, rmtree
 from pip._internal.utils.temp_dir import TempDirectory
 from pip._internal.utils.unpacking import unpack_file
 from pip._internal.vcs import vcs
 
 logger = logging.getLogger(__name__)
 
 
 def _get_prepared_distribution(
-    req,  # type: InstallRequirement
-    req_tracker,  # type: RequirementTracker
-    finder,  # type: PackageFinder
-    build_isolation,  # type: bool
-):
-    # type: (...) -> Distribution
+    req: InstallRequirement,
+    req_tracker: RequirementTracker,
+    finder: PackageFinder,
+    build_isolation: bool,
+) -> BaseDistribution:
     """Prepare a distribution for installation."""
     abstract_dist = make_distribution_for_install_requirement(req)
     with req_tracker.track(req):
         abstract_dist.prepare_distribution_metadata(finder, build_isolation)
-    return abstract_dist.get_pkg_resources_distribution()
+    return abstract_dist.get_metadata_distribution()
 
 
-def unpack_vcs_link(link, location):
-    # type: (Link, str) -> None
+def unpack_vcs_link(link: Link, location: str) -> None:
     vcs_backend = vcs.get_backend_for_scheme(link.scheme)
     assert vcs_backend is not None
     vcs_backend.unpack(location, url=hide_url(link.url))
 
 
 class File:
-
-    def __init__(self, path, content_type):
-        # type: (str, Optional[str]) -> None
+    def __init__(self, path: str, content_type: Optional[str]) -> None:
         self.path = path
         if content_type is None:
             self.content_type = mimetypes.guess_type(path)[0]
         else:
             self.content_type = content_type
 
 
 def get_http_url(
-    link,  # type: Link
-    download,  # type: Downloader
-    download_dir=None,  # type: Optional[str]
-    hashes=None,  # type: Optional[Hashes]
-):
-    # type: (...) -> File
+    link: Link,
+    download: Downloader,
+    download_dir: Optional[str] = None,
+    hashes: Optional[Hashes] = None,
+) -> File:
     temp_dir = TempDirectory(kind="unpack", globally_managed=True)
     # If a download dir is specified, is the file already downloaded there?
     already_downloaded_path = None
     if download_dir:
-        already_downloaded_path = _check_download_dir(
-            link, download_dir, hashes
-        )
+        already_downloaded_path = _check_download_dir(link, download_dir, hashes)
 
     if already_downloaded_path:
         from_path = already_downloaded_path
         content_type = None
     else:
         # let's download to a tmp dir
         from_path, content_type = download(link, temp_dir.path)
         if hashes:
             hashes.check_against_path(from_path)
 
     return File(from_path, content_type)
 
 
-def _copy2_ignoring_special_files(src, dest):
-    # type: (str, str) -> None
+def _copy2_ignoring_special_files(src: str, dest: str) -> None:
     """Copying special files is not supported, but as a convenience to users
     we skip errors copying them. This supports tools that may create e.g.
     socket files in the project source directory.
     """
     try:
         copy2_fixed(src, dest)
     except shutil.SpecialFileError as e:
@@ -123,29 +114,27 @@
             "Ignoring special file error '%s' encountered copying %s to %s.",
             str(e),
             src,
             dest,
         )
 
 
-def _copy_source_tree(source, target):
-    # type: (str, str) -> None
+def _copy_source_tree(source: str, target: str) -> None:
     target_abspath = os.path.abspath(target)
     target_basename = os.path.basename(target_abspath)
     target_dirname = os.path.dirname(target_abspath)
 
-    def ignore(d, names):
-        # type: (str, List[str]) -> List[str]
-        skipped = []  # type: List[str]
+    def ignore(d: str, names: List[str]) -> List[str]:
+        skipped: List[str] = []
         if d == source:
             # Pulling in those directories can potentially be very slow,
             # exclude the following directories if they appear in the top
             # level dir (and only it).
             # See discussion at https://github.com/pypa/pip/pull/6770
-            skipped += ['.tox', '.nox']
+            skipped += [".tox", ".nox"]
         if os.path.abspath(d) == target_dirname:
             # Prevent an infinite recursion if the target is in source.
             # This can happen when TMPDIR is set to ${PWD}/...
             # and we copy PWD to TMPDIR.
             skipped += [target_basename]
         return skipped
 
@@ -155,27 +144,21 @@
         ignore=ignore,
         symlinks=True,
         copy_function=_copy2_ignoring_special_files,
     )
 
 
 def get_file_url(
-    link,  # type: Link
-    download_dir=None,  # type: Optional[str]
-    hashes=None  # type: Optional[Hashes]
-):
-    # type: (...) -> File
-    """Get file and optionally check its hash.
-    """
+    link: Link, download_dir: Optional[str] = None, hashes: Optional[Hashes] = None
+) -> File:
+    """Get file and optionally check its hash."""
     # If a download dir is specified, is the file already there and valid?
     already_downloaded_path = None
     if download_dir:
-        already_downloaded_path = _check_download_dir(
-            link, download_dir, hashes
-        )
+        already_downloaded_path = _check_download_dir(link, download_dir, hashes)
 
     if already_downloaded_path:
         from_path = already_downloaded_path
     else:
         from_path = link.file_path
 
     # If --require-hashes is off, `hashes` is either empty, the
@@ -185,21 +168,20 @@
     # one; no internet-sourced hash will be in `hashes`.
     if hashes:
         hashes.check_against_path(from_path)
     return File(from_path, None)
 
 
 def unpack_url(
-    link,  # type: Link
-    location,  # type: str
-    download,  # type: Downloader
-    download_dir=None,  # type: Optional[str]
-    hashes=None,  # type: Optional[Hashes]
-):
-    # type: (...) -> Optional[File]
+    link: Link,
+    location: str,
+    download: Downloader,
+    download_dir: Optional[str] = None,
+    hashes: Optional[Hashes] = None,
+) -> Optional[File]:
     """Unpack link into location, downloading if required.
 
     :param hashes: A Hashes object, one of whose embedded hashes must match,
         or HashMismatch will be raised. If the Hashes is empty, no matches are
         required, and unhashable types of requirements (like VCS ones, which
         would ordinarily raise HashUnsupported) are allowed.
     """
@@ -210,25 +192,17 @@
 
     # Once out-of-tree-builds are no longer supported, could potentially
     # replace the below condition with `assert not link.is_existing_dir`
     # - unpack_url does not need to be called for in-tree-builds.
     #
     # As further cleanup, _copy_source_tree and accompanying tests can
     # be removed.
+    #
+    # TODO when use-deprecated=out-of-tree-build is removed
     if link.is_existing_dir():
-        deprecated(
-            "A future pip version will change local packages to be built "
-            "in-place without first copying to a temporary directory. "
-            "We recommend you use --use-feature=in-tree-build to test "
-            "your packages with this new behavior before it becomes the "
-            "default.\n",
-            replacement=None,
-            gone_in="21.3",
-            issue=7555
-        )
         if os.path.isdir(location):
             rmtree(location)
         _copy_source_tree(link.file_path, location)
         return None
 
     # file urls
     if link.is_file:
@@ -247,60 +221,58 @@
     # archives, they have to be unpacked to parse dependencies, except wheels
     if not link.is_wheel:
         unpack_file(file.path, location, file.content_type)
 
     return file
 
 
-def _check_download_dir(link, download_dir, hashes):
-    # type: (Link, str, Optional[Hashes]) -> Optional[str]
-    """ Check download_dir for previously downloaded file with correct hash
-        If a correct file is found return its path else None
+def _check_download_dir(
+    link: Link, download_dir: str, hashes: Optional[Hashes]
+) -> Optional[str]:
+    """Check download_dir for previously downloaded file with correct hash
+    If a correct file is found return its path else None
     """
     download_path = os.path.join(download_dir, link.filename)
 
     if not os.path.exists(download_path):
         return None
 
     # If already downloaded, does its hash match?
-    logger.info('File was already downloaded %s', download_path)
+    logger.info("File was already downloaded %s", download_path)
     if hashes:
         try:
             hashes.check_against_path(download_path)
         except HashMismatch:
             logger.warning(
-                'Previously-downloaded file %s has bad hash. '
-                'Re-downloading.',
-                download_path
+                "Previously-downloaded file %s has bad hash. Re-downloading.",
+                download_path,
             )
             os.unlink(download_path)
             return None
     return download_path
 
 
 class RequirementPreparer:
-    """Prepares a Requirement
-    """
+    """Prepares a Requirement"""
 
     def __init__(
         self,
-        build_dir,  # type: str
-        download_dir,  # type: Optional[str]
-        src_dir,  # type: str
-        build_isolation,  # type: bool
-        req_tracker,  # type: RequirementTracker
-        session,  # type: PipSession
-        progress_bar,  # type: str
-        finder,  # type: PackageFinder
-        require_hashes,  # type: bool
-        use_user_site,  # type: bool
-        lazy_wheel,  # type: bool
-        in_tree_build,  # type: bool
-    ):
-        # type: (...) -> None
+        build_dir: str,
+        download_dir: Optional[str],
+        src_dir: str,
+        build_isolation: bool,
+        req_tracker: RequirementTracker,
+        session: PipSession,
+        progress_bar: str,
+        finder: PackageFinder,
+        require_hashes: bool,
+        use_user_site: bool,
+        lazy_wheel: bool,
+        in_tree_build: bool,
+    ) -> None:
         super().__init__()
 
         self.src_dir = src_dir
         self.build_dir = build_dir
         self.req_tracker = req_tracker
         self._session = session
         self._download = Downloader(session, progress_bar)
@@ -322,22 +294,21 @@
 
         # Should wheels be downloaded lazily?
         self.use_lazy_wheel = lazy_wheel
 
         # Should in-tree builds be used for local paths?
         self.in_tree_build = in_tree_build
 
-        # Memoized downloaded files, as mapping of url: (path, mime type)
-        self._downloaded = {}  # type: Dict[str, Tuple[str, str]]
+        # Memoized downloaded files, as mapping of url: path.
+        self._downloaded: Dict[str, str] = {}
 
         # Previous "header" printed for a link-based InstallRequirement
         self._previous_requirement_header = ("", "")
 
-    def _log_preparing_link(self, req):
-        # type: (InstallRequirement) -> None
+    def _log_preparing_link(self, req: InstallRequirement) -> None:
         """Provide context for the requirement being prepared."""
         if req.link.is_file and not req.original_link_is_in_wheel_cache:
             message = "Processing %s"
             information = str(display_path(req.link.file_path))
         else:
             message = "Collecting %s"
             information = str(req.req or req)
@@ -346,16 +317,17 @@
             self._previous_requirement_header = (message, information)
             logger.info(message, information)
 
         if req.original_link_is_in_wheel_cache:
             with indent_log():
                 logger.info("Using cached %s", req.link.filename)
 
-    def _ensure_link_req_src_dir(self, req, parallel_builds):
-        # type: (InstallRequirement, bool) -> None
+    def _ensure_link_req_src_dir(
+        self, req: InstallRequirement, parallel_builds: bool
+    ) -> None:
         """Ensure source_dir of a linked InstallRequirement."""
         # Since source_dir is only set for editable requirements.
         if req.link.is_wheel:
             # We don't need to unpack wheels, so no need for a source
             # directory.
             return
         assert req.source_dir is None
@@ -372,25 +344,25 @@
         )
 
         # If a checkout exists, it's unwise to keep going.  version
         # inconsistencies are logged later, but do not fail the
         # installation.
         # FIXME: this won't upgrade when there's an existing
         # package unpacked in `req.source_dir`
+        # TODO: this check is now probably dead code
         if is_installable_dir(req.source_dir):
             raise PreviousBuildDirError(
                 "pip can't proceed with requirements '{}' due to a"
                 "pre-existing build directory ({}). This is likely "
                 "due to a previous installation that failed . pip is "
                 "being responsible and not assuming it can delete this. "
                 "Please delete it and try again.".format(req, req.source_dir)
             )
 
-    def _get_linked_req_hashes(self, req):
-        # type: (InstallRequirement) -> Hashes
+    def _get_linked_req_hashes(self, req: InstallRequirement) -> Hashes:
         # By the time this is called, the requirement's link should have
         # been checked so we can tell what kind of requirements req is
         # and raise some more informative errors than otherwise.
         # (For example, we can raise VcsHashUnsupported for a VCS URL
         # rather than HashMissing.)
         if not self.require_hashes:
             return req.hashes(trust_internet=True)
@@ -414,58 +386,59 @@
 
         # If known-good hashes are missing for this requirement,
         # shim it with a facade object that will provoke hash
         # computation and then raise a HashMissing exception
         # showing the user what the hash should be.
         return req.hashes(trust_internet=False) or MissingHashes()
 
-    def _fetch_metadata_using_lazy_wheel(self, link):
-        # type: (Link) -> Optional[Distribution]
+    def _fetch_metadata_using_lazy_wheel(
+        self,
+        link: Link,
+    ) -> Optional[BaseDistribution]:
         """Fetch metadata using lazy wheel, if possible."""
         if not self.use_lazy_wheel:
             return None
         if self.require_hashes:
-            logger.debug('Lazy wheel is not used as hash checking is required')
+            logger.debug("Lazy wheel is not used as hash checking is required")
             return None
         if link.is_file or not link.is_wheel:
             logger.debug(
-                'Lazy wheel is not used as '
-                '%r does not points to a remote wheel',
+                "Lazy wheel is not used as %r does not points to a remote wheel",
                 link,
             )
             return None
 
         wheel = Wheel(link.filename)
         name = canonicalize_name(wheel.name)
         logger.info(
-            'Obtaining dependency information from %s %s',
-            name, wheel.version,
+            "Obtaining dependency information from %s %s",
+            name,
+            wheel.version,
         )
-        url = link.url.split('#', 1)[0]
+        url = link.url.split("#", 1)[0]
         try:
             return dist_from_wheel_url(name, url, self._session)
         except HTTPRangeRequestUnsupported:
-            logger.debug('%s does not support range requests', url)
+            logger.debug("%s does not support range requests", url)
             return None
 
     def _complete_partial_requirements(
         self,
-        partially_downloaded_reqs,  # type: Iterable[InstallRequirement]
-        parallel_builds=False,      # type: bool
-    ):
-        # type: (...) -> None
+        partially_downloaded_reqs: Iterable[InstallRequirement],
+        parallel_builds: bool = False,
+    ) -> None:
         """Download any requirements which were only fetched by metadata."""
         # Download to a temporary directory. These will be copied over as
         # needed for downstream 'download', 'wheel', and 'install' commands.
         temp_dir = TempDirectory(kind="unpack", globally_managed=True).path
 
         # Map each link to the requirement that owns it. This allows us to set
         # `req.local_file_path` on the appropriate requirement after passing
         # all the links at once into BatchDownloader.
-        links_to_fully_download = {}  # type: Dict[Link, InstallRequirement]
+        links_to_fully_download: Dict[Link, InstallRequirement] = {}
         for req in partially_downloaded_reqs:
             assert req.link
             links_to_fully_download[req.link] = req
 
         batch_download = self._batch_download(
             links_to_fully_download.keys(),
             temp_dir,
@@ -476,180 +449,184 @@
             req.local_file_path = filepath
 
         # This step is necessary to ensure all lazy wheels are processed
         # successfully by the 'download', 'wheel', and 'install' commands.
         for req in partially_downloaded_reqs:
             self._prepare_linked_requirement(req, parallel_builds)
 
-    def prepare_linked_requirement(self, req, parallel_builds=False):
-        # type: (InstallRequirement, bool) -> Distribution
+    def prepare_linked_requirement(
+        self, req: InstallRequirement, parallel_builds: bool = False
+    ) -> BaseDistribution:
         """Prepare a requirement to be obtained from req.link."""
         assert req.link
         link = req.link
         self._log_preparing_link(req)
         with indent_log():
             # Check if the relevant file is already available
             # in the download directory
             file_path = None
             if self.download_dir is not None and link.is_wheel:
                 hashes = self._get_linked_req_hashes(req)
                 file_path = _check_download_dir(req.link, self.download_dir, hashes)
 
             if file_path is not None:
                 # The file is already available, so mark it as downloaded
-                self._downloaded[req.link.url] = file_path, None
+                self._downloaded[req.link.url] = file_path
             else:
                 # The file is not available, attempt to fetch only metadata
                 wheel_dist = self._fetch_metadata_using_lazy_wheel(link)
                 if wheel_dist is not None:
                     req.needs_more_preparation = True
                     return wheel_dist
 
             # None of the optimizations worked, fully prepare the requirement
             return self._prepare_linked_requirement(req, parallel_builds)
 
-    def prepare_linked_requirements_more(self, reqs, parallel_builds=False):
-        # type: (Iterable[InstallRequirement], bool) -> None
+    def prepare_linked_requirements_more(
+        self, reqs: Iterable[InstallRequirement], parallel_builds: bool = False
+    ) -> None:
         """Prepare linked requirements more, if needed."""
         reqs = [req for req in reqs if req.needs_more_preparation]
         for req in reqs:
             # Determine if any of these requirements were already downloaded.
             if self.download_dir is not None and req.link.is_wheel:
                 hashes = self._get_linked_req_hashes(req)
                 file_path = _check_download_dir(req.link, self.download_dir, hashes)
                 if file_path is not None:
-                    self._downloaded[req.link.url] = file_path, None
+                    self._downloaded[req.link.url] = file_path
                     req.needs_more_preparation = False
 
         # Prepare requirements we found were already downloaded for some
         # reason. The other downloads will be completed separately.
-        partially_downloaded_reqs = []  # type: List[InstallRequirement]
+        partially_downloaded_reqs: List[InstallRequirement] = []
         for req in reqs:
             if req.needs_more_preparation:
                 partially_downloaded_reqs.append(req)
             else:
                 self._prepare_linked_requirement(req, parallel_builds)
 
         # TODO: separate this part out from RequirementPreparer when the v1
         # resolver can be removed!
         self._complete_partial_requirements(
-            partially_downloaded_reqs, parallel_builds=parallel_builds,
+            partially_downloaded_reqs,
+            parallel_builds=parallel_builds,
         )
 
-    def _prepare_linked_requirement(self, req, parallel_builds):
-        # type: (InstallRequirement, bool) -> Distribution
+    def _prepare_linked_requirement(
+        self, req: InstallRequirement, parallel_builds: bool
+    ) -> BaseDistribution:
         assert req.link
         link = req.link
 
         self._ensure_link_req_src_dir(req, parallel_builds)
         hashes = self._get_linked_req_hashes(req)
 
         if link.is_existing_dir() and self.in_tree_build:
             local_file = None
         elif link.url not in self._downloaded:
             try:
                 local_file = unpack_url(
-                    link, req.source_dir, self._download,
-                    self.download_dir, hashes
+                    link, req.source_dir, self._download, self.download_dir, hashes
                 )
             except NetworkConnectionError as exc:
                 raise InstallationError(
-                    'Could not install requirement {} because of HTTP '
-                    'error {} for URL {}'.format(req, exc, link)
+                    "Could not install requirement {} because of HTTP "
+                    "error {} for URL {}".format(req, exc, link)
                 )
         else:
-            file_path, content_type = self._downloaded[link.url]
+            file_path = self._downloaded[link.url]
             if hashes:
                 hashes.check_against_path(file_path)
-            local_file = File(file_path, content_type)
+            local_file = File(file_path, content_type=None)
 
         # For use in later processing,
         # preserve the file path on the requirement.
         if local_file:
             req.local_file_path = local_file.path
 
         dist = _get_prepared_distribution(
-            req, self.req_tracker, self.finder, self.build_isolation,
+            req,
+            self.req_tracker,
+            self.finder,
+            self.build_isolation,
         )
         return dist
 
-    def save_linked_requirement(self, req):
-        # type: (InstallRequirement) -> None
+    def save_linked_requirement(self, req: InstallRequirement) -> None:
         assert self.download_dir is not None
         assert req.link is not None
         link = req.link
         if link.is_vcs or (link.is_existing_dir() and req.editable):
             # Make a .zip of the source_dir we already created.
             req.archive(self.download_dir)
             return
 
         if link.is_existing_dir():
             logger.debug(
-                'Not copying link to destination directory '
-                'since it is a directory: %s', link,
+                "Not copying link to destination directory "
+                "since it is a directory: %s",
+                link,
             )
             return
         if req.local_file_path is None:
             # No distribution was downloaded for this requirement.
             return
 
         download_location = os.path.join(self.download_dir, link.filename)
         if not os.path.exists(download_location):
             shutil.copy(req.local_file_path, download_location)
             download_path = display_path(download_location)
-            logger.info('Saved %s', download_path)
+            logger.info("Saved %s", download_path)
 
     def prepare_editable_requirement(
         self,
-        req,  # type: InstallRequirement
-    ):
-        # type: (...) -> Distribution
-        """Prepare an editable requirement
-        """
+        req: InstallRequirement,
+    ) -> BaseDistribution:
+        """Prepare an editable requirement."""
         assert req.editable, "cannot prepare a non-editable req as editable"
 
-        logger.info('Obtaining %s', req)
+        logger.info("Obtaining %s", req)
 
         with indent_log():
             if self.require_hashes:
                 raise InstallationError(
-                    'The editable requirement {} cannot be installed when '
-                    'requiring hashes, because there is no single file to '
-                    'hash.'.format(req)
+                    "The editable requirement {} cannot be installed when "
+                    "requiring hashes, because there is no single file to "
+                    "hash.".format(req)
                 )
             req.ensure_has_source_dir(self.src_dir)
             req.update_editable()
 
             dist = _get_prepared_distribution(
-                req, self.req_tracker, self.finder, self.build_isolation,
+                req,
+                self.req_tracker,
+                self.finder,
+                self.build_isolation,
             )
 
             req.check_if_exists(self.use_user_site)
 
         return dist
 
     def prepare_installed_requirement(
         self,
-        req,  # type: InstallRequirement
-        skip_reason  # type: str
-    ):
-        # type: (...) -> Distribution
-        """Prepare an already-installed requirement
-        """
+        req: InstallRequirement,
+        skip_reason: str,
+    ) -> BaseDistribution:
+        """Prepare an already-installed requirement."""
         assert req.satisfied_by, "req should have been satisfied but isn't"
         assert skip_reason is not None, (
             "did not get skip reason skipped but req.satisfied_by "
             "is set to {}".format(req.satisfied_by)
         )
         logger.info(
-            'Requirement %s: %s (%s)',
-            skip_reason, req, req.satisfied_by.version
+            "Requirement %s: %s (%s)", skip_reason, req, req.satisfied_by.version
         )
         with indent_log():
             if self.require_hashes:
                 logger.debug(
-                    'Since it is already installed, we are trusting this '
-                    'package without checking its hash. To ensure a '
-                    'completely repeatable environment, install into an '
-                    'empty virtualenv.'
+                    "Since it is already installed, we are trusting this "
+                    "package without checking its hash. To ensure a "
+                    "completely repeatable environment, install into an "
+                    "empty virtualenv."
                 )
-            return InstalledDistribution(req).get_pkg_resources_distribution()
+            return InstalledDistribution(req).get_metadata_distribution()
```

#### pip/_internal/operations/build/metadata.py

```diff
@@ -6,30 +6,25 @@
 from pip._vendor.pep517.wrappers import Pep517HookCaller
 
 from pip._internal.build_env import BuildEnvironment
 from pip._internal.utils.subprocess import runner_with_spinner_message
 from pip._internal.utils.temp_dir import TempDirectory
 
 
-def generate_metadata(build_env, backend):
-    # type: (BuildEnvironment, Pep517HookCaller) -> str
+def generate_metadata(build_env: BuildEnvironment, backend: Pep517HookCaller) -> str:
     """Generate metadata using mechanisms described in PEP 517.
 
     Returns the generated metadata directory.
     """
-    metadata_tmpdir = TempDirectory(
-        kind="modern-metadata", globally_managed=True
-    )
+    metadata_tmpdir = TempDirectory(kind="modern-metadata", globally_managed=True)
 
     metadata_dir = metadata_tmpdir.path
 
     with build_env:
         # Note that Pep517HookCaller implements a fallback for
         # prepare_metadata_for_build_wheel, so we don't have to
         # consider the possibility that this hook doesn't exist.
-        runner = runner_with_spinner_message("Preparing wheel metadata")
+        runner = runner_with_spinner_message("Preparing metadata (pyproject.toml)")
         with backend.subprocess_runner(runner):
-            distinfo_dir = backend.prepare_metadata_for_build_wheel(
-                metadata_dir
-            )
+            distinfo_dir = backend.prepare_metadata_for_build_wheel(metadata_dir)
 
     return os.path.join(metadata_dir, distinfo_dir)
```

#### pip/_internal/operations/build/metadata_legacy.py

```diff
@@ -1,74 +1,67 @@
 """Metadata generation logic for legacy source distributions.
 """
 
 import logging
 import os
 
 from pip._internal.build_env import BuildEnvironment
+from pip._internal.cli.spinners import open_spinner
 from pip._internal.exceptions import InstallationError
 from pip._internal.utils.setuptools_build import make_setuptools_egg_info_args
 from pip._internal.utils.subprocess import call_subprocess
 from pip._internal.utils.temp_dir import TempDirectory
 
 logger = logging.getLogger(__name__)
 
 
-def _find_egg_info(directory):
-    # type: (str) -> str
-    """Find an .egg-info subdirectory in `directory`.
-    """
-    filenames = [
-        f for f in os.listdir(directory) if f.endswith(".egg-info")
-    ]
+def _find_egg_info(directory: str) -> str:
+    """Find an .egg-info subdirectory in `directory`."""
+    filenames = [f for f in os.listdir(directory) if f.endswith(".egg-info")]
 
     if not filenames:
-        raise InstallationError(
-            f"No .egg-info directory found in {directory}"
-        )
+        raise InstallationError(f"No .egg-info directory found in {directory}")
 
     if len(filenames) > 1:
         raise InstallationError(
-            "More than one .egg-info directory found in {}".format(
-                directory
-            )
+            "More than one .egg-info directory found in {}".format(directory)
         )
 
     return os.path.join(directory, filenames[0])
 
 
 def generate_metadata(
-    build_env,  # type: BuildEnvironment
-    setup_py_path,  # type: str
-    source_dir,  # type: str
-    isolated,  # type: bool
-    details,  # type: str
-):
-    # type: (...) -> str
+    build_env: BuildEnvironment,
+    setup_py_path: str,
+    source_dir: str,
+    isolated: bool,
+    details: str,
+) -> str:
     """Generate metadata using setup.py-based defacto mechanisms.
 
     Returns the generated metadata directory.
     """
     logger.debug(
-        'Running setup.py (path:%s) egg_info for package %s',
-        setup_py_path, details,
+        "Running setup.py (path:%s) egg_info for package %s",
+        setup_py_path,
+        details,
     )
 
-    egg_info_dir = TempDirectory(
-        kind="pip-egg-info", globally_managed=True
-    ).path
+    egg_info_dir = TempDirectory(kind="pip-egg-info", globally_managed=True).path
 
     args = make_setuptools_egg_info_args(
         setup_py_path,
         egg_info_dir=egg_info_dir,
         no_user_config=isolated,
     )
 
     with build_env:
-        call_subprocess(
-            args,
-            cwd=source_dir,
-            command_desc='python setup.py egg_info',
-        )
+        with open_spinner("Preparing metadata (setup.py)") as spinner:
+            call_subprocess(
+                args,
+                cwd=source_dir,
+                command_desc="python setup.py egg_info",
+                spinner=spinner,
+            )
 
     # Return the .egg-info directory.
     return _find_egg_info(egg_info_dir)
```

#### pip/_internal/operations/build/wheel.py

```diff
@@ -6,33 +6,32 @@
 
 from pip._internal.utils.subprocess import runner_with_spinner_message
 
 logger = logging.getLogger(__name__)
 
 
 def build_wheel_pep517(
-    name,  # type: str
-    backend,  # type: Pep517HookCaller
-    metadata_directory,  # type: str
-    tempd,  # type: str
-):
-    # type: (...) -> Optional[str]
+    name: str,
+    backend: Pep517HookCaller,
+    metadata_directory: str,
+    tempd: str,
+) -> Optional[str]:
     """Build one InstallRequirement using the PEP 517 build process.
 
     Returns path to wheel if successfully built. Otherwise, returns None.
     """
     assert metadata_directory is not None
     try:
-        logger.debug('Destination directory: %s', tempd)
+        logger.debug("Destination directory: %s", tempd)
 
         runner = runner_with_spinner_message(
-            f'Building wheel for {name} (PEP 517)'
+            f"Building wheel for {name} (pyproject.toml)"
         )
         with backend.subprocess_runner(runner):
             wheel_name = backend.build_wheel(
                 tempd,
                 metadata_directory=metadata_directory,
             )
     except Exception:
-        logger.error('Failed building wheel for %s', name)
+        logger.error("Failed building wheel for %s", name)
         return None
     return os.path.join(tempd, wheel_name)
```

#### pip/_internal/operations/build/wheel_legacy.py

```diff
@@ -10,97 +10,92 @@
     format_command_args,
 )
 
 logger = logging.getLogger(__name__)
 
 
 def format_command_result(
-    command_args,  # type: List[str]
-    command_output,  # type: str
-):
-    # type: (...) -> str
+    command_args: List[str],
+    command_output: str,
+) -> str:
     """Format command information for logging."""
     command_desc = format_command_args(command_args)
-    text = f'Command arguments: {command_desc}\n'
+    text = f"Command arguments: {command_desc}\n"
 
     if not command_output:
-        text += 'Command output: None'
+        text += "Command output: None"
     elif logger.getEffectiveLevel() > logging.DEBUG:
-        text += 'Command output: [use --verbose to show]'
+        text += "Command output: [use --verbose to show]"
     else:
-        if not command_output.endswith('\n'):
-            command_output += '\n'
-        text += f'Command output:\n{command_output}{LOG_DIVIDER}'
+        if not command_output.endswith("\n"):
+            command_output += "\n"
+        text += f"Command output:\n{command_output}{LOG_DIVIDER}"
 
     return text
 
 
 def get_legacy_build_wheel_path(
-    names,  # type: List[str]
-    temp_dir,  # type: str
-    name,  # type: str
-    command_args,  # type: List[str]
-    command_output,  # type: str
-):
-    # type: (...) -> Optional[str]
+    names: List[str],
+    temp_dir: str,
+    name: str,
+    command_args: List[str],
+    command_output: str,
+) -> Optional[str]:
     """Return the path to the wheel in the temporary build directory."""
     # Sort for determinism.
     names = sorted(names)
     if not names:
-        msg = (
-            'Legacy build of wheel for {!r} created no files.\n'
-        ).format(name)
+        msg = ("Legacy build of wheel for {!r} created no files.\n").format(name)
         msg += format_command_result(command_args, command_output)
         logger.warning(msg)
         return None
 
     if len(names) > 1:
         msg = (
-            'Legacy build of wheel for {!r} created more than one file.\n'
-            'Filenames (choosing first): {}\n'
+            "Legacy build of wheel for {!r} created more than one file.\n"
+            "Filenames (choosing first): {}\n"
         ).format(name, names)
         msg += format_command_result(command_args, command_output)
         logger.warning(msg)
 
     return os.path.join(temp_dir, names[0])
 
 
 def build_wheel_legacy(
-    name,  # type: str
-    setup_py_path,  # type: str
-    source_dir,  # type: str
-    global_options,  # type: List[str]
-    build_options,  # type: List[str]
-    tempd,  # type: str
-):
-    # type: (...) -> Optional[str]
+    name: str,
+    setup_py_path: str,
+    source_dir: str,
+    global_options: List[str],
+    build_options: List[str],
+    tempd: str,
+) -> Optional[str]:
     """Build one unpacked package using the "legacy" build process.
 
     Returns path to wheel if successfully built. Otherwise, returns None.
     """
     wheel_args = make_setuptools_bdist_wheel_args(
         setup_py_path,
         global_options=global_options,
         build_options=build_options,
         destination_dir=tempd,
     )
 
-    spin_message = f'Building wheel for {name} (setup.py)'
+    spin_message = f"Building wheel for {name} (setup.py)"
     with open_spinner(spin_message) as spinner:
-        logger.debug('Destination directory: %s', tempd)
+        logger.debug("Destination directory: %s", tempd)
 
         try:
             output = call_subprocess(
                 wheel_args,
                 cwd=source_dir,
                 spinner=spinner,
             )
         except Exception:
             spinner.finish("error")
-            logger.error('Failed building wheel for %s', name)
+            logger.error("Failed building wheel for %s", name)
             return None
 
         names = os.listdir(tempd)
         wheel_path = get_legacy_build_wheel_path(
             names=names,
             temp_dir=tempd,
             name=name,
```

#### pip/_internal/operations/install/editable_legacy.py

```diff
@@ -8,30 +8,29 @@
 from pip._internal.utils.setuptools_build import make_setuptools_develop_args
 from pip._internal.utils.subprocess import call_subprocess
 
 logger = logging.getLogger(__name__)
 
 
 def install_editable(
-    install_options,  # type: List[str]
-    global_options,  # type: Sequence[str]
-    prefix,  # type: Optional[str]
-    home,  # type: Optional[str]
-    use_user_site,  # type: bool
-    name,  # type: str
-    setup_py_path,  # type: str
-    isolated,  # type: bool
-    build_env,  # type: BuildEnvironment
-    unpacked_source_directory,  # type: str
-):
-    # type: (...) -> None
+    install_options: List[str],
+    global_options: Sequence[str],
+    prefix: Optional[str],
+    home: Optional[str],
+    use_user_site: bool,
+    name: str,
+    setup_py_path: str,
+    isolated: bool,
+    build_env: BuildEnvironment,
+    unpacked_source_directory: str,
+) -> None:
     """Install a package in editable mode. Most arguments are pass-through
     to setuptools.
     """
-    logger.info('Running setup.py develop for %s', name)
+    logger.info("Running setup.py develop for %s", name)
 
     args = make_setuptools_develop_args(
         setup_py_path,
         global_options=global_options,
         install_options=install_options,
         no_user_config=isolated,
         prefix=prefix,
```

#### pip/_internal/operations/install/legacy.py

```diff
@@ -1,13 +1,12 @@
 """Legacy installation process, i.e. `setup.py install`.
 """
 
 import logging
 import os
-import sys
 from distutils.util import change_root
 from typing import List, Optional, Sequence
 
 from pip._internal.build_env import BuildEnvironment
 from pip._internal.exceptions import InstallationError
 from pip._internal.models.scheme import Scheme
 from pip._internal.utils.logging import indent_log
@@ -16,34 +15,31 @@
 from pip._internal.utils.subprocess import runner_with_spinner_message
 from pip._internal.utils.temp_dir import TempDirectory
 
 logger = logging.getLogger(__name__)
 
 
 class LegacyInstallFailure(Exception):
-    def __init__(self):
-        # type: () -> None
-        self.parent = sys.exc_info()
+    pass
 
 
 def write_installed_files_from_setuptools_record(
     record_lines: List[str],
     root: Optional[str],
     req_description: str,
 ) -> None:
-    def prepend_root(path):
-        # type: (str) -> str
+    def prepend_root(path: str) -> str:
         if root is None or not os.path.isabs(path):
             return path
         else:
             return change_root(root, path)
 
     for line in record_lines:
         directory = os.path.dirname(line)
-        if directory.endswith('.egg-info'):
+        if directory.endswith(".egg-info"):
             egg_info_dir = prepend_root(directory)
             break
     else:
         message = (
             "{} did not indicate that it installed an "
             ".egg-info directory. Only setup.py projects "
             "generating .egg-info directories are supported."
@@ -51,47 +47,44 @@
         raise InstallationError(message)
 
     new_lines = []
     for line in record_lines:
         filename = line.strip()
         if os.path.isdir(filename):
             filename += os.path.sep
-        new_lines.append(
-            os.path.relpath(prepend_root(filename), egg_info_dir)
-        )
+        new_lines.append(os.path.relpath(prepend_root(filename), egg_info_dir))
     new_lines.sort()
     ensure_dir(egg_info_dir)
-    inst_files_path = os.path.join(egg_info_dir, 'installed-files.txt')
-    with open(inst_files_path, 'w') as f:
-        f.write('\n'.join(new_lines) + '\n')
+    inst_files_path = os.path.join(egg_info_dir, "installed-files.txt")
+    with open(inst_files_path, "w") as f:
+        f.write("\n".join(new_lines) + "\n")
 
 
 def install(
-    install_options,  # type: List[str]
-    global_options,  # type: Sequence[str]
-    root,  # type: Optional[str]
-    home,  # type: Optional[str]
-    prefix,  # type: Optional[str]
-    use_user_site,  # type: bool
-    pycompile,  # type: bool
-    scheme,  # type: Scheme
-    setup_py_path,  # type: str
-    isolated,  # type: bool
-    req_name,  # type: str
-    build_env,  # type: BuildEnvironment
-    unpacked_source_directory,  # type: str
-    req_description,  # type: str
-):
-    # type: (...) -> bool
+    install_options: List[str],
+    global_options: Sequence[str],
+    root: Optional[str],
+    home: Optional[str],
+    prefix: Optional[str],
+    use_user_site: bool,
+    pycompile: bool,
+    scheme: Scheme,
+    setup_py_path: str,
+    isolated: bool,
+    req_name: str,
+    build_env: BuildEnvironment,
+    unpacked_source_directory: str,
+    req_description: str,
+) -> bool:
 
     header_dir = scheme.headers
 
     with TempDirectory(kind="record") as temp_dir:
         try:
-            record_filename = os.path.join(temp_dir.path, 'install-record.txt')
+            record_filename = os.path.join(temp_dir.path, "install-record.txt")
             install_args = make_setuptools_install_args(
                 setup_py_path,
                 global_options=global_options,
                 install_options=install_options,
                 record_filename=record_filename,
                 root=root,
                 prefix=prefix,
@@ -108,21 +101,21 @@
             with indent_log(), build_env:
                 runner(
                     cmd=install_args,
                     cwd=unpacked_source_directory,
                 )
 
             if not os.path.exists(record_filename):
-                logger.debug('Record file %s not found', record_filename)
+                logger.debug("Record file %s not found", record_filename)
                 # Signal to the caller that we didn't install the new package
                 return False
 
-        except Exception:
+        except Exception as e:
             # Signal to the caller that we didn't install the new package
-            raise LegacyInstallFailure
+            raise LegacyInstallFailure from e
 
         # At this point, we have successfully installed the requirement.
 
         # We intentionally do not use any encoding to read the file because
         # setuptools writes the file using distutils.file_util.write_file,
         # which does not specify an encoding.
         with open(record_filename) as f:
```

#### pip/_internal/operations/install/wheel.py

```diff
@@ -34,19 +34,22 @@
     cast,
 )
 from zipfile import ZipFile, ZipInfo
 
 from pip._vendor.distlib.scripts import ScriptMaker
 from pip._vendor.distlib.util import get_export_entry
 from pip._vendor.packaging.utils import canonicalize_name
-from pip._vendor.six import ensure_str, ensure_text, reraise
 
 from pip._internal.exceptions import InstallationError
 from pip._internal.locations import get_major_minor_version
-from pip._internal.metadata import BaseDistribution, get_wheel_distribution
+from pip._internal.metadata import (
+    BaseDistribution,
+    FilesystemWheel,
+    get_wheel_distribution,
+)
 from pip._internal.models.direct_url import DIRECT_URL_METADATA_NAME, DirectUrl
 from pip._internal.models.scheme import SCHEME_KEYS, Scheme
 from pip._internal.utils.filesystem import adjacent_tmp_file, replace
 from pip._internal.utils.misc import captured_stdout, ensure_dir, hash_file, partition
 from pip._internal.utils.unpacking import (
     current_umask,
     is_within_directory,
@@ -55,129 +58,123 @@
 )
 from pip._internal.utils.wheel import parse_wheel
 
 if TYPE_CHECKING:
     from typing import Protocol
 
     class File(Protocol):
-        src_record_path = None  # type: RecordPath
-        dest_path = None  # type: str
-        changed = None  # type: bool
+        src_record_path: "RecordPath"
+        dest_path: str
+        changed: bool
 
-        def save(self):
-            # type: () -> None
+        def save(self) -> None:
             pass
 
 
 logger = logging.getLogger(__name__)
 
-RecordPath = NewType('RecordPath', str)
+RecordPath = NewType("RecordPath", str)
 InstalledCSVRow = Tuple[RecordPath, str, Union[int, str]]
 
 
-def rehash(path, blocksize=1 << 20):
-    # type: (str, int) -> Tuple[str, str]
+def rehash(path: str, blocksize: int = 1 << 20) -> Tuple[str, str]:
     """Return (encoded_digest, length) for path using hashlib.sha256()"""
     h, length = hash_file(path, blocksize)
-    digest = 'sha256=' + urlsafe_b64encode(
-        h.digest()
-    ).decode('latin1').rstrip('=')
+    digest = "sha256=" + urlsafe_b64encode(h.digest()).decode("latin1").rstrip("=")
     return (digest, str(length))
 
 
-def csv_io_kwargs(mode):
-    # type: (str) -> Dict[str, Any]
+def csv_io_kwargs(mode: str) -> Dict[str, Any]:
     """Return keyword arguments to properly open a CSV file
     in the given mode.
     """
-    return {'mode': mode, 'newline': '', 'encoding': 'utf-8'}
+    return {"mode": mode, "newline": "", "encoding": "utf-8"}
 
 
-def fix_script(path):
-    # type: (str) -> bool
+def fix_script(path: str) -> bool:
     """Replace #!python with #!/path/to/python
     Return True if file was changed.
     """
     # XXX RECORD hashes will need to be updated
     assert os.path.isfile(path)
 
-    with open(path, 'rb') as script:
+    with open(path, "rb") as script:
         firstline = script.readline()
-        if not firstline.startswith(b'#!python'):
+        if not firstline.startswith(b"#!python"):
             return False
         exename = sys.executable.encode(sys.getfilesystemencoding())
-        firstline = b'#!' + exename + os.linesep.encode("ascii")
+        firstline = b"#!" + exename + os.linesep.encode("ascii")
         rest = script.read()
-    with open(path, 'wb') as script:
+    with open(path, "wb") as script:
         script.write(firstline)
         script.write(rest)
     return True
 
 
-def wheel_root_is_purelib(metadata):
-    # type: (Message) -> bool
+def wheel_root_is_purelib(metadata: Message) -> bool:
     return metadata.get("Root-Is-Purelib", "").lower() == "true"
 
 
 def get_entrypoints(dist: BaseDistribution) -> Tuple[Dict[str, str], Dict[str, str]]:
     console_scripts = {}
     gui_scripts = {}
     for entry_point in dist.iter_entry_points():
         if entry_point.group == "console_scripts":
             console_scripts[entry_point.name] = entry_point.value
         elif entry_point.group == "gui_scripts":
             gui_scripts[entry_point.name] = entry_point.value
     return console_scripts, gui_scripts
 
 
-def message_about_scripts_not_on_PATH(scripts):
-    # type: (Sequence[str]) -> Optional[str]
+def message_about_scripts_not_on_PATH(scripts: Sequence[str]) -> Optional[str]:
     """Determine if any scripts are not on PATH and format a warning.
     Returns a warning message if one or more scripts are not on PATH,
     otherwise None.
     """
     if not scripts:
         return None
 
     # Group scripts by the path they were installed in
-    grouped_by_dir = collections.defaultdict(set)  # type: Dict[str, Set[str]]
+    grouped_by_dir: Dict[str, Set[str]] = collections.defaultdict(set)
     for destfile in scripts:
         parent_dir = os.path.dirname(destfile)
         script_name = os.path.basename(destfile)
         grouped_by_dir[parent_dir].add(script_name)
 
     # We don't want to warn for directories that are on PATH.
     not_warn_dirs = [
-        os.path.normcase(i).rstrip(os.sep) for i in
-        os.environ.get("PATH", "").split(os.pathsep)
+        os.path.normcase(i).rstrip(os.sep)
+        for i in os.environ.get("PATH", "").split(os.pathsep)
     ]
     # If an executable sits with sys.executable, we don't warn for it.
     #     This covers the case of venv invocations without activating the venv.
     not_warn_dirs.append(os.path.normcase(os.path.dirname(sys.executable)))
-    warn_for = {
-        parent_dir: scripts for parent_dir, scripts in grouped_by_dir.items()
+    warn_for: Dict[str, Set[str]] = {
+        parent_dir: scripts
+        for parent_dir, scripts in grouped_by_dir.items()
         if os.path.normcase(parent_dir) not in not_warn_dirs
-    }  # type: Dict[str, Set[str]]
+    }
     if not warn_for:
         return None
 
     # Format a message
     msg_lines = []
     for parent_dir, dir_scripts in warn_for.items():
-        sorted_scripts = sorted(dir_scripts)  # type: List[str]
+        sorted_scripts: List[str] = sorted(dir_scripts)
         if len(sorted_scripts) == 1:
             start_text = "script {} is".format(sorted_scripts[0])
         else:
             start_text = "scripts {} are".format(
                 ", ".join(sorted_scripts[:-1]) + " and " + sorted_scripts[-1]
             )
 
         msg_lines.append(
-            "The {} installed in '{}' which is not on PATH."
-            .format(start_text, parent_dir)
+            "The {} installed in '{}' which is not on PATH.".format(
+                start_text, parent_dir
+            )
         )
 
     last_line_fmt = (
         "Consider adding {} to PATH or, if you prefer "
         "to suppress this warning, use --no-warn-script-location."
     )
     if len(msg_lines) == 1:
@@ -196,16 +193,17 @@
         )
         msg_lines.append(tilde_warning_msg)
 
     # Returns the formatted multiline message
     return "\n".join(msg_lines)
 
 
-def _normalized_outrows(outrows):
-    # type: (Iterable[InstalledCSVRow]) -> List[Tuple[str, str, str]]
+def _normalized_outrows(
+    outrows: Iterable[InstalledCSVRow],
+) -> List[Tuple[str, str, str]]:
     """Normalize the given rows of a RECORD file.
 
     Items in each row are converted into str. Rows are then sorted to make
     the value more predictable for tests.
 
     Each row is a 3-tuple (path, hash, size) and corresponds to a record of
     a RECORD file (see PEP 376 and PEP 427 for details).  For the rows
@@ -217,77 +215,68 @@
     # However, in cases in the wild where a path might happen to occur twice,
     # we don't want the sort operation to trigger an error (but still want
     # determinism).  Since the third element can be an int or string, we
     # coerce each element to a string to avoid a TypeError in this case.
     # For additional background, see--
     # https://github.com/pypa/pip/issues/5868
     return sorted(
-        (ensure_str(record_path, encoding='utf-8'), hash_, str(size))
-        for record_path, hash_, size in outrows
+        (record_path, hash_, str(size)) for record_path, hash_, size in outrows
     )
 
 
-def _record_to_fs_path(record_path):
-    # type: (RecordPath) -> str
+def _record_to_fs_path(record_path: RecordPath) -> str:
     return record_path
 
 
-def _fs_to_record_path(path, relative_to=None):
-    # type: (str, Optional[str]) -> RecordPath
+def _fs_to_record_path(path: str, relative_to: Optional[str] = None) -> RecordPath:
     if relative_to is not None:
         # On Windows, do not handle relative paths if they belong to different
         # logical disks
-        if os.path.splitdrive(path)[0].lower() == \
-                os.path.splitdrive(relative_to)[0].lower():
+        if (
+            os.path.splitdrive(path)[0].lower()
+            == os.path.splitdrive(relative_to)[0].lower()
+        ):
             path = os.path.relpath(path, relative_to)
-    path = path.replace(os.path.sep, '/')
-    return cast('RecordPath', path)
-
-
-def _parse_record_path(record_column):
-    # type: (str) -> RecordPath
-    p = ensure_text(record_column, encoding='utf-8')
-    return cast('RecordPath', p)
+    path = path.replace(os.path.sep, "/")
+    return cast("RecordPath", path)
 
 
 def get_csv_rows_for_installed(
-    old_csv_rows,  # type: List[List[str]]
-    installed,  # type: Dict[RecordPath, RecordPath]
-    changed,  # type: Set[RecordPath]
-    generated,  # type: List[str]
-    lib_dir,  # type: str
-):
-    # type: (...) -> List[InstalledCSVRow]
+    old_csv_rows: List[List[str]],
+    installed: Dict[RecordPath, RecordPath],
+    changed: Set[RecordPath],
+    generated: List[str],
+    lib_dir: str,
+) -> List[InstalledCSVRow]:
     """
     :param installed: A map from archive RECORD path to installation RECORD
         path.
     """
-    installed_rows = []  # type: List[InstalledCSVRow]
+    installed_rows: List[InstalledCSVRow] = []
     for row in old_csv_rows:
         if len(row) > 3:
-            logger.warning('RECORD line has more than three elements: %s', row)
-        old_record_path = _parse_record_path(row[0])
+            logger.warning("RECORD line has more than three elements: %s", row)
+        old_record_path = cast("RecordPath", row[0])
         new_record_path = installed.pop(old_record_path, old_record_path)
         if new_record_path in changed:
             digest, length = rehash(_record_to_fs_path(new_record_path))
         else:
-            digest = row[1] if len(row) > 1 else ''
-            length = row[2] if len(row) > 2 else ''
+            digest = row[1] if len(row) > 1 else ""
+            length = row[2] if len(row) > 2 else ""
         installed_rows.append((new_record_path, digest, length))
     for f in generated:
         path = _fs_to_record_path(f, lib_dir)
         digest, length = rehash(f)
         installed_rows.append((path, digest, length))
     for installed_record_path in installed.values():
-        installed_rows.append((installed_record_path, '', ''))
+        installed_rows.append((installed_record_path, "", ""))
     return installed_rows
 
 
-def get_console_script_specs(console):
-    # type: (Dict[str, str]) -> List[str]
+def get_console_script_specs(console: Dict[str, str]) -> List[str]:
     """
     Given the mapping from entrypoint name to callable, return the relevant
     console script specs.
     """
     # Don't mutate caller's version
     console = console.copy()
 
@@ -322,70 +311,65 @@
     # ENSUREPIP_OPTIONS=install
     #   - pipX.Y, pipX, easy_install-X.Y will be generated and installed. Note
     #     that this option is technically if ENSUREPIP_OPTIONS is set and is
     #     not altinstall
     # DEFAULT
     #   - The default behavior is to install pip, pipX, pipX.Y, easy_install
     #     and easy_install-X.Y.
-    pip_script = console.pop('pip', None)
+    pip_script = console.pop("pip", None)
     if pip_script:
         if "ENSUREPIP_OPTIONS" not in os.environ:
-            scripts_to_generate.append('pip = ' + pip_script)
+            scripts_to_generate.append("pip = " + pip_script)
 
         if os.environ.get("ENSUREPIP_OPTIONS", "") != "altinstall":
             scripts_to_generate.append(
-                'pip{} = {}'.format(sys.version_info[0], pip_script)
+                "pip{} = {}".format(sys.version_info[0], pip_script)
             )
 
-        scripts_to_generate.append(
-            f'pip{get_major_minor_version()} = {pip_script}'
-        )
+        scripts_to_generate.append(f"pip{get_major_minor_version()} = {pip_script}")
         # Delete any other versioned pip entry points
-        pip_ep = [k for k in console if re.match(r'pip(\d(\.\d)?)?$', k)]
+        pip_ep = [k for k in console if re.match(r"pip(\d(\.\d)?)?$", k)]
         for k in pip_ep:
             del console[k]
-    easy_install_script = console.pop('easy_install', None)
+    easy_install_script = console.pop("easy_install", None)
     if easy_install_script:
         if "ENSUREPIP_OPTIONS" not in os.environ:
-            scripts_to_generate.append(
-                'easy_install = ' + easy_install_script
-            )
+            scripts_to_generate.append("easy_install = " + easy_install_script)
 
         scripts_to_generate.append(
-            'easy_install-{} = {}'.format(
+            "easy_install-{} = {}".format(
                 get_major_minor_version(), easy_install_script
             )
         )
         # Delete any other versioned easy_install entry points
         easy_install_ep = [
-            k for k in console if re.match(r'easy_install(-\d\.\d)?$', k)
+            k for k in console if re.match(r"easy_install(-\d\.\d)?$", k)
         ]
         for k in easy_install_ep:
             del console[k]
 
     # Generate the console entry points specified in the wheel
-    scripts_to_generate.extend(starmap('{} = {}'.format, console.items()))
+    scripts_to_generate.extend(starmap("{} = {}".format, console.items()))
 
     return scripts_to_generate
 
 
 class ZipBackedFile:
-    def __init__(self, src_record_path, dest_path, zip_file):
-        # type: (RecordPath, str, ZipFile) -> None
+    def __init__(
+        self, src_record_path: RecordPath, dest_path: str, zip_file: ZipFile
+    ) -> None:
         self.src_record_path = src_record_path
         self.dest_path = dest_path
         self._zip_file = zip_file
         self.changed = False
 
-    def _getinfo(self):
-        # type: () -> ZipInfo
+    def _getinfo(self) -> ZipInfo:
         return self._zip_file.getinfo(self.src_record_path)
 
-    def save(self):
-        # type: () -> None
+    def save(self) -> None:
         # directory creation is lazy and after file filtering
         # to ensure we don't install empty dirs; empty dirs can't be
         # uninstalled.
         parent_dir = os.path.dirname(self.dest_path)
         ensure_dir(parent_dir)
 
         # When we open the output file below, any existing file is truncated
@@ -406,63 +390,57 @@
                 shutil.copyfileobj(f, dest)
 
         if zip_item_is_executable(zipinfo):
             set_extracted_file_to_default_mode_plus_executable(self.dest_path)
 
 
 class ScriptFile:
-    def __init__(self, file):
-        # type: (File) -> None
+    def __init__(self, file: "File") -> None:
         self._file = file
         self.src_record_path = self._file.src_record_path
         self.dest_path = self._file.dest_path
         self.changed = False
 
-    def save(self):
-        # type: () -> None
+    def save(self) -> None:
         self._file.save()
         self.changed = fix_script(self.dest_path)
 
 
 class MissingCallableSuffix(InstallationError):
-    def __init__(self, entry_point):
-        # type: (str) -> None
+    def __init__(self, entry_point: str) -> None:
         super().__init__(
             "Invalid script entry point: {} - A callable "
             "suffix is required. Cf https://packaging.python.org/"
             "specifications/entry-points/#use-for-scripts for more "
             "information.".format(entry_point)
         )
 
 
-def _raise_for_invalid_entrypoint(specification):
-    # type: (str) -> None
+def _raise_for_invalid_entrypoint(specification: str) -> None:
     entry = get_export_entry(specification)
     if entry is not None and entry.suffix is None:
         raise MissingCallableSuffix(str(entry))
 
 
 class PipScriptMaker(ScriptMaker):
-    def make(self, specification, options=None):
-        # type: (str, Dict[str, Any]) -> List[str]
+    def make(self, specification: str, options: Dict[str, Any] = None) -> List[str]:
         _raise_for_invalid_entrypoint(specification)
         return super().make(specification, options)
 
 
 def _install_wheel(
-    name,  # type: str
-    wheel_zip,  # type: ZipFile
-    wheel_path,  # type: str
-    scheme,  # type: Scheme
-    pycompile=True,  # type: bool
-    warn_script_location=True,  # type: bool
-    direct_url=None,  # type: Optional[DirectUrl]
-    requested=False,  # type: bool
-):
-    # type: (...) -> None
+    name: str,
+    wheel_zip: ZipFile,
+    wheel_path: str,
+    scheme: Scheme,
+    pycompile: bool = True,
+    warn_script_location: bool = True,
+    direct_url: Optional[DirectUrl] = None,
+    requested: bool = False,
+) -> None:
     """Install a wheel.
 
     :param name: Name of the project to install
     :param wheel_zip: open ZipFile for wheel being installed
     :param scheme: Distutils scheme dictating the install directories
     :param req_description: String used in place of the requirement, for
         logging
@@ -481,72 +459,57 @@
     else:
         lib_dir = scheme.platlib
 
     # Record details of the files moved
     #   installed = files copied from the wheel to the destination
     #   changed = files changed while installing (scripts #! line typically)
     #   generated = files newly generated during the install (script wrappers)
-    installed = {}  # type: Dict[RecordPath, RecordPath]
-    changed = set()  # type: Set[RecordPath]
-    generated = []  # type: List[str]
-
-    def record_installed(srcfile, destfile, modified=False):
-        # type: (RecordPath, str, bool) -> None
+    installed: Dict[RecordPath, RecordPath] = {}
+    changed: Set[RecordPath] = set()
+    generated: List[str] = []
+
+    def record_installed(
+        srcfile: RecordPath, destfile: str, modified: bool = False
+    ) -> None:
         """Map archive RECORD paths to installation RECORD paths."""
         newpath = _fs_to_record_path(destfile, lib_dir)
         installed[srcfile] = newpath
         if modified:
             changed.add(_fs_to_record_path(destfile))
 
-    def all_paths():
-        # type: () -> Iterable[RecordPath]
-        names = wheel_zip.namelist()
-        # If a flag is set, names may be unicode in Python 2. We convert to
-        # text explicitly so these are valid for lookup in RECORD.
-        decoded_names = map(ensure_text, names)
-        for name in decoded_names:
-            yield cast("RecordPath", name)
-
-    def is_dir_path(path):
-        # type: (RecordPath) -> bool
+    def is_dir_path(path: RecordPath) -> bool:
         return path.endswith("/")
 
-    def assert_no_path_traversal(dest_dir_path, target_path):
-        # type: (str, str) -> None
+    def assert_no_path_traversal(dest_dir_path: str, target_path: str) -> None:
         if not is_within_directory(dest_dir_path, target_path):
             message = (
                 "The wheel {!r} has a file {!r} trying to install"
                 " outside the target directory {!r}"
             )
             raise InstallationError(
                 message.format(wheel_path, target_path, dest_dir_path)
             )
 
-    def root_scheme_file_maker(zip_file, dest):
-        # type: (ZipFile, str) -> Callable[[RecordPath], File]
-        def make_root_scheme_file(record_path):
-            # type: (RecordPath) -> File
+    def root_scheme_file_maker(
+        zip_file: ZipFile, dest: str
+    ) -> Callable[[RecordPath], "File"]:
+        def make_root_scheme_file(record_path: RecordPath) -> "File":
             normed_path = os.path.normpath(record_path)
             dest_path = os.path.join(dest, normed_path)
             assert_no_path_traversal(dest, dest_path)
             return ZipBackedFile(record_path, dest_path, zip_file)
 
         return make_root_scheme_file
 
-    def data_scheme_file_maker(zip_file, scheme):
-        # type: (ZipFile, Scheme) -> Callable[[RecordPath], File]
-        scheme_paths = {}
-        for key in SCHEME_KEYS:
-            encoded_key = ensure_text(key)
-            scheme_paths[encoded_key] = ensure_text(
-                getattr(scheme, key), encoding=sys.getfilesystemencoding()
-            )
+    def data_scheme_file_maker(
+        zip_file: ZipFile, scheme: Scheme
+    ) -> Callable[[RecordPath], "File"]:
+        scheme_paths = {key: getattr(scheme, key) for key in SCHEME_KEYS}
 
-        def make_data_scheme_file(record_path):
-            # type: (RecordPath) -> File
+        def make_data_scheme_file(record_path: RecordPath) -> "File":
             normed_path = os.path.normpath(record_path)
             try:
                 _, scheme_key, dest_subpath = normed_path.split(os.path.sep, 2)
             except ValueError:
                 message = (
                     "Unexpected file in {}: {!r}. .data directory contents"
                     " should be named like: '<scheme key>/<path>'."
@@ -557,124 +520,103 @@
                 scheme_path = scheme_paths[scheme_key]
             except KeyError:
                 valid_scheme_keys = ", ".join(sorted(scheme_paths))
                 message = (
                     "Unknown scheme key used in {}: {} (for file {!r}). .data"
                     " directory contents should be in subdirectories named"
                     " with a valid scheme key ({})"
-                ).format(
-                    wheel_path, scheme_key, record_path, valid_scheme_keys
-                )
+                ).format(wheel_path, scheme_key, record_path, valid_scheme_keys)
                 raise InstallationError(message)
 
             dest_path = os.path.join(scheme_path, dest_subpath)
             assert_no_path_traversal(scheme_path, dest_path)
             return ZipBackedFile(record_path, dest_path, zip_file)
 
         return make_data_scheme_file
 
-    def is_data_scheme_path(path):
-        # type: (RecordPath) -> bool
+    def is_data_scheme_path(path: RecordPath) -> bool:
         return path.split("/", 1)[0].endswith(".data")
 
-    paths = all_paths()
+    paths = cast(List[RecordPath], wheel_zip.namelist())
     file_paths = filterfalse(is_dir_path, paths)
-    root_scheme_paths, data_scheme_paths = partition(
-        is_data_scheme_path, file_paths
-    )
+    root_scheme_paths, data_scheme_paths = partition(is_data_scheme_path, file_paths)
 
-    make_root_scheme_file = root_scheme_file_maker(
-        wheel_zip,
-        ensure_text(lib_dir, encoding=sys.getfilesystemencoding()),
-    )
-    files = map(make_root_scheme_file, root_scheme_paths)
+    make_root_scheme_file = root_scheme_file_maker(wheel_zip, lib_dir)
+    files: Iterator[File] = map(make_root_scheme_file, root_scheme_paths)
 
-    def is_script_scheme_path(path):
-        # type: (RecordPath) -> bool
+    def is_script_scheme_path(path: RecordPath) -> bool:
         parts = path.split("/", 2)
-        return (
-            len(parts) > 2 and
-            parts[0].endswith(".data") and
-            parts[1] == "scripts"
-        )
+        return len(parts) > 2 and parts[0].endswith(".data") and parts[1] == "scripts"
 
     other_scheme_paths, script_scheme_paths = partition(
         is_script_scheme_path, data_scheme_paths
     )
 
     make_data_scheme_file = data_scheme_file_maker(wheel_zip, scheme)
     other_scheme_files = map(make_data_scheme_file, other_scheme_paths)
     files = chain(files, other_scheme_files)
 
     # Get the defined entry points
-    distribution = get_wheel_distribution(wheel_path, canonicalize_name(name))
+    distribution = get_wheel_distribution(
+        FilesystemWheel(wheel_path),
+        canonicalize_name(name),
+    )
     console, gui = get_entrypoints(distribution)
 
-    def is_entrypoint_wrapper(file):
-        # type: (File) -> bool
+    def is_entrypoint_wrapper(file: "File") -> bool:
         # EP, EP.exe and EP-script.py are scripts generated for
         # entry point EP by setuptools
         path = file.dest_path
         name = os.path.basename(path)
-        if name.lower().endswith('.exe'):
+        if name.lower().endswith(".exe"):
             matchname = name[:-4]
-        elif name.lower().endswith('-script.py'):
+        elif name.lower().endswith("-script.py"):
             matchname = name[:-10]
         elif name.lower().endswith(".pya"):
             matchname = name[:-4]
         else:
             matchname = name
         # Ignore setuptools-generated scripts
-        return (matchname in console or matchname in gui)
+        return matchname in console or matchname in gui
 
-    script_scheme_files = map(make_data_scheme_file, script_scheme_paths)
-    script_scheme_files = filterfalse(
-        is_entrypoint_wrapper, script_scheme_files
+    script_scheme_files: Iterator[File] = map(
+        make_data_scheme_file, script_scheme_paths
     )
+    script_scheme_files = filterfalse(is_entrypoint_wrapper, script_scheme_files)
     script_scheme_files = map(ScriptFile, script_scheme_files)
     files = chain(files, script_scheme_files)
 
     for file in files:
         file.save()
         record_installed(file.src_record_path, file.dest_path, file.changed)
 
-    def pyc_source_file_paths():
-        # type: () -> Iterator[str]
+    def pyc_source_file_paths() -> Iterator[str]:
         # We de-duplicate installation paths, since there can be overlap (e.g.
         # file in .data maps to same location as file in wheel root).
         # Sorting installation paths makes it easier to reproduce and debug
         # issues related to permissions on existing files.
         for installed_path in sorted(set(installed.values())):
             full_installed_path = os.path.join(lib_dir, installed_path)
             if not os.path.isfile(full_installed_path):
                 continue
-            if not full_installed_path.endswith('.py'):
+            if not full_installed_path.endswith(".py"):
                 continue
             yield full_installed_path
 
-    def pyc_output_path(path):
-        # type: (str) -> str
-        """Return the path the pyc file would have been written to.
-        """
+    def pyc_output_path(path: str) -> str:
+        """Return the path the pyc file would have been written to."""
         return importlib.util.cache_from_source(path)
 
     # Compile all of the pyc files for the installed files
     if pycompile:
         with captured_stdout() as stdout:
             with warnings.catch_warnings():
-                warnings.filterwarnings('ignore')
+                warnings.filterwarnings("ignore")
                 for path in pyc_source_file_paths():
-                    # Python 2's `compileall.compile_file` requires a str in
-                    # error cases, so we must convert to the native type.
-                    path_arg = ensure_str(
-                        path, encoding=sys.getfilesystemencoding()
-                    )
-                    success = compileall.compile_file(
-                        path_arg, force=True, quiet=True
-                    )
+                    success = compileall.compile_file(path, force=True, quiet=True)
                     if success:
                         pyc_path = pyc_output_path(path)
                         assert os.path.exists(pyc_path)
                         pyc_record_path = cast(
                             "RecordPath", pyc_path.replace(os.path.sep, "/")
                         )
                         record_installed(pyc_record_path, pyc_path)
@@ -685,114 +627,107 @@
     # Ensure old scripts are overwritten.
     # See https://github.com/pypa/pip/issues/1800
     maker.clobber = True
 
     # Ensure we don't generate any variants for scripts because this is almost
     # never what somebody wants.
     # See https://bitbucket.org/pypa/distlib/issue/35/
-    maker.variants = {''}
+    maker.variants = {""}
 
     # This is required because otherwise distlib creates scripts that are not
     # executable.
     # See https://bitbucket.org/pypa/distlib/issue/32/
     maker.set_mode = True
 
     # Generate the console and GUI entry points specified in the wheel
     scripts_to_generate = get_console_script_specs(console)
 
-    gui_scripts_to_generate = list(starmap('{} = {}'.format, gui.items()))
+    gui_scripts_to_generate = list(starmap("{} = {}".format, gui.items()))
 
     generated_console_scripts = maker.make_multiple(scripts_to_generate)
     generated.extend(generated_console_scripts)
 
-    generated.extend(
-        maker.make_multiple(gui_scripts_to_generate, {'gui': True})
-    )
+    generated.extend(maker.make_multiple(gui_scripts_to_generate, {"gui": True}))
 
     if warn_script_location:
         msg = message_about_scripts_not_on_PATH(generated_console_scripts)
         if msg is not None:
             logger.warning(msg)
 
     generated_file_mode = 0o666 & ~current_umask()
 
     @contextlib.contextmanager
-    def _generate_file(path, **kwargs):
-        # type: (str, **Any) -> Iterator[BinaryIO]
+    def _generate_file(path: str, **kwargs: Any) -> Iterator[BinaryIO]:
         with adjacent_tmp_file(path, **kwargs) as f:
             yield f
         os.chmod(f.name, generated_file_mode)
         replace(f.name, path)
 
     dest_info_dir = os.path.join(lib_dir, info_dir)
 
     # Record pip as the installer
-    installer_path = os.path.join(dest_info_dir, 'INSTALLER')
+    installer_path = os.path.join(dest_info_dir, "INSTALLER")
     with _generate_file(installer_path) as installer_file:
-        installer_file.write(b'pip\n')
+        installer_file.write(b"pip\n")
     generated.append(installer_path)
 
     # Record the PEP 610 direct URL reference
     if direct_url is not None:
         direct_url_path = os.path.join(dest_info_dir, DIRECT_URL_METADATA_NAME)
         with _generate_file(direct_url_path) as direct_url_file:
             direct_url_file.write(direct_url.to_json().encode("utf-8"))
         generated.append(direct_url_path)
 
     # Record the REQUESTED file
     if requested:
-        requested_path = os.path.join(dest_info_dir, 'REQUESTED')
+        requested_path = os.path.join(dest_info_dir, "REQUESTED")
         with open(requested_path, "wb"):
             pass
         generated.append(requested_path)
 
-    record_text = distribution.read_text('RECORD')
+    record_text = distribution.read_text("RECORD")
     record_rows = list(csv.reader(record_text.splitlines()))
 
     rows = get_csv_rows_for_installed(
         record_rows,
         installed=installed,
         changed=changed,
         generated=generated,
-        lib_dir=lib_dir)
+        lib_dir=lib_dir,
+    )
 
     # Record details of all files installed
-    record_path = os.path.join(dest_info_dir, 'RECORD')
+    record_path = os.path.join(dest_info_dir, "RECORD")
 
-    with _generate_file(record_path, **csv_io_kwargs('w')) as record_file:
-        # The type mypy infers for record_file is different for Python 3
-        # (typing.IO[Any]) and Python 2 (typing.BinaryIO). We explicitly
-        # cast to typing.IO[str] as a workaround.
-        writer = csv.writer(cast('IO[str]', record_file))
+    with _generate_file(record_path, **csv_io_kwargs("w")) as record_file:
+        # Explicitly cast to typing.IO[str] as a workaround for the mypy error:
+        # "writer" has incompatible type "BinaryIO"; expected "_Writer"
+        writer = csv.writer(cast("IO[str]", record_file))
         writer.writerows(_normalized_outrows(rows))
 
 
 @contextlib.contextmanager
-def req_error_context(req_description):
-    # type: (str) -> Iterator[None]
+def req_error_context(req_description: str) -> Iterator[None]:
     try:
         yield
     except InstallationError as e:
         message = "For req: {}. {}".format(req_description, e.args[0])
-        reraise(
-            InstallationError, InstallationError(message), sys.exc_info()[2]
-        )
+        raise InstallationError(message) from e
 
 
 def install_wheel(
-    name,  # type: str
-    wheel_path,  # type: str
-    scheme,  # type: Scheme
-    req_description,  # type: str
-    pycompile=True,  # type: bool
-    warn_script_location=True,  # type: bool
-    direct_url=None,  # type: Optional[DirectUrl]
-    requested=False,  # type: bool
-):
-    # type: (...) -> None
+    name: str,
+    wheel_path: str,
+    scheme: Scheme,
+    req_description: str,
+    pycompile: bool = True,
+    warn_script_location: bool = True,
+    direct_url: Optional[DirectUrl] = None,
+    requested: bool = False,
+) -> None:
     with ZipFile(wheel_path, allowZip64=True) as z:
         with req_error_context(req_description):
             _install_wheel(
                 name=name,
                 wheel_zip=z,
                 wheel_path=wheel_path,
                 scheme=scheme,
```

#### pip/_internal/req/__init__.py

```diff
@@ -5,16 +5,18 @@
 from pip._internal.utils.logging import indent_log
 
 from .req_file import parse_requirements
 from .req_install import InstallRequirement
 from .req_set import RequirementSet
 
 __all__ = [
-    "RequirementSet", "InstallRequirement",
-    "parse_requirements", "install_given_reqs",
+    "RequirementSet",
+    "InstallRequirement",
+    "parse_requirements",
+    "install_given_reqs",
 ]
 
 logger = logging.getLogger(__name__)
 
 
 class InstallationResult:
     def __init__(self, name: str) -> None:
@@ -48,28 +50,26 @@
 
     (to be called after having downloaded and unpacked the packages)
     """
     to_install = collections.OrderedDict(_validate_requirements(requirements))
 
     if to_install:
         logger.info(
-            'Installing collected packages: %s',
-            ', '.join(to_install.keys()),
+            "Installing collected packages: %s",
+            ", ".join(to_install.keys()),
         )
 
     installed = []
 
     with indent_log():
         for req_name, requirement in to_install.items():
             if requirement.should_reinstall:
-                logger.info('Attempting uninstall: %s', req_name)
+                logger.info("Attempting uninstall: %s", req_name)
                 with indent_log():
-                    uninstalled_pathset = requirement.uninstall(
-                        auto_confirm=True
-                    )
+                    uninstalled_pathset = requirement.uninstall(auto_confirm=True)
             else:
                 uninstalled_pathset = None
 
             try:
                 requirement.install(
                     install_options,
                     global_options,
```

#### pip/_internal/req/constructors.py

```diff
@@ -18,47 +18,48 @@
 from pip._vendor.packaging.specifiers import Specifier
 from pip._vendor.pkg_resources import RequirementParseError, parse_requirements
 
 from pip._internal.exceptions import InstallationError
 from pip._internal.models.index import PyPI, TestPyPI
 from pip._internal.models.link import Link
 from pip._internal.models.wheel import Wheel
-from pip._internal.pyproject import make_pyproject_path
 from pip._internal.req.req_file import ParsedRequirement
 from pip._internal.req.req_install import InstallRequirement
 from pip._internal.utils.filetypes import is_archive_file
 from pip._internal.utils.misc import is_installable_dir
+from pip._internal.utils.packaging import get_requirement
 from pip._internal.utils.urls import path_to_url
 from pip._internal.vcs import is_url, vcs
 
 __all__ = [
-    "install_req_from_editable", "install_req_from_line",
-    "parse_editable"
+    "install_req_from_editable",
+    "install_req_from_line",
+    "parse_editable",
 ]
 
 logger = logging.getLogger(__name__)
 operators = Specifier._operators.keys()
 
 
 def _strip_extras(path: str) -> Tuple[str, Optional[str]]:
-    m = re.match(r'^(.+)(\[[^\]]+\])$', path)
+    m = re.match(r"^(.+)(\[[^\]]+\])$", path)
     extras = None
     if m:
         path_no_extras = m.group(1)
         extras = m.group(2)
     else:
         path_no_extras = path
 
     return path_no_extras, extras
 
 
 def convert_extras(extras: Optional[str]) -> Set[str]:
     if not extras:
         return set()
-    return Requirement("placeholder" + extras.lower()).extras
+    return get_requirement("placeholder" + extras.lower()).extras
 
 
 def parse_editable(editable_req: str) -> Tuple[Optional[str], str, Set[str]]:
     """Parses an editable requirement into:
         - a requirement name
         - an URL
         - extras
@@ -70,57 +71,41 @@
 
     url = editable_req
 
     # If a file path is specified with extras, strip off the extras.
     url_no_extras, extras = _strip_extras(url)
 
     if os.path.isdir(url_no_extras):
-        setup_py = os.path.join(url_no_extras, 'setup.py')
-        setup_cfg = os.path.join(url_no_extras, 'setup.cfg')
-        if not os.path.exists(setup_py) and not os.path.exists(setup_cfg):
-            msg = (
-                'File "setup.py" or "setup.cfg" not found. Directory cannot be '
-                'installed in editable mode: {}'
-                .format(os.path.abspath(url_no_extras))
-            )
-            pyproject_path = make_pyproject_path(url_no_extras)
-            if os.path.isfile(pyproject_path):
-                msg += (
-                    '\n(A "pyproject.toml" file was found, but editable '
-                    'mode currently requires a setuptools-based build.)'
-                )
-            raise InstallationError(msg)
-
         # Treating it as code that has already been checked out
         url_no_extras = path_to_url(url_no_extras)
 
-    if url_no_extras.lower().startswith('file:'):
+    if url_no_extras.lower().startswith("file:"):
         package_name = Link(url_no_extras).egg_fragment
         if extras:
             return (
                 package_name,
                 url_no_extras,
-                Requirement("placeholder" + extras.lower()).extras,
+                get_requirement("placeholder" + extras.lower()).extras,
             )
         else:
             return package_name, url_no_extras, set()
 
     for version_control in vcs:
-        if url.lower().startswith(f'{version_control}:'):
-            url = f'{version_control}+{url}'
+        if url.lower().startswith(f"{version_control}:"):
+            url = f"{version_control}+{url}"
             break
 
     link = Link(url)
 
     if not link.is_vcs:
         backends = ", ".join(vcs.all_schemes)
         raise InstallationError(
-            f'{editable_req} is not a valid editable requirement. '
-            f'It should either be a path to a local project or a VCS URL '
-            f'(beginning with {backends}).'
+            f"{editable_req} is not a valid editable requirement. "
+            f"It should either be a path to a local project or a VCS URL "
+            f"(beginning with {backends})."
         )
 
     package_name = link.egg_fragment
     if not package_name:
         raise InstallationError(
             "Could not detect requirement name for '{}', please specify one "
             "with #egg=your_package_name".format(editable_req)
@@ -146,29 +131,27 @@
                     "The argument you provided "
                     "({}) appears to be a"
                     " requirements file. If that is the"
                     " case, use the '-r' flag to install"
                     " the packages specified within it."
                 ).format(req)
         except RequirementParseError:
-            logger.debug(
-                "Cannot parse '%s' as requirements file", req, exc_info=True
-            )
+            logger.debug("Cannot parse '%s' as requirements file", req, exc_info=True)
     else:
         msg += f" File '{req}' does not exist."
     return msg
 
 
 class RequirementParts:
     def __init__(
-            self,
-            requirement: Optional[Requirement],
-            link: Optional[Link],
-            markers: Optional[Marker],
-            extras: Set[str],
+        self,
+        requirement: Optional[Requirement],
+        link: Optional[Link],
+        markers: Optional[Marker],
+        extras: Set[str],
     ):
         self.requirement = requirement
         self.link = link
         self.markers = markers
         self.extras = extras
 
 
@@ -195,23 +178,25 @@
     editable_req: str,
     comes_from: Optional[Union[InstallRequirement, str]] = None,
     use_pep517: Optional[bool] = None,
     isolated: bool = False,
     options: Optional[Dict[str, Any]] = None,
     constraint: bool = False,
     user_supplied: bool = False,
+    permit_editable_wheels: bool = False,
 ) -> InstallRequirement:
 
     parts = parse_req_from_editable(editable_req)
 
     return InstallRequirement(
         parts.requirement,
         comes_from=comes_from,
         user_supplied=user_supplied,
         editable=True,
+        permit_editable_wheels=permit_editable_wheels,
         link=parts.link,
         constraint=constraint,
         use_pep517=use_pep517,
         isolated=isolated,
         install_options=options.get("install_options", []) if options else [],
         global_options=options.get("global_options", []) if options else [],
         hash_options=options.get("hashes", {}) if options else {},
@@ -246,40 +231,41 @@
     If false, check if the path is an archive file (such as a .whl).
     The function checks if the path is a file. If false, if the path has
     an @, it will treat it as a PEP 440 URL requirement and return the path.
     """
     if _looks_like_path(name) and os.path.isdir(path):
         if is_installable_dir(path):
             return path_to_url(path)
+        # TODO: The is_installable_dir test here might not be necessary
+        #       now that it is done in load_pyproject_toml too.
         raise InstallationError(
             f"Directory {name!r} is not installable. Neither 'setup.py' "
             "nor 'pyproject.toml' found."
         )
     if not is_archive_file(path):
         return None
     if os.path.isfile(path):
         return path_to_url(path)
-    urlreq_parts = name.split('@', 1)
+    urlreq_parts = name.split("@", 1)
     if len(urlreq_parts) >= 2 and not _looks_like_path(urlreq_parts[0]):
         # If the path contains '@' and the part before it does not look
         # like a path, try to treat it as a PEP 440 URL req instead.
         return None
     logger.warning(
-        'Requirement %r looks like a filename, but the '
-        'file does not exist',
-        name
+        "Requirement %r looks like a filename, but the file does not exist",
+        name,
     )
     return path_to_url(path)
 
 
 def parse_req_from_line(name: str, line_source: Optional[str]) -> RequirementParts:
     if is_url(name):
-        marker_sep = '; '
+        marker_sep = "; "
     else:
-        marker_sep = ';'
+        marker_sep = ";"
     if marker_sep in name:
         name, markers_as_string = name.split(marker_sep, 1)
         markers_as_string = markers_as_string.strip()
         if not markers_as_string:
             markers = None
         else:
             markers = Marker(markers_as_string)
@@ -298,17 +284,16 @@
         url = _get_url_from_path(p, name)
         if url is not None:
             link = Link(url)
 
     # it's a local file, dir, or url
     if link:
         # Handle relative file URLs
-        if link.scheme == 'file' and re.search(r'\.\./', link.url):
-            link = Link(
-                path_to_url(os.path.normpath(os.path.abspath(link.path))))
+        if link.scheme == "file" and re.search(r"\.\./", link.url):
+            link = Link(path_to_url(os.path.normpath(os.path.abspath(link.path))))
         # wheel file
         if link.is_wheel:
             wheel = Wheel(link.filename)  # can raise InvalidWheelFilename
             req_as_string = f"{wheel.name}=={wheel.version}"
         else:
             # set the req to the egg fragment.  when it's not there, this
             # will become an 'unnamed' requirement
@@ -319,42 +304,41 @@
         req_as_string = name
 
     extras = convert_extras(extras_as_string)
 
     def with_source(text: str) -> str:
         if not line_source:
             return text
-        return f'{text} (from {line_source})'
+        return f"{text} (from {line_source})"
 
     def _parse_req_string(req_as_string: str) -> Requirement:
         try:
-            req = Requirement(req_as_string)
+            req = get_requirement(req_as_string)
         except InvalidRequirement:
             if os.path.sep in req_as_string:
                 add_msg = "It looks like a path."
                 add_msg += deduce_helpful_msg(req_as_string)
-            elif ('=' in req_as_string and
-                  not any(op in req_as_string for op in operators)):
+            elif "=" in req_as_string and not any(
+                op in req_as_string for op in operators
+            ):
                 add_msg = "= is not a valid operator. Did you mean == ?"
             else:
-                add_msg = ''
-            msg = with_source(
-                f'Invalid requirement: {req_as_string!r}'
-            )
+                add_msg = ""
+            msg = with_source(f"Invalid requirement: {req_as_string!r}")
             if add_msg:
-                msg += f'\nHint: {add_msg}'
+                msg += f"\nHint: {add_msg}"
             raise InstallationError(msg)
         else:
             # Deprecate extras after specifiers: "name>=1.0[extras]"
             # This currently works by accident because _strip_extras() parses
             # any extras in the end of the string and those are saved in
             # RequirementParts
             for spec in req.specifier:
                 spec_str = str(spec)
-                if spec_str.endswith(']'):
+                if spec_str.endswith("]"):
                     msg = f"Extras after version '{spec_str}'."
                     raise InstallationError(msg)
         return req
 
     if req_as_string is not None:
         req: Optional[Requirement] = _parse_req_string(req_as_string)
     else:
@@ -378,16 +362,20 @@
 
     :param line_source: An optional string describing where the line is from,
         for logging purposes in case of an error.
     """
     parts = parse_req_from_line(name, line_source)
 
     return InstallRequirement(
-        parts.requirement, comes_from, link=parts.link, markers=parts.markers,
-        use_pep517=use_pep517, isolated=isolated,
+        parts.requirement,
+        comes_from,
+        link=parts.link,
+        markers=parts.markers,
+        use_pep517=use_pep517,
+        isolated=isolated,
         install_options=options.get("install_options", []) if options else [],
         global_options=options.get("global_options", []) if options else [],
         hash_options=options.get("hashes", {}) if options else {},
         constraint=constraint,
         extras=parts.extras,
         user_supplied=user_supplied,
     )
@@ -397,24 +385,28 @@
     req_string: str,
     comes_from: Optional[InstallRequirement] = None,
     isolated: bool = False,
     use_pep517: Optional[bool] = None,
     user_supplied: bool = False,
 ) -> InstallRequirement:
     try:
-        req = Requirement(req_string)
+        req = get_requirement(req_string)
     except InvalidRequirement:
         raise InstallationError(f"Invalid requirement: '{req_string}'")
 
     domains_not_allowed = [
         PyPI.file_storage_domain,
         TestPyPI.file_storage_domain,
     ]
-    if (req.url and comes_from and comes_from.link and
-            comes_from.link.netloc in domains_not_allowed):
+    if (
+        req.url
+        and comes_from
+        and comes_from.link
+        and comes_from.link.netloc in domains_not_allowed
+    ):
         # Explicitly disallow pypi packages that depend on external urls
         raise InstallationError(
             "Packages installed from PyPI cannot depend on packages "
             "which are not also hosted on PyPI.\n"
             "{} depends on {} ".format(comes_from.name, req)
         )
```

#### pip/_internal/req/req_file.py

```diff
@@ -4,15 +4,25 @@
 
 import optparse
 import os
 import re
 import shlex
 import urllib.parse
 from optparse import Values
-from typing import TYPE_CHECKING, Any, Callable, Dict, Iterator, List, Optional, Tuple
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Callable,
+    Dict,
+    Iterable,
+    Iterator,
+    List,
+    Optional,
+    Tuple,
+)
 
 from pip._internal.cli import cmdoptions
 from pip._internal.exceptions import InstallationError, RequirementsFileParseError
 from pip._internal.models.search_scope import SearchScope
 from pip._internal.network.session import PipSession
 from pip._internal.network.utils import raise_for_status
 from pip._internal.utils.encoding import auto_decode
@@ -21,28 +31,28 @@
 if TYPE_CHECKING:
     # NoReturn introduced in 3.6.2; imported only for type checking to maintain
     # pip compatibility with older patch versions of Python 3.6
     from typing import NoReturn
 
     from pip._internal.index.package_finder import PackageFinder
 
-__all__ = ['parse_requirements']
+__all__ = ["parse_requirements"]
 
-ReqFileLines = Iterator[Tuple[int, str]]
+ReqFileLines = Iterable[Tuple[int, str]]
 
 LineParser = Callable[[str], Tuple[str, Values]]
 
-SCHEME_RE = re.compile(r'^(http|https|file):', re.I)
-COMMENT_RE = re.compile(r'(^|\s+)#.*$')
+SCHEME_RE = re.compile(r"^(http|https|file):", re.I)
+COMMENT_RE = re.compile(r"(^|\s+)#.*$")
 
 # Matches environment variable-style values in '${MY_VARIABLE_1}' with the
 # variable name consisting of only uppercase letters, digits or the '_'
 # (underscore). This follows the POSIX standard defined in IEEE Std 1003.1,
 # 2013 Edition.
-ENV_VAR_RE = re.compile(r'(?P<var>\$\{(?P<name>[A-Z0-9_]+)\})')
+ENV_VAR_RE = re.compile(r"(?P<var>\$\{(?P<name>[A-Z0-9_]+)\})")
 
 SUPPORTED_OPTIONS: List[Callable[..., optparse.Option]] = [
     cmdoptions.index_url,
     cmdoptions.extra_index_url,
     cmdoptions.no_index,
     cmdoptions.constraints,
     cmdoptions.requirements,
@@ -130,18 +140,15 @@
         requirements file.
     """
     line_parser = get_line_parser(finder)
     parser = RequirementsFileParser(session, line_parser)
 
     for parsed_line in parser.parse(filename, constraint):
         parsed_req = handle_line(
-            parsed_line,
-            options=options,
-            finder=finder,
-            session=session
+            parsed_line, options=options, finder=finder, session=session
         )
         if parsed_req is not None:
             yield parsed_req
 
 
 def preprocess(content: str) -> ReqFileLines:
     """Split, filter, and join lines, and return a line iterator
@@ -157,16 +164,18 @@
 
 def handle_requirement_line(
     line: ParsedLine,
     options: Optional[optparse.Values] = None,
 ) -> ParsedRequirement:
 
     # preserve for the nested code path
-    line_comes_from = '{} {} (line {})'.format(
-        '-c' if line.constraint else '-r', line.filename, line.lineno,
+    line_comes_from = "{} {} (line {})".format(
+        "-c" if line.constraint else "-r",
+        line.filename,
+        line.lineno,
     )
 
     assert line.is_requirement
 
     if line.is_editable:
         # For editable requirements, we don't support per-requirement
         # options, so just return the parsed requirement.
@@ -183,15 +192,15 @@
 
         # get the options that apply to requirements
         req_options = {}
         for dest in SUPPORTED_OPTIONS_REQ_DEST:
             if dest in line.opts.__dict__ and line.opts.__dict__[dest]:
                 req_options[dest] = line.opts.__dict__[dest]
 
-        line_source = f'line {line.lineno} of {line.filename}'
+        line_source = f"line {line.lineno} of {line.filename}"
         return ParsedRequirement(
             requirement=line.requirement,
             is_editable=line.is_editable,
             comes_from=line_comes_from,
             constraint=line.constraint,
             options=req_options,
             line_source=line_source,
@@ -209,16 +218,15 @@
 
     if options:
         # percolate options upward
         if opts.require_hashes:
             options.require_hashes = opts.require_hashes
         if opts.features_enabled:
             options.features_enabled.extend(
-                f for f in opts.features_enabled
-                if f not in options.features_enabled
+                f for f in opts.features_enabled if f not in options.features_enabled
             )
 
     # set finder options
     if finder:
         find_links = finder.find_links
         index_urls = finder.index_urls
         if opts.index_url:
@@ -252,15 +260,15 @@
             finder.set_allow_all_prereleases()
 
         if opts.prefer_binary:
             finder.set_prefer_binary()
 
         if session:
             for host in opts.trusted_hosts or []:
-                source = f'line {lineno} of {filename}'
+                source = f"line {lineno} of {filename}"
                 session.add_trusted_host(host, source=source)
 
 
 def handle_line(
     line: ParsedLine,
     options: Optional[optparse.Values] = None,
     finder: Optional["PackageFinder"] = None,
@@ -310,25 +318,23 @@
         session: PipSession,
         line_parser: LineParser,
     ) -> None:
         self._session = session
         self._line_parser = line_parser
 
     def parse(self, filename: str, constraint: bool) -> Iterator[ParsedLine]:
-        """Parse a given file, yielding parsed lines.
-        """
+        """Parse a given file, yielding parsed lines."""
         yield from self._parse_and_recurse(filename, constraint)
 
     def _parse_and_recurse(
         self, filename: str, constraint: bool
     ) -> Iterator[ParsedLine]:
         for line in self._parse_file(filename, constraint):
-            if (
-                not line.is_requirement and
-                (line.opts.requirements or line.opts.constraints)
+            if not line.is_requirement and (
+                line.opts.requirements or line.opts.constraints
             ):
                 # parse a nested requirements file
                 if line.opts.requirements:
                     req_path = line.opts.requirements[0]
                     nested_constraint = False
                 else:
                     req_path = line.opts.constraints[0]
@@ -338,15 +344,16 @@
                 if SCHEME_RE.search(filename):
                     # do a url join so relative paths work
                     req_path = urllib.parse.urljoin(filename, req_path)
                 # original file and nested file are paths
                 elif not SCHEME_RE.search(req_path):
                     # do a join so relative paths work
                     req_path = os.path.join(
-                        os.path.dirname(filename), req_path,
+                        os.path.dirname(filename),
+                        req_path,
                     )
 
                 yield from self._parse_and_recurse(req_path, nested_constraint)
             else:
                 yield line
 
     def _parse_file(self, filename: str, constraint: bool) -> Iterator[ParsedLine]:
@@ -355,15 +362,15 @@
         lines_enum = preprocess(content)
 
         for line_number, line in lines_enum:
             try:
                 args_str, opts = self._line_parser(line)
             except OptionParsingError as e:
                 # add offending line
-                msg = f'Invalid requirement: {line}\n{e.msg}'
+                msg = f"Invalid requirement: {line}\n{e.msg}"
                 raise RequirementsFileParseError(msg)
 
             yield ParsedLine(
                 filename,
                 line_number,
                 args_str,
                 opts,
@@ -391,24 +398,24 @@
 
 
 def break_args_options(line: str) -> Tuple[str, str]:
     """Break up the line into an args and options string.  We only want to shlex
     (and then optparse) the options, not the args.  args can contain markers
     which are corrupted by shlex.
     """
-    tokens = line.split(' ')
+    tokens = line.split(" ")
     args = []
     options = tokens[:]
     for token in tokens:
-        if token.startswith('-') or token.startswith('--'):
+        if token.startswith("-") or token.startswith("--"):
             break
         else:
             args.append(token)
             options.pop(0)
-    return ' '.join(args), ' '.join(options)
+    return " ".join(args), " ".join(options)
 
 
 class OptionParsingError(Exception):
     def __init__(self, msg: str) -> None:
         self.msg = msg
 
 
@@ -423,58 +430,59 @@
         option = option_factory()
         parser.add_option(option)
 
     # By default optparse sys.exits on parsing errors. We want to wrap
     # that in our own exception.
     def parser_exit(self: Any, msg: str) -> "NoReturn":
         raise OptionParsingError(msg)
+
     # NOTE: mypy disallows assigning to a method
     #       https://github.com/python/mypy/issues/2427
     parser.exit = parser_exit  # type: ignore
 
     return parser
 
 
 def join_lines(lines_enum: ReqFileLines) -> ReqFileLines:
     """Joins a line ending in '\' with the previous line (except when following
     comments).  The joined line takes on the index of the first line.
     """
     primary_line_number = None
     new_line: List[str] = []
     for line_number, line in lines_enum:
-        if not line.endswith('\\') or COMMENT_RE.match(line):
+        if not line.endswith("\\") or COMMENT_RE.match(line):
             if COMMENT_RE.match(line):
                 # this ensures comments are always matched later
-                line = ' ' + line
+                line = " " + line
             if new_line:
                 new_line.append(line)
                 assert primary_line_number is not None
-                yield primary_line_number, ''.join(new_line)
+                yield primary_line_number, "".join(new_line)
                 new_line = []
             else:
                 yield line_number, line
         else:
             if not new_line:
                 primary_line_number = line_number
-            new_line.append(line.strip('\\'))
+            new_line.append(line.strip("\\"))
 
     # last line contains \
     if new_line:
         assert primary_line_number is not None
-        yield primary_line_number, ''.join(new_line)
+        yield primary_line_number, "".join(new_line)
 
     # TODO: handle space after '\'.
 
 
 def ignore_comments(lines_enum: ReqFileLines) -> ReqFileLines:
     """
     Strips comments and filter empty lines.
     """
     for line_number, line in lines_enum:
-        line = COMMENT_RE.sub('', line)
+        line = COMMENT_RE.sub("", line)
         line = line.strip()
         if line:
             yield line_number, line
 
 
 def expand_env_variables(lines_enum: ReqFileLines) -> ReqFileLines:
     """Replace all environment variables that can be retrieved via `os.getenv`.
@@ -510,19 +518,19 @@
 
     :param url:         File path or url.
     :param session:     PipSession instance.
     """
     scheme = get_url_scheme(url)
 
     # Pip has special support for file:// URLs (LocalFSAdapter).
-    if scheme in ['http', 'https', 'file']:
+    if scheme in ["http", "https", "file"]:
         resp = session.get(url)
         raise_for_status(resp)
         return resp.url, resp.text
 
     # Assume this is a bare path.
     try:
-        with open(url, 'rb') as f:
+        with open(url, "rb") as f:
             content = auto_decode(f.read())
     except OSError as exc:
-        raise InstallationError(f'Could not open requirements file: {exc}')
+        raise InstallationError(f"Could not open requirements file: {exc}")
     return url, content
```

#### pip/_internal/req/req_install.py

```diff
@@ -1,59 +1,64 @@
 # The following comment should be removed at some point in the future.
 # mypy: strict-optional=False
 
+import functools
 import logging
 import os
 import shutil
 import sys
 import uuid
 import zipfile
-from typing import Any, Dict, Iterable, List, Optional, Sequence, Union
+from typing import Any, Collection, Dict, Iterable, List, Optional, Sequence, Union
 
-from pip._vendor import pkg_resources, six
+from pip._vendor import pkg_resources
 from pip._vendor.packaging.markers import Marker
 from pip._vendor.packaging.requirements import Requirement
 from pip._vendor.packaging.specifiers import SpecifierSet
 from pip._vendor.packaging.utils import canonicalize_name
 from pip._vendor.packaging.version import Version
 from pip._vendor.packaging.version import parse as parse_version
 from pip._vendor.pep517.wrappers import Pep517HookCaller
 from pip._vendor.pkg_resources import Distribution
 
 from pip._internal.build_env import BuildEnvironment, NoOpBuildEnvironment
 from pip._internal.exceptions import InstallationError
 from pip._internal.locations import get_scheme
 from pip._internal.models.link import Link
 from pip._internal.operations.build.metadata import generate_metadata
+from pip._internal.operations.build.metadata_editable import generate_editable_metadata
 from pip._internal.operations.build.metadata_legacy import (
     generate_metadata as generate_metadata_legacy,
 )
 from pip._internal.operations.install.editable_legacy import (
     install_editable as install_editable_legacy,
 )
 from pip._internal.operations.install.legacy import LegacyInstallFailure
 from pip._internal.operations.install.legacy import install as install_legacy
 from pip._internal.operations.install.wheel import install_wheel
 from pip._internal.pyproject import load_pyproject_toml, make_pyproject_path
 from pip._internal.req.req_uninstall import UninstallPathSet
 from pip._internal.utils.deprecation import deprecated
-from pip._internal.utils.direct_url_helpers import direct_url_from_link
+from pip._internal.utils.direct_url_helpers import (
+    direct_url_for_editable,
+    direct_url_from_link,
+)
 from pip._internal.utils.hashes import Hashes
-from pip._internal.utils.logging import indent_log
 from pip._internal.utils.misc import (
     ask_path_exists,
     backup_dir,
     display_path,
     dist_in_site_packages,
     dist_in_usersite,
     get_distribution,
     hide_url,
     redact_auth_from_url,
 )
 from pip._internal.utils.packaging import get_metadata
+from pip._internal.utils.subprocess import runner_with_spinner_message
 from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
 from pip._internal.utils.virtualenv import running_under_virtualenv
 from pip._internal.vcs import vcs
 
 logger = logging.getLogger(__name__)
 
 
@@ -99,36 +104,36 @@
         markers: Optional[Marker] = None,
         use_pep517: Optional[bool] = None,
         isolated: bool = False,
         install_options: Optional[List[str]] = None,
         global_options: Optional[List[str]] = None,
         hash_options: Optional[Dict[str, List[str]]] = None,
         constraint: bool = False,
-        extras: Iterable[str] = (),
+        extras: Collection[str] = (),
         user_supplied: bool = False,
+        permit_editable_wheels: bool = False,
     ) -> None:
         assert req is None or isinstance(req, Requirement), req
         self.req = req
         self.comes_from = comes_from
         self.constraint = constraint
         self.editable = editable
+        self.permit_editable_wheels = permit_editable_wheels
         self.legacy_install_reason: Optional[int] = None
 
         # source_dir is the local directory where the linked requirement is
         # located, or unpacked. In case unpacking is needed, creating and
         # populating source_dir is done by the RequirementPreparer. Note this
         # is not necessarily the directory where pyproject.toml or setup.py is
         # located - that one is obtained via unpacked_source_directory.
         self.source_dir: Optional[str] = None
         if self.editable:
             assert link
             if link.is_file:
-                self.source_dir = os.path.normpath(
-                    os.path.abspath(link.file_path)
-                )
+                self.source_dir = os.path.normpath(os.path.abspath(link.file_path))
 
         if link is None and req and req.url:
             # PEP 508 URL requirement
             link = Link(req.url)
         self.link = self.original_link = link
         self.original_link_is_in_wheel_cache = False
 
@@ -136,17 +141,15 @@
         self.local_file_path: Optional[str] = None
         if self.link and self.link.is_file:
             self.local_file_path = self.link.file_path
 
         if extras:
             self.extras = extras
         elif req:
-            self.extras = {
-                pkg_resources.safe_extra(extra) for extra in req.extras
-            }
+            self.extras = {pkg_resources.safe_extra(extra) for extra in req.extras}
         else:
             self.extras = set()
         if markers is None and req:
             markers = req.marker
         self.markers = markers
 
         # This holds the pkg_resources.Distribution object if this requirement
@@ -198,78 +201,87 @@
         # This requirement needs more preparation before it can be built
         self.needs_more_preparation = False
 
     def __str__(self) -> str:
         if self.req:
             s = str(self.req)
             if self.link:
-                s += ' from {}'.format(redact_auth_from_url(self.link.url))
+                s += " from {}".format(redact_auth_from_url(self.link.url))
         elif self.link:
             s = redact_auth_from_url(self.link.url)
         else:
-            s = '<InstallRequirement>'
+            s = "<InstallRequirement>"
         if self.satisfied_by is not None:
-            s += ' in {}'.format(display_path(self.satisfied_by.location))
+            s += " in {}".format(display_path(self.satisfied_by.location))
         if self.comes_from:
             if isinstance(self.comes_from, str):
                 comes_from: Optional[str] = self.comes_from
             else:
                 comes_from = self.comes_from.from_path()
             if comes_from:
-                s += f' (from {comes_from})'
+                s += f" (from {comes_from})"
         return s
 
     def __repr__(self) -> str:
-        return '<{} object: {} editable={!r}>'.format(
-            self.__class__.__name__, str(self), self.editable)
+        return "<{} object: {} editable={!r}>".format(
+            self.__class__.__name__, str(self), self.editable
+        )
 
     def format_debug(self) -> str:
-        """An un-tested helper for getting state, for debugging.
-        """
+        """An un-tested helper for getting state, for debugging."""
         attributes = vars(self)
         names = sorted(attributes)
 
-        state = (
-            "{}={!r}".format(attr, attributes[attr]) for attr in sorted(names)
-        )
-        return '<{name} object: {{{state}}}>'.format(
+        state = ("{}={!r}".format(attr, attributes[attr]) for attr in sorted(names))
+        return "<{name} object: {{{state}}}>".format(
             name=self.__class__.__name__,
             state=", ".join(state),
         )
 
     # Things that are valid for all kinds of requirements?
     @property
     def name(self) -> Optional[str]:
         if self.req is None:
             return None
         return pkg_resources.safe_name(self.req.name)
 
+    @functools.lru_cache()  # use cached_property in python 3.8+
+    def supports_pyproject_editable(self) -> bool:
+        if not self.use_pep517:
+            return False
+        assert self.pep517_backend
+        with self.build_env:
+            runner = runner_with_spinner_message(
+                "Checking if build backend supports build_editable"
+            )
+            with self.pep517_backend.subprocess_runner(runner):
+                return "build_editable" in self.pep517_backend._supported_features()
+
     @property
     def specifier(self) -> SpecifierSet:
         return self.req.specifier
 
     @property
     def is_pinned(self) -> bool:
         """Return whether I am pinned to an exact version.
 
         For example, some-package==1.2 is pinned; some-package>1.2 is not.
         """
         specifiers = self.specifier
-        return (len(specifiers) == 1 and
-                next(iter(specifiers)).operator in {'==', '==='})
+        return len(specifiers) == 1 and next(iter(specifiers)).operator in {"==", "==="}
 
     def match_markers(self, extras_requested: Optional[Iterable[str]] = None) -> bool:
         if not extras_requested:
             # Provide an extra to safely evaluate the markers
             # without matching any extra
-            extras_requested = ('',)
+            extras_requested = ("",)
         if self.markers is not None:
             return any(
-                self.markers.evaluate({'extra': extra})
-                for extra in extras_requested)
+                self.markers.evaluate({"extra": extra}) for extra in extras_requested
+            )
         else:
             return True
 
     @property
     def has_hash_options(self) -> bool:
         """Return whether any known-good hashes are specified as options.
 
@@ -297,26 +309,25 @@
         good_hashes = self.hash_options.copy()
         link = self.link if trust_internet else self.original_link
         if link and link.hash:
             good_hashes.setdefault(link.hash_name, []).append(link.hash)
         return Hashes(good_hashes)
 
     def from_path(self) -> Optional[str]:
-        """Format a nice indicator to show where this "comes from"
-        """
+        """Format a nice indicator to show where this "comes from" """
         if self.req is None:
             return None
         s = str(self.req)
         if self.comes_from:
             if isinstance(self.comes_from, str):
                 comes_from = self.comes_from
             else:
                 comes_from = self.comes_from.from_path()
             if comes_from:
-                s += '->' + comes_from
+                s += "->" + comes_from
         return s
 
     def ensure_build_location(
         self, build_dir: str, autodelete: bool, parallel_builds: bool
     ) -> str:
         assert build_dir is not None
         if self._temp_build_dir is not None:
@@ -341,60 +352,63 @@
         dir_name: str = canonicalize_name(self.name)
         if parallel_builds:
             dir_name = f"{dir_name}_{uuid.uuid4().hex}"
 
         # FIXME: Is there a better place to create the build_dir? (hg and bzr
         # need this)
         if not os.path.exists(build_dir):
-            logger.debug('Creating directory %s', build_dir)
+            logger.debug("Creating directory %s", build_dir)
             os.makedirs(build_dir)
         actual_build_dir = os.path.join(build_dir, dir_name)
         # `None` indicates that we respect the globally-configured deletion
         # settings, which is what we actually want when auto-deleting.
         delete_arg = None if autodelete else False
         return TempDirectory(
             path=actual_build_dir,
             delete=delete_arg,
             kind=tempdir_kinds.REQ_BUILD,
             globally_managed=True,
         ).path
 
     def _set_requirement(self) -> None:
-        """Set requirement after generating metadata.
-        """
+        """Set requirement after generating metadata."""
         assert self.req is None
         assert self.metadata is not None
         assert self.source_dir is not None
 
         # Construct a Requirement object from the generated metadata
         if isinstance(parse_version(self.metadata["Version"]), Version):
             op = "=="
         else:
             op = "==="
 
         self.req = Requirement(
-            "".join([
-                self.metadata["Name"],
-                op,
-                self.metadata["Version"],
-            ])
+            "".join(
+                [
+                    self.metadata["Name"],
+                    op,
+                    self.metadata["Version"],
+                ]
+            )
         )
 
     def warn_on_mismatching_name(self) -> None:
         metadata_name = canonicalize_name(self.metadata["Name"])
         if canonicalize_name(self.req.name) == metadata_name:
             # Everything is fine.
             return
 
         # If we're here, there's a mismatch. Log a warning about it.
         logger.warning(
-            'Generating metadata for package %s '
-            'produced metadata for project name %s. Fix your '
-            '#egg=%s fragments.',
-            self.name, metadata_name, self.name
+            "Generating metadata for package %s "
+            "produced metadata for project name %s. Fix your "
+            "#egg=%s fragments.",
+            self.name,
+            metadata_name,
+            self.name,
         )
         self.req = Requirement(metadata_name)
 
     def check_if_exists(self, use_user_site: bool) -> None:
         """Find an installed distribution that satisfies or conflicts
         with this requirement, and set self.satisfied_by or
         self.should_reinstall appropriately.
@@ -407,28 +421,30 @@
 
         # pkg_resouces may contain a different copy of packaging.version from
         # pip in if the downstream distributor does a poor job debundling pip.
         # We avoid existing_dist.parsed_version and let SpecifierSet.contains
         # parses the version instead.
         existing_version = existing_dist.version
         version_compatible = (
-            existing_version is not None and
-            self.req.specifier.contains(existing_version, prereleases=True)
+            existing_version is not None
+            and self.req.specifier.contains(existing_version, prereleases=True)
         )
         if not version_compatible:
             self.satisfied_by = None
             if use_user_site:
                 if dist_in_usersite(existing_dist):
                     self.should_reinstall = True
-                elif (running_under_virtualenv() and
-                        dist_in_site_packages(existing_dist)):
+                elif running_under_virtualenv() and dist_in_site_packages(
+                    existing_dist
+                ):
                     raise InstallationError(
                         "Will not install to the user site because it will "
                         "lack sys.path precedence to {} in {}".format(
-                            existing_dist.project_name, existing_dist.location)
+                            existing_dist.project_name, existing_dist.location
+                        )
                     )
             else:
                 self.should_reinstall = True
         else:
             if self.editable:
                 self.should_reinstall = True
                 # when installing editables, nothing pre-existing should ever
@@ -444,123 +460,146 @@
             return False
         return self.link.is_wheel
 
     # Things valid for sdists
     @property
     def unpacked_source_directory(self) -> str:
         return os.path.join(
-            self.source_dir,
-            self.link and self.link.subdirectory_fragment or '')
+            self.source_dir, self.link and self.link.subdirectory_fragment or ""
+        )
 
     @property
     def setup_py_path(self) -> str:
         assert self.source_dir, f"No source dir for {self}"
-        setup_py = os.path.join(self.unpacked_source_directory, 'setup.py')
+        setup_py = os.path.join(self.unpacked_source_directory, "setup.py")
 
         return setup_py
 
     @property
+    def setup_cfg_path(self) -> str:
+        assert self.source_dir, f"No source dir for {self}"
+        setup_cfg = os.path.join(self.unpacked_source_directory, "setup.cfg")
+
+        return setup_cfg
+
+    @property
     def pyproject_toml_path(self) -> str:
         assert self.source_dir, f"No source dir for {self}"
         return make_pyproject_path(self.unpacked_source_directory)
 
     def load_pyproject_toml(self) -> None:
         """Load the pyproject.toml file.
 
         After calling this routine, all of the attributes related to PEP 517
         processing for this requirement have been set. In particular, the
         use_pep517 attribute can be used to determine whether we should
         follow the PEP 517 or legacy (setup.py) code path.
         """
         pyproject_toml_data = load_pyproject_toml(
-            self.use_pep517,
-            self.pyproject_toml_path,
-            self.setup_py_path,
-            str(self)
+            self.use_pep517, self.pyproject_toml_path, self.setup_py_path, str(self)
         )
 
         if pyproject_toml_data is None:
             self.use_pep517 = False
             return
 
         self.use_pep517 = True
         requires, backend, check, backend_path = pyproject_toml_data
         self.requirements_to_check = check
         self.pyproject_requires = requires
         self.pep517_backend = Pep517HookCaller(
-            self.unpacked_source_directory, backend, backend_path=backend_path,
+            self.unpacked_source_directory,
+            backend,
+            backend_path=backend_path,
         )
 
-    def _generate_metadata(self) -> str:
-        """Invokes metadata generator functions, with the required arguments.
-        """
-        if not self.use_pep517:
-            assert self.unpacked_source_directory
-
-            if not os.path.exists(self.setup_py_path):
-                raise InstallationError(
-                    f'File "setup.py" not found for legacy project {self}.'
-                )
+    def isolated_editable_sanity_check(self) -> None:
+        """Check that an editable requirement if valid for use with PEP 517/518.
 
-            return generate_metadata_legacy(
-                build_env=self.build_env,
-                setup_py_path=self.setup_py_path,
-                source_dir=self.unpacked_source_directory,
-                isolated=self.isolated,
-                details=self.name or f"from {self.link}"
+        This verifies that an editable that has a pyproject.toml either supports PEP 660
+        or as a setup.py or a setup.cfg
+        """
+        if (
+            self.editable
+            and self.use_pep517
+            and not self.supports_pyproject_editable()
+            and not os.path.isfile(self.setup_py_path)
+            and not os.path.isfile(self.setup_cfg_path)
+        ):
+            raise InstallationError(
+                f"Project {self} has a 'pyproject.toml' and its build "
+                f"backend is missing the 'build_editable' hook. Since it does not "
+                f"have a 'setup.py' nor a 'setup.cfg', "
+                f"it cannot be installed in editable mode. "
+                f"Consider using a build backend that supports PEP 660."
             )
 
-        assert self.pep517_backend is not None
-
-        return generate_metadata(
-            build_env=self.build_env,
-            backend=self.pep517_backend,
-        )
-
     def prepare_metadata(self) -> None:
         """Ensure that project metadata is available.
 
-        Under PEP 517, call the backend hook to prepare the metadata.
+        Under PEP 517 and PEP 660, call the backend hook to prepare the metadata.
         Under legacy processing, call setup.py egg-info.
         """
         assert self.source_dir
 
-        with indent_log():
-            self.metadata_directory = self._generate_metadata()
+        if self.use_pep517:
+            assert self.pep517_backend is not None
+            if (
+                self.editable
+                and self.permit_editable_wheels
+                and self.supports_pyproject_editable()
+            ):
+                self.metadata_directory = generate_editable_metadata(
+                    build_env=self.build_env,
+                    backend=self.pep517_backend,
+                )
+            else:
+                self.metadata_directory = generate_metadata(
+                    build_env=self.build_env,
+                    backend=self.pep517_backend,
+                )
+        else:
+            self.metadata_directory = generate_metadata_legacy(
+                build_env=self.build_env,
+                setup_py_path=self.setup_py_path,
+                source_dir=self.unpacked_source_directory,
+                isolated=self.isolated,
+                details=self.name or f"from {self.link}",
+            )
 
         # Act on the newly generated metadata, based on the name and version.
         if not self.name:
             self._set_requirement()
         else:
             self.warn_on_mismatching_name()
 
         self.assert_source_matches_version()
 
     @property
     def metadata(self) -> Any:
-        if not hasattr(self, '_metadata'):
+        if not hasattr(self, "_metadata"):
             self._metadata = get_metadata(self.get_dist())
 
         return self._metadata
 
     def get_dist(self) -> Distribution:
         return _get_dist(self.metadata_directory)
 
     def assert_source_matches_version(self) -> None:
         assert self.source_dir
-        version = self.metadata['version']
+        version = self.metadata["version"]
         if self.req.specifier and version not in self.req.specifier:
             logger.warning(
-                'Requested %s, but installing version %s',
+                "Requested %s, but installing version %s",
                 self,
                 version,
             )
         else:
             logger.debug(
-                'Source in %s has version %s, which satisfies requirement %s',
+                "Source in %s has version %s, which satisfies requirement %s",
                 display_path(self.source_dir),
                 version,
                 self,
             )
 
     # For both source distributions and editables
     def ensure_has_source_dir(
@@ -585,22 +624,21 @@
                 parallel_builds=parallel_builds,
             )
 
     # For editable installations
     def update_editable(self) -> None:
         if not self.link:
             logger.debug(
-                "Cannot update repository at %s; repository location is "
-                "unknown",
+                "Cannot update repository at %s; repository location is unknown",
                 self.source_dir,
             )
             return
         assert self.editable
         assert self.source_dir
-        if self.link.scheme == 'file':
+        if self.link.scheme == "file":
             # Static paths don't get updated
             return
         vcs_backend = vcs.get_backend_for_scheme(self.link.scheme)
         # Editable requirements are validated in Requirement constructors.
         # So here, if it's neither a path nor a valid VCS URL, it's a bug.
         assert vcs_backend, f"Unsupported VCS URL {self.link.url}"
         hidden_url = hide_url(self.link.url)
@@ -623,118 +661,122 @@
 
         """
         assert self.req
         dist = get_distribution(self.req.name)
         if not dist:
             logger.warning("Skipping %s as it is not installed.", self.name)
             return None
-        logger.info('Found existing installation: %s', dist)
+        logger.info("Found existing installation: %s", dist)
 
         uninstalled_pathset = UninstallPathSet.from_dist(dist)
         uninstalled_pathset.remove(auto_confirm, verbose)
         return uninstalled_pathset
 
     def _get_archive_name(self, path: str, parentdir: str, rootdir: str) -> str:
-
         def _clean_zip_name(name: str, prefix: str) -> str:
-            assert name.startswith(prefix + os.path.sep), (
-                f"name {name!r} doesn't start with prefix {prefix!r}"
-            )
-            name = name[len(prefix) + 1:]
-            name = name.replace(os.path.sep, '/')
+            assert name.startswith(
+                prefix + os.path.sep
+            ), f"name {name!r} doesn't start with prefix {prefix!r}"
+            name = name[len(prefix) + 1 :]
+            name = name.replace(os.path.sep, "/")
             return name
 
         path = os.path.join(parentdir, path)
         name = _clean_zip_name(path, rootdir)
-        return self.name + '/' + name
+        return self.name + "/" + name
 
     def archive(self, build_dir: Optional[str]) -> None:
         """Saves archive to provided build_dir.
 
         Used for saving downloaded VCS requirements as part of `pip download`.
         """
         assert self.source_dir
         if build_dir is None:
             return
 
         create_archive = True
-        archive_name = '{}-{}.zip'.format(self.name, self.metadata["version"])
+        archive_name = "{}-{}.zip".format(self.name, self.metadata["version"])
         archive_path = os.path.join(build_dir, archive_name)
 
         if os.path.exists(archive_path):
             response = ask_path_exists(
-                'The file {} exists. (i)gnore, (w)ipe, '
-                '(b)ackup, (a)bort '.format(
-                    display_path(archive_path)),
-                ('i', 'w', 'b', 'a'))
-            if response == 'i':
+                "The file {} exists. (i)gnore, (w)ipe, "
+                "(b)ackup, (a)bort ".format(display_path(archive_path)),
+                ("i", "w", "b", "a"),
+            )
+            if response == "i":
                 create_archive = False
-            elif response == 'w':
-                logger.warning('Deleting %s', display_path(archive_path))
+            elif response == "w":
+                logger.warning("Deleting %s", display_path(archive_path))
                 os.remove(archive_path)
-            elif response == 'b':
+            elif response == "b":
                 dest_file = backup_dir(archive_path)
                 logger.warning(
-                    'Backing up %s to %s',
+                    "Backing up %s to %s",
                     display_path(archive_path),
                     display_path(dest_file),
                 )
                 shutil.move(archive_path, dest_file)
-            elif response == 'a':
+            elif response == "a":
                 sys.exit(-1)
 
         if not create_archive:
             return
 
         zip_output = zipfile.ZipFile(
-            archive_path, 'w', zipfile.ZIP_DEFLATED, allowZip64=True,
+            archive_path,
+            "w",
+            zipfile.ZIP_DEFLATED,
+            allowZip64=True,
         )
         with zip_output:
-            dir = os.path.normcase(
-                os.path.abspath(self.unpacked_source_directory)
-            )
+            dir = os.path.normcase(os.path.abspath(self.unpacked_source_directory))
             for dirpath, dirnames, filenames in os.walk(dir):
                 for dirname in dirnames:
                     dir_arcname = self._get_archive_name(
-                        dirname, parentdir=dirpath, rootdir=dir,
+                        dirname,
+                        parentdir=dirpath,
+                        rootdir=dir,
                     )
-                    zipdir = zipfile.ZipInfo(dir_arcname + '/')
+                    zipdir = zipfile.ZipInfo(dir_arcname + "/")
                     zipdir.external_attr = 0x1ED << 16  # 0o755
-                    zip_output.writestr(zipdir, '')
+                    zip_output.writestr(zipdir, "")
                 for filename in filenames:
                     file_arcname = self._get_archive_name(
-                        filename, parentdir=dirpath, rootdir=dir,
+                        filename,
+                        parentdir=dirpath,
+                        rootdir=dir,
                     )
                     filename = os.path.join(dirpath, filename)
                     zip_output.write(filename, file_arcname)
 
-        logger.info('Saved %s', display_path(archive_path))
+        logger.info("Saved %s", display_path(archive_path))
 
     def install(
         self,
         install_options: List[str],
         global_options: Optional[Sequence[str]] = None,
         root: Optional[str] = None,
         home: Optional[str] = None,
         prefix: Optional[str] = None,
         warn_script_location: bool = True,
         use_user_site: bool = False,
-        pycompile: bool = True
+        pycompile: bool = True,
     ) -> None:
         scheme = get_scheme(
             self.name,
             user=use_user_site,
             home=home,
             root=root,
             isolated=self.isolated,
             prefix=prefix,
         )
 
         global_options = global_options if global_options is not None else []
-        if self.editable:
+        if self.editable and not self.is_wheel:
             install_editable_legacy(
                 install_options,
                 global_options,
                 prefix=prefix,
                 home=home,
                 use_user_site=use_user_site,
                 name=self.name,
@@ -745,15 +787,17 @@
             )
             self.install_succeeded = True
             return
 
         if self.is_wheel:
             assert self.local_file_path
             direct_url = None
-            if self.original_link:
+            if self.editable:
+                direct_url = direct_url_for_editable(self.unpacked_source_directory)
+            elif self.original_link:
                 direct_url = direct_url_from_link(
                     self.original_link,
                     self.source_dir,
                     self.original_link_is_in_wheel_cache,
                 )
             install_wheel(
                 self.name,
@@ -793,27 +837,28 @@
                 req_name=self.name,
                 build_env=self.build_env,
                 unpacked_source_directory=self.unpacked_source_directory,
                 req_description=str(self.req),
             )
         except LegacyInstallFailure as exc:
             self.install_succeeded = False
-            six.reraise(*exc.parent)
+            raise exc.__cause__
         except Exception:
             self.install_succeeded = True
             raise
 
         self.install_succeeded = success
 
         if success and self.legacy_install_reason == 8368:
             deprecated(
                 reason=(
                     "{} was installed using the legacy 'setup.py install' "
-                    "method, because a wheel could not be built for it.".
-                    format(self.name)
+                    "method, because a wheel could not be built for it.".format(
+                        self.name
+                    )
                 ),
                 replacement="to fix the wheel build issue reported above",
                 gone_in=None,
                 issue=8368,
             )
```

#### pip/_internal/req/req_set.py

```diff
@@ -9,42 +9,40 @@
 from pip._internal.req.req_install import InstallRequirement
 from pip._internal.utils import compatibility_tags
 
 logger = logging.getLogger(__name__)
 
 
 class RequirementSet:
-
     def __init__(self, check_supported_wheels: bool = True) -> None:
-        """Create a RequirementSet.
-        """
+        """Create a RequirementSet."""
 
         self.requirements: Dict[str, InstallRequirement] = OrderedDict()
         self.check_supported_wheels = check_supported_wheels
 
         self.unnamed_requirements: List[InstallRequirement] = []
 
     def __str__(self) -> str:
         requirements = sorted(
             (req for req in self.requirements.values() if not req.comes_from),
             key=lambda req: canonicalize_name(req.name or ""),
         )
-        return ' '.join(str(req.req) for req in requirements)
+        return " ".join(str(req.req) for req in requirements)
 
     def __repr__(self) -> str:
         requirements = sorted(
             self.requirements.values(),
             key=lambda req: canonicalize_name(req.name or ""),
         )
 
-        format_string = '<{classname} object; {count} requirement(s): {reqs}>'
+        format_string = "<{classname} object; {count} requirement(s): {reqs}>"
         return format_string.format(
             classname=self.__class__.__name__,
             count=len(requirements),
-            reqs=', '.join(str(req.req) for req in requirements),
+            reqs=", ".join(str(req.req) for req in requirements),
         )
 
     def add_unnamed_requirement(self, install_req: InstallRequirement) -> None:
         assert not install_req.name
         self.unnamed_requirements.append(install_req)
 
     def add_named_requirement(self, install_req: InstallRequirement) -> None:
@@ -53,15 +51,15 @@
         project_name = canonicalize_name(install_req.name)
         self.requirements[project_name] = install_req
 
     def add_requirement(
         self,
         install_req: InstallRequirement,
         parent_req_name: Optional[str] = None,
-        extras_requested: Optional[Iterable[str]] = None
+        extras_requested: Optional[Iterable[str]] = None,
     ) -> Tuple[List[InstallRequirement], Optional[InstallRequirement]]:
         """Add install_req as a requirement to install.
 
         :param parent_req_name: The name of the requirement that needed this
             added. The name is used because when multiple unnamed requirements
             resolve to the same name, we could otherwise end up with dependency
             links that point outside the Requirements set. parent_req must
@@ -73,112 +71,113 @@
             the requirement is not applicable, or [install_req] if the
             requirement is applicable and has just been added.
         """
         # If the markers do not match, ignore this requirement.
         if not install_req.match_markers(extras_requested):
             logger.info(
                 "Ignoring %s: markers '%s' don't match your environment",
-                install_req.name, install_req.markers,
+                install_req.name,
+                install_req.markers,
             )
             return [], None
 
         # If the wheel is not supported, raise an error.
         # Should check this after filtering out based on environment markers to
         # allow specifying different wheels based on the environment/OS, in a
         # single requirements file.
         if install_req.link and install_req.link.is_wheel:
             wheel = Wheel(install_req.link.filename)
             tags = compatibility_tags.get_supported()
-            if (self.check_supported_wheels and not wheel.supported(tags)):
+            if self.check_supported_wheels and not wheel.supported(tags):
                 raise InstallationError(
                     "{} is not a supported wheel on this platform.".format(
-                        wheel.filename)
+                        wheel.filename
+                    )
                 )
 
         # This next bit is really a sanity check.
-        assert not install_req.user_supplied or parent_req_name is None, (
-            "a user supplied req shouldn't have a parent"
-        )
+        assert (
+            not install_req.user_supplied or parent_req_name is None
+        ), "a user supplied req shouldn't have a parent"
 
         # Unnamed requirements are scanned again and the requirement won't be
         # added as a dependency until after scanning.
         if not install_req.name:
             self.add_unnamed_requirement(install_req)
             return [install_req], None
 
         try:
             existing_req: Optional[InstallRequirement] = self.get_requirement(
-                install_req.name)
+                install_req.name
+            )
         except KeyError:
             existing_req = None
 
         has_conflicting_requirement = (
-            parent_req_name is None and
-            existing_req and
-            not existing_req.constraint and
-            existing_req.extras == install_req.extras and
-            existing_req.req and
-            install_req.req and
-            existing_req.req.specifier != install_req.req.specifier
+            parent_req_name is None
+            and existing_req
+            and not existing_req.constraint
+            and existing_req.extras == install_req.extras
+            and existing_req.req
+            and install_req.req
+            and existing_req.req.specifier != install_req.req.specifier
         )
         if has_conflicting_requirement:
             raise InstallationError(
-                "Double requirement given: {} (already in {}, name={!r})"
-                .format(install_req, existing_req, install_req.name)
+                "Double requirement given: {} (already in {}, name={!r})".format(
+                    install_req, existing_req, install_req.name
+                )
             )
 
         # When no existing requirement exists, add the requirement as a
         # dependency and it will be scanned again after.
         if not existing_req:
             self.add_named_requirement(install_req)
             # We'd want to rescan this requirement later
             return [install_req], install_req
 
         # Assume there's no need to scan, and that we've already
         # encountered this for scanning.
         if install_req.constraint or not existing_req.constraint:
             return [], existing_req
 
-        does_not_satisfy_constraint = (
-            install_req.link and
-            not (
-                existing_req.link and
-                install_req.link.path == existing_req.link.path
-            )
+        does_not_satisfy_constraint = install_req.link and not (
+            existing_req.link and install_req.link.path == existing_req.link.path
         )
         if does_not_satisfy_constraint:
             raise InstallationError(
                 "Could not satisfy constraints for '{}': "
                 "installation from path or url cannot be "
                 "constrained to a version".format(install_req.name)
             )
         # If we're now installing a constraint, mark the existing
         # object for real installation.
         existing_req.constraint = False
         # If we're now installing a user supplied requirement,
         # mark the existing object as such.
         if install_req.user_supplied:
             existing_req.user_supplied = True
-        existing_req.extras = tuple(sorted(
-            set(existing_req.extras) | set(install_req.extras)
-        ))
+        existing_req.extras = tuple(
+            sorted(set(existing_req.extras) | set(install_req.extras))
+        )
         logger.debug(
             "Setting %s extras to: %s",
-            existing_req, existing_req.extras,
+            existing_req,
+            existing_req.extras,
         )
         # Return the existing requirement for addition to the parent and
         # scanning again.
         return [existing_req], existing_req
 
     def has_requirement(self, name: str) -> bool:
         project_name = canonicalize_name(name)
 
         return (
-            project_name in self.requirements and
-            not self.requirements[project_name].constraint
+            project_name in self.requirements
+            and not self.requirements[project_name].constraint
         )
 
     def get_requirement(self, name: str) -> InstallRequirement:
         project_name = canonicalize_name(name)
 
         if project_name in self.requirements:
             return self.requirements[project_name]
```

#### pip/_internal/req/req_tracker.py

```diff
@@ -36,90 +36,84 @@
             else:
                 assert isinstance(original_value, str)  # for mypy
                 target[name] = original_value
 
 
 @contextlib.contextmanager
 def get_requirement_tracker() -> Iterator["RequirementTracker"]:
-    root = os.environ.get('PIP_REQ_TRACKER')
+    root = os.environ.get("PIP_REQ_TRACKER")
     with contextlib.ExitStack() as ctx:
         if root is None:
-            root = ctx.enter_context(
-                TempDirectory(kind='req-tracker')
-            ).path
+            root = ctx.enter_context(TempDirectory(kind="req-tracker")).path
             ctx.enter_context(update_env_context_manager(PIP_REQ_TRACKER=root))
             logger.debug("Initialized build tracking at %s", root)
 
         with RequirementTracker(root) as tracker:
             yield tracker
 
 
 class RequirementTracker:
-
     def __init__(self, root: str) -> None:
         self._root = root
         self._entries: Set[InstallRequirement] = set()
         logger.debug("Created build tracker: %s", self._root)
 
     def __enter__(self) -> "RequirementTracker":
         logger.debug("Entered build tracker: %s", self._root)
         return self
 
     def __exit__(
         self,
         exc_type: Optional[Type[BaseException]],
         exc_val: Optional[BaseException],
-        exc_tb: Optional[TracebackType]
+        exc_tb: Optional[TracebackType],
     ) -> None:
         self.cleanup()
 
     def _entry_path(self, link: Link) -> str:
         hashed = hashlib.sha224(link.url_without_fragment.encode()).hexdigest()
         return os.path.join(self._root, hashed)
 
     def add(self, req: InstallRequirement) -> None:
-        """Add an InstallRequirement to build tracking.
-        """
+        """Add an InstallRequirement to build tracking."""
 
         assert req.link
         # Get the file to write information about this requirement.
         entry_path = self._entry_path(req.link)
 
         # Try reading from the file. If it exists and can be read from, a build
         # is already in progress, so a LookupError is raised.
         try:
             with open(entry_path) as fp:
                 contents = fp.read()
         except FileNotFoundError:
             pass
         else:
-            message = '{} is already being built: {}'.format(
-                req.link, contents)
+            message = "{} is already being built: {}".format(req.link, contents)
             raise LookupError(message)
 
         # If we're here, req should really not be building already.
         assert req not in self._entries
 
         # Start tracking this requirement.
-        with open(entry_path, 'w', encoding="utf-8") as fp:
+        with open(entry_path, "w", encoding="utf-8") as fp:
             fp.write(str(req))
         self._entries.add(req)
 
-        logger.debug('Added %s to build tracker %r', req, self._root)
+        logger.debug("Added %s to build tracker %r", req, self._root)
 
     def remove(self, req: InstallRequirement) -> None:
-        """Remove an InstallRequirement from build tracking.
-        """
+        """Remove an InstallRequirement from build tracking."""
 
         assert req.link
         # Delete the created file and the corresponding entries.
         os.unlink(self._entry_path(req.link))
         self._entries.remove(req)
 
-        logger.debug('Removed %s from build tracker %r', req, self._root)
+        logger.debug("Removed %s from build tracker %r", req, self._root)
 
     def cleanup(self) -> None:
         for req in set(self._entries):
             self.remove(req)
 
         logger.debug("Removed build tracker: %r", self._root)
```

#### pip/_internal/req/req_uninstall.py

```diff
@@ -8,20 +8,20 @@
 
 from pip._vendor import pkg_resources
 from pip._vendor.pkg_resources import Distribution
 
 from pip._internal.exceptions import UninstallationError
 from pip._internal.locations import get_bin_prefix, get_bin_user
 from pip._internal.utils.compat import WINDOWS
+from pip._internal.utils.egg_link import egg_link_path_from_location
 from pip._internal.utils.logging import getLogger, indent_log
 from pip._internal.utils.misc import (
     ask,
     dist_in_usersite,
     dist_is_local,
-    egg_link_path,
     is_local,
     normalize_path,
     renames,
     rmtree,
 )
 from pip._internal.utils.temp_dir import AdjacentTempDirectory, TempDirectory
 
@@ -36,31 +36,32 @@
     if dist_in_usersite(dist):
         bin_dir = get_bin_user()
     else:
         bin_dir = get_bin_prefix()
     exe_name = os.path.join(bin_dir, script_name)
     paths_to_remove = [exe_name]
     if WINDOWS:
-        paths_to_remove.append(exe_name + '.exe')
-        paths_to_remove.append(exe_name + '.exe.manifest')
+        paths_to_remove.append(exe_name + ".exe")
+        paths_to_remove.append(exe_name + ".exe.manifest")
         if is_gui:
-            paths_to_remove.append(exe_name + '-script.pyw')
+            paths_to_remove.append(exe_name + "-script.pyw")
         else:
-            paths_to_remove.append(exe_name + '-script.py')
+            paths_to_remove.append(exe_name + "-script.py")
     return paths_to_remove
 
 
 def _unique(fn: Callable[..., Iterator[Any]]) -> Callable[..., Iterator[Any]]:
     @functools.wraps(fn)
     def unique(*args: Any, **kw: Any) -> Iterator[Any]:
         seen: Set[Any] = set()
         for item in fn(*args, **kw):
             if item not in seen:
                 seen.add(item)
                 yield item
+
     return unique
 
 
 @_unique
 def uninstallation_paths(dist: Distribution) -> Iterator[str]:
     """
     Yield all the uninstallation paths for dist based on RECORD-without-.py[co]
@@ -72,52 +73,54 @@
 
     If RECORD is not found, raises UninstallationError,
     with possible information from the INSTALLER file.
 
     https://packaging.python.org/specifications/recording-installed-packages/
     """
     try:
-        r = csv.reader(dist.get_metadata_lines('RECORD'))
+        r = csv.reader(dist.get_metadata_lines("RECORD"))
     except FileNotFoundError as missing_record_exception:
-        msg = 'Cannot uninstall {dist}, RECORD file not found.'.format(dist=dist)
+        msg = "Cannot uninstall {dist}, RECORD file not found.".format(dist=dist)
         try:
-            installer = next(dist.get_metadata_lines('INSTALLER'))
-            if not installer or installer == 'pip':
+            installer = next(dist.get_metadata_lines("INSTALLER"))
+            if not installer or installer == "pip":
                 raise ValueError()
         except (OSError, StopIteration, ValueError):
-            dep = '{}=={}'.format(dist.project_name, dist.version)
-            msg += (" You might be able to recover from this via: "
-                    "'pip install --force-reinstall --no-deps {}'.".format(dep))
+            dep = "{}=={}".format(dist.project_name, dist.version)
+            msg += (
+                " You might be able to recover from this via: "
+                "'pip install --force-reinstall --no-deps {}'.".format(dep)
+            )
         else:
-            msg += ' Hint: The package was installed by {}.'.format(installer)
+            msg += " Hint: The package was installed by {}.".format(installer)
         raise UninstallationError(msg) from missing_record_exception
     for row in r:
         path = os.path.join(dist.location, row[0])
         yield path
-        if path.endswith('.py'):
+        if path.endswith(".py"):
             dn, fn = os.path.split(path)
             base = fn[:-3]
-            path = os.path.join(dn, base + '.pyc')
+            path = os.path.join(dn, base + ".pyc")
             yield path
-            path = os.path.join(dn, base + '.pyo')
+            path = os.path.join(dn, base + ".pyo")
             yield path
 
 
 def compact(paths: Iterable[str]) -> Set[str]:
     """Compact a path set to contain the minimal number of paths
     necessary to contain all paths in the set. If /a/path/ and
     /a/path/to/a/file.txt are both in the set, leave only the
     shorter path."""
 
     sep = os.path.sep
     short_paths: Set[str] = set()
     for path in sorted(paths, key=len):
         should_skip = any(
-            path.startswith(shortpath.rstrip("*")) and
-            path[len(shortpath.rstrip("*").rstrip(sep))] == sep
+            path.startswith(shortpath.rstrip("*"))
+            and path[len(shortpath.rstrip("*").rstrip(sep))] == sep
             for shortpath in short_paths
         )
         if not should_skip:
             short_paths.add(path)
     return short_paths
 
 
@@ -132,26 +135,23 @@
     unchecked = sorted({os.path.split(p)[0] for p in case_map.values()}, key=len)
     wildcards: Set[str] = set()
 
     def norm_join(*a: str) -> str:
         return os.path.normcase(os.path.join(*a))
 
     for root in unchecked:
-        if any(os.path.normcase(root).startswith(w)
-               for w in wildcards):
+        if any(os.path.normcase(root).startswith(w) for w in wildcards):
             # This directory has already been handled.
             continue
 
         all_files: Set[str] = set()
         all_subdirs: Set[str] = set()
         for dirname, subdirs, files in os.walk(root):
-            all_subdirs.update(norm_join(root, dirname, d)
-                               for d in subdirs)
-            all_files.update(norm_join(root, dirname, f)
-                             for f in files)
+            all_subdirs.update(norm_join(root, dirname, d) for d in subdirs)
+            all_files.update(norm_join(root, dirname, f) for f in files)
         # If all the files we found are in our remaining set of files to
         # remove, then remove them from the latter set and add a wildcard
         # for the directory.
         if not (all_files - remaining):
             remaining.difference_update(all_files)
             wildcards.add(root + os.sep)
 
@@ -192,29 +192,30 @@
     for folder in folders:
         for dirpath, _, dirfiles in os.walk(folder):
             for fname in dirfiles:
                 if fname.endswith(".pyc"):
                     continue
 
                 file_ = os.path.join(dirpath, fname)
-                if (os.path.isfile(file_) and
-                        os.path.normcase(file_) not in _normcased_files):
+                if (
+                    os.path.isfile(file_)
+                    and os.path.normcase(file_) not in _normcased_files
+                ):
                     # We are skipping this file. Add it to the set.
                     will_skip.add(file_)
 
-    will_remove = files | {
-        os.path.join(folder, "*") for folder in folders
-    }
+    will_remove = files | {os.path.join(folder, "*") for folder in folders}
 
     return will_remove, will_skip
 
 
 class StashedUninstallPathSet:
     """A set of file rename operations to stash files while
     tentatively uninstalling them."""
+
     def __init__(self) -> None:
         # Mapping from source file root to [Adjacent]TempDirectory
         # for files under that directory.
         self._save_dirs: Dict[str, TempDirectory] = {}
         # (old path, new path) tuples for each move that may need
         # to be undone.
         self._moves: List[Tuple[str, str]] = []
@@ -248,15 +249,15 @@
                 break
             except KeyError:
                 pass
             head, old_head = os.path.dirname(head), head
         else:
             # Did not find any suitable root
             head = os.path.dirname(path)
-            save_dir = TempDirectory(kind='uninstall')
+            save_dir = TempDirectory(kind="uninstall")
             self._save_dirs[head] = save_dir
 
         relpath = os.path.relpath(path, head)
         if relpath and relpath != os.path.curdir:
             return os.path.join(save_dir.path, relpath)
         return save_dir.path
 
@@ -267,15 +268,15 @@
         path_is_dir = os.path.isdir(path) and not os.path.islink(path)
         if path_is_dir:
             new_path = self._get_directory_stash(path)
         else:
             new_path = self._get_file_stash(path)
 
         self._moves.append((path, new_path))
-        if (path_is_dir and os.path.isdir(new_path)):
+        if path_is_dir and os.path.isdir(new_path):
             # If we're moving a directory, we need to
             # remove the destination first or else it will be
             # moved to inside the existing directory.
             # We just created new_path ourselves, so it will
             # be removable.
             os.rmdir(new_path)
         renames(path, new_path)
@@ -291,15 +292,15 @@
     def rollback(self) -> None:
         """Undoes the uninstall by moving stashed files back."""
         for p in self._moves:
             logger.info("Moving to %s\n from %s", *p)
 
         for new_path, path in self._moves:
             try:
-                logger.debug('Replacing %s from %s', new_path, path)
+                logger.debug("Replacing %s from %s", new_path, path)
                 if os.path.isfile(new_path) or os.path.islink(new_path):
                     os.unlink(new_path)
                 elif os.path.isdir(new_path):
                     rmtree(new_path)
                 renames(path, new_path)
             except OSError as ex:
                 logger.error("Failed to restore %s", new_path)
@@ -311,14 +312,15 @@
     def can_rollback(self) -> bool:
         return bool(self._moves)
 
 
 class UninstallPathSet:
     """A set of file paths to be removed in the uninstallation of a
     requirement."""
+
     def __init__(self, dist: Distribution) -> None:
         self.paths: Set[str] = set()
         self._refuse: Set[str] = set()
         self.pth: Dict[str, UninstallPthEntries] = {}
         self.dist = dist
         self._moved_paths = StashedUninstallPathSet()
 
@@ -342,15 +344,15 @@
         if self._permitted(path):
             self.paths.add(path)
         else:
             self._refuse.add(path)
 
         # __pycache__ files can show up after 'installed-files.txt' is created,
         # due to imports
-        if os.path.splitext(path)[1] == '.py':
+        if os.path.splitext(path)[1] == ".py":
             self.add(cache_from_source(path))
 
     def add_pth(self, pth_file: str, entry: str) -> None:
         pth_file = normalize_path(pth_file)
         if self._permitted(pth_file):
             if pth_file not in self.pth:
                 self.pth[pth_file] = UninstallPthEntries(pth_file)
@@ -365,37 +367,34 @@
         if not self.paths:
             logger.info(
                 "Can't uninstall '%s'. No files were found to uninstall.",
                 self.dist.project_name,
             )
             return
 
-        dist_name_version = (
-            self.dist.project_name + "-" + self.dist.version
-        )
-        logger.info('Uninstalling %s:', dist_name_version)
+        dist_name_version = self.dist.project_name + "-" + self.dist.version
+        logger.info("Uninstalling %s:", dist_name_version)
 
         with indent_log():
             if auto_confirm or self._allowed_to_proceed(verbose):
                 moved = self._moved_paths
 
                 for_rename = compress_for_rename(self.paths)
 
                 for path in sorted(compact(for_rename)):
                     moved.stash(path)
-                    logger.verbose('Removing file or directory %s', path)
+                    logger.verbose("Removing file or directory %s", path)
 
                 for pth in self.pth.values():
                     pth.remove()
 
-                logger.info('Successfully uninstalled %s', dist_name_version)
+                logger.info("Successfully uninstalled %s", dist_name_version)
 
     def _allowed_to_proceed(self, verbose: bool) -> bool:
-        """Display which files would be deleted and prompt for confirmation
-        """
+        """Display which files would be deleted and prompt for confirmation"""
 
         def _display(msg: str, paths: Iterable[str]) -> None:
             if not paths:
                 return
 
             logger.info(msg)
             with indent_log():
@@ -406,31 +405,31 @@
             will_remove, will_skip = compress_for_output_listing(self.paths)
         else:
             # In verbose mode, display all the files that are going to be
             # deleted.
             will_remove = set(self.paths)
             will_skip = set()
 
-        _display('Would remove:', will_remove)
-        _display('Would not remove (might be manually added):', will_skip)
-        _display('Would not remove (outside of prefix):', self._refuse)
+        _display("Would remove:", will_remove)
+        _display("Would not remove (might be manually added):", will_skip)
+        _display("Would not remove (outside of prefix):", self._refuse)
         if verbose:
-            _display('Will actually move:', compress_for_rename(self.paths))
+            _display("Will actually move:", compress_for_rename(self.paths))
 
-        return ask('Proceed (Y/n)? ', ('y', 'n', '')) != 'n'
+        return ask("Proceed (Y/n)? ", ("y", "n", "")) != "n"
 
     def rollback(self) -> None:
         """Rollback the changes previously made by remove()."""
         if not self._moved_paths.can_rollback:
             logger.error(
                 "Can't roll back %s; was not uninstalled",
                 self.dist.project_name,
             )
             return
-        logger.info('Rolling back uninstall of %s', self.dist.project_name)
+        logger.info("Rolling back uninstall of %s", self.dist.project_name)
         self._moved_paths.rollback()
         for pth in self.pth.values():
             pth.rollback()
 
     def commit(self) -> None:
         """Remove temporary save dir: rollback will no longer be possible."""
         self._moved_paths.commit()
@@ -443,125 +442,134 @@
                 "Not uninstalling %s at %s, outside environment %s",
                 dist.key,
                 dist_path,
                 sys.prefix,
             )
             return cls(dist)
 
-        if dist_path in {p for p in {sysconfig.get_path("stdlib"),
-                                     sysconfig.get_path("platstdlib")}
-                         if p}:
+        if dist_path in {
+            p
+            for p in {sysconfig.get_path("stdlib"), sysconfig.get_path("platstdlib")}
+            if p
+        }:
             logger.info(
                 "Not uninstalling %s at %s, as it is in the standard library.",
                 dist.key,
                 dist_path,
             )
             return cls(dist)
 
         paths_to_remove = cls(dist)
-        develop_egg_link = egg_link_path(dist)
-        develop_egg_link_egg_info = '{}.egg-info'.format(
-            pkg_resources.to_filename(dist.project_name))
+        develop_egg_link = egg_link_path_from_location(dist.project_name)
+        develop_egg_link_egg_info = "{}.egg-info".format(
+            pkg_resources.to_filename(dist.project_name)
+        )
         egg_info_exists = dist.egg_info and os.path.exists(dist.egg_info)
         # Special case for distutils installed package
-        distutils_egg_info = getattr(dist._provider, 'path', None)
+        distutils_egg_info = getattr(dist._provider, "path", None)
 
         # Uninstall cases order do matter as in the case of 2 installs of the
         # same package, pip needs to uninstall the currently detected version
-        if (egg_info_exists and dist.egg_info.endswith('.egg-info') and
-                not dist.egg_info.endswith(develop_egg_link_egg_info)):
+        if (
+            egg_info_exists
+            and dist.egg_info.endswith(".egg-info")
+            and not dist.egg_info.endswith(develop_egg_link_egg_info)
+        ):
             # if dist.egg_info.endswith(develop_egg_link_egg_info), we
             # are in fact in the develop_egg_link case
             paths_to_remove.add(dist.egg_info)
-            if dist.has_metadata('installed-files.txt'):
+            if dist.has_metadata("installed-files.txt"):
                 for installed_file in dist.get_metadata(
-                        'installed-files.txt').splitlines():
-                    path = os.path.normpath(
-                        os.path.join(dist.egg_info, installed_file)
-                    )
+                    "installed-files.txt"
+                ).splitlines():
+                    path = os.path.normpath(os.path.join(dist.egg_info, installed_file))
                     paths_to_remove.add(path)
             # FIXME: need a test for this elif block
             # occurs with --single-version-externally-managed/--record outside
             # of pip
-            elif dist.has_metadata('top_level.txt'):
-                if dist.has_metadata('namespace_packages.txt'):
-                    namespaces = dist.get_metadata('namespace_packages.txt')
+            elif dist.has_metadata("top_level.txt"):
+                if dist.has_metadata("namespace_packages.txt"):
+                    namespaces = dist.get_metadata("namespace_packages.txt")
                 else:
                     namespaces = []
                 for top_level_pkg in [
-                        p for p
-                        in dist.get_metadata('top_level.txt').splitlines()
-                        if p and p not in namespaces]:
+                    p
+                    for p in dist.get_metadata("top_level.txt").splitlines()
+                    if p and p not in namespaces
+                ]:
                     path = os.path.join(dist.location, top_level_pkg)
                     paths_to_remove.add(path)
-                    paths_to_remove.add(path + '.py')
-                    paths_to_remove.add(path + '.pyc')
-                    paths_to_remove.add(path + '.pyo')
+                    paths_to_remove.add(path + ".py")
+                    paths_to_remove.add(path + ".pyc")
+                    paths_to_remove.add(path + ".pyo")
 
         elif distutils_egg_info:
             raise UninstallationError(
                 "Cannot uninstall {!r}. It is a distutils installed project "
                 "and thus we cannot accurately determine which files belong "
                 "to it which would lead to only a partial uninstall.".format(
                     dist.project_name,
                 )
             )
 
-        elif dist.location.endswith('.egg'):
+        elif dist.location.endswith(".egg"):
             # package installed by easy_install
             # We cannot match on dist.egg_name because it can slightly vary
             # i.e. setuptools-0.6c11-py2.6.egg vs setuptools-0.6rc11-py2.6.egg
             paths_to_remove.add(dist.location)
             easy_install_egg = os.path.split(dist.location)[1]
-            easy_install_pth = os.path.join(os.path.dirname(dist.location),
-                                            'easy-install.pth')
-            paths_to_remove.add_pth(easy_install_pth, './' + easy_install_egg)
+            easy_install_pth = os.path.join(
+                os.path.dirname(dist.location), "easy-install.pth"
+            )
+            paths_to_remove.add_pth(easy_install_pth, "./" + easy_install_egg)
 
-        elif egg_info_exists and dist.egg_info.endswith('.dist-info'):
+        elif egg_info_exists and dist.egg_info.endswith(".dist-info"):
             for path in uninstallation_paths(dist):
                 paths_to_remove.add(path)
 
         elif develop_egg_link:
             # develop egg
             with open(develop_egg_link) as fh:
                 link_pointer = os.path.normcase(fh.readline().strip())
-            assert (link_pointer == dist.location), (
-                'Egg-link {} does not match installed location of {} '
-                '(at {})'.format(
-                    link_pointer, dist.project_name, dist.location)
+            assert (
+                link_pointer == dist.location
+            ), "Egg-link {} does not match installed location of {} (at {})".format(
+                link_pointer, dist.project_name, dist.location
             )
             paths_to_remove.add(develop_egg_link)
-            easy_install_pth = os.path.join(os.path.dirname(develop_egg_link),
-                                            'easy-install.pth')
+            easy_install_pth = os.path.join(
+                os.path.dirname(develop_egg_link), "easy-install.pth"
+            )
             paths_to_remove.add_pth(easy_install_pth, dist.location)
 
         else:
             logger.debug(
-                'Not sure how to uninstall: %s - Check: %s',
-                dist, dist.location,
+                "Not sure how to uninstall: %s - Check: %s",
+                dist,
+                dist.location,
             )
 
         # find distutils scripts= scripts
-        if dist.has_metadata('scripts') and dist.metadata_isdir('scripts'):
-            for script in dist.metadata_listdir('scripts'):
+        if dist.has_metadata("scripts") and dist.metadata_isdir("scripts"):
+            for script in dist.metadata_listdir("scripts"):
                 if dist_in_usersite(dist):
                     bin_dir = get_bin_user()
                 else:
                     bin_dir = get_bin_prefix()
                 paths_to_remove.add(os.path.join(bin_dir, script))
                 if WINDOWS:
-                    paths_to_remove.add(os.path.join(bin_dir, script) + '.bat')
+                    paths_to_remove.add(os.path.join(bin_dir, script) + ".bat")
 
         # find console_scripts
         _scripts_to_remove = []
-        console_scripts = dist.get_entry_map(group='console_scripts')
+        console_scripts = dist.get_entry_map(group="console_scripts")
         for name in console_scripts.keys():
             _scripts_to_remove.extend(_script_names(dist, name, False))
         # find gui_scripts
-        gui_scripts = dist.get_entry_map(group='gui_scripts')
+        gui_scripts = dist.get_entry_map(group="gui_scripts")
         for name in gui_scripts.keys():
             _scripts_to_remove.extend(_script_names(dist, name, True))
 
         for s in _scripts_to_remove:
             paths_to_remove.add(s)
 
         return paths_to_remove
@@ -581,49 +589,45 @@
         # slashes.
         # os.path.splitdrive is used instead of os.path.isabs because isabs
         # treats non-absolute paths with drive letter markings like c:foo\bar
         # as absolute paths. It also does not recognize UNC paths if they don't
         # have more than "\\sever\share". Valid examples: "\\server\share\" or
         # "\\server\share\folder".
         if WINDOWS and not os.path.splitdrive(entry)[0]:
-            entry = entry.replace('\\', '/')
+            entry = entry.replace("\\", "/")
         self.entries.add(entry)
 
     def remove(self) -> None:
-        logger.verbose('Removing pth entries from %s:', self.file)
+        logger.verbose("Removing pth entries from %s:", self.file)
 
         # If the file doesn't exist, log a warning and return
         if not os.path.isfile(self.file):
-            logger.warning(
-                "Cannot remove entries from nonexistent file %s", self.file
-            )
+            logger.warning("Cannot remove entries from nonexistent file %s", self.file)
             return
-        with open(self.file, 'rb') as fh:
+        with open(self.file, "rb") as fh:
             # windows uses '\r\n' with py3k, but uses '\n' with py2.x
             lines = fh.readlines()
             self._saved_lines = lines
-        if any(b'\r\n' in line for line in lines):
-            endline = '\r\n'
+        if any(b"\r\n" in line for line in lines):
+            endline = "\r\n"
         else:
-            endline = '\n'
+            endline = "\n"
         # handle missing trailing newline
         if lines and not lines[-1].endswith(endline.encode("utf-8")):
             lines[-1] = lines[-1] + endline.encode("utf-8")
         for entry in self.entries:
             try:
-                logger.verbose('Removing entry: %s', entry)
+                logger.verbose("Removing entry: %s", entry)
                 lines.remove((entry + endline).encode("utf-8"))
             except ValueError:
                 pass
-        with open(self.file, 'wb') as fh:
+        with open(self.file, "wb") as fh:
             fh.writelines(lines)
 
     def rollback(self) -> bool:
         if self._saved_lines is None:
-            logger.error(
-                'Cannot roll back changes to %s, none were made', self.file
-            )
+            logger.error("Cannot roll back changes to %s, none were made", self.file)
             return False
-        logger.debug('Rolling %s back to previous state', self.file)
-        with open(self.file, 'wb') as fh:
+        logger.debug("Rolling %s back to previous state", self.file)
+        with open(self.file, "wb") as fh:
             fh.writelines(self._saved_lines)
         return True
```

#### pip/_internal/resolution/base.py

```diff
@@ -1,13 +1,15 @@
-from typing import Callable, List
+from typing import Callable, List, Optional
 
 from pip._internal.req.req_install import InstallRequirement
 from pip._internal.req.req_set import RequirementSet
 
-InstallRequirementProvider = Callable[[str, InstallRequirement], InstallRequirement]
+InstallRequirementProvider = Callable[
+    [str, Optional[InstallRequirement]], InstallRequirement
+]
 
 
 class BaseResolver:
     def resolve(
         self, root_reqs: List[InstallRequirement], check_supported_wheels: bool
     ) -> RequirementSet:
         raise NotImplementedError()
```

#### pip/_internal/resolution/legacy/resolver.py

```diff
@@ -16,45 +16,47 @@
 import logging
 import sys
 from collections import defaultdict
 from itertools import chain
 from typing import DefaultDict, Iterable, List, Optional, Set, Tuple
 
 from pip._vendor.packaging import specifiers
-from pip._vendor.pkg_resources import Distribution
+from pip._vendor.packaging.requirements import Requirement
 
 from pip._internal.cache import WheelCache
 from pip._internal.exceptions import (
     BestVersionAlreadyInstalled,
     DistributionNotFound,
     HashError,
     HashErrors,
+    NoneMetadataError,
     UnsupportedPythonVersion,
 )
 from pip._internal.index.package_finder import PackageFinder
+from pip._internal.metadata import BaseDistribution
 from pip._internal.models.link import Link
 from pip._internal.operations.prepare import RequirementPreparer
 from pip._internal.req.req_install import (
     InstallRequirement,
     check_invalid_constraint_type,
 )
 from pip._internal.req.req_set import RequirementSet
 from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
 from pip._internal.utils.compatibility_tags import get_supported
 from pip._internal.utils.logging import indent_log
 from pip._internal.utils.misc import dist_in_usersite, normalize_version_info
-from pip._internal.utils.packaging import check_requires_python, get_requires_python
+from pip._internal.utils.packaging import check_requires_python
 
 logger = logging.getLogger(__name__)
 
 DiscoveredDependencies = DefaultDict[str, List[InstallRequirement]]
 
 
 def _check_dist_requires_python(
-    dist: Distribution,
+    dist: BaseDistribution,
     version_info: Tuple[int, int, int],
     ignore_requires_python: bool = False,
 ) -> None:
     """
     Check whether the given Python version is compatible with a distribution's
     "Requires-Python" value.
 
@@ -62,41 +64,48 @@
         major-minor-micro version to check.
     :param ignore_requires_python: Whether to ignore the "Requires-Python"
         value if the given Python version isn't compatible.
 
     :raises UnsupportedPythonVersion: When the given Python version isn't
         compatible.
     """
-    requires_python = get_requires_python(dist)
+    # This idiosyncratically converts the SpecifierSet to str and let
+    # check_requires_python then parse it again into SpecifierSet. But this
+    # is the legacy resolver so I'm just not going to bother refactoring.
+    try:
+        requires_python = str(dist.requires_python)
+    except FileNotFoundError as e:
+        raise NoneMetadataError(dist, str(e))
     try:
         is_compatible = check_requires_python(
-            requires_python, version_info=version_info
+            requires_python,
+            version_info=version_info,
         )
     except specifiers.InvalidSpecifier as exc:
         logger.warning(
-            "Package %r has an invalid Requires-Python: %s", dist.project_name, exc
+            "Package %r has an invalid Requires-Python: %s", dist.raw_name, exc
         )
         return
 
     if is_compatible:
         return
 
     version = ".".join(map(str, version_info))
     if ignore_requires_python:
         logger.debug(
             "Ignoring failed Requires-Python check for package %r: %s not in %r",
-            dist.project_name,
+            dist.raw_name,
             version,
             requires_python,
         )
         return
 
     raise UnsupportedPythonVersion(
         "Package {!r} requires a different Python: {} not in {!r}".format(
-            dist.project_name, version, requires_python
+            dist.raw_name, version, requires_python
         )
     )
 
 
 class Resolver(BaseResolver):
     """Resolves which packages need to be installed/uninstalled to perform \
     the requested operation without breaking the requirements of any package.
@@ -299,15 +308,15 @@
         )
         if cache_entry is not None:
             logger.debug("Using cached wheel link: %s", cache_entry.link)
             if req.link is req.original_link and cache_entry.persistent:
                 req.original_link_is_in_wheel_cache = True
             req.link = cache_entry.link
 
-    def _get_dist_for(self, req: InstallRequirement) -> Distribution:
+    def _get_dist_for(self, req: InstallRequirement) -> BaseDistribution:
         """Takes a InstallRequirement and returns a single AbstractDist \
         representing a prepared variant of the same.
         """
         if req.editable:
             return self.preparer.prepare_editable_requirement(req)
 
         # satisfied_by is only evaluated by calling _check_skip_installed,
@@ -374,19 +383,19 @@
             dist,
             version_info=self._py_version_info,
             ignore_requires_python=self.ignore_requires_python,
         )
 
         more_reqs: List[InstallRequirement] = []
 
-        def add_req(subreq: Distribution, extras_requested: Iterable[str]) -> None:
-            sub_install_req = self._make_install_req(
-                str(subreq),
-                req_to_install,
-            )
+        def add_req(subreq: Requirement, extras_requested: Iterable[str]) -> None:
+            # This idiosyncratically converts the Requirement to str and let
+            # make_install_req then parse it again into Requirement. But this is
+            # the legacy resolver so I'm just not going to bother refactoring.
+            sub_install_req = self._make_install_req(str(subreq), req_to_install)
             parent_req_name = req_to_install.name
             to_scan_again, add_to_parent = requirement_set.add_requirement(
                 sub_install_req,
                 parent_req_name=parent_req_name,
                 extras_requested=extras_requested,
             )
             if parent_req_name and add_to_parent:
@@ -406,23 +415,28 @@
             if not self.ignore_dependencies:
                 if req_to_install.extras:
                     logger.debug(
                         "Installing extra requirements: %r",
                         ",".join(req_to_install.extras),
                     )
                 missing_requested = sorted(
-                    set(req_to_install.extras) - set(dist.extras)
+                    set(req_to_install.extras) - set(dist.iter_provided_extras())
                 )
                 for missing in missing_requested:
-                    logger.warning("%s does not provide the extra '%s'", dist, missing)
+                    logger.warning(
+                        "%s %s does not provide the extra '%s'",
+                        dist.raw_name,
+                        dist.version,
+                        missing,
+                    )
 
                 available_requested = sorted(
-                    set(dist.extras) & set(req_to_install.extras)
+                    set(dist.iter_provided_extras()) & set(req_to_install.extras)
                 )
-                for subreq in dist.requires(available_requested):
+                for subreq in dist.iter_dependencies(available_requested):
                     add_req(subreq, extras_requested=available_requested)
 
         return more_reqs
 
     def get_installation_order(
         self, req_set: RequirementSet
     ) -> List[InstallRequirement]:
```

#### pip/_internal/resolution/resolvelib/base.py

```diff
@@ -32,19 +32,16 @@
         return Constraint(SpecifierSet(), Hashes(), frozenset())
 
     @classmethod
     def from_ireq(cls, ireq: InstallRequirement) -> "Constraint":
         links = frozenset([ireq.link]) if ireq.link else frozenset()
         return Constraint(ireq.specifier, ireq.hashes(trust_internet=False), links)
 
-    def __nonzero__(self) -> bool:
-        return bool(self.specifier) or bool(self.hashes) or bool(self.links)
-
     def __bool__(self) -> bool:
-        return self.__nonzero__()
+        return bool(self.specifier) or bool(self.hashes) or bool(self.links)
 
     def __and__(self, other: InstallRequirement) -> "Constraint":
         if not isinstance(other, InstallRequirement):
             return NotImplemented
         specifier = self.specifier & other.specifier
         hashes = self.hashes & other.hashes(trust_internet=False)
         links = self.links
```

#### pip/_internal/resolution/resolvelib/candidates.py

```diff
@@ -1,27 +1,24 @@
 import logging
 import sys
 from typing import TYPE_CHECKING, Any, FrozenSet, Iterable, Optional, Tuple, Union, cast
 
-from pip._vendor.packaging.specifiers import InvalidSpecifier, SpecifierSet
 from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
 from pip._vendor.packaging.version import Version
-from pip._vendor.packaging.version import parse as parse_version
-from pip._vendor.pkg_resources import Distribution
 
 from pip._internal.exceptions import HashError, MetadataInconsistent
+from pip._internal.metadata import BaseDistribution
 from pip._internal.models.link import Link, links_equivalent
 from pip._internal.models.wheel import Wheel
 from pip._internal.req.constructors import (
     install_req_from_editable,
     install_req_from_line,
 )
 from pip._internal.req.req_install import InstallRequirement
-from pip._internal.utils.misc import dist_is_editable, normalize_version_info
-from pip._internal.utils.packaging import get_requires_python
+from pip._internal.utils.misc import normalize_version_info
 
 from .base import Candidate, CandidateVersion, Requirement, format_name
 
 if TYPE_CHECKING:
     from .factory import Factory
 
 logger = logging.getLogger(__name__)
@@ -81,46 +78,48 @@
     return install_req_from_editable(
         link.url,
         user_supplied=template.user_supplied,
         comes_from=template.comes_from,
         use_pep517=template.use_pep517,
         isolated=template.isolated,
         constraint=template.constraint,
+        permit_editable_wheels=template.permit_editable_wheels,
         options=dict(
             install_options=template.install_options,
             global_options=template.global_options,
             hashes=template.hash_options,
         ),
     )
 
 
-def make_install_req_from_dist(
-    dist: Distribution, template: InstallRequirement
+def _make_install_req_from_dist(
+    dist: BaseDistribution, template: InstallRequirement
 ) -> InstallRequirement:
-    project_name = canonicalize_name(dist.project_name)
+    from pip._internal.metadata.pkg_resources import Distribution as _Dist
+
     if template.req:
         line = str(template.req)
     elif template.link:
-        line = f"{project_name} @ {template.link.url}"
+        line = f"{dist.canonical_name} @ {template.link.url}"
     else:
-        line = f"{project_name}=={dist.parsed_version}"
+        line = f"{dist.canonical_name}=={dist.version}"
     ireq = install_req_from_line(
         line,
         user_supplied=template.user_supplied,
         comes_from=template.comes_from,
         use_pep517=template.use_pep517,
         isolated=template.isolated,
         constraint=template.constraint,
         options=dict(
             install_options=template.install_options,
             global_options=template.global_options,
             hashes=template.hash_options,
         ),
     )
-    ireq.satisfied_by = dist
+    ireq.satisfied_by = cast(_Dist, dist)._dist
     return ireq
 
 
 class _InstallRequirementBackedCandidate(Candidate):
     """A candidate backed by an ``InstallRequirement``.
 
     This represents a package request with the target not being already
@@ -132,14 +131,15 @@
         ``InstallRequirement`` will use this link to fetch the distribution.
     :param source_link: The link this candidate "originates" from. This is
         different from ``link`` when the link is found in the wheel cache.
         ``link`` would point to the wheel cache, while this points to the
         found remote link (e.g. from pypi.org).
     """
 
+    dist: BaseDistribution
     is_installed = False
 
     def __init__(
         self,
         link: Link,
         source_link: Link,
         ireq: InstallRequirement,
@@ -176,85 +176,71 @@
     def source_link(self) -> Optional[Link]:
         return self._source_link
 
     @property
     def project_name(self) -> NormalizedName:
         """The normalised name of the project the candidate refers to"""
         if self._name is None:
-            self._name = canonicalize_name(self.dist.project_name)
+            self._name = self.dist.canonical_name
         return self._name
 
     @property
     def name(self) -> str:
         return self.project_name
 
     @property
     def version(self) -> CandidateVersion:
         if self._version is None:
-            self._version = parse_version(self.dist.version)
+            self._version = self.dist.version
         return self._version
 
     def format_for_error(self) -> str:
         return "{} {} (from {})".format(
             self.name,
             self.version,
             self._link.file_path if self._link.is_file else self._link,
         )
 
-    def _prepare_distribution(self) -> Distribution:
+    def _prepare_distribution(self) -> BaseDistribution:
         raise NotImplementedError("Override in subclass")
 
-    def _check_metadata_consistency(self, dist: Distribution) -> None:
+    def _check_metadata_consistency(self, dist: BaseDistribution) -> None:
         """Check for consistency of project name and version of dist."""
-        canonical_name = canonicalize_name(dist.project_name)
-        if self._name is not None and self._name != canonical_name:
+        if self._name is not None and self._name != dist.canonical_name:
             raise MetadataInconsistent(
                 self._ireq,
                 "name",
                 self._name,
-                dist.project_name,
+                dist.canonical_name,
             )
-        parsed_version = parse_version(dist.version)
-        if self._version is not None and self._version != parsed_version:
+        if self._version is not None and self._version != dist.version:
             raise MetadataInconsistent(
                 self._ireq,
                 "version",
                 str(self._version),
-                dist.version,
+                str(dist.version),
             )
 
-    def _prepare(self) -> Distribution:
+    def _prepare(self) -> BaseDistribution:
         try:
             dist = self._prepare_distribution()
         except HashError as e:
             # Provide HashError the underlying ireq that caused it. This
             # provides context for the resulting error message to show the
             # offending line to the user.
             e.req = self._ireq
             raise
         self._check_metadata_consistency(dist)
         return dist
 
-    def _get_requires_python_dependency(self) -> Optional[Requirement]:
-        requires_python = get_requires_python(self.dist)
-        if requires_python is None:
-            return None
-        try:
-            spec = SpecifierSet(requires_python)
-        except InvalidSpecifier as e:
-            message = "Package %r has an invalid Requires-Python: %s"
-            logger.warning(message, self.name, e)
-            return None
-        return self._factory.make_requires_python_requirement(spec)
-
     def iter_dependencies(self, with_requires: bool) -> Iterable[Optional[Requirement]]:
-        requires = self.dist.requires() if with_requires else ()
+        requires = self.dist.iter_dependencies() if with_requires else ()
         for r in requires:
             yield self._factory.make_requirement_from_spec(str(r), self._ireq)
-        yield self._get_requires_python_dependency()
+        yield self._factory.make_requires_python_requirement(self.dist.requires_python)
 
     def get_install_requirement(self) -> Optional[InstallRequirement]:
         return self._ireq
 
 
 class LinkCandidate(_InstallRequirementBackedCandidate):
     is_editable = False
@@ -297,18 +283,17 @@
             source_link=source_link,
             ireq=ireq,
             factory=factory,
             name=name,
             version=version,
         )
 
-    def _prepare_distribution(self) -> Distribution:
-        return self._factory.preparer.prepare_linked_requirement(
-            self._ireq, parallel_builds=True
-        )
+    def _prepare_distribution(self) -> BaseDistribution:
+        preparer = self._factory.preparer
+        return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)
 
 
 class EditableCandidate(_InstallRequirementBackedCandidate):
     is_editable = True
 
     def __init__(
         self,
@@ -323,35 +308,35 @@
             source_link=link,
             ireq=make_install_req_from_editable(link, template),
             factory=factory,
             name=name,
             version=version,
         )
 
-    def _prepare_distribution(self) -> Distribution:
+    def _prepare_distribution(self) -> BaseDistribution:
         return self._factory.preparer.prepare_editable_requirement(self._ireq)
 
 
 class AlreadyInstalledCandidate(Candidate):
     is_installed = True
     source_link = None
 
     def __init__(
         self,
-        dist: Distribution,
+        dist: BaseDistribution,
         template: InstallRequirement,
         factory: "Factory",
     ) -> None:
         self.dist = dist
-        self._ireq = make_install_req_from_dist(dist, template)
+        self._ireq = _make_install_req_from_dist(dist, template)
         self._factory = factory
 
         # This is just logging some messages, so we can do it eagerly.
         # The returned dist would be exactly the same as self.dist because we
-        # set satisfied_by in make_install_req_from_dist.
+        # set satisfied_by in _make_install_req_from_dist.
         # TODO: Supply reason based on force_reinstall and upgrade_strategy.
         skip_reason = "already satisfied"
         factory.preparer.prepare_installed_requirement(self._ireq, skip_reason)
 
     def __str__(self) -> str:
         return str(self.dist)
 
@@ -367,35 +352,35 @@
     def __eq__(self, other: Any) -> bool:
         if isinstance(other, self.__class__):
             return self.name == other.name and self.version == other.version
         return False
 
     @property
     def project_name(self) -> NormalizedName:
-        return canonicalize_name(self.dist.project_name)
+        return self.dist.canonical_name
 
     @property
     def name(self) -> str:
         return self.project_name
 
     @property
     def version(self) -> CandidateVersion:
-        return parse_version(self.dist.version)
+        return self.dist.version
 
     @property
     def is_editable(self) -> bool:
-        return dist_is_editable(self.dist)
+        return self.dist.editable
 
     def format_for_error(self) -> str:
         return f"{self.name} {self.version} (Installed)"
 
     def iter_dependencies(self, with_requires: bool) -> Iterable[Optional[Requirement]]:
         if not with_requires:
             return
-        for r in self.dist.requires():
+        for r in self.dist.iter_dependencies():
             yield self._factory.make_requirement_from_spec(str(r), self._ireq)
 
     def get_install_requirement(self) -> Optional[InstallRequirement]:
         return None
 
 
 class ExtrasCandidate(Candidate):
@@ -487,25 +472,25 @@
         # (See note 2b in the class docstring)
         yield factory.make_requirement_from_candidate(self.base)
         if not with_requires:
             return
 
         # The user may have specified extras that the candidate doesn't
         # support. We ignore any unsupported extras here.
-        valid_extras = self.extras.intersection(self.base.dist.extras)
-        invalid_extras = self.extras.difference(self.base.dist.extras)
+        valid_extras = self.extras.intersection(self.base.dist.iter_provided_extras())
+        invalid_extras = self.extras.difference(self.base.dist.iter_provided_extras())
         for extra in sorted(invalid_extras):
             logger.warning(
                 "%s %s does not provide the extra '%s'",
                 self.base.name,
                 self.version,
                 extra,
             )
 
-        for r in self.base.dist.requires(valid_extras):
+        for r in self.base.dist.iter_dependencies(valid_extras):
             requirement = factory.make_requirement_from_spec(
                 str(r), self.base._ireq, valid_extras
             )
             if requirement:
                 yield requirement
 
     def get_install_requirement(self) -> Optional[InstallRequirement]:
```

#### pip/_internal/resolution/resolvelib/factory.py

```diff
@@ -15,15 +15,14 @@
     Set,
     Tuple,
     TypeVar,
     cast,
 )
 
 from pip._vendor.packaging.requirements import InvalidRequirement
-from pip._vendor.packaging.requirements import Requirement as PackagingRequirement
 from pip._vendor.packaging.specifiers import SpecifierSet
 from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
 from pip._vendor.resolvelib import ResolutionImpossible
 
 from pip._internal.cache import CacheEntry, WheelCache
 from pip._internal.exceptions import (
     DistributionNotFound,
@@ -42,14 +41,15 @@
 from pip._internal.req.req_install import (
     InstallRequirement,
     check_invalid_constraint_type,
 )
 from pip._internal.resolution.base import InstallRequirementProvider
 from pip._internal.utils.compatibility_tags import get_supported
 from pip._internal.utils.hashes import Hashes
+from pip._internal.utils.packaging import get_requirement
 from pip._internal.utils.virtualenv import running_under_virtualenv
 
 from .base import Candidate, CandidateVersion, Constraint, Requirement
 from .candidates import (
     AlreadyInstalledCandidate,
     BaseCandidate,
     EditableCandidate,
@@ -154,18 +154,15 @@
         dist: BaseDistribution,
         extras: FrozenSet[str],
         template: InstallRequirement,
     ) -> Candidate:
         try:
             base = self._installed_candidate_cache[dist.canonical_name]
         except KeyError:
-            from pip._internal.metadata.pkg_resources import Distribution as _Dist
-
-            compat_dist = cast(_Dist, dist)._dist
-            base = AlreadyInstalledCandidate(compat_dist, template, factory=self)
+            base = AlreadyInstalledCandidate(dist, template, factory=self)
             self._installed_candidate_cache[dist.canonical_name] = base
         if not extras:
             return base
         return self._make_extras_candidate(base, extras)
 
     def _make_candidate_from_link(
         self,
@@ -346,15 +343,15 @@
             )
             if candidate:
                 yield candidate
 
     def find_candidates(
         self,
         identifier: str,
-        requirements: Mapping[str, Iterator[Requirement]],
+        requirements: Mapping[str, Iterable[Requirement]],
         incompatibilities: Mapping[str, Iterator[Candidate]],
         constraint: Constraint,
         prefers_installed: bool,
     ) -> Iterable[Candidate]:
         # Collect basic lookup information from the requirements.
         explicit_candidates: Set[Candidate] = set()
         ireqs: List[InstallRequirement] = []
@@ -364,15 +361,15 @@
                 explicit_candidates.add(cand)
             if ireq is not None:
                 ireqs.append(ireq)
 
         # If the current identifier contains extras, add explicit candidates
         # from entries from extra-less identifier.
         with contextlib.suppress(InvalidRequirement):
-            parsed_requirement = PackagingRequirement(identifier)
+            parsed_requirement = get_requirement(identifier)
             explicit_candidates.update(
                 self._iter_explicit_candidates_from_base(
                     requirements.get(parsed_requirement.name, ()),
                     frozenset(parsed_requirement.extras),
                 ),
             )
 
@@ -483,24 +480,28 @@
         self, candidate: Candidate
     ) -> ExplicitRequirement:
         return ExplicitRequirement(candidate)
 
     def make_requirement_from_spec(
         self,
         specifier: str,
-        comes_from: InstallRequirement,
+        comes_from: Optional[InstallRequirement],
         requested_extras: Iterable[str] = (),
     ) -> Optional[Requirement]:
         ireq = self._make_install_req_from_spec(specifier, comes_from)
         return self._make_requirement_from_install_req(ireq, requested_extras)
 
     def make_requires_python_requirement(
-        self, specifier: Optional[SpecifierSet]
+        self,
+        specifier: SpecifierSet,
     ) -> Optional[Requirement]:
-        if self._ignore_requires_python or specifier is None:
+        if self._ignore_requires_python:
+            return None
+        # Don't bother creating a dependency for an empty Requires-Python.
+        if not str(specifier):
             return None
         return RequiresPythonRequirement(specifier, self._python_candidate)
 
     def get_wheel_cache_entry(
         self, link: Link, name: Optional[str]
     ) -> Optional[CacheEntry]:
         """Look up the link in the wheel cache.
```

#### pip/_internal/resolution/resolvelib/found_candidates.py

```diff
@@ -5,23 +5,38 @@
 distribution metadata. It is therefore crucial for performance to keep
 everything here lazy all the way down, so we only touch candidates that we
 absolutely need, and not "download the world" when we only need one version of
 something.
 """
 
 import functools
-from typing import Callable, Iterator, Optional, Set, Tuple
+from collections.abc import Sequence
+from typing import TYPE_CHECKING, Any, Callable, Iterator, Optional, Set, Tuple
 
 from pip._vendor.packaging.version import _BaseVersion
-from pip._vendor.six.moves import collections_abc  # type: ignore
 
 from .base import Candidate
 
 IndexCandidateInfo = Tuple[_BaseVersion, Callable[[], Optional[Candidate]]]
 
+if TYPE_CHECKING:
+    SequenceCandidate = Sequence[Candidate]
+else:
+    # For compatibility: Python before 3.9 does not support using [] on the
+    # Sequence class.
+    #
+    # >>> from collections.abc import Sequence
+    # >>> Sequence[str]
+    # Traceback (most recent call last):
+    #   File "<stdin>", line 1, in <module>
+    # TypeError: 'ABCMeta' object is not subscriptable
+    #
+    # TODO: Remove this block after dropping Python 3.8 support.
+    SequenceCandidate = Sequence
+
 
 def _iter_built(infos: Iterator[IndexCandidateInfo]) -> Iterator[Candidate]:
     """Iterator for ``FoundCandidates``.
 
     This iterator is used when the package is not already installed. Candidates
     from index come later in their normal ordering.
     """
@@ -86,15 +101,15 @@
         versions_found.add(version)
 
     # If the installed candidate is older than all other candidates.
     if installed.version not in versions_found:
         yield installed
 
 
-class FoundCandidates(collections_abc.Sequence):
+class FoundCandidates(SequenceCandidate):
     """A lazy sequence to provide candidates to the resolver.
 
     The intended usage is to return this from `find_matches()` so the resolver
     can iterate through the sequence multiple times, but only access the index
     page when remote packages are actually needed. This improve performances
     when suitable candidates are already installed on disk.
     """
@@ -107,15 +122,15 @@
         incompatible_ids: Set[int],
     ):
         self._get_infos = get_infos
         self._installed = installed
         self._prefers_installed = prefers_installed
         self._incompatible_ids = incompatible_ids
 
-    def __getitem__(self, index: int) -> Candidate:
+    def __getitem__(self, index: Any) -> Any:
         # Implemented to satisfy the ABC check. This is not needed by the
         # resolver, and should not be used by the provider either (for
         # performance reasons).
         raise NotImplementedError("don't do this")
 
     def __iter__(self) -> Iterator[Candidate]:
         infos = self._get_infos()
@@ -134,9 +149,7 @@
         raise NotImplementedError("don't do this")
 
     @functools.lru_cache(maxsize=1)
     def __bool__(self) -> bool:
         if self._prefers_installed and self._installed:
             return True
         return any(self)
-
-    __nonzero__ = __bool__  # XXX: Python 2.
```

#### pip/_internal/resolution/resolvelib/provider.py

```diff
@@ -62,20 +62,21 @@
         self._upgrade_strategy = upgrade_strategy
         self._user_requested = user_requested
         self._known_depths: Dict[str, float] = collections.defaultdict(lambda: math.inf)
 
     def identify(self, requirement_or_candidate: Union[Requirement, Candidate]) -> str:
         return requirement_or_candidate.name
 
-    def get_preference(
+    def get_preference(  # type: ignore
         self,
         identifier: str,
         resolutions: Mapping[str, Candidate],
         candidates: Mapping[str, Iterator[Candidate]],
-        information: Mapping[str, Iterator["PreferenceInformation"]],
+        information: Mapping[str, Iterable["PreferenceInformation"]],
+        backtrack_causes: Sequence["PreferenceInformation"],
     ) -> "Preference":
         """Produce a sort key for given requirement based on preference.
 
         The lower the return value is, the more preferred this group of
         arguments is.
 
         Currently pip considers the followings in order:
@@ -108,17 +109,17 @@
         except KeyError:
             requested_order = math.inf
             parent_depths = (
                 self._known_depths[parent.name] if parent is not None else 0.0
                 for _, parent in information[identifier]
             )
             inferred_depth = min(d for d in parent_depths) + 1.0
-            self._known_depths[identifier] = inferred_depth
         else:
             inferred_depth = 1.0
+        self._known_depths[identifier] = inferred_depth
 
         requested_order = self._user_requested.get(identifier, math.inf)
 
         # Requires-Python has only one candidate and the check is basically
         # free, so we always do it first to avoid needless work if it fails.
         requires_python = identifier == REQUIRES_PYTHON_IDENTIFIER
 
@@ -128,19 +129,25 @@
         # (Most projects specify it only to request for an installer feature,
         # which does not work, but that's another topic.) Intentionally
         # delaying Setuptools helps reduce branches the resolver has to check.
         # This serves as a temporary fix for issues like "apache-airlfow[all]"
         # while we work on "proper" branch pruning techniques.
         delay_this = identifier == "setuptools"
 
+        # Prefer the causes of backtracking on the assumption that the problem
+        # resolving the dependency tree is related to the failures that caused
+        # the backtracking
+        backtrack_cause = self.is_backtrack_cause(identifier, backtrack_causes)
+
         return (
             not requires_python,
             delay_this,
             not direct,
             not pinned,
+            not backtrack_cause,
             inferred_depth,
             requested_order,
             not unfree,
             identifier,
         )
 
     def _get_constraint(self, identifier: str) -> Constraint:
@@ -191,7 +198,18 @@
 
     def is_satisfied_by(self, requirement: Requirement, candidate: Candidate) -> bool:
         return requirement.is_satisfied_by(candidate)
 
     def get_dependencies(self, candidate: Candidate) -> Sequence[Requirement]:
         with_requires = not self._ignore_dependencies
         return [r for r in candidate.iter_dependencies(with_requires) if r is not None]
+
+    @staticmethod
+    def is_backtrack_cause(
+        identifier: str, backtrack_causes: Sequence["PreferenceInformation"]
+    ) -> bool:
+        for backtrack_cause in backtrack_causes:
+            if identifier == backtrack_cause.requirement.name:
+                return True
+            if backtrack_cause.parent and identifier == backtrack_cause.parent.name:
+                return True
+        return False
```

#### pip/_internal/resolution/resolvelib/reporter.py

```diff
@@ -23,17 +23,16 @@
                 "pip is looking at multiple versions of {package_name} to "
                 "determine which version is compatible with other "
                 "requirements. This could take a while."
             ),
             13: (
                 "This is taking longer than usual. You might need to provide "
                 "the dependency resolver with stricter constraints to reduce "
-                "runtime. If you want to abort this run, you can press "
-                "Ctrl + C to do so. To improve how pip performs, tell us what "
-                "happened here: https://pip.pypa.io/surveys/backtracking"
+                "runtime. See https://pip.pypa.io/warnings/backtracking for "
+                "guidance. If you want to abort this run, press Ctrl + C."
             ),
         }
 
     def backtracking(self, candidate: Candidate) -> None:
         self.backtracks_by_package[candidate.name] += 1
 
         count = self.backtracks_by_package[candidate.name]
```

#### pip/_internal/resolution/resolvelib/resolver.py

```diff
@@ -15,16 +15,14 @@
 from pip._internal.req.req_set import RequirementSet
 from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
 from pip._internal.resolution.resolvelib.provider import PipProvider
 from pip._internal.resolution.resolvelib.reporter import (
     PipDebuggingReporter,
     PipReporter,
 )
-from pip._internal.utils.deprecation import deprecated
-from pip._internal.utils.filetypes import is_archive_file
 
 from .base import Candidate, Requirement
 from .factory import Factory
 
 if TYPE_CHECKING:
     from pip._vendor.resolvelib.resolvers import Result as RLResult
 
@@ -132,33 +130,14 @@
                         "%s is already installed with the same version as the "
                         "provided wheel. Use --force-reinstall to force an "
                         "installation of the wheel.",
                         ireq.name,
                     )
                     continue
 
-                looks_like_sdist = (
-                    is_archive_file(candidate.source_link.file_path)
-                    and candidate.source_link.ext != ".zip"
-                )
-                if looks_like_sdist:
-                    # is a local sdist -- show a deprecation warning!
-                    reason = (
-                        "Source distribution is being reinstalled despite an "
-                        "installed package having the same name and version as "
-                        "the installed package."
-                    )
-                    replacement = "use --force-reinstall"
-                    deprecated(
-                        reason=reason,
-                        replacement=replacement,
-                        gone_in="21.3",
-                        issue=8711,
-                    )
-
                 # is a local sdist or path -- reinstall
                 ireq.should_reinstall = True
             else:
                 continue
 
             link = candidate.source_link
             if link and link.is_yanked:
```

#### pip/_internal/utils/appdirs.py

```diff
@@ -3,33 +3,50 @@
 compatible for the current pip code base.
 
 The intention is to rewrite current usages gradually, keeping the tests pass,
 and eventually drop this after all usages are changed.
 """
 
 import os
+import sys
 from typing import List
 
-from pip._vendor import appdirs as _appdirs
+from pip._vendor import platformdirs as _appdirs
 
 
 def user_cache_dir(appname: str) -> str:
     return _appdirs.user_cache_dir(appname, appauthor=False)
 
 
+def _macos_user_config_dir(appname: str, roaming: bool = True) -> str:
+    # Use ~/Application Support/pip, if the directory exists.
+    path = _appdirs.user_data_dir(appname, appauthor=False, roaming=roaming)
+    if os.path.isdir(path):
+        return path
+
+    # Use a Linux-like ~/.config/pip, by default.
+    linux_like_path = "~/.config/"
+    if appname:
+        linux_like_path = os.path.join(linux_like_path, appname)
+
+    return os.path.expanduser(linux_like_path)
+
+
 def user_config_dir(appname: str, roaming: bool = True) -> str:
-    path = _appdirs.user_config_dir(appname, appauthor=False, roaming=roaming)
-    if _appdirs.system == "darwin" and not os.path.isdir(path):
-        path = os.path.expanduser("~/.config/")
-        if appname:
-            path = os.path.join(path, appname)
-    return path
+    if sys.platform == "darwin":
+        return _macos_user_config_dir(appname, roaming)
+
+    return _appdirs.user_config_dir(appname, appauthor=False, roaming=roaming)
 
 
 # for the discussion regarding site_config_dir locations
 # see <https://github.com/pypa/pip/issues/1733>
 def site_config_dirs(appname: str) -> List[str]:
+    if sys.platform == "darwin":
+        return [_appdirs.site_data_dir(appname, appauthor=False, multipath=True)]
+
     dirval = _appdirs.site_config_dir(appname, appauthor=False, multipath=True)
-    if _appdirs.system not in ["win32", "darwin"]:
-        # always look in /etc directly as well
-        return dirval.split(os.pathsep) + ["/etc"]
-    return [dirval]
+    if sys.platform == "win32":
+        return [dirval]
+
+    # Unix-y system. Look in /etc as well.
+    return dirval.split(os.pathsep) + ["/etc"]
```

#### pip/_internal/utils/compatibility_tags.py

```diff
@@ -1,27 +1,24 @@
 """Generate and work with PEP 425 Compatibility Tags.
 """
 
 import re
-from typing import TYPE_CHECKING, List, Optional, Tuple
+from typing import List, Optional, Tuple
 
 from pip._vendor.packaging.tags import (
+    PythonVersion,
     Tag,
     compatible_tags,
     cpython_tags,
     generic_tags,
     interpreter_name,
     interpreter_version,
     mac_platforms,
 )
 
-if TYPE_CHECKING:
-    from pip._vendor.packaging.tags import PythonVersion
-
-
 _osx_arch_pat = re.compile(r"(.+)_(\d+)_(\d+)_(.+)")
 
 
 def version_info_to_nodot(version_info: Tuple[int, ...]) -> str:
     # Only use up to the first two numbers.
     return "".join(map(str, version_info[:2]))
 
@@ -91,15 +88,15 @@
         additions = [c for c in _get_custom_platforms(p) if c not in seen]
         seen.update(additions)
         result.extend(additions)
 
     return result
 
 
-def _get_python_version(version: str) -> "PythonVersion":
+def _get_python_version(version: str) -> PythonVersion:
     if len(version) > 1:
         return int(version[0]), int(version[1:])
     else:
         return (int(version[0]),)
 
 
 def _get_custom_interpreter(
@@ -128,15 +125,15 @@
     :param impl: specify the exact implementation you want valid
         tags for, or None. If None, use the local interpreter impl.
     :param abis: specify a list of abis you want valid
         tags for, or None. If None, use the local interpreter abi.
     """
     supported: List[Tag] = []
 
-    python_version: Optional["PythonVersion"] = None
+    python_version: Optional[PythonVersion] = None
     if version is not None:
         python_version = _get_python_version(version)
 
     interpreter = _get_custom_interpreter(impl, version)
 
     platforms = _expand_allowed_platforms(platforms)
```

#### pip/_internal/utils/deprecation.py

```diff
@@ -4,15 +4,15 @@
 
 import logging
 import warnings
 from typing import Any, Optional, TextIO, Type, Union
 
 from pip._vendor.packaging.version import parse
 
-from pip import __version__ as current_version
+from pip import __version__ as current_version  # NOTE: tests patch this name.
 
 DEPRECATION_MSG_PREFIX = "DEPRECATION: "
 
 
 class PipDeprecationWarning(Warning):
     pass
 
@@ -49,56 +49,72 @@
 
     if _original_showwarning is None:
         _original_showwarning = warnings.showwarning
         warnings.showwarning = _showwarning
 
 
 def deprecated(
+    *,
     reason: str,
     replacement: Optional[str],
     gone_in: Optional[str],
+    feature_flag: Optional[str] = None,
     issue: Optional[int] = None,
 ) -> None:
     """Helper to deprecate existing functionality.
 
     reason:
         Textual reason shown to the user about why this functionality has
-        been deprecated.
+        been deprecated. Should be a complete sentence.
     replacement:
         Textual suggestion shown to the user about what alternative
         functionality they can use.
     gone_in:
         The version of pip does this functionality should get removed in.
-        Raises errors if pip's current version is greater than or equal to
+        Raises an error if pip's current version is greater than or equal to
         this.
+    feature_flag:
+        Command-line flag of the form --use-feature={feature_flag} for testing
+        upcoming functionality.
     issue:
         Issue number on the tracker that would serve as a useful place for
         users to find related discussion and provide feedback.
-
-    Always pass replacement, gone_in and issue as keyword arguments for clarity
-    at the call site.
     """
 
-    # Construct a nice message.
-    #   This is eagerly formatted as we want it to get logged as if someone
-    #   typed this entire message out.
-    sentences = [
-        (reason, DEPRECATION_MSG_PREFIX + "{}"),
-        (gone_in, "pip {} will remove support for this functionality."),
-        (replacement, "A possible replacement is {}."),
+    # Determine whether or not the feature is already gone in this version.
+    is_gone = gone_in is not None and parse(current_version) >= parse(gone_in)
+
+    message_parts = [
+        (reason, f"{DEPRECATION_MSG_PREFIX}{{}}"),
+        (
+            gone_in,
+            "pip {} will enforce this behaviour change."
+            if not is_gone
+            else "Since pip {}, this is no longer supported.",
+        ),
+        (
+            replacement,
+            "A possible replacement is {}.",
+        ),
+        (
+            feature_flag,
+            "You can use the flag --use-feature={} to test the upcoming behaviour."
+            if not is_gone
+            else None,
+        ),
         (
             issue,
-            (
-                "You can find discussion regarding this at "
-                "https://github.com/pypa/pip/issues/{}."
-            ),
+            "Discussion can be found at https://github.com/pypa/pip/issues/{}",
         ),
     ]
+
     message = " ".join(
-        template.format(val) for val, template in sentences if val is not None
+        format_str.format(value)
+        for value, format_str in message_parts
+        if format_str is not None and value is not None
     )
 
-    # Raise as an error if it has to be removed.
-    if gone_in is not None and parse(current_version) >= parse(gone_in):
+    # Raise as an error if this behaviour is deprecated.
+    if is_gone:
         raise PipDeprecationWarning(message)
 
     warnings.warn(message, category=PipDeprecationWarning, stacklevel=2)
```

#### pip/_internal/utils/direct_url_helpers.py

```diff
@@ -1,11 +1,12 @@
 from typing import Optional
 
 from pip._internal.models.direct_url import ArchiveInfo, DirectUrl, DirInfo, VcsInfo
 from pip._internal.models.link import Link
+from pip._internal.utils.urls import path_to_url
 from pip._internal.vcs import vcs
 
 
 def direct_url_as_pep440_direct_reference(direct_url: DirectUrl, name: str) -> str:
     """Convert a DirectUrl to a pip requirement string."""
     direct_url.validate()  # if invalid, this is a pip bug
     requirement = name + " @ "
@@ -24,14 +25,21 @@
     if direct_url.subdirectory:
         fragments.append("subdirectory=" + direct_url.subdirectory)
     if fragments:
         requirement += "#" + "&".join(fragments)
     return requirement
 
 
+def direct_url_for_editable(source_dir: str) -> DirectUrl:
+    return DirectUrl(
+        url=path_to_url(source_dir),
+        info=DirInfo(editable=True),
+    )
+
+
 def direct_url_from_link(
     link: Link, source_dir: Optional[str] = None, link_is_in_wheel_cache: bool = False
 ) -> DirectUrl:
     if link.is_vcs:
         vcs_backend = vcs.get_backend_for_scheme(link.scheme)
         assert vcs_backend
         url, requested_revision, _ = vcs_backend.get_url_rev_and_auth(
```

#### pip/_internal/utils/filetypes.py

```diff
@@ -2,27 +2,26 @@
 """
 
 from typing import Tuple
 
 from pip._internal.utils.misc import splitext
 
 WHEEL_EXTENSION = ".whl"
-BZ2_EXTENSIONS = (".tar.bz2", ".tbz")  # type: Tuple[str, ...]
-XZ_EXTENSIONS = (
+BZ2_EXTENSIONS: Tuple[str, ...] = (".tar.bz2", ".tbz")
+XZ_EXTENSIONS: Tuple[str, ...] = (
     ".tar.xz",
     ".txz",
     ".tlz",
     ".tar.lz",
     ".tar.lzma",
-)  # type: Tuple[str, ...]
-ZIP_EXTENSIONS = (".zip", WHEEL_EXTENSION)  # type: Tuple[str, ...]
-TAR_EXTENSIONS = (".tar.gz", ".tgz", ".tar")  # type: Tuple[str, ...]
+)
+ZIP_EXTENSIONS: Tuple[str, ...] = (".zip", WHEEL_EXTENSION)
+TAR_EXTENSIONS: Tuple[str, ...] = (".tar.gz", ".tgz", ".tar")
 ARCHIVE_EXTENSIONS = ZIP_EXTENSIONS + BZ2_EXTENSIONS + TAR_EXTENSIONS + XZ_EXTENSIONS
 
 
-def is_archive_file(name):
-    # type: (str) -> bool
+def is_archive_file(name: str) -> bool:
     """Return True if `name` is a considered as an archive file."""
     ext = splitext(name)[1].lower()
     if ext in ARCHIVE_EXTENSIONS:
         return True
     return False
```

#### pip/_internal/utils/glibc.py

```diff
@@ -2,22 +2,20 @@
 # mypy: strict-optional=False
 
 import os
 import sys
 from typing import Optional, Tuple
 
 
-def glibc_version_string():
-    # type: () -> Optional[str]
+def glibc_version_string() -> Optional[str]:
     "Returns glibc version string, or None if not using glibc."
     return glibc_version_string_confstr() or glibc_version_string_ctypes()
 
 
-def glibc_version_string_confstr():
-    # type: () -> Optional[str]
+def glibc_version_string_confstr() -> Optional[str]:
     "Primary implementation of glibc_version_string using os.confstr."
     # os.confstr is quite a bit faster than ctypes.DLL. It's also less likely
     # to be broken or missing. This strategy is used in the standard library
     # platform module:
     # https://github.com/python/cpython/blob/fcf1d003bf4f0100c9d0921ff3d70e1127ca1b71/Lib/platform.py#L175-L183
     if sys.platform == "win32":
         return None
@@ -26,16 +24,15 @@
         _, version = os.confstr("CS_GNU_LIBC_VERSION").split()
     except (AttributeError, OSError, ValueError):
         # os.confstr() or CS_GNU_LIBC_VERSION not available (or a bad value)...
         return None
     return version
 
 
-def glibc_version_string_ctypes():
-    # type: () -> Optional[str]
+def glibc_version_string_ctypes() -> Optional[str]:
     "Fallback implementation of glibc_version_string using ctypes."
 
     try:
         import ctypes
     except ImportError:
         return None
 
@@ -74,16 +71,15 @@
 #   ~$ ldd --version
 #   ldd (Debian GLIBC 2.22-11) 2.22
 #
 # This is unfortunate, because it means that the linehaul data on libc
 # versions that was generated by pip 8.1.2 and earlier is useless and
 # misleading. Solution: instead of using platform, use our code that actually
 # works.
-def libc_ver():
-    # type: () -> Tuple[str, str]
+def libc_ver() -> Tuple[str, str]:
     """Try to determine the glibc version
 
     Returns a tuple of strings (lib, version) which default to empty strings
     in case the lookup fails.
     """
     glibc_version = glibc_version_string()
     if glibc_version is None:
```

#### pip/_internal/utils/hashes.py

```diff
@@ -24,29 +24,27 @@
 
 class Hashes:
     """A wrapper that builds multiple hashes at once and checks them against
     known-good values
 
     """
 
-    def __init__(self, hashes=None):
-        # type: (Dict[str, List[str]]) -> None
+    def __init__(self, hashes: Dict[str, List[str]] = None) -> None:
         """
         :param hashes: A dict of algorithm names pointing to lists of allowed
             hex digests
         """
         allowed = {}
         if hashes is not None:
             for alg, keys in hashes.items():
                 # Make sure values are always sorted (to ease equality checks)
                 allowed[alg] = sorted(keys)
         self._allowed = allowed
 
-    def __and__(self, other):
-        # type: (Hashes) -> Hashes
+    def __and__(self, other: "Hashes") -> "Hashes":
         if not isinstance(other, Hashes):
             return NotImplemented
 
         # If either of the Hashes object is entirely empty (i.e. no hash
         # specified at all), all hashes from the other object are allowed.
         if not other:
             return self
@@ -58,29 +56,22 @@
         for alg, values in other._allowed.items():
             if alg not in self._allowed:
                 continue
             new[alg] = [v for v in values if v in self._allowed[alg]]
         return Hashes(new)
 
     @property
-    def digest_count(self):
-        # type: () -> int
+    def digest_count(self) -> int:
         return sum(len(digests) for digests in self._allowed.values())
 
-    def is_hash_allowed(
-        self,
-        hash_name,  # type: str
-        hex_digest,  # type: str
-    ):
-        # type: (...) -> bool
+    def is_hash_allowed(self, hash_name: str, hex_digest: str) -> bool:
         """Return whether the given hex digest is allowed."""
         return hex_digest in self._allowed.get(hash_name, [])
 
-    def check_against_chunks(self, chunks):
-        # type: (Iterator[bytes]) -> None
+    def check_against_chunks(self, chunks: Iterator[bytes]) -> None:
         """Check good hashes against ones built from iterable of chunks of
         data.
 
         Raise HashMismatch if none match.
 
         """
         gots = {}
@@ -95,49 +86,39 @@
                 hash.update(chunk)
 
         for hash_name, got in gots.items():
             if got.hexdigest() in self._allowed[hash_name]:
                 return
         self._raise(gots)
 
-    def _raise(self, gots):
-        # type: (Dict[str, _Hash]) -> NoReturn
+    def _raise(self, gots: Dict[str, "_Hash"]) -> "NoReturn":
         raise HashMismatch(self._allowed, gots)
 
-    def check_against_file(self, file):
-        # type: (BinaryIO) -> None
+    def check_against_file(self, file: BinaryIO) -> None:
         """Check good hashes against a file-like object
 
         Raise HashMismatch if none match.
 
         """
         return self.check_against_chunks(read_chunks(file))
 
-    def check_against_path(self, path):
-        # type: (str) -> None
+    def check_against_path(self, path: str) -> None:
         with open(path, "rb") as file:
             return self.check_against_file(file)
 
-    def __nonzero__(self):
-        # type: () -> bool
+    def __bool__(self) -> bool:
         """Return whether I know any known-good hashes."""
         return bool(self._allowed)
 
-    def __bool__(self):
-        # type: () -> bool
-        return self.__nonzero__()
-
-    def __eq__(self, other):
-        # type: (object) -> bool
+    def __eq__(self, other: object) -> bool:
         if not isinstance(other, Hashes):
             return NotImplemented
         return self._allowed == other._allowed
 
-    def __hash__(self):
-        # type: () -> int
+    def __hash__(self) -> int:
         return hash(
             ",".join(
                 sorted(
                     ":".join((alg, digest))
                     for alg, digest_list in self._allowed.items()
                     for digest in digest_list
                 )
@@ -149,17 +130,15 @@
     """A workalike for Hashes used when we're missing a hash for a requirement
 
     It computes the actual hash of the requirement and raises a HashMissing
     exception showing it to the user.
 
     """
 
-    def __init__(self):
-        # type: () -> None
+    def __init__(self) -> None:
         """Don't offer the ``hashes`` kwarg."""
         # Pass our favorite hash in to generate a "gotten hash". With the
         # empty list, it will never match, so an error will always raise.
         super().__init__(hashes={FAVORITE_HASH: []})
 
-    def _raise(self, gots):
-        # type: (Dict[str, _Hash]) -> NoReturn
+    def _raise(self, gots: Dict[str, "_Hash"]) -> "NoReturn":
         raise HashMissing(gots[FAVORITE_HASH].hexdigest())
```

#### pip/_internal/utils/inject_securetransport.py

```diff
@@ -6,16 +6,15 @@
 Note that we only do the injection on macOS, when the linked OpenSSL is too
 old to handle TLSv1.2.
 """
 
 import sys
 
 
-def inject_securetransport():
-    # type: () -> None
+def inject_securetransport() -> None:
     # Only relevant on macOS
     if sys.platform != "darwin":
         return
 
     try:
         import ssl
     except ImportError:
```

#### pip/_internal/utils/logging.py

```diff
@@ -31,86 +31,66 @@
 
 
 class BrokenStdoutLoggingError(Exception):
     """
     Raised if BrokenPipeError occurs for the stdout stream while logging.
     """
 
-    pass
 
+def _is_broken_pipe_error(exc_class: Type[BaseException], exc: BaseException) -> bool:
+    if exc_class is BrokenPipeError:
+        return True
 
-# BrokenPipeError manifests differently in Windows and non-Windows.
-if WINDOWS:
-    # In Windows, a broken pipe can show up as EINVAL rather than EPIPE:
+    # On Windows, a broken pipe can show up as EINVAL rather than EPIPE:
     # https://bugs.python.org/issue19612
     # https://bugs.python.org/issue30418
-    def _is_broken_pipe_error(exc_class, exc):
-        # type: (Type[BaseException], BaseException) -> bool
-        """See the docstring for non-Windows below."""
-        return (exc_class is BrokenPipeError) or (
-            isinstance(exc, OSError) and exc.errno in (errno.EINVAL, errno.EPIPE)
-        )
-
+    if not WINDOWS:
+        return False
 
-else:
-    # Then we are in the non-Windows case.
-    def _is_broken_pipe_error(exc_class, exc):
-        # type: (Type[BaseException], BaseException) -> bool
-        """
-        Return whether an exception is a broken pipe error.
-
-        Args:
-          exc_class: an exception class.
-          exc: an exception instance.
-        """
-        return exc_class is BrokenPipeError
+    return isinstance(exc, OSError) and exc.errno in (errno.EINVAL, errno.EPIPE)
 
 
 @contextlib.contextmanager
-def indent_log(num=2):
-    # type: (int) -> Iterator[None]
+def indent_log(num: int = 2) -> Iterator[None]:
     """
     A context manager which will cause the log output to be indented for any
     log messages emitted inside it.
     """
     # For thread-safety
     _log_state.indentation = get_indentation()
     _log_state.indentation += num
     try:
         yield
     finally:
         _log_state.indentation -= num
 
 
-def get_indentation():
-    # type: () -> int
+def get_indentation() -> int:
     return getattr(_log_state, "indentation", 0)
 
 
 class IndentingFormatter(logging.Formatter):
     default_time_format = "%Y-%m-%dT%H:%M:%S"
 
     def __init__(
         self,
-        *args,  # type: Any
-        add_timestamp=False,  # type: bool
-        **kwargs,  # type: Any
-    ):
-        # type: (...) -> None
+        *args: Any,
+        add_timestamp: bool = False,
+        **kwargs: Any,
+    ) -> None:
         """
         A logging.Formatter that obeys the indent_log() context manager.
 
         :param add_timestamp: A bool indicating output lines should be prefixed
             with their record's timestamp.
         """
         self.add_timestamp = add_timestamp
         super().__init__(*args, **kwargs)
 
-    def get_message_start(self, formatted, levelno):
-        # type: (str, int) -> str
+    def get_message_start(self, formatted: str, levelno: int) -> str:
         """
         Return the start of the formatted log message (not counting the
         prefix to add to each line).
         """
         if levelno < logging.WARNING:
             return ""
         if formatted.startswith(DEPRECATION_MSG_PREFIX):
@@ -118,16 +98,15 @@
             # look like "WARNING: DEPRECATION: ...."
             return ""
         if levelno < logging.ERROR:
             return "WARNING: "
 
         return "ERROR: "
 
-    def format(self, record):
-        # type: (logging.LogRecord) -> str
+    def format(self, record: logging.LogRecord) -> str:
         """
         Calls the standard formatter, but will indent all of the log message
         lines by our current indentation level.
         """
         formatted = super().format(record)
         message_start = self.get_message_start(formatted, record.levelno)
         formatted = message_start + formatted
@@ -136,18 +115,16 @@
         if self.add_timestamp:
             prefix = f"{self.formatTime(record)} "
         prefix += " " * get_indentation()
         formatted = "".join([prefix + line for line in formatted.splitlines(True)])
         return formatted
 
 
-def _color_wrap(*colors):
-    # type: (*str) -> Callable[[str], str]
-    def wrapped(inp):
-        # type: (str) -> str
+def _color_wrap(*colors: str) -> Callable[[str], str]:
+    def wrapped(inp: str) -> str:
         return "".join(list(colors) + [inp, colorama.Style.RESET_ALL])
 
     return wrapped
 
 
 class ColorizedStreamHandler(logging.StreamHandler):
 
@@ -157,36 +134,33 @@
             # This needs to be in order from highest logging level to lowest.
             (logging.ERROR, _color_wrap(colorama.Fore.RED)),
             (logging.WARNING, _color_wrap(colorama.Fore.YELLOW)),
         ]
     else:
         COLORS = []
 
-    def __init__(self, stream=None, no_color=None):
-        # type: (Optional[TextIO], bool) -> None
+    def __init__(self, stream: Optional[TextIO] = None, no_color: bool = None) -> None:
         super().__init__(stream)
         self._no_color = no_color
 
         if WINDOWS and colorama:
             self.stream = colorama.AnsiToWin32(self.stream)
 
-    def _using_stdout(self):
-        # type: () -> bool
+    def _using_stdout(self) -> bool:
         """
         Return whether the handler is using sys.stdout.
         """
         if WINDOWS and colorama:
             # Then self.stream is an AnsiToWin32 object.
             stream = cast(colorama.AnsiToWin32, self.stream)
             return stream.wrapped is sys.stdout
 
         return self.stream is sys.stdout
 
-    def should_color(self):
-        # type: () -> bool
+    def should_color(self) -> bool:
         # Don't colorize things if we do not have colorama or if told not to
         if not colorama or self._no_color:
             return False
 
         real_stream = (
             self.stream
             if not isinstance(self.stream, colorama.AnsiToWin32)
@@ -200,29 +174,27 @@
         # If we have an ANSI term we should color it
         if os.environ.get("TERM") == "ANSI":
             return True
 
         # If anything else we should not color it
         return False
 
-    def format(self, record):
-        # type: (logging.LogRecord) -> str
+    def format(self, record: logging.LogRecord) -> str:
         msg = super().format(record)
 
         if self.should_color():
             for level, color in self.COLORS:
                 if record.levelno >= level:
                     msg = color(msg)
                     break
 
         return msg
 
     # The logging module says handleError() can be customized.
-    def handleError(self, record):
-        # type: (logging.LogRecord) -> None
+    def handleError(self, record: logging.LogRecord) -> None:
         exc_class, exc = sys.exc_info()[:2]
         # If a broken pipe occurred while calling write() or flush() on the
         # stdout stream in logging's Handler.emit(), then raise our special
         # exception so we can handle it in main() instead of logging the
         # broken pipe error and continuing.
         if (
             exc_class
@@ -232,45 +204,40 @@
         ):
             raise BrokenStdoutLoggingError()
 
         return super().handleError(record)
 
 
 class BetterRotatingFileHandler(logging.handlers.RotatingFileHandler):
-    def _open(self):
-        # type: () -> IO[Any]
+    def _open(self) -> IO[Any]:
         ensure_dir(os.path.dirname(self.baseFilename))
         return super()._open()
 
 
 class MaxLevelFilter(Filter):
-    def __init__(self, level):
-        # type: (int) -> None
+    def __init__(self, level: int) -> None:
         self.level = level
 
-    def filter(self, record):
-        # type: (logging.LogRecord) -> bool
+    def filter(self, record: logging.LogRecord) -> bool:
         return record.levelno < self.level
 
 
 class ExcludeLoggerFilter(Filter):
 
     """
     A logging Filter that excludes records from a logger (or its children).
     """
 
-    def filter(self, record):
-        # type: (logging.LogRecord) -> bool
+    def filter(self, record: logging.LogRecord) -> bool:
         # The base Filter class allows only records from a logger (or its
         # children).
         return not super().filter(record)
 
 
-def setup_logging(verbosity, no_color, user_log_file):
-    # type: (int, bool, Optional[str]) -> int
+def setup_logging(verbosity: int, no_color: bool, user_log_file: Optional[str]) -> int:
     """Configures and sets up all of the logging
 
     Returns the requested logging level, as its integer value.
     """
 
     # Determine the level to be logging at.
     if verbosity >= 2:
```

#### pip/_internal/utils/misc.py

```diff
@@ -14,18 +14,16 @@
 import sys
 import urllib.parse
 from io import StringIO
 from itertools import filterfalse, tee, zip_longest
 from types import TracebackType
 from typing import (
     Any,
-    AnyStr,
     BinaryIO,
     Callable,
-    Container,
     ContextManager,
     Iterable,
     Iterator,
     List,
     Optional,
     TextIO,
     Tuple,
@@ -36,19 +34,17 @@
 
 from pip._vendor.pkg_resources import Distribution
 from pip._vendor.tenacity import retry, stop_after_delay, wait_fixed
 
 from pip import __version__
 from pip._internal.exceptions import CommandError
 from pip._internal.locations import get_major_minor_version, site_packages, user_site
-from pip._internal.utils.compat import WINDOWS, stdlib_pkgs
-from pip._internal.utils.virtualenv import (
-    running_under_virtualenv,
-    virtualenv_no_global,
-)
+from pip._internal.utils.compat import WINDOWS
+from pip._internal.utils.egg_link import egg_link_path_from_location
+from pip._internal.utils.virtualenv import running_under_virtualenv
 
 __all__ = [
     "rmtree",
     "display_path",
     "backup_dir",
     "ask",
     "splitext",
@@ -67,28 +63,26 @@
 
 T = TypeVar("T")
 ExcInfo = Tuple[Type[BaseException], BaseException, TracebackType]
 VersionInfo = Tuple[int, int, int]
 NetlocTuple = Tuple[str, Tuple[Optional[str], Optional[str]]]
 
 
-def get_pip_version():
-    # type: () -> str
+def get_pip_version() -> str:
     pip_pkg_dir = os.path.join(os.path.dirname(__file__), "..", "..")
     pip_pkg_dir = os.path.abspath(pip_pkg_dir)
 
     return "pip {} from {} (python {})".format(
         __version__,
         pip_pkg_dir,
         get_major_minor_version(),
     )
 
 
-def normalize_version_info(py_version_info):
-    # type: (Tuple[int, ...]) -> Tuple[int, int, int]
+def normalize_version_info(py_version_info: Tuple[int, ...]) -> Tuple[int, int, int]:
     """
     Convert a tuple of ints representing a Python version to one of length
     three.
 
     :param py_version_info: a tuple of ints representing a Python version,
         or None to specify no version. The tuple can have any length.
 
@@ -99,48 +93,44 @@
         py_version_info += (3 - len(py_version_info)) * (0,)
     elif len(py_version_info) > 3:
         py_version_info = py_version_info[:3]
 
     return cast("VersionInfo", py_version_info)
 
 
-def ensure_dir(path):
-    # type: (AnyStr) -> None
+def ensure_dir(path: str) -> None:
     """os.path.makedirs without EEXIST."""
     try:
         os.makedirs(path)
     except OSError as e:
         # Windows can raise spurious ENOTEMPTY errors. See #6426.
         if e.errno != errno.EEXIST and e.errno != errno.ENOTEMPTY:
             raise
 
 
-def get_prog():
-    # type: () -> str
+def get_prog() -> str:
     try:
         prog = os.path.basename(sys.argv[0])
         if prog in ("__main__.py", "-c"):
             return f"{sys.executable} -m pip"
         else:
             return prog
     except (AttributeError, TypeError, IndexError):
         pass
     return "pip"
 
 
 # Retry every half second for up to 3 seconds
 # Tenacity raises RetryError by default, explicitly raise the original exception
 @retry(reraise=True, stop=stop_after_delay(3), wait=wait_fixed(0.5))
-def rmtree(dir, ignore_errors=False):
-    # type: (AnyStr, bool) -> None
+def rmtree(dir: str, ignore_errors: bool = False) -> None:
     shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)
 
 
-def rmtree_errorhandler(func, path, exc_info):
-    # type: (Callable[..., Any], str, ExcInfo) -> None
+def rmtree_errorhandler(func: Callable[..., Any], path: str, exc_info: ExcInfo) -> None:
     """On Windows, the files in .svn are read-only, so when rmtree() tries to
     remove them, an exception is thrown.  We catch that here, remove the
     read-only attribute, and hopefully continue without problems."""
     try:
         has_attr_readonly = not (os.stat(path).st_mode & stat.S_IWRITE)
     except OSError:
         # it's equivalent to os.path.exists
@@ -152,85 +142,77 @@
         # use the original function to repeat the operation
         func(path)
         return
     else:
         raise
 
 
-def display_path(path):
-    # type: (str) -> str
+def display_path(path: str) -> str:
     """Gives the display value for a given path, making it relative to cwd
     if possible."""
     path = os.path.normcase(os.path.abspath(path))
     if path.startswith(os.getcwd() + os.path.sep):
         path = "." + path[len(os.getcwd()) :]
     return path
 
 
-def backup_dir(dir, ext=".bak"):
-    # type: (str, str) -> str
+def backup_dir(dir: str, ext: str = ".bak") -> str:
     """Figure out the name of a directory to back up the given dir to
     (adding .bak, .bak2, etc)"""
     n = 1
     extension = ext
     while os.path.exists(dir + extension):
         n += 1
         extension = ext + str(n)
     return dir + extension
 
 
-def ask_path_exists(message, options):
-    # type: (str, Iterable[str]) -> str
+def ask_path_exists(message: str, options: Iterable[str]) -> str:
     for action in os.environ.get("PIP_EXISTS_ACTION", "").split():
         if action in options:
             return action
     return ask(message, options)
 
 
-def _check_no_input(message):
-    # type: (str) -> None
+def _check_no_input(message: str) -> None:
     """Raise an error if no input is allowed."""
     if os.environ.get("PIP_NO_INPUT"):
         raise Exception(
             f"No input was expected ($PIP_NO_INPUT set); question: {message}"
         )
 
 
-def ask(message, options):
-    # type: (str, Iterable[str]) -> str
+def ask(message: str, options: Iterable[str]) -> str:
     """Ask the message interactively, with the given possible responses"""
     while 1:
         _check_no_input(message)
         response = input(message)
         response = response.strip().lower()
         if response not in options:
             print(
                 "Your response ({!r}) was not one of the expected responses: "
                 "{}".format(response, ", ".join(options))
             )
         else:
             return response
 
 
-def ask_input(message):
-    # type: (str) -> str
+def ask_input(message: str) -> str:
     """Ask for input interactively."""
     _check_no_input(message)
     return input(message)
 
 
-def ask_password(message):
-    # type: (str) -> str
+def ask_password(message: str) -> str:
     """Ask for a password interactively."""
     _check_no_input(message)
     return getpass.getpass(message)
 
 
-def strtobool(val):
-    # type: (str) -> int
+def strtobool(val: str) -> int:
     """Convert a string representation of truth to true (1) or false (0).
 
     True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values
     are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if
     'val' is anything else.
     """
     val = val.lower()
@@ -238,28 +220,26 @@
         return 1
     elif val in ("n", "no", "f", "false", "off", "0"):
         return 0
     else:
         raise ValueError(f"invalid truth value {val!r}")
 
 
-def format_size(bytes):
-    # type: (float) -> str
+def format_size(bytes: float) -> str:
     if bytes > 1000 * 1000:
         return "{:.1f} MB".format(bytes / 1000.0 / 1000)
     elif bytes > 10 * 1000:
         return "{} kB".format(int(bytes / 1000))
     elif bytes > 1000:
         return "{:.1f} kB".format(bytes / 1000.0)
     else:
         return "{} bytes".format(int(bytes))
 
 
-def tabulate(rows):
-    # type: (Iterable[Iterable[Any]]) -> Tuple[List[str], List[int]]
+def tabulate(rows: Iterable[Iterable[Any]]) -> Tuple[List[str], List[int]]:
     """Return a list of formatted rows and a list of column sizes.
 
     For example::
 
     >>> tabulate([['foobar', 2000], [0xdeadbeef]])
     (['foobar     2000', '3735928559'], [10, 4])
     """
@@ -282,50 +262,46 @@
     if os.path.isfile(os.path.join(path, "pyproject.toml")):
         return True
     if os.path.isfile(os.path.join(path, "setup.py")):
         return True
     return False
 
 
-def read_chunks(file, size=io.DEFAULT_BUFFER_SIZE):
-    # type: (BinaryIO, int) -> Iterator[bytes]
+def read_chunks(file: BinaryIO, size: int = io.DEFAULT_BUFFER_SIZE) -> Iterator[bytes]:
     """Yield pieces of data from a file-like object until EOF."""
     while True:
         chunk = file.read(size)
         if not chunk:
             break
         yield chunk
 
 
-def normalize_path(path, resolve_symlinks=True):
-    # type: (str, bool) -> str
+def normalize_path(path: str, resolve_symlinks: bool = True) -> str:
     """
     Convert a path to its canonical, case-normalized, absolute version.
 
     """
     path = os.path.expanduser(path)
     if resolve_symlinks:
         path = os.path.realpath(path)
     else:
         path = os.path.abspath(path)
     return os.path.normcase(path)
 
 
-def splitext(path):
-    # type: (str) -> Tuple[str, str]
+def splitext(path: str) -> Tuple[str, str]:
     """Like os.path.splitext, but take off .tar too"""
     base, ext = posixpath.splitext(path)
     if base.lower().endswith(".tar"):
         ext = base[-4:] + ext
         base = base[:-4]
     return base, ext
 
 
-def renames(old, new):
-    # type: (str, str) -> None
+def renames(old: str, new: str) -> None:
     """Like os.renames(), but handles renaming across devices."""
     # Implementation borrowed from os.renames().
     head, tail = os.path.split(new)
     if head and tail and not os.path.exists(head):
         os.makedirs(head)
 
     shutil.move(old, new)
@@ -334,102 +310,55 @@
     if head and tail:
         try:
             os.removedirs(head)
         except OSError:
             pass
 
 
-def is_local(path):
-    # type: (str) -> bool
+def is_local(path: str) -> bool:
     """
     Return True if path is within sys.prefix, if we're running in a virtualenv.
 
     If we're not in a virtualenv, all paths are considered "local."
 
     Caution: this function assumes the head of path has been normalized
     with normalize_path.
     """
     if not running_under_virtualenv():
         return True
     return path.startswith(normalize_path(sys.prefix))
 
 
-def dist_is_local(dist):
-    # type: (Distribution) -> bool
+def dist_is_local(dist: Distribution) -> bool:
     """
     Return True if given Distribution object is installed locally
     (i.e. within current virtualenv).
 
     Always True if we're not in a virtualenv.
 
     """
     return is_local(dist_location(dist))
 
 
-def dist_in_usersite(dist):
-    # type: (Distribution) -> bool
+def dist_in_usersite(dist: Distribution) -> bool:
     """
     Return True if given Distribution is installed in user site.
     """
     return dist_location(dist).startswith(normalize_path(user_site))
 
 
-def dist_in_site_packages(dist):
-    # type: (Distribution) -> bool
+def dist_in_site_packages(dist: Distribution) -> bool:
     """
     Return True if given Distribution is installed in
     sysconfig.get_python_lib().
     """
     return dist_location(dist).startswith(normalize_path(site_packages))
 
 
-def dist_is_editable(dist):
-    # type: (Distribution) -> bool
-    """
-    Return True if given Distribution is an editable install.
-    """
-    for path_item in sys.path:
-        egg_link = os.path.join(path_item, dist.project_name + ".egg-link")
-        if os.path.isfile(egg_link):
-            return True
-    return False
-
-
-def get_installed_distributions(
-    local_only=True,  # type: bool
-    skip=stdlib_pkgs,  # type: Container[str]
-    include_editables=True,  # type: bool
-    editables_only=False,  # type: bool
-    user_only=False,  # type: bool
-    paths=None,  # type: Optional[List[str]]
-):
-    # type: (...) -> List[Distribution]
-    """Return a list of installed Distribution objects.
-
-    Left for compatibility until direct pkg_resources uses are refactored out.
-    """
-    from pip._internal.metadata import get_default_environment, get_environment
-    from pip._internal.metadata.pkg_resources import Distribution as _Dist
-
-    if paths is None:
-        env = get_default_environment()
-    else:
-        env = get_environment(paths)
-    dists = env.iter_installed_distributions(
-        local_only=local_only,
-        skip=skip,
-        include_editables=include_editables,
-        editables_only=editables_only,
-        user_only=user_only,
-    )
-    return [cast(_Dist, dist)._dist for dist in dists]
-
-
-def get_distribution(req_name):
-    # type: (str) -> Optional[Distribution]
+def get_distribution(req_name: str) -> Optional[Distribution]:
     """Given a requirement name, return the installed Distribution object.
 
     This searches from *all* distributions available in the environment, to
     match the behavior of ``pkg_resources.get_distribution()``.
 
     Left for compatibility until direct pkg_resources uses are refactored out.
     """
@@ -438,182 +367,135 @@
 
     dist = get_default_environment().get_distribution(req_name)
     if dist is None:
         return None
     return cast(_Dist, dist)._dist
 
 
-def egg_link_path(dist):
-    # type: (Distribution) -> Optional[str]
-    """
-    Return the path for the .egg-link file if it exists, otherwise, None.
-
-    There's 3 scenarios:
-    1) not in a virtualenv
-       try to find in site.USER_SITE, then site_packages
-    2) in a no-global virtualenv
-       try to find in site_packages
-    3) in a yes-global virtualenv
-       try to find in site_packages, then site.USER_SITE
-       (don't look in global location)
-
-    For #1 and #3, there could be odd cases, where there's an egg-link in 2
-    locations.
-
-    This method will just return the first one found.
-    """
-    sites = []
-    if running_under_virtualenv():
-        sites.append(site_packages)
-        if not virtualenv_no_global() and user_site:
-            sites.append(user_site)
-    else:
-        if user_site:
-            sites.append(user_site)
-        sites.append(site_packages)
-
-    for site in sites:
-        egglink = os.path.join(site, dist.project_name) + ".egg-link"
-        if os.path.isfile(egglink):
-            return egglink
-    return None
-
-
-def dist_location(dist):
-    # type: (Distribution) -> str
+def dist_location(dist: Distribution) -> str:
     """
     Get the site-packages location of this distribution. Generally
     this is dist.location, except in the case of develop-installed
     packages, where dist.location is the source code location, and we
     want to know where the egg-link file is.
 
     The returned location is normalized (in particular, with symlinks removed).
     """
-    egg_link = egg_link_path(dist)
+    egg_link = egg_link_path_from_location(dist.project_name)
     if egg_link:
         return normalize_path(egg_link)
     return normalize_path(dist.location)
 
 
-def write_output(msg, *args):
-    # type: (Any, Any) -> None
+def write_output(msg: Any, *args: Any) -> None:
     logger.info(msg, *args)
 
 
 class StreamWrapper(StringIO):
-    orig_stream = None  # type: TextIO
+    orig_stream: TextIO = None
 
     @classmethod
-    def from_stream(cls, orig_stream):
-        # type: (TextIO) -> StreamWrapper
+    def from_stream(cls, orig_stream: TextIO) -> "StreamWrapper":
         cls.orig_stream = orig_stream
         return cls()
 
     # compileall.compile_dir() needs stdout.encoding to print to stdout
     # https://github.com/python/mypy/issues/4125
     @property
     def encoding(self):  # type: ignore
         return self.orig_stream.encoding
 
 
 @contextlib.contextmanager
-def captured_output(stream_name):
-    # type: (str) -> Iterator[StreamWrapper]
+def captured_output(stream_name: str) -> Iterator[StreamWrapper]:
     """Return a context manager used by captured_stdout/stdin/stderr
     that temporarily replaces the sys stream *stream_name* with a StringIO.
 
     Taken from Lib/support/__init__.py in the CPython repo.
     """
     orig_stdout = getattr(sys, stream_name)
     setattr(sys, stream_name, StreamWrapper.from_stream(orig_stdout))
     try:
         yield getattr(sys, stream_name)
     finally:
         setattr(sys, stream_name, orig_stdout)
 
 
-def captured_stdout():
-    # type: () -> ContextManager[StreamWrapper]
+def captured_stdout() -> ContextManager[StreamWrapper]:
     """Capture the output of sys.stdout:
 
        with captured_stdout() as stdout:
            print('hello')
        self.assertEqual(stdout.getvalue(), 'hello\n')
 
     Taken from Lib/support/__init__.py in the CPython repo.
     """
     return captured_output("stdout")
 
 
-def captured_stderr():
-    # type: () -> ContextManager[StreamWrapper]
+def captured_stderr() -> ContextManager[StreamWrapper]:
     """
     See captured_stdout().
     """
     return captured_output("stderr")
 
 
 # Simulates an enum
-def enum(*sequential, **named):
-    # type: (*Any, **Any) -> Type[Any]
+def enum(*sequential: Any, **named: Any) -> Type[Any]:
     enums = dict(zip(sequential, range(len(sequential))), **named)
     reverse = {value: key for key, value in enums.items()}
     enums["reverse_mapping"] = reverse
     return type("Enum", (), enums)
 
 
-def build_netloc(host, port):
-    # type: (str, Optional[int]) -> str
+def build_netloc(host: str, port: Optional[int]) -> str:
     """
     Build a netloc from a host-port pair
     """
     if port is None:
         return host
     if ":" in host:
         # Only wrap host with square brackets when it is IPv6
         host = f"[{host}]"
     return f"{host}:{port}"
 
 
-def build_url_from_netloc(netloc, scheme="https"):
-    # type: (str, str) -> str
+def build_url_from_netloc(netloc: str, scheme: str = "https") -> str:
     """
     Build a full URL from a netloc.
     """
     if netloc.count(":") >= 2 and "@" not in netloc and "[" not in netloc:
         # It must be a bare IPv6 address, so wrap it with brackets.
         netloc = f"[{netloc}]"
     return f"{scheme}://{netloc}"
 
 
-def parse_netloc(netloc):
-    # type: (str) -> Tuple[str, Optional[int]]
+def parse_netloc(netloc: str) -> Tuple[str, Optional[int]]:
     """
     Return the host-port pair from a netloc.
     """
     url = build_url_from_netloc(netloc)
     parsed = urllib.parse.urlparse(url)
     return parsed.hostname, parsed.port
 
 
-def split_auth_from_netloc(netloc):
-    # type: (str) -> NetlocTuple
+def split_auth_from_netloc(netloc: str) -> NetlocTuple:
     """
     Parse out and remove the auth information from a netloc.
 
     Returns: (netloc, (username, password)).
     """
     if "@" not in netloc:
         return netloc, (None, None)
 
     # Split from the right because that's how urllib.parse.urlsplit()
     # behaves if more than one @ is present (which can be checked using
     # the password attribute of urlsplit()'s return value).
     auth, netloc = netloc.rsplit("@", 1)
-    pw = None  # type: Optional[str]
+    pw: Optional[str] = None
     if ":" in auth:
         # Split from the left because that's how urllib.parse.urlsplit()
         # behaves if more than one : is present (which again can be checked
         # using the password attribute of the return value)
         user, pw = auth.split(":", 1)
     else:
         user, pw = auth, None
@@ -621,16 +503,15 @@
     user = urllib.parse.unquote(user)
     if pw is not None:
         pw = urllib.parse.unquote(pw)
 
     return netloc, (user, pw)
 
 
-def redact_netloc(netloc):
-    # type: (str) -> str
+def redact_netloc(netloc: str) -> str:
     """
     Replace the sensitive data in a netloc with "****", if it exists.
 
     For example:
         - "user:pass@example.com" returns "user:****@example.com"
         - "accesstoken@example.com" returns "****@example.com"
     """
@@ -644,16 +525,17 @@
         user = urllib.parse.quote(user)
         password = ":****"
     return "{user}{password}@{netloc}".format(
         user=user, password=password, netloc=netloc
     )
 
 
-def _transform_url(url, transform_netloc):
-    # type: (str, Callable[[str], Tuple[Any, ...]]) -> Tuple[str, NetlocTuple]
+def _transform_url(
+    url: str, transform_netloc: Callable[[str], Tuple[Any, ...]]
+) -> Tuple[str, NetlocTuple]:
     """Transform and replace netloc in a url.
 
     transform_netloc is a function taking the netloc and returning a
     tuple. The first element of this tuple is the new netloc. The
     entire tuple is returned.
 
     Returns a tuple containing the transformed url as item 0 and the
@@ -663,91 +545,75 @@
     netloc_tuple = transform_netloc(purl.netloc)
     # stripped url
     url_pieces = (purl.scheme, netloc_tuple[0], purl.path, purl.query, purl.fragment)
     surl = urllib.parse.urlunsplit(url_pieces)
     return surl, cast("NetlocTuple", netloc_tuple)
 
 
-def _get_netloc(netloc):
-    # type: (str) -> NetlocTuple
+def _get_netloc(netloc: str) -> NetlocTuple:
     return split_auth_from_netloc(netloc)
 
 
-def _redact_netloc(netloc):
-    # type: (str) -> Tuple[str,]
+def _redact_netloc(netloc: str) -> Tuple[str]:
     return (redact_netloc(netloc),)
 
 
-def split_auth_netloc_from_url(url):
-    # type: (str) -> Tuple[str, str, Tuple[str, str]]
+def split_auth_netloc_from_url(url: str) -> Tuple[str, str, Tuple[str, str]]:
     """
     Parse a url into separate netloc, auth, and url with no auth.
 
     Returns: (url_without_auth, netloc, (username, password))
     """
     url_without_auth, (netloc, auth) = _transform_url(url, _get_netloc)
     return url_without_auth, netloc, auth
 
 
-def remove_auth_from_url(url):
-    # type: (str) -> str
+def remove_auth_from_url(url: str) -> str:
     """Return a copy of url with 'username:password@' removed."""
     # username/pass params are passed to subversion through flags
     # and are not recognized in the url.
     return _transform_url(url, _get_netloc)[0]
 
 
-def redact_auth_from_url(url):
-    # type: (str) -> str
+def redact_auth_from_url(url: str) -> str:
     """Replace the password in a given url with ****."""
     return _transform_url(url, _redact_netloc)[0]
 
 
 class HiddenText:
-    def __init__(
-        self,
-        secret,  # type: str
-        redacted,  # type: str
-    ):
-        # type: (...) -> None
+    def __init__(self, secret: str, redacted: str) -> None:
         self.secret = secret
         self.redacted = redacted
 
-    def __repr__(self):
-        # type: (...) -> str
+    def __repr__(self) -> str:
         return "<HiddenText {!r}>".format(str(self))
 
-    def __str__(self):
-        # type: (...) -> str
+    def __str__(self) -> str:
         return self.redacted
 
     # This is useful for testing.
-    def __eq__(self, other):
-        # type: (Any) -> bool
+    def __eq__(self, other: Any) -> bool:
         if type(self) != type(other):
             return False
 
         # The string being used for redaction doesn't also have to match,
         # just the raw, original string.
         return self.secret == other.secret
 
 
-def hide_value(value):
-    # type: (str) -> HiddenText
+def hide_value(value: str) -> HiddenText:
     return HiddenText(value, redacted="****")
 
 
-def hide_url(url):
-    # type: (str) -> HiddenText
+def hide_url(url: str) -> HiddenText:
     redacted = redact_auth_from_url(url)
     return HiddenText(url, redacted=redacted)
 
 
-def protect_pip_from_modification_on_windows(modifying_pip):
-    # type: (bool) -> None
+def protect_pip_from_modification_on_windows(modifying_pip: bool) -> None:
     """Protection of pip.exe from modification on Windows
 
     On Windows, any operation modifying pip should be run as:
         python -m pip ...
     """
     pip_names = [
         "pip.exe",
@@ -765,63 +631,58 @@
         raise CommandError(
             "To modify pip, please run the following command:\n{}".format(
                 " ".join(new_command)
             )
         )
 
 
-def is_console_interactive():
-    # type: () -> bool
+def is_console_interactive() -> bool:
     """Is this console interactive?"""
     return sys.stdin is not None and sys.stdin.isatty()
 
 
-def hash_file(path, blocksize=1 << 20):
-    # type: (str, int) -> Tuple[Any, int]
+def hash_file(path: str, blocksize: int = 1 << 20) -> Tuple[Any, int]:
     """Return (hash, length) for path using hashlib.sha256()"""
 
     h = hashlib.sha256()
     length = 0
     with open(path, "rb") as f:
         for block in read_chunks(f, size=blocksize):
             length += len(block)
             h.update(block)
     return h, length
 
 
-def is_wheel_installed():
-    # type: () -> bool
+def is_wheel_installed() -> bool:
     """
     Return whether the wheel package is installed.
     """
     try:
         import wheel  # noqa: F401
     except ImportError:
         return False
 
     return True
 
 
-def pairwise(iterable):
-    # type: (Iterable[Any]) -> Iterator[Tuple[Any, Any]]
+def pairwise(iterable: Iterable[Any]) -> Iterator[Tuple[Any, Any]]:
     """
     Return paired elements.
 
     For example:
         s -> (s0, s1), (s2, s3), (s4, s5), ...
     """
     iterable = iter(iterable)
     return zip_longest(iterable, iterable)
 
 
 def partition(
-    pred,  # type: Callable[[T], bool]
-    iterable,  # type: Iterable[T]
-):
-    # type: (...) -> Tuple[Iterable[T], Iterable[T]]
+    pred: Callable[[T], bool],
+    iterable: Iterable[T],
+) -> Tuple[Iterable[T], Iterable[T]]:
     """
     Use a predicate to partition entries into false entries and true entries,
     like
 
         partition(is_odd, range(10)) --> 0 2 4 6 8   and  1 3 5 7 9
     """
     t1, t2 = tee(iterable)
```

#### pip/_internal/utils/models.py

```diff
@@ -6,42 +6,34 @@
 
 
 class KeyBasedCompareMixin:
     """Provides comparison capabilities that is based on a key"""
 
     __slots__ = ["_compare_key", "_defining_class"]
 
-    def __init__(self, key, defining_class):
-        # type: (Any, Type[KeyBasedCompareMixin]) -> None
+    def __init__(self, key: Any, defining_class: Type["KeyBasedCompareMixin"]) -> None:
         self._compare_key = key
         self._defining_class = defining_class
 
-    def __hash__(self):
-        # type: () -> int
+    def __hash__(self) -> int:
         return hash(self._compare_key)
 
-    def __lt__(self, other):
-        # type: (Any) -> bool
+    def __lt__(self, other: Any) -> bool:
         return self._compare(other, operator.__lt__)
 
-    def __le__(self, other):
-        # type: (Any) -> bool
+    def __le__(self, other: Any) -> bool:
         return self._compare(other, operator.__le__)
 
-    def __gt__(self, other):
-        # type: (Any) -> bool
+    def __gt__(self, other: Any) -> bool:
         return self._compare(other, operator.__gt__)
 
-    def __ge__(self, other):
-        # type: (Any) -> bool
+    def __ge__(self, other: Any) -> bool:
         return self._compare(other, operator.__ge__)
 
-    def __eq__(self, other):
-        # type: (Any) -> bool
+    def __eq__(self, other: Any) -> bool:
         return self._compare(other, operator.__eq__)
 
-    def _compare(self, other, method):
-        # type: (Any, Callable[[Any, Any], bool]) -> bool
+    def _compare(self, other: Any, method: Callable[[Any, Any], bool]) -> bool:
         if not isinstance(other, self._defining_class):
             return NotImplemented
 
         return method(self._compare_key, other._compare_key)
```

#### pip/_internal/utils/packaging.py

```diff
@@ -1,24 +1,27 @@
+import functools
 import logging
 from email.message import Message
 from email.parser import FeedParser
 from typing import Optional, Tuple
 
 from pip._vendor import pkg_resources
 from pip._vendor.packaging import specifiers, version
+from pip._vendor.packaging.requirements import Requirement
 from pip._vendor.pkg_resources import Distribution
 
 from pip._internal.exceptions import NoneMetadataError
 from pip._internal.utils.misc import display_path
 
 logger = logging.getLogger(__name__)
 
 
-def check_requires_python(requires_python, version_info):
-    # type: (Optional[str], Tuple[int, ...]) -> bool
+def check_requires_python(
+    requires_python: Optional[str], version_info: Tuple[int, ...]
+) -> bool:
     """
     Check if the given Python version matches a "Requires-Python" specifier.
 
     :param version_info: A 3-tuple of ints representing a Python
         major-minor-micro version to check (e.g. `sys.version_info[:3]`).
 
     :return: `True` if the given Python version satisfies the requirement.
@@ -31,16 +34,15 @@
         return True
     requires_python_specifier = specifiers.SpecifierSet(requires_python)
 
     python_version = version.parse(".".join(map(str, version_info)))
     return python_version in requires_python_specifier
 
 
-def get_metadata(dist):
-    # type: (Distribution) -> Message
+def get_metadata(dist: Distribution) -> Message:
     """
     :raises NoneMetadataError: if the distribution reports `has_metadata()`
         True but `get_metadata()` returns None.
     """
     metadata_name = "METADATA"
     if isinstance(dist, pkg_resources.DistInfoDistribution) and dist.has_metadata(
         metadata_name
@@ -59,31 +61,24 @@
     feed_parser = FeedParser()
     # The following line errors out if with a "NoneType" TypeError if
     # passed metadata=None.
     feed_parser.feed(metadata)
     return feed_parser.close()
 
 
-def get_requires_python(dist):
-    # type: (pkg_resources.Distribution) -> Optional[str]
-    """
-    Return the "Requires-Python" metadata for a distribution, or None
-    if not present.
-    """
-    pkg_info_dict = get_metadata(dist)
-    requires_python = pkg_info_dict.get("Requires-Python")
-
-    if requires_python is not None:
-        # Convert to a str to satisfy the type checker, since requires_python
-        # can be a Header object.
-        requires_python = str(requires_python)
-
-    return requires_python
-
-
-def get_installer(dist):
-    # type: (Distribution) -> str
+def get_installer(dist: Distribution) -> str:
     if dist.has_metadata("INSTALLER"):
         for line in dist.get_metadata_lines("INSTALLER"):
             if line.strip():
                 return line.strip()
     return ""
+
+
+@functools.lru_cache(maxsize=512)
+def get_requirement(req_string: str) -> Requirement:
+    """Construct a packaging.Requirement object with caching"""
+    # Parsing requirement strings is expensive, and is also expected to happen
+    # with a low diversity of different arguments (at least relative the number
+    # constructed). This method adds a cache to requirement object creation to
+    # minimize repeated parsing of the same string to construct equivalent
+    # Requirement objects.
+    return Requirement(req_string)
```

#### pip/_internal/utils/parallel.py

```diff
@@ -40,53 +40,55 @@
     LACK_SEM_OPEN = False
 
 # Incredibly large timeout to work around bpo-8296 on Python 2.
 TIMEOUT = 2000000
 
 
 @contextmanager
-def closing(pool):
-    # type: (Pool) -> Iterator[Pool]
+def closing(pool: Pool) -> Iterator[Pool]:
     """Return a context manager making sure the pool closes properly."""
     try:
         yield pool
     finally:
         # For Pool.imap*, close and join are needed
         # for the returned iterator to begin yielding.
         pool.close()
         pool.join()
         pool.terminate()
 
 
-def _map_fallback(func, iterable, chunksize=1):
-    # type: (Callable[[S], T], Iterable[S], int) -> Iterator[T]
+def _map_fallback(
+    func: Callable[[S], T], iterable: Iterable[S], chunksize: int = 1
+) -> Iterator[T]:
     """Make an iterator applying func to each element in iterable.
 
     This function is the sequential fallback either on Python 2
     where Pool.imap* doesn't react to KeyboardInterrupt
     or when sem_open is unavailable.
     """
     return map(func, iterable)
 
 
-def _map_multiprocess(func, iterable, chunksize=1):
-    # type: (Callable[[S], T], Iterable[S], int) -> Iterator[T]
+def _map_multiprocess(
+    func: Callable[[S], T], iterable: Iterable[S], chunksize: int = 1
+) -> Iterator[T]:
     """Chop iterable into chunks and submit them to a process pool.
 
     For very long iterables using a large value for chunksize can make
     the job complete much faster than using the default value of 1.
 
     Return an unordered iterator of the results.
     """
     with closing(ProcessPool()) as pool:
         return pool.imap_unordered(func, iterable, chunksize)
 
 
-def _map_multithread(func, iterable, chunksize=1):
-    # type: (Callable[[S], T], Iterable[S], int) -> Iterator[T]
+def _map_multithread(
+    func: Callable[[S], T], iterable: Iterable[S], chunksize: int = 1
+) -> Iterator[T]:
     """Chop iterable into chunks and submit them to a thread pool.
 
     For very long iterables using a large value for chunksize can make
     the job complete much faster than using the default value of 1.
 
     Return an unordered iterator of the results.
     """
```

#### pip/_internal/utils/pkg_resources.py

```diff
@@ -2,39 +2,32 @@
 
 from pip._vendor.pkg_resources import yield_lines
 
 
 class DictMetadata:
     """IMetadataProvider that reads metadata files from a dictionary."""
 
-    def __init__(self, metadata):
-        # type: (Dict[str, bytes]) -> None
+    def __init__(self, metadata: Dict[str, bytes]) -> None:
         self._metadata = metadata
 
-    def has_metadata(self, name):
-        # type: (str) -> bool
+    def has_metadata(self, name: str) -> bool:
         return name in self._metadata
 
-    def get_metadata(self, name):
-        # type: (str) -> str
+    def get_metadata(self, name: str) -> str:
         try:
             return self._metadata[name].decode()
         except UnicodeDecodeError as e:
             # Mirrors handling done in pkg_resources.NullProvider.
             e.reason += f" in {name} file"
             raise
 
-    def get_metadata_lines(self, name):
-        # type: (str) -> Iterable[str]
+    def get_metadata_lines(self, name: str) -> Iterable[str]:
         return yield_lines(self.get_metadata(name))
 
-    def metadata_isdir(self, name):
-        # type: (str) -> bool
+    def metadata_isdir(self, name: str) -> bool:
         return False
 
-    def metadata_listdir(self, name):
-        # type: (str) -> List[str]
+    def metadata_listdir(self, name: str) -> List[str]:
         return []
 
-    def run_script(self, script_name, namespace):
-        # type: (str, str) -> None
+    def run_script(self, script_name: str, namespace: str) -> None:
         pass
```

#### pip/_internal/utils/setuptools_build.py

```diff
@@ -15,20 +15,19 @@
     "code = f.read().replace('\\r\\n', '\\n');"
     "f.close();"
     "exec(compile(code, __file__, 'exec'))"
 )
 
 
 def make_setuptools_shim_args(
-    setup_py_path,  # type: str
-    global_options=None,  # type: Sequence[str]
-    no_user_config=False,  # type: bool
-    unbuffered_output=False,  # type: bool
-):
-    # type: (...) -> List[str]
+    setup_py_path: str,
+    global_options: Sequence[str] = None,
+    no_user_config: bool = False,
+    unbuffered_output: bool = False,
+) -> List[str]:
     """
     Get setuptools command arguments with shim wrapped setup file invocation.
 
     :param setup_py_path: The path to setup.py to be wrapped.
     :param global_options: Additional global options.
     :param no_user_config: If True, disables personal user configuration.
     :param unbuffered_output: If True, adds the unbuffered switch to the
@@ -42,54 +41,51 @@
         args += global_options
     if no_user_config:
         args += ["--no-user-cfg"]
     return args
 
 
 def make_setuptools_bdist_wheel_args(
-    setup_py_path,  # type: str
-    global_options,  # type: Sequence[str]
-    build_options,  # type: Sequence[str]
-    destination_dir,  # type: str
-):
-    # type: (...) -> List[str]
+    setup_py_path: str,
+    global_options: Sequence[str],
+    build_options: Sequence[str],
+    destination_dir: str,
+) -> List[str]:
     # NOTE: Eventually, we'd want to also -S to the flags here, when we're
     # isolating. Currently, it breaks Python in virtualenvs, because it
     # relies on site.py to find parts of the standard library outside the
     # virtualenv.
     args = make_setuptools_shim_args(
         setup_py_path, global_options=global_options, unbuffered_output=True
     )
     args += ["bdist_wheel", "-d", destination_dir]
     args += build_options
     return args
 
 
 def make_setuptools_clean_args(
-    setup_py_path,  # type: str
-    global_options,  # type: Sequence[str]
-):
-    # type: (...) -> List[str]
+    setup_py_path: str,
+    global_options: Sequence[str],
+) -> List[str]:
     args = make_setuptools_shim_args(
         setup_py_path, global_options=global_options, unbuffered_output=True
     )
     args += ["clean", "--all"]
     return args
 
 
 def make_setuptools_develop_args(
-    setup_py_path,  # type: str
-    global_options,  # type: Sequence[str]
-    install_options,  # type: Sequence[str]
-    no_user_config,  # type: bool
-    prefix,  # type: Optional[str]
-    home,  # type: Optional[str]
-    use_user_site,  # type: bool
-):
-    # type: (...) -> List[str]
+    setup_py_path: str,
+    global_options: Sequence[str],
+    install_options: Sequence[str],
+    no_user_config: bool,
+    prefix: Optional[str],
+    home: Optional[str],
+    use_user_site: bool,
+) -> List[str]:
     assert not (use_user_site and prefix)
 
     args = make_setuptools_shim_args(
         setup_py_path,
         global_options=global_options,
         no_user_config=no_user_config,
     )
@@ -106,43 +102,41 @@
     if use_user_site:
         args += ["--user", "--prefix="]
 
     return args
 
 
 def make_setuptools_egg_info_args(
-    setup_py_path,  # type: str
-    egg_info_dir,  # type: Optional[str]
-    no_user_config,  # type: bool
-):
-    # type: (...) -> List[str]
+    setup_py_path: str,
+    egg_info_dir: Optional[str],
+    no_user_config: bool,
+) -> List[str]:
     args = make_setuptools_shim_args(setup_py_path, no_user_config=no_user_config)
 
     args += ["egg_info"]
 
     if egg_info_dir:
         args += ["--egg-base", egg_info_dir]
 
     return args
 
 
 def make_setuptools_install_args(
-    setup_py_path,  # type: str
-    global_options,  # type: Sequence[str]
-    install_options,  # type: Sequence[str]
-    record_filename,  # type: str
-    root,  # type: Optional[str]
-    prefix,  # type: Optional[str]
-    header_dir,  # type: Optional[str]
-    home,  # type: Optional[str]
-    use_user_site,  # type: bool
-    no_user_config,  # type: bool
-    pycompile,  # type: bool
-):
-    # type: (...) -> List[str]
+    setup_py_path: str,
+    global_options: Sequence[str],
+    install_options: Sequence[str],
+    record_filename: str,
+    root: Optional[str],
+    prefix: Optional[str],
+    header_dir: Optional[str],
+    home: Optional[str],
+    use_user_site: bool,
+    no_user_config: bool,
+    pycompile: bool,
+) -> List[str]:
     assert not (use_user_site and prefix)
     assert not (use_user_site and root)
 
     args = make_setuptools_shim_args(
         setup_py_path,
         global_options=global_options,
         no_user_config=no_user_config,
```

#### pip/_internal/utils/subprocess.py

```diff
@@ -1,73 +1,84 @@
 import logging
 import os
 import shlex
 import subprocess
-from typing import Any, Callable, Iterable, List, Mapping, Optional, Union
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Callable,
+    Iterable,
+    List,
+    Mapping,
+    Optional,
+    Union,
+)
 
 from pip._internal.cli.spinners import SpinnerInterface, open_spinner
 from pip._internal.exceptions import InstallationSubprocessError
 from pip._internal.utils.logging import VERBOSE, subprocess_logger
 from pip._internal.utils.misc import HiddenText
 
+if TYPE_CHECKING:
+    # Literal was introduced in Python 3.8.
+    #
+    # TODO: Remove `if TYPE_CHECKING` when dropping support for Python 3.7.
+    from typing import Literal
+
 CommandArgs = List[Union[str, HiddenText]]
 
 
 LOG_DIVIDER = "----------------------------------------"
 
 
-def make_command(*args):
-    # type: (Union[str, HiddenText, CommandArgs]) -> CommandArgs
+def make_command(*args: Union[str, HiddenText, CommandArgs]) -> CommandArgs:
     """
     Create a CommandArgs object.
     """
-    command_args = []  # type: CommandArgs
+    command_args: CommandArgs = []
     for arg in args:
         # Check for list instead of CommandArgs since CommandArgs is
         # only known during type-checking.
         if isinstance(arg, list):
             command_args.extend(arg)
         else:
             # Otherwise, arg is str or HiddenText.
             command_args.append(arg)
 
     return command_args
 
 
-def format_command_args(args):
-    # type: (Union[List[str], CommandArgs]) -> str
+def format_command_args(args: Union[List[str], CommandArgs]) -> str:
     """
     Format command arguments for display.
     """
     # For HiddenText arguments, display the redacted form by calling str().
     # Also, we don't apply str() to arguments that aren't HiddenText since
     # this can trigger a UnicodeDecodeError in Python 2 if the argument
     # has type unicode and includes a non-ascii character.  (The type
     # checker doesn't ensure the annotations are correct in all cases.)
     return " ".join(
         shlex.quote(str(arg)) if isinstance(arg, HiddenText) else shlex.quote(arg)
         for arg in args
     )
 
 
-def reveal_command_args(args):
-    # type: (Union[List[str], CommandArgs]) -> List[str]
+def reveal_command_args(args: Union[List[str], CommandArgs]) -> List[str]:
     """
     Return the arguments in their raw, unredacted form.
     """
     return [arg.secret if isinstance(arg, HiddenText) else arg for arg in args]
 
 
 def make_subprocess_output_error(
-    cmd_args,  # type: Union[List[str], CommandArgs]
-    cwd,  # type: Optional[str]
-    lines,  # type: List[str]
-    exit_status,  # type: int
-):
-    # type: (...) -> str
+    cmd_args: Union[List[str], CommandArgs],
+    cwd: Optional[str],
+    lines: List[str],
+    exit_status: int,
+) -> str:
     """
     Create and return the error message to use to log a subprocess error
     with command output.
 
     :param lines: A list of lines, each ending with a newline.
     """
     command = format_command_args(cmd_args)
@@ -90,27 +101,26 @@
         output=output,
         divider=LOG_DIVIDER,
     )
     return msg
 
 
 def call_subprocess(
-    cmd,  # type: Union[List[str], CommandArgs]
-    show_stdout=False,  # type: bool
-    cwd=None,  # type: Optional[str]
-    on_returncode="raise",  # type: str
-    extra_ok_returncodes=None,  # type: Optional[Iterable[int]]
-    command_desc=None,  # type: Optional[str]
-    extra_environ=None,  # type: Optional[Mapping[str, Any]]
-    unset_environ=None,  # type: Optional[Iterable[str]]
-    spinner=None,  # type: Optional[SpinnerInterface]
-    log_failed_cmd=True,  # type: Optional[bool]
-    stdout_only=False,  # type: Optional[bool]
-):
-    # type: (...) -> str
+    cmd: Union[List[str], CommandArgs],
+    show_stdout: bool = False,
+    cwd: Optional[str] = None,
+    on_returncode: 'Literal["raise", "warn", "ignore"]' = "raise",
+    extra_ok_returncodes: Optional[Iterable[int]] = None,
+    command_desc: Optional[str] = None,
+    extra_environ: Optional[Mapping[str, Any]] = None,
+    unset_environ: Optional[Iterable[str]] = None,
+    spinner: Optional[SpinnerInterface] = None,
+    log_failed_cmd: Optional[bool] = True,
+    stdout_only: Optional[bool] = False,
+) -> str:
     """
     Args:
       show_stdout: if true, use INFO to log the subprocess's stderr and
         stdout streams.  Otherwise, use DEBUG.  Defaults to False.
       extra_ok_returncodes: an iterable of integer return codes that are
         acceptable, in addition to 0. Defaults to None, which means [].
       unset_environ: an iterable of environment variable names to unset
@@ -187,15 +197,15 @@
     all_output = []
     if not stdout_only:
         assert proc.stdout
         assert proc.stdin
         proc.stdin.close()
         # In this mode, stdout and stderr are in the same pipe.
         while True:
-            line = proc.stdout.readline()  # type: str
+            line: str = proc.stdout.readline()
             if not line:
                 break
             line = line.rstrip()
             all_output.append(line + "\n")
 
             # Show the line immediately.
             log_subprocess(line)
@@ -252,28 +262,26 @@
         elif on_returncode == "ignore":
             pass
         else:
             raise ValueError(f"Invalid value: on_returncode={on_returncode!r}")
     return output
 
 
-def runner_with_spinner_message(message):
-    # type: (str) -> Callable[..., None]
+def runner_with_spinner_message(message: str) -> Callable[..., None]:
     """Provide a subprocess_runner that shows a spinner message.
 
     Intended for use with for pep517's Pep517HookCaller. Thus, the runner has
     an API that matches what's expected by Pep517HookCaller.subprocess_runner.
     """
 
     def runner(
-        cmd,  # type: List[str]
-        cwd=None,  # type: Optional[str]
-        extra_environ=None,  # type: Optional[Mapping[str, Any]]
-    ):
-        # type: (...) -> None
+        cmd: List[str],
+        cwd: Optional[str] = None,
+        extra_environ: Optional[Mapping[str, Any]] = None,
+    ) -> None:
         with open_spinner(message) as spinner:
             call_subprocess(
                 cmd,
                 cwd=cwd,
                 extra_environ=extra_environ,
                 spinner=spinner,
             )
```

#### pip/_internal/utils/temp_dir.py

```diff
@@ -18,57 +18,52 @@
 tempdir_kinds = enum(
     BUILD_ENV="build-env",
     EPHEM_WHEEL_CACHE="ephem-wheel-cache",
     REQ_BUILD="req-build",
 )
 
 
-_tempdir_manager = None  # type: Optional[ExitStack]
+_tempdir_manager: Optional[ExitStack] = None
 
 
 @contextmanager
-def global_tempdir_manager():
-    # type: () -> Iterator[None]
+def global_tempdir_manager() -> Iterator[None]:
     global _tempdir_manager
     with ExitStack() as stack:
         old_tempdir_manager, _tempdir_manager = _tempdir_manager, stack
         try:
             yield
         finally:
             _tempdir_manager = old_tempdir_manager
 
 
 class TempDirectoryTypeRegistry:
     """Manages temp directory behavior"""
 
-    def __init__(self):
-        # type: () -> None
-        self._should_delete = {}  # type: Dict[str, bool]
+    def __init__(self) -> None:
+        self._should_delete: Dict[str, bool] = {}
 
-    def set_delete(self, kind, value):
-        # type: (str, bool) -> None
+    def set_delete(self, kind: str, value: bool) -> None:
         """Indicate whether a TempDirectory of the given kind should be
         auto-deleted.
         """
         self._should_delete[kind] = value
 
-    def get_delete(self, kind):
-        # type: (str) -> bool
+    def get_delete(self, kind: str) -> bool:
         """Get configured auto-delete flag for a given TempDirectory type,
         default True.
         """
         return self._should_delete.get(kind, True)
 
 
-_tempdir_registry = None  # type: Optional[TempDirectoryTypeRegistry]
+_tempdir_registry: Optional[TempDirectoryTypeRegistry] = None
 
 
 @contextmanager
-def tempdir_registry():
-    # type: () -> Iterator[TempDirectoryTypeRegistry]
+def tempdir_registry() -> Iterator[TempDirectoryTypeRegistry]:
     """Provides a scoped global tempdir registry that can be used to dictate
     whether directories should be deleted.
     """
     global _tempdir_registry
     old_tempdir_registry = _tempdir_registry
     _tempdir_registry = TempDirectoryTypeRegistry()
     try:
@@ -103,18 +98,18 @@
 
     When used as a context manager, if the delete attribute is True, on
     exiting the context the temporary directory is deleted.
     """
 
     def __init__(
         self,
-        path=None,  # type: Optional[str]
-        delete=_default,  # type: Union[bool, None, _Default]
-        kind="temp",  # type: str
-        globally_managed=False,  # type: bool
+        path: Optional[str] = None,
+        delete: Union[bool, None, _Default] = _default,
+        kind: str = "temp",
+        globally_managed: bool = False,
     ):
         super().__init__()
 
         if delete is _default:
             if path is not None:
                 # If we were given an explicit directory, resolve delete option
                 # now.
@@ -135,52 +130,46 @@
         self.kind = kind
 
         if globally_managed:
             assert _tempdir_manager is not None
             _tempdir_manager.enter_context(self)
 
     @property
-    def path(self):
-        # type: () -> str
+    def path(self) -> str:
         assert not self._deleted, f"Attempted to access deleted path: {self._path}"
         return self._path
 
-    def __repr__(self):
-        # type: () -> str
+    def __repr__(self) -> str:
         return f"<{self.__class__.__name__} {self.path!r}>"
 
-    def __enter__(self):
-        # type: (_T) -> _T
+    def __enter__(self: _T) -> _T:
         return self
 
-    def __exit__(self, exc, value, tb):
-        # type: (Any, Any, Any) -> None
+    def __exit__(self, exc: Any, value: Any, tb: Any) -> None:
         if self.delete is not None:
             delete = self.delete
         elif _tempdir_registry:
             delete = _tempdir_registry.get_delete(self.kind)
         else:
             delete = True
 
         if delete:
             self.cleanup()
 
-    def _create(self, kind):
-        # type: (str) -> str
+    def _create(self, kind: str) -> str:
         """Create a temporary directory and store its path in self.path"""
         # We realpath here because some systems have their default tmpdir
         # symlinked to another directory.  This tends to confuse build
         # scripts, so we canonicalize the path by traversing potential
         # symlinks here.
         path = os.path.realpath(tempfile.mkdtemp(prefix=f"pip-{kind}-"))
         logger.debug("Created temporary directory: %s", path)
         return path
 
-    def cleanup(self):
-        # type: () -> None
+    def cleanup(self) -> None:
         """Remove the temporary directory created and reset state"""
         self._deleted = True
         if not os.path.exists(self._path):
             return
         rmtree(self._path)
 
 
@@ -202,22 +191,20 @@
     # The characters that may be used to name the temp directory
     # We always prepend a ~ and then rotate through these until
     # a usable name is found.
     # pkg_resources raises a different error for .dist-info folder
     # with leading '-' and invalid metadata
     LEADING_CHARS = "-~.=%0123456789"
 
-    def __init__(self, original, delete=None):
-        # type: (str, Optional[bool]) -> None
+    def __init__(self, original: str, delete: Optional[bool] = None) -> None:
         self.original = original.rstrip("/\\")
         super().__init__(delete=delete)
 
     @classmethod
-    def _generate_names(cls, name):
-        # type: (str) -> Iterator[str]
+    def _generate_names(cls, name: str) -> Iterator[str]:
         """Generates a series of temporary names.
 
         The algorithm replaces the leading characters in the name
         with ones that are valid filesystem characters, but are not
         valid package names (for both Python and pip definitions of
         package).
         """
@@ -234,16 +221,15 @@
             for candidate in itertools.combinations_with_replacement(
                 cls.LEADING_CHARS, i
             ):
                 new_name = "~" + "".join(candidate) + name
                 if new_name != name:
                     yield new_name
 
-    def _create(self, kind):
-        # type: (str) -> str
+    def _create(self, kind: str) -> str:
         root, name = os.path.split(self.original)
         for candidate in self._generate_names(name):
             path = os.path.join(root, candidate)
             try:
                 os.mkdir(path)
             except OSError as ex:
                 # Continue if the name exists already
```

#### pip/_internal/utils/unpacking.py

```diff
@@ -36,82 +36,75 @@
     import lzma  # noqa
 
     SUPPORTED_EXTENSIONS += XZ_EXTENSIONS
 except ImportError:
     logger.debug("lzma module is not available")
 
 
-def current_umask():
-    # type: () -> int
+def current_umask() -> int:
     """Get the current umask which involves having to set it temporarily."""
     mask = os.umask(0)
     os.umask(mask)
     return mask
 
 
-def split_leading_dir(path):
-    # type: (str) -> List[str]
+def split_leading_dir(path: str) -> List[str]:
     path = path.lstrip("/").lstrip("\\")
     if "/" in path and (
         ("\\" in path and path.find("/") < path.find("\\")) or "\\" not in path
     ):
         return path.split("/", 1)
     elif "\\" in path:
         return path.split("\\", 1)
     else:
         return [path, ""]
 
 
-def has_leading_dir(paths):
-    # type: (Iterable[str]) -> bool
+def has_leading_dir(paths: Iterable[str]) -> bool:
     """Returns true if all the paths have the same leading path name
     (i.e., everything is in one subdirectory in an archive)"""
     common_prefix = None
     for path in paths:
         prefix, rest = split_leading_dir(path)
         if not prefix:
             return False
         elif common_prefix is None:
             common_prefix = prefix
         elif prefix != common_prefix:
             return False
     return True
 
 
-def is_within_directory(directory, target):
-    # type: (str, str) -> bool
+def is_within_directory(directory: str, target: str) -> bool:
     """
     Return true if the absolute path of target is within the directory
     """
     abs_directory = os.path.abspath(directory)
     abs_target = os.path.abspath(target)
 
     prefix = os.path.commonprefix([abs_directory, abs_target])
     return prefix == abs_directory
 
 
-def set_extracted_file_to_default_mode_plus_executable(path):
-    # type: (str) -> None
+def set_extracted_file_to_default_mode_plus_executable(path: str) -> None:
     """
     Make file present at path have execute for user/group/world
     (chmod +x) is no-op on windows per python docs
     """
     os.chmod(path, (0o777 & ~current_umask() | 0o111))
 
 
-def zip_item_is_executable(info):
-    # type: (ZipInfo) -> bool
+def zip_item_is_executable(info: ZipInfo) -> bool:
     mode = info.external_attr >> 16
     # if mode and regular file and any execute permissions for
     # user/group/world?
     return bool(mode and stat.S_ISREG(mode) and mode & 0o111)
 
 
-def unzip_file(filename, location, flatten=True):
-    # type: (str, str, bool) -> None
+def unzip_file(filename: str, location: str, flatten: bool = True) -> None:
     """
     Unzip the file (with path `filename`) to the destination `location`.  All
     files are written based on system defaults and umask (i.e. permissions are
     not preserved), except that regular file members with any execute
     permissions (user, group, or world) have "chmod +x" applied after being
     written. Note that for windows, any execute changes using os.chmod are
     no-ops per the python docs.
@@ -149,16 +142,15 @@
                     fp.close()
                     if zip_item_is_executable(info):
                         set_extracted_file_to_default_mode_plus_executable(fn)
     finally:
         zipfp.close()
 
 
-def untar_file(filename, location):
-    # type: (str, str) -> None
+def untar_file(filename: str, location: str) -> None:
     """
     Untar the file (with path `filename`) to the destination `location`.
     All files are written based on system defaults and umask (i.e. permissions
     are not preserved), except that regular file members with any execute
     permissions (user, group, or world) have "chmod +x" applied after being
     written.  Note that for windows, any execute changes using os.chmod are
     no-ops per the python docs.
@@ -232,19 +224,18 @@
                 if member.mode & 0o111:
                     set_extracted_file_to_default_mode_plus_executable(path)
     finally:
         tar.close()
 
 
 def unpack_file(
-    filename,  # type: str
-    location,  # type: str
-    content_type=None,  # type: Optional[str]
-):
-    # type: (...) -> None
+    filename: str,
+    location: str,
+    content_type: Optional[str] = None,
+) -> None:
     filename = os.path.realpath(filename)
     if (
         content_type == "application/zip"
         or filename.lower().endswith(ZIP_EXTENSIONS)
         or zipfile.is_zipfile(filename)
     ):
         unzip_file(filename, location, flatten=not filename.endswith(".whl"))
```

#### pip/_internal/utils/urls.py

```diff
@@ -3,34 +3,31 @@
 import urllib.parse
 import urllib.request
 from typing import Optional
 
 from .compat import WINDOWS
 
 
-def get_url_scheme(url):
-    # type: (str) -> Optional[str]
+def get_url_scheme(url: str) -> Optional[str]:
     if ":" not in url:
         return None
     return url.split(":", 1)[0].lower()
 
 
-def path_to_url(path):
-    # type: (str) -> str
+def path_to_url(path: str) -> str:
     """
     Convert a path to a file: URL.  The path will be made absolute and have
     quoted path parts.
     """
     path = os.path.normpath(os.path.abspath(path))
     url = urllib.parse.urljoin("file:", urllib.request.pathname2url(path))
     return url
 
 
-def url_to_path(url):
-    # type: (str) -> str
+def url_to_path(url: str) -> str:
     """
     Convert a file: URL to a path.
     """
     assert url.startswith(
         "file:"
     ), f"You can only turn file: urls into filenames (not {url!r})"
```

#### pip/_internal/utils/virtualenv.py

```diff
@@ -7,57 +7,52 @@
 
 logger = logging.getLogger(__name__)
 _INCLUDE_SYSTEM_SITE_PACKAGES_REGEX = re.compile(
     r"include-system-site-packages\s*=\s*(?P<value>true|false)"
 )
 
 
-def _running_under_venv():
-    # type: () -> bool
+def _running_under_venv() -> bool:
     """Checks if sys.base_prefix and sys.prefix match.
 
     This handles PEP 405 compliant virtual environments.
     """
     return sys.prefix != getattr(sys, "base_prefix", sys.prefix)
 
 
-def _running_under_regular_virtualenv():
-    # type: () -> bool
+def _running_under_regular_virtualenv() -> bool:
     """Checks if sys.real_prefix is set.
 
     This handles virtual environments created with pypa's virtualenv.
     """
     # pypa/virtualenv case
     return hasattr(sys, "real_prefix")
 
 
-def running_under_virtualenv():
-    # type: () -> bool
+def running_under_virtualenv() -> bool:
     """Return True if we're running inside a virtualenv, False otherwise."""
     return _running_under_venv() or _running_under_regular_virtualenv()
 
 
-def _get_pyvenv_cfg_lines():
-    # type: () -> Optional[List[str]]
+def _get_pyvenv_cfg_lines() -> Optional[List[str]]:
     """Reads {sys.prefix}/pyvenv.cfg and returns its contents as list of lines
 
     Returns None, if it could not read/access the file.
     """
     pyvenv_cfg_file = os.path.join(sys.prefix, "pyvenv.cfg")
     try:
         # Although PEP 405 does not specify, the built-in venv module always
         # writes with UTF-8. (pypa/pip#8717)
         with open(pyvenv_cfg_file, encoding="utf-8") as f:
             return f.read().splitlines()  # avoids trailing newlines
     except OSError:
         return None
 
 
-def _no_global_under_venv():
-    # type: () -> bool
+def _no_global_under_venv() -> bool:
     """Check `{sys.prefix}/pyvenv.cfg` for system site-packages inclusion
 
     PEP 405 specifies that when system site-packages are not supposed to be
     visible from a virtual environment, `pyvenv.cfg` must contain the following
     line:
 
         include-system-site-packages = false
@@ -78,31 +73,29 @@
     for line in cfg_lines:
         match = _INCLUDE_SYSTEM_SITE_PACKAGES_REGEX.match(line)
         if match is not None and match.group("value") == "false":
             return True
     return False
 
 
-def _no_global_under_regular_virtualenv():
-    # type: () -> bool
+def _no_global_under_regular_virtualenv() -> bool:
     """Check if "no-global-site-packages.txt" exists beside site.py
 
     This mirrors logic in pypa/virtualenv for determining whether system
     site-packages are visible in the virtual environment.
     """
     site_mod_dir = os.path.dirname(os.path.abspath(site.__file__))
     no_global_site_packages_file = os.path.join(
         site_mod_dir,
         "no-global-site-packages.txt",
     )
     return os.path.exists(no_global_site_packages_file)
 
 
-def virtualenv_no_global():
-    # type: () -> bool
+def virtualenv_no_global() -> bool:
     """Returns a boolean, whether running in venv with no system site-packages."""
     # PEP 405 compliance needs to be checked first since virtualenv >=20 would
     # return True for both checks, but is only able to use the PEP 405 config.
     if _running_under_venv():
         return _no_global_under_venv()
 
     if _running_under_regular_virtualenv():
```

#### pip/_internal/utils/wheel.py

```diff
@@ -20,56 +20,54 @@
 
 
 class WheelMetadata(DictMetadata):
     """Metadata provider that maps metadata decoding exceptions to our
     internal exception type.
     """
 
-    def __init__(self, metadata, wheel_name):
-        # type: (Dict[str, bytes], str) -> None
+    def __init__(self, metadata: Dict[str, bytes], wheel_name: str) -> None:
         super().__init__(metadata)
         self._wheel_name = wheel_name
 
-    def get_metadata(self, name):
-        # type: (str) -> str
+    def get_metadata(self, name: str) -> str:
         try:
             return super().get_metadata(name)
         except UnicodeDecodeError as e:
             # Augment the default error with the origin of the file.
             raise UnsupportedWheel(
                 f"Error decoding metadata for {self._wheel_name}: {e}"
             )
 
 
-def pkg_resources_distribution_for_wheel(wheel_zip, name, location):
-    # type: (ZipFile, str, str) -> Distribution
+def pkg_resources_distribution_for_wheel(
+    wheel_zip: ZipFile, name: str, location: str
+) -> Distribution:
     """Get a pkg_resources distribution given a wheel.
 
     :raises UnsupportedWheel: on any errors
     """
     info_dir, _ = parse_wheel(wheel_zip, name)
 
     metadata_files = [p for p in wheel_zip.namelist() if p.startswith(f"{info_dir}/")]
 
-    metadata_text = {}  # type: Dict[str, bytes]
+    metadata_text: Dict[str, bytes] = {}
     for path in metadata_files:
         _, metadata_name = path.split("/", 1)
 
         try:
             metadata_text[metadata_name] = read_wheel_metadata_file(wheel_zip, path)
         except UnsupportedWheel as e:
             raise UnsupportedWheel("{} has an invalid wheel, {}".format(name, str(e)))
 
     metadata = WheelMetadata(metadata_text, location)
 
     return DistInfoDistribution(location=location, metadata=metadata, project_name=name)
 
 
-def parse_wheel(wheel_zip, name):
-    # type: (ZipFile, str) -> Tuple[str, Message]
+def parse_wheel(wheel_zip: ZipFile, name: str) -> Tuple[str, Message]:
     """Extract information from the provided wheel, ensuring it meets basic
     standards.
 
     Returns the name of the .dist-info directory and the parsed WHEEL metadata.
     """
     try:
         info_dir = wheel_dist_info_dir(wheel_zip, name)
@@ -79,16 +77,15 @@
         raise UnsupportedWheel("{} has an invalid wheel, {}".format(name, str(e)))
 
     check_compatibility(version, name)
 
     return info_dir, metadata
 
 
-def wheel_dist_info_dir(source, name):
-    # type: (ZipFile, str) -> str
+def wheel_dist_info_dir(source: ZipFile, name: str) -> str:
     """Returns the name of the contained .dist-info directory.
 
     Raises AssertionError or UnsupportedWheel if not found, >1 found, or
     it doesn't match the provided name.
     """
     # Zip file path separators must be /
     subdirs = {p.split("/", 1)[0] for p in source.namelist()}
@@ -113,26 +110,24 @@
                 info_dir, canonical_name
             )
         )
 
     return info_dir
 
 
-def read_wheel_metadata_file(source, path):
-    # type: (ZipFile, str) -> bytes
+def read_wheel_metadata_file(source: ZipFile, path: str) -> bytes:
     try:
         return source.read(path)
         # BadZipFile for general corruption, KeyError for missing entry,
         # and RuntimeError for password-protected files
     except (BadZipFile, KeyError, RuntimeError) as e:
         raise UnsupportedWheel(f"could not read {path!r} file: {e!r}")
 
 
-def wheel_metadata(source, dist_info_dir):
-    # type: (ZipFile, str) -> Message
+def wheel_metadata(source: ZipFile, dist_info_dir: str) -> Message:
     """Return the WHEEL metadata of an extracted wheel, if possible.
     Otherwise, raise UnsupportedWheel.
     """
     path = f"{dist_info_dir}/WHEEL"
     # Zip file path separators must be /
     wheel_contents = read_wheel_metadata_file(source, path)
 
@@ -143,16 +138,15 @@
 
     # FeedParser (used by Parser) does not raise any exceptions. The returned
     # message may have .defects populated, but for backwards-compatibility we
     # currently ignore them.
     return Parser().parsestr(wheel_text)
 
 
-def wheel_version(wheel_data):
-    # type: (Message) -> Tuple[int, ...]
+def wheel_version(wheel_data: Message) -> Tuple[int, ...]:
     """Given WHEEL metadata, return the parsed Wheel-Version.
     Otherwise, raise UnsupportedWheel.
     """
     version_text = wheel_data["Wheel-Version"]
     if version_text is None:
         raise UnsupportedWheel("WHEEL is missing Wheel-Version")
 
@@ -160,16 +154,15 @@
 
     try:
         return tuple(map(int, version.split(".")))
     except ValueError:
         raise UnsupportedWheel(f"invalid Wheel-Version: {version!r}")
 
 
-def check_compatibility(version, name):
-    # type: (Tuple[int, ...], str) -> None
+def check_compatibility(version: Tuple[int, ...], name: str) -> None:
     """Raises errors or warns if called with an incompatible Wheel-Version.
 
     pip should refuse to install a Wheel-Version that's a major series
     ahead of what it's compatible with (e.g 2.0 > 1.1); and warn when
     installing a version only minor version ahead (e.g 1.2 > 1.1).
 
     version: a 2-tuple representing a Wheel-Version (Major, Minor)
```

#### pip/_internal/vcs/bazaar.py

```diff
@@ -12,85 +12,82 @@
     vcs,
 )
 
 logger = logging.getLogger(__name__)
 
 
 class Bazaar(VersionControl):
-    name = 'bzr'
-    dirname = '.bzr'
-    repo_name = 'branch'
+    name = "bzr"
+    dirname = ".bzr"
+    repo_name = "branch"
     schemes = (
-        'bzr+http', 'bzr+https', 'bzr+ssh', 'bzr+sftp', 'bzr+ftp',
-        'bzr+lp', 'bzr+file'
+        "bzr+http",
+        "bzr+https",
+        "bzr+ssh",
+        "bzr+sftp",
+        "bzr+ftp",
+        "bzr+lp",
+        "bzr+file",
     )
 
     @staticmethod
-    def get_base_rev_args(rev):
-        # type: (str) -> List[str]
-        return ['-r', rev]
+    def get_base_rev_args(rev: str) -> List[str]:
+        return ["-r", rev]
 
-    def fetch_new(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def fetch_new(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         rev_display = rev_options.to_display()
         logger.info(
-            'Checking out %s%s to %s',
+            "Checking out %s%s to %s",
             url,
             rev_display,
             display_path(dest),
         )
-        cmd_args = (
-            make_command('branch', '-q', rev_options.to_args(), url, dest)
-        )
+        cmd_args = make_command("branch", "-q", rev_options.to_args(), url, dest)
         self.run_command(cmd_args)
 
-    def switch(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
-        self.run_command(make_command('switch', url), cwd=dest)
-
-    def update(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
-        cmd_args = make_command('pull', '-q', rev_options.to_args())
+    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
+        self.run_command(make_command("switch", url), cwd=dest)
+
+    def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
+        cmd_args = make_command("pull", "-q", rev_options.to_args())
         self.run_command(cmd_args, cwd=dest)
 
     @classmethod
-    def get_url_rev_and_auth(cls, url):
-        # type: (str) -> Tuple[str, Optional[str], AuthInfo]
+    def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:
         # hotfix the URL scheme after removing bzr+ from bzr+ssh:// readd it
         url, rev, user_pass = super().get_url_rev_and_auth(url)
-        if url.startswith('ssh://'):
-            url = 'bzr+' + url
+        if url.startswith("ssh://"):
+            url = "bzr+" + url
         return url, rev, user_pass
 
     @classmethod
-    def get_remote_url(cls, location):
-        # type: (str) -> str
+    def get_remote_url(cls, location: str) -> str:
         urls = cls.run_command(
-            ['info'], show_stdout=False, stdout_only=True, cwd=location
+            ["info"], show_stdout=False, stdout_only=True, cwd=location
         )
         for line in urls.splitlines():
             line = line.strip()
-            for x in ('checkout of branch: ',
-                      'parent branch: '):
+            for x in ("checkout of branch: ", "parent branch: "):
                 if line.startswith(x):
                     repo = line.split(x)[1]
                     if cls._is_local_repository(repo):
                         return path_to_url(repo)
                     return repo
         raise RemoteNotFoundError
 
     @classmethod
-    def get_revision(cls, location):
-        # type: (str) -> str
+    def get_revision(cls, location: str) -> str:
         revision = cls.run_command(
-            ['revno'], show_stdout=False, stdout_only=True, cwd=location,
+            ["revno"],
+            show_stdout=False,
+            stdout_only=True,
+            cwd=location,
         )
         return revision.splitlines()[-1]
 
     @classmethod
-    def is_commit_id_equal(cls, dest, name):
-        # type: (str, Optional[str]) -> bool
+    def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
         """Always assume the versions don't match"""
         return False
 
 
 vcs.register(Bazaar)
```

#### pip/_internal/vcs/git.py

```diff
@@ -30,153 +30,151 @@
     r"^git version "  # Prefix.
     r"(\d+)"  # Major.
     r"\.(\d+)"  # Dot, minor.
     r"(?:\.(\d+))?"  # Optional dot, patch.
     r".*$"  # Suffix, including any pre- and post-release segments we don't care about.
 )
 
-HASH_REGEX = re.compile('^[a-fA-F0-9]{40}$')
+HASH_REGEX = re.compile("^[a-fA-F0-9]{40}$")
 
 # SCP (Secure copy protocol) shorthand. e.g. 'git@example.com:foo/bar.git'
-SCP_REGEX = re.compile(r"""^
+SCP_REGEX = re.compile(
+    r"""^
     # Optional user, e.g. 'git@'
     (\w+@)?
     # Server, e.g. 'github.com'.
     ([^/:]+):
     # The server-side path. e.g. 'user/project.git'. Must start with an
     # alphanumeric character so as not to be confusable with a Windows paths
     # like 'C:/foo/bar' or 'C:\foo\bar'.
     (\w[^:]*)
-$""", re.VERBOSE)
+    $""",
+    re.VERBOSE,
+)
 
 
-def looks_like_hash(sha):
-    # type: (str) -> bool
+def looks_like_hash(sha: str) -> bool:
     return bool(HASH_REGEX.match(sha))
 
 
 class Git(VersionControl):
-    name = 'git'
-    dirname = '.git'
-    repo_name = 'clone'
+    name = "git"
+    dirname = ".git"
+    repo_name = "clone"
     schemes = (
-        'git+http', 'git+https', 'git+ssh', 'git+git', 'git+file',
+        "git+http",
+        "git+https",
+        "git+ssh",
+        "git+git",
+        "git+file",
     )
     # Prevent the user's environment variables from interfering with pip:
     # https://github.com/pypa/pip/issues/1130
-    unset_environ = ('GIT_DIR', 'GIT_WORK_TREE')
-    default_arg_rev = 'HEAD'
+    unset_environ = ("GIT_DIR", "GIT_WORK_TREE")
+    default_arg_rev = "HEAD"
 
     @staticmethod
-    def get_base_rev_args(rev):
-        # type: (str) -> List[str]
+    def get_base_rev_args(rev: str) -> List[str]:
         return [rev]
 
-    def is_immutable_rev_checkout(self, url, dest):
-        # type: (str, str) -> bool
+    def is_immutable_rev_checkout(self, url: str, dest: str) -> bool:
         _, rev_options = self.get_url_rev_options(hide_url(url))
         if not rev_options.rev:
             return False
         if not self.is_commit_id_equal(dest, rev_options.rev):
             # the current commit is different from rev,
             # which means rev was something else than a commit hash
             return False
         # return False in the rare case rev is both a commit hash
         # and a tag or a branch; we don't want to cache in that case
         # because that branch/tag could point to something else in the future
-        is_tag_or_branch = bool(
-            self.get_revision_sha(dest, rev_options.rev)[0]
-        )
+        is_tag_or_branch = bool(self.get_revision_sha(dest, rev_options.rev)[0])
         return not is_tag_or_branch
 
     def get_git_version(self) -> Tuple[int, ...]:
-        version = self.run_command(
-            ['version'], show_stdout=False, stdout_only=True
-        )
+        version = self.run_command(["version"], show_stdout=False, stdout_only=True)
         match = GIT_VERSION_REGEX.match(version)
         if not match:
+            logger.warning("Can't parse git version: %s", version)
             return ()
         return tuple(int(c) for c in match.groups())
 
     @classmethod
-    def get_current_branch(cls, location):
-        # type: (str) -> Optional[str]
+    def get_current_branch(cls, location: str) -> Optional[str]:
         """
         Return the current branch, or None if HEAD isn't at a branch
         (e.g. detached HEAD).
         """
         # git-symbolic-ref exits with empty stdout if "HEAD" is a detached
         # HEAD rather than a symbolic ref.  In addition, the -q causes the
         # command to exit with status code 1 instead of 128 in this case
         # and to suppress the message to stderr.
-        args = ['symbolic-ref', '-q', 'HEAD']
+        args = ["symbolic-ref", "-q", "HEAD"]
         output = cls.run_command(
             args,
-            extra_ok_returncodes=(1, ),
+            extra_ok_returncodes=(1,),
             show_stdout=False,
             stdout_only=True,
             cwd=location,
         )
         ref = output.strip()
 
-        if ref.startswith('refs/heads/'):
-            return ref[len('refs/heads/'):]
+        if ref.startswith("refs/heads/"):
+            return ref[len("refs/heads/") :]
 
         return None
 
     @classmethod
-    def get_revision_sha(cls, dest, rev):
-        # type: (str, str) -> Tuple[Optional[str], bool]
+    def get_revision_sha(cls, dest: str, rev: str) -> Tuple[Optional[str], bool]:
         """
         Return (sha_or_none, is_branch), where sha_or_none is a commit hash
         if the revision names a remote branch or tag, otherwise None.
 
         Args:
           dest: the repository directory.
           rev: the revision name.
         """
         # Pass rev to pre-filter the list.
         output = cls.run_command(
-            ['show-ref', rev],
+            ["show-ref", rev],
             cwd=dest,
             show_stdout=False,
             stdout_only=True,
-            on_returncode='ignore',
+            on_returncode="ignore",
         )
         refs = {}
         # NOTE: We do not use splitlines here since that would split on other
         #       unicode separators, which can be maliciously used to install a
         #       different revision.
         for line in output.strip().split("\n"):
             line = line.rstrip("\r")
             if not line:
                 continue
             try:
                 ref_sha, ref_name = line.split(" ", maxsplit=2)
             except ValueError:
                 # Include the offending line to simplify troubleshooting if
                 # this error ever occurs.
-                raise ValueError(f'unexpected show-ref line: {line!r}')
+                raise ValueError(f"unexpected show-ref line: {line!r}")
 
             refs[ref_name] = ref_sha
 
-        branch_ref = f'refs/remotes/origin/{rev}'
-        tag_ref = f'refs/tags/{rev}'
+        branch_ref = f"refs/remotes/origin/{rev}"
+        tag_ref = f"refs/tags/{rev}"
 
         sha = refs.get(branch_ref)
         if sha is not None:
             return (sha, True)
 
         sha = refs.get(tag_ref)
 
         return (sha, False)
 
     @classmethod
-    def _should_fetch(cls, dest, rev):
-        # type: (str, str) -> bool
+    def _should_fetch(cls, dest: str, rev: str) -> bool:
         """
         Return true if rev is a ref or is a commit that we don't have locally.
 
         Branches and tags are not considered in this method because they are
         assumed to be always available locally (which is a normal outcome of
         ``git clone`` and ``git fetch --tags``).
         """
@@ -191,16 +189,17 @@
         if cls.has_commit(dest, rev):
             # Don't fetch if we have the commit locally.
             return False
 
         return True
 
     @classmethod
-    def resolve_revision(cls, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> RevOptions
+    def resolve_revision(
+        cls, dest: str, url: HiddenText, rev_options: RevOptions
+    ) -> RevOptions:
         """
         Resolve a revision to a new RevOptions object with the SHA1 of the
         branch, tag, or ref if found.
 
         Args:
           rev_options: a RevOptions object.
         """
@@ -226,134 +225,149 @@
             )
 
         if not cls._should_fetch(dest, rev):
             return rev_options
 
         # fetch the requested revision
         cls.run_command(
-            make_command('fetch', '-q', url, rev_options.to_args()),
+            make_command("fetch", "-q", url, rev_options.to_args()),
             cwd=dest,
         )
         # Change the revision to the SHA of the ref we fetched
-        sha = cls.get_revision(dest, rev='FETCH_HEAD')
+        sha = cls.get_revision(dest, rev="FETCH_HEAD")
         rev_options = rev_options.make_new(sha)
 
         return rev_options
 
     @classmethod
-    def is_commit_id_equal(cls, dest, name):
-        # type: (str, Optional[str]) -> bool
+    def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
         """
         Return whether the current commit hash equals the given name.
 
         Args:
           dest: the repository directory.
           name: a string name.
         """
         if not name:
             # Then avoid an unnecessary subprocess call.
             return False
 
         return cls.get_revision(dest) == name
 
-    def fetch_new(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def fetch_new(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         rev_display = rev_options.to_display()
-        logger.info('Cloning %s%s to %s', url, rev_display, display_path(dest))
-        self.run_command(make_command('clone', '-q', url, dest))
+        logger.info("Cloning %s%s to %s", url, rev_display, display_path(dest))
+        if self.get_git_version() >= (2, 17):
+            # Git added support for partial clone in 2.17
+            # https://git-scm.com/docs/partial-clone
+            # Speeds up cloning by functioning without a complete copy of repository
+            self.run_command(
+                make_command(
+                    "clone",
+                    "--filter=blob:none",
+                    "-q",
+                    url,
+                    dest,
+                )
+            )
+        else:
+            self.run_command(make_command("clone", "-q", url, dest))
 
         if rev_options.rev:
             # Then a specific revision was requested.
             rev_options = self.resolve_revision(dest, url, rev_options)
-            branch_name = getattr(rev_options, 'branch_name', None)
+            branch_name = getattr(rev_options, "branch_name", None)
+            logger.debug("Rev options %s, branch_name %s", rev_options, branch_name)
             if branch_name is None:
                 # Only do a checkout if the current commit id doesn't match
                 # the requested revision.
                 if not self.is_commit_id_equal(dest, rev_options.rev):
                     cmd_args = make_command(
-                        'checkout', '-q', rev_options.to_args(),
+                        "checkout",
+                        "-q",
+                        rev_options.to_args(),
                     )
                     self.run_command(cmd_args, cwd=dest)
             elif self.get_current_branch(dest) != branch_name:
                 # Then a specific branch was requested, and that branch
                 # is not yet checked out.
-                track_branch = f'origin/{branch_name}'
+                track_branch = f"origin/{branch_name}"
                 cmd_args = [
-                    'checkout', '-b', branch_name, '--track', track_branch,
+                    "checkout",
+                    "-b",
+                    branch_name,
+                    "--track",
+                    track_branch,
                 ]
                 self.run_command(cmd_args, cwd=dest)
         else:
             sha = self.get_revision(dest)
             rev_options = rev_options.make_new(sha)
 
         logger.info("Resolved %s to commit %s", url, rev_options.rev)
 
         #: repo may contain submodules
         self.update_submodules(dest)
 
-    def switch(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         self.run_command(
-            make_command('config', 'remote.origin.url', url),
+            make_command("config", "remote.origin.url", url),
             cwd=dest,
         )
-        cmd_args = make_command('checkout', '-q', rev_options.to_args())
+        cmd_args = make_command("checkout", "-q", rev_options.to_args())
         self.run_command(cmd_args, cwd=dest)
 
         self.update_submodules(dest)
 
-    def update(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         # First fetch changes from the default remote
         if self.get_git_version() >= (1, 9):
             # fetch tags in addition to everything else
-            self.run_command(['fetch', '-q', '--tags'], cwd=dest)
+            self.run_command(["fetch", "-q", "--tags"], cwd=dest)
         else:
-            self.run_command(['fetch', '-q'], cwd=dest)
+            self.run_command(["fetch", "-q"], cwd=dest)
         # Then reset to wanted revision (maybe even origin/master)
         rev_options = self.resolve_revision(dest, url, rev_options)
-        cmd_args = make_command('reset', '--hard', '-q', rev_options.to_args())
+        cmd_args = make_command("reset", "--hard", "-q", rev_options.to_args())
         self.run_command(cmd_args, cwd=dest)
         #: update submodules
         self.update_submodules(dest)
 
     @classmethod
-    def get_remote_url(cls, location):
-        # type: (str) -> str
+    def get_remote_url(cls, location: str) -> str:
         """
         Return URL of the first remote encountered.
 
         Raises RemoteNotFoundError if the repository does not have a remote
         url configured.
         """
         # We need to pass 1 for extra_ok_returncodes since the command
         # exits with return code 1 if there are no matching lines.
         stdout = cls.run_command(
-            ['config', '--get-regexp', r'remote\..*\.url'],
-            extra_ok_returncodes=(1, ),
+            ["config", "--get-regexp", r"remote\..*\.url"],
+            extra_ok_returncodes=(1,),
             show_stdout=False,
             stdout_only=True,
             cwd=location,
         )
         remotes = stdout.splitlines()
         try:
             found_remote = remotes[0]
         except IndexError:
             raise RemoteNotFoundError
 
         for remote in remotes:
-            if remote.startswith('remote.origin.url '):
+            if remote.startswith("remote.origin.url "):
                 found_remote = remote
                 break
-        url = found_remote.split(' ')[1]
+        url = found_remote.split(" ")[1]
         return cls._git_remote_to_pip_url(url.strip())
 
     @staticmethod
-    def _git_remote_to_pip_url(url):
-        # type: (str) -> str
+    def _git_remote_to_pip_url(url: str) -> str:
         """
         Convert a remote url from what git uses to what pip accepts.
 
         There are 3 legal forms **url** may take:
 
             1. A fully qualified url: ssh://git@example.com/foo/bar.git
             2. A local project.git folder: /path/to/bare/repository.git
@@ -376,131 +390,124 @@
         if scp_match:
             # Add an ssh:// prefix and replace the ':' with a '/'.
             return scp_match.expand(r"ssh://\1\2/\3")
         # Otherwise, bail out.
         raise RemoteNotValidError(url)
 
     @classmethod
-    def has_commit(cls, location, rev):
-        # type: (str, str) -> bool
+    def has_commit(cls, location: str, rev: str) -> bool:
         """
         Check if rev is a commit that is available in the local repository.
         """
         try:
             cls.run_command(
-                ['rev-parse', '-q', '--verify', "sha^" + rev],
+                ["rev-parse", "-q", "--verify", "sha^" + rev],
                 cwd=location,
                 log_failed_cmd=False,
             )
         except InstallationError:
             return False
         else:
             return True
 
     @classmethod
-    def get_revision(cls, location, rev=None):
-        # type: (str, Optional[str]) -> str
+    def get_revision(cls, location: str, rev: Optional[str] = None) -> str:
         if rev is None:
-            rev = 'HEAD'
+            rev = "HEAD"
         current_rev = cls.run_command(
-            ['rev-parse', rev],
+            ["rev-parse", rev],
             show_stdout=False,
             stdout_only=True,
             cwd=location,
         )
         return current_rev.strip()
 
     @classmethod
-    def get_subdirectory(cls, location):
-        # type: (str) -> Optional[str]
+    def get_subdirectory(cls, location: str) -> Optional[str]:
         """
         Return the path to Python project root, relative to the repo root.
         Return None if the project root is in the repo root.
         """
         # find the repo root
         git_dir = cls.run_command(
-            ['rev-parse', '--git-dir'],
+            ["rev-parse", "--git-dir"],
             show_stdout=False,
             stdout_only=True,
             cwd=location,
         ).strip()
         if not os.path.isabs(git_dir):
             git_dir = os.path.join(location, git_dir)
-        repo_root = os.path.abspath(os.path.join(git_dir, '..'))
+        repo_root = os.path.abspath(os.path.join(git_dir, ".."))
         return find_path_to_project_root_from_repo_root(location, repo_root)
 
     @classmethod
-    def get_url_rev_and_auth(cls, url):
-        # type: (str) -> Tuple[str, Optional[str], AuthInfo]
+    def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:
         """
         Prefixes stub URLs like 'user@hostname:user/repo.git' with 'ssh://'.
         That's required because although they use SSH they sometimes don't
         work with a ssh:// scheme (e.g. GitHub). But we need a scheme for
         parsing. Hence we remove it again afterwards and return it as a stub.
         """
         # Works around an apparent Git bug
         # (see https://article.gmane.org/gmane.comp.version-control.git/146500)
         scheme, netloc, path, query, fragment = urlsplit(url)
-        if scheme.endswith('file'):
-            initial_slashes = path[:-len(path.lstrip('/'))]
-            newpath = (
-                initial_slashes +
-                urllib.request.url2pathname(path)
-                .replace('\\', '/').lstrip('/')
-            )
-            after_plus = scheme.find('+') + 1
+        if scheme.endswith("file"):
+            initial_slashes = path[: -len(path.lstrip("/"))]
+            newpath = initial_slashes + urllib.request.url2pathname(path).replace(
+                "\\", "/"
+            ).lstrip("/")
+            after_plus = scheme.find("+") + 1
             url = scheme[:after_plus] + urlunsplit(
                 (scheme[after_plus:], netloc, newpath, query, fragment),
             )
 
-        if '://' not in url:
-            assert 'file:' not in url
-            url = url.replace('git+', 'git+ssh://')
+        if "://" not in url:
+            assert "file:" not in url
+            url = url.replace("git+", "git+ssh://")
             url, rev, user_pass = super().get_url_rev_and_auth(url)
-            url = url.replace('ssh://', '')
+            url = url.replace("ssh://", "")
         else:
             url, rev, user_pass = super().get_url_rev_and_auth(url)
 
         return url, rev, user_pass
 
     @classmethod
-    def update_submodules(cls, location):
-        # type: (str) -> None
-        if not os.path.exists(os.path.join(location, '.gitmodules')):
+    def update_submodules(cls, location: str) -> None:
+        if not os.path.exists(os.path.join(location, ".gitmodules")):
             return
         cls.run_command(
-            ['submodule', 'update', '--init', '--recursive', '-q'],
+            ["submodule", "update", "--init", "--recursive", "-q"],
             cwd=location,
         )
 
     @classmethod
-    def get_repository_root(cls, location):
-        # type: (str) -> Optional[str]
+    def get_repository_root(cls, location: str) -> Optional[str]:
         loc = super().get_repository_root(location)
         if loc:
             return loc
         try:
             r = cls.run_command(
-                ['rev-parse', '--show-toplevel'],
+                ["rev-parse", "--show-toplevel"],
                 cwd=location,
                 show_stdout=False,
                 stdout_only=True,
-                on_returncode='raise',
+                on_returncode="raise",
                 log_failed_cmd=False,
             )
         except BadCommand:
-            logger.debug("could not determine if %s is under git control "
-                         "because git is not available", location)
+            logger.debug(
+                "could not determine if %s is under git control "
+                "because git is not available",
+                location,
+            )
             return None
         except InstallationError:
             return None
-        return os.path.normpath(r.rstrip('\r\n'))
+        return os.path.normpath(r.rstrip("\r\n"))
 
     @staticmethod
-    def should_add_vcs_url_prefix(repo_url):
-        # type: (str) -> bool
-        """In either https or ssh form, requirements must be prefixed with git+.
-        """
+    def should_add_vcs_url_prefix(repo_url: str) -> bool:
+        """In either https or ssh form, requirements must be prefixed with git+."""
         return True
 
 
 vcs.register(Git)
```

#### pip/_internal/vcs/mercurial.py

```diff
@@ -14,145 +14,140 @@
     vcs,
 )
 
 logger = logging.getLogger(__name__)
 
 
 class Mercurial(VersionControl):
-    name = 'hg'
-    dirname = '.hg'
-    repo_name = 'clone'
+    name = "hg"
+    dirname = ".hg"
+    repo_name = "clone"
     schemes = (
-        'hg+file', 'hg+http', 'hg+https', 'hg+ssh', 'hg+static-http',
+        "hg+file",
+        "hg+http",
+        "hg+https",
+        "hg+ssh",
+        "hg+static-http",
     )
 
     @staticmethod
-    def get_base_rev_args(rev):
-        # type: (str) -> List[str]
+    def get_base_rev_args(rev: str) -> List[str]:
         return [rev]
 
-    def fetch_new(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def fetch_new(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         rev_display = rev_options.to_display()
         logger.info(
-            'Cloning hg %s%s to %s',
+            "Cloning hg %s%s to %s",
             url,
             rev_display,
             display_path(dest),
         )
-        self.run_command(make_command('clone', '--noupdate', '-q', url, dest))
+        self.run_command(make_command("clone", "--noupdate", "-q", url, dest))
         self.run_command(
-            make_command('update', '-q', rev_options.to_args()),
+            make_command("update", "-q", rev_options.to_args()),
             cwd=dest,
         )
 
-    def switch(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
-        repo_config = os.path.join(dest, self.dirname, 'hgrc')
+    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
+        repo_config = os.path.join(dest, self.dirname, "hgrc")
         config = configparser.RawConfigParser()
         try:
             config.read(repo_config)
-            config.set('paths', 'default', url.secret)
-            with open(repo_config, 'w') as config_file:
+            config.set("paths", "default", url.secret)
+            with open(repo_config, "w") as config_file:
                 config.write(config_file)
         except (OSError, configparser.NoSectionError) as exc:
-            logger.warning(
-                'Could not switch Mercurial repository to %s: %s', url, exc,
-            )
+            logger.warning("Could not switch Mercurial repository to %s: %s", url, exc)
         else:
-            cmd_args = make_command('update', '-q', rev_options.to_args())
+            cmd_args = make_command("update", "-q", rev_options.to_args())
             self.run_command(cmd_args, cwd=dest)
 
-    def update(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
-        self.run_command(['pull', '-q'], cwd=dest)
-        cmd_args = make_command('update', '-q', rev_options.to_args())
+    def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
+        self.run_command(["pull", "-q"], cwd=dest)
+        cmd_args = make_command("update", "-q", rev_options.to_args())
         self.run_command(cmd_args, cwd=dest)
 
     @classmethod
-    def get_remote_url(cls, location):
-        # type: (str) -> str
+    def get_remote_url(cls, location: str) -> str:
         url = cls.run_command(
-            ['showconfig', 'paths.default'],
+            ["showconfig", "paths.default"],
             show_stdout=False,
             stdout_only=True,
             cwd=location,
         ).strip()
         if cls._is_local_repository(url):
             url = path_to_url(url)
         return url.strip()
 
     @classmethod
-    def get_revision(cls, location):
-        # type: (str) -> str
+    def get_revision(cls, location: str) -> str:
         """
         Return the repository-local changeset revision number, as an integer.
         """
         current_revision = cls.run_command(
-            ['parents', '--template={rev}'],
+            ["parents", "--template={rev}"],
             show_stdout=False,
             stdout_only=True,
             cwd=location,
         ).strip()
         return current_revision
 
     @classmethod
-    def get_requirement_revision(cls, location):
-        # type: (str) -> str
+    def get_requirement_revision(cls, location: str) -> str:
         """
         Return the changeset identification hash, as a 40-character
         hexadecimal string
         """
         current_rev_hash = cls.run_command(
-            ['parents', '--template={node}'],
+            ["parents", "--template={node}"],
             show_stdout=False,
             stdout_only=True,
             cwd=location,
         ).strip()
         return current_rev_hash
 
     @classmethod
-    def is_commit_id_equal(cls, dest, name):
-        # type: (str, Optional[str]) -> bool
+    def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
         """Always assume the versions don't match"""
         return False
 
     @classmethod
-    def get_subdirectory(cls, location):
-        # type: (str) -> Optional[str]
+    def get_subdirectory(cls, location: str) -> Optional[str]:
         """
         Return the path to Python project root, relative to the repo root.
         Return None if the project root is in the repo root.
         """
         # find the repo root
         repo_root = cls.run_command(
-            ['root'], show_stdout=False, stdout_only=True, cwd=location
+            ["root"], show_stdout=False, stdout_only=True, cwd=location
         ).strip()
         if not os.path.isabs(repo_root):
             repo_root = os.path.abspath(os.path.join(location, repo_root))
         return find_path_to_project_root_from_repo_root(location, repo_root)
 
     @classmethod
-    def get_repository_root(cls, location):
-        # type: (str) -> Optional[str]
+    def get_repository_root(cls, location: str) -> Optional[str]:
         loc = super().get_repository_root(location)
         if loc:
             return loc
         try:
             r = cls.run_command(
-                ['root'],
+                ["root"],
                 cwd=location,
                 show_stdout=False,
                 stdout_only=True,
-                on_returncode='raise',
+                on_returncode="raise",
                 log_failed_cmd=False,
             )
         except BadCommand:
-            logger.debug("could not determine if %s is under hg control "
-                         "because hg is not available", location)
+            logger.debug(
+                "could not determine if %s is under hg control "
+                "because hg is not available",
+                location,
+            )
             return None
         except InstallationError:
             return None
-        return os.path.normpath(r.rstrip('\r\n'))
+        return os.path.normpath(r.rstrip("\r\n"))
 
 
 vcs.register(Mercurial)
```

#### pip/_internal/vcs/subversion.py

```diff
@@ -20,102 +20,97 @@
 )
 
 logger = logging.getLogger(__name__)
 
 _svn_xml_url_re = re.compile('url="([^"]+)"')
 _svn_rev_re = re.compile(r'committed-rev="(\d+)"')
 _svn_info_xml_rev_re = re.compile(r'\s*revision="(\d+)"')
-_svn_info_xml_url_re = re.compile(r'<url>(.*)</url>')
+_svn_info_xml_url_re = re.compile(r"<url>(.*)</url>")
 
 
 class Subversion(VersionControl):
-    name = 'svn'
-    dirname = '.svn'
-    repo_name = 'checkout'
-    schemes = (
-        'svn+ssh', 'svn+http', 'svn+https', 'svn+svn', 'svn+file'
-    )
+    name = "svn"
+    dirname = ".svn"
+    repo_name = "checkout"
+    schemes = ("svn+ssh", "svn+http", "svn+https", "svn+svn", "svn+file")
 
     @classmethod
-    def should_add_vcs_url_prefix(cls, remote_url):
-        # type: (str) -> bool
+    def should_add_vcs_url_prefix(cls, remote_url: str) -> bool:
         return True
 
     @staticmethod
-    def get_base_rev_args(rev):
-        # type: (str) -> List[str]
-        return ['-r', rev]
+    def get_base_rev_args(rev: str) -> List[str]:
+        return ["-r", rev]
 
     @classmethod
-    def get_revision(cls, location):
-        # type: (str) -> str
+    def get_revision(cls, location: str) -> str:
         """
         Return the maximum revision for all files under a given location
         """
         # Note: taken from setuptools.command.egg_info
         revision = 0
 
         for base, dirs, _ in os.walk(location):
             if cls.dirname not in dirs:
                 dirs[:] = []
-                continue    # no sense walking uncontrolled subdirs
+                continue  # no sense walking uncontrolled subdirs
             dirs.remove(cls.dirname)
-            entries_fn = os.path.join(base, cls.dirname, 'entries')
+            entries_fn = os.path.join(base, cls.dirname, "entries")
             if not os.path.exists(entries_fn):
                 # FIXME: should we warn?
                 continue
 
             dirurl, localrev = cls._get_svn_url_rev(base)
 
             if base == location:
                 assert dirurl is not None
-                base = dirurl + '/'   # save the root url
+                base = dirurl + "/"  # save the root url
             elif not dirurl or not dirurl.startswith(base):
                 dirs[:] = []
-                continue    # not part of the same svn tree, skip it
+                continue  # not part of the same svn tree, skip it
             revision = max(revision, localrev)
         return str(revision)
 
     @classmethod
-    def get_netloc_and_auth(cls, netloc, scheme):
-        # type: (str, str) -> Tuple[str, Tuple[Optional[str], Optional[str]]]
+    def get_netloc_and_auth(
+        cls, netloc: str, scheme: str
+    ) -> Tuple[str, Tuple[Optional[str], Optional[str]]]:
         """
         This override allows the auth information to be passed to svn via the
         --username and --password options instead of via the URL.
         """
-        if scheme == 'ssh':
+        if scheme == "ssh":
             # The --username and --password options can't be used for
             # svn+ssh URLs, so keep the auth information in the URL.
             return super().get_netloc_and_auth(netloc, scheme)
 
         return split_auth_from_netloc(netloc)
 
     @classmethod
-    def get_url_rev_and_auth(cls, url):
-        # type: (str) -> Tuple[str, Optional[str], AuthInfo]
+    def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:
         # hotfix the URL scheme after removing svn+ from svn+ssh:// readd it
         url, rev, user_pass = super().get_url_rev_and_auth(url)
-        if url.startswith('ssh://'):
-            url = 'svn+' + url
+        if url.startswith("ssh://"):
+            url = "svn+" + url
         return url, rev, user_pass
 
     @staticmethod
-    def make_rev_args(username, password):
-        # type: (Optional[str], Optional[HiddenText]) -> CommandArgs
-        extra_args = []  # type: CommandArgs
+    def make_rev_args(
+        username: Optional[str], password: Optional[HiddenText]
+    ) -> CommandArgs:
+        extra_args: CommandArgs = []
         if username:
-            extra_args += ['--username', username]
+            extra_args += ["--username", username]
         if password:
-            extra_args += ['--password', password]
+            extra_args += ["--password", password]
 
         return extra_args
 
     @classmethod
-    def get_remote_url(cls, location):
-        # type: (str) -> str
+    def get_remote_url(cls, location: str) -> str:
         # In cases where the source is in a subdirectory, we have to look up in
         # the location until we find a valid project root.
         orig_location = location
         while not is_installable_dir(location):
             last_location = location
             location = os.path.dirname(location)
             if location == last_location:
@@ -131,122 +126,111 @@
         url, _rev = cls._get_svn_url_rev(location)
         if url is None:
             raise RemoteNotFoundError
 
         return url
 
     @classmethod
-    def _get_svn_url_rev(cls, location):
-        # type: (str) -> Tuple[Optional[str], int]
+    def _get_svn_url_rev(cls, location: str) -> Tuple[Optional[str], int]:
         from pip._internal.exceptions import InstallationError
 
-        entries_path = os.path.join(location, cls.dirname, 'entries')
+        entries_path = os.path.join(location, cls.dirname, "entries")
         if os.path.exists(entries_path):
             with open(entries_path) as f:
                 data = f.read()
         else:  # subversion >= 1.7 does not have the 'entries' file
-            data = ''
+            data = ""
 
         url = None
-        if (data.startswith('8') or
-                data.startswith('9') or
-                data.startswith('10')):
-            entries = list(map(str.splitlines, data.split('\n\x0c\n')))
+        if data.startswith("8") or data.startswith("9") or data.startswith("10"):
+            entries = list(map(str.splitlines, data.split("\n\x0c\n")))
             del entries[0][0]  # get rid of the '8'
             url = entries[0][3]
             revs = [int(d[9]) for d in entries if len(d) > 9 and d[9]] + [0]
-        elif data.startswith('<?xml'):
+        elif data.startswith("<?xml"):
             match = _svn_xml_url_re.search(data)
             if not match:
-                raise ValueError(f'Badly formatted data: {data!r}')
-            url = match.group(1)    # get repository URL
+                raise ValueError(f"Badly formatted data: {data!r}")
+            url = match.group(1)  # get repository URL
             revs = [int(m.group(1)) for m in _svn_rev_re.finditer(data)] + [0]
         else:
             try:
                 # subversion >= 1.7
                 # Note that using get_remote_call_options is not necessary here
                 # because `svn info` is being run against a local directory.
                 # We don't need to worry about making sure interactive mode
                 # is being used to prompt for passwords, because passwords
                 # are only potentially needed for remote server requests.
                 xml = cls.run_command(
-                    ['info', '--xml', location],
+                    ["info", "--xml", location],
                     show_stdout=False,
                     stdout_only=True,
                 )
                 match = _svn_info_xml_url_re.search(xml)
                 assert match is not None
                 url = match.group(1)
-                revs = [
-                    int(m.group(1)) for m in _svn_info_xml_rev_re.finditer(xml)
-                ]
+                revs = [int(m.group(1)) for m in _svn_info_xml_rev_re.finditer(xml)]
             except InstallationError:
                 url, revs = None, []
 
         if revs:
             rev = max(revs)
         else:
             rev = 0
 
         return url, rev
 
     @classmethod
-    def is_commit_id_equal(cls, dest, name):
-        # type: (str, Optional[str]) -> bool
+    def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
         """Always assume the versions don't match"""
         return False
 
-    def __init__(self, use_interactive=None):
-        # type: (bool) -> None
+    def __init__(self, use_interactive: bool = None) -> None:
         if use_interactive is None:
             use_interactive = is_console_interactive()
         self.use_interactive = use_interactive
 
         # This member is used to cache the fetched version of the current
         # ``svn`` client.
         # Special value definitions:
         #   None: Not evaluated yet.
         #   Empty tuple: Could not parse version.
-        self._vcs_version = None  # type: Optional[Tuple[int, ...]]
+        self._vcs_version: Optional[Tuple[int, ...]] = None
 
         super().__init__()
 
-    def call_vcs_version(self):
-        # type: () -> Tuple[int, ...]
+    def call_vcs_version(self) -> Tuple[int, ...]:
         """Query the version of the currently installed Subversion client.
 
         :return: A tuple containing the parts of the version information or
             ``()`` if the version returned from ``svn`` could not be parsed.
         :raises: BadCommand: If ``svn`` is not installed.
         """
         # Example versions:
         #   svn, version 1.10.3 (r1842928)
         #      compiled Feb 25 2019, 14:20:39 on x86_64-apple-darwin17.0.0
         #   svn, version 1.7.14 (r1542130)
         #      compiled Mar 28 2018, 08:49:13 on x86_64-pc-linux-gnu
         #   svn, version 1.12.0-SlikSvn (SlikSvn/1.12.0)
         #      compiled May 28 2019, 13:44:56 on x86_64-microsoft-windows6.2
-        version_prefix = 'svn, version '
-        version = self.run_command(
-            ['--version'], show_stdout=False, stdout_only=True
-        )
+        version_prefix = "svn, version "
+        version = self.run_command(["--version"], show_stdout=False, stdout_only=True)
         if not version.startswith(version_prefix):
             return ()
 
-        version = version[len(version_prefix):].split()[0]
-        version_list = version.partition('-')[0].split('.')
+        version = version[len(version_prefix) :].split()[0]
+        version_list = version.partition("-")[0].split(".")
         try:
             parsed_version = tuple(map(int, version_list))
         except ValueError:
             return ()
 
         return parsed_version
 
-    def get_vcs_version(self):
-        # type: () -> Tuple[int, ...]
+    def get_vcs_version(self) -> Tuple[int, ...]:
         """Return the version of the currently installed Subversion client.
 
         If the version of the Subversion client has already been queried,
         a cached value will be used.
 
         :return: A tuple containing the parts of the version information or
             ``()`` if the version returned from ``svn`` could not be parsed.
@@ -258,72 +242,77 @@
             # do not attempt to parse it again.
             return self._vcs_version
 
         vcs_version = self.call_vcs_version()
         self._vcs_version = vcs_version
         return vcs_version
 
-    def get_remote_call_options(self):
-        # type: () -> CommandArgs
+    def get_remote_call_options(self) -> CommandArgs:
         """Return options to be used on calls to Subversion that contact the server.
 
         These options are applicable for the following ``svn`` subcommands used
         in this class.
 
             - checkout
             - switch
             - update
 
         :return: A list of command line arguments to pass to ``svn``.
         """
         if not self.use_interactive:
             # --non-interactive switch is available since Subversion 0.14.4.
             # Subversion < 1.8 runs in interactive mode by default.
-            return ['--non-interactive']
+            return ["--non-interactive"]
 
         svn_version = self.get_vcs_version()
         # By default, Subversion >= 1.8 runs in non-interactive mode if
         # stdin is not a TTY. Since that is how pip invokes SVN, in
         # call_subprocess(), pip must pass --force-interactive to ensure
         # the user can be prompted for a password, if required.
         #   SVN added the --force-interactive option in SVN 1.8. Since
         # e.g. RHEL/CentOS 7, which is supported until 2024, ships with
         # SVN 1.7, pip should continue to support SVN 1.7. Therefore, pip
         # can't safely add the option if the SVN version is < 1.8 (or unknown).
         if svn_version >= (1, 8):
-            return ['--force-interactive']
+            return ["--force-interactive"]
 
         return []
 
-    def fetch_new(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def fetch_new(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         rev_display = rev_options.to_display()
         logger.info(
-            'Checking out %s%s to %s',
+            "Checking out %s%s to %s",
             url,
             rev_display,
             display_path(dest),
         )
         cmd_args = make_command(
-            'checkout', '-q', self.get_remote_call_options(),
-            rev_options.to_args(), url, dest,
+            "checkout",
+            "-q",
+            self.get_remote_call_options(),
+            rev_options.to_args(),
+            url,
+            dest,
         )
         self.run_command(cmd_args)
 
-    def switch(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         cmd_args = make_command(
-            'switch', self.get_remote_call_options(), rev_options.to_args(),
-            url, dest,
+            "switch",
+            self.get_remote_call_options(),
+            rev_options.to_args(),
+            url,
+            dest,
         )
         self.run_command(cmd_args)
 
-    def update(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         cmd_args = make_command(
-            'update', self.get_remote_call_options(), rev_options.to_args(),
+            "update",
+            self.get_remote_call_options(),
+            rev_options.to_args(),
             dest,
         )
         self.run_command(cmd_args)
 
 
 vcs.register(Subversion)
```

#### pip/_internal/vcs/versioncontrol.py

```diff
@@ -2,14 +2,15 @@
 
 import logging
 import os
 import shutil
 import sys
 import urllib.parse
 from typing import (
+    TYPE_CHECKING,
     Any,
     Dict,
     Iterable,
     Iterator,
     List,
     Mapping,
     Optional,
@@ -29,52 +30,60 @@
     hide_value,
     is_installable_dir,
     rmtree,
 )
 from pip._internal.utils.subprocess import CommandArgs, call_subprocess, make_command
 from pip._internal.utils.urls import get_url_scheme
 
-__all__ = ['vcs']
+if TYPE_CHECKING:
+    # Literal was introduced in Python 3.8.
+    #
+    # TODO: Remove `if TYPE_CHECKING` when dropping support for Python 3.7.
+    from typing import Literal
+
+
+__all__ = ["vcs"]
 
 
 logger = logging.getLogger(__name__)
 
 AuthInfo = Tuple[Optional[str], Optional[str]]
 
 
-def is_url(name):
-    # type: (str) -> bool
+def is_url(name: str) -> bool:
     """
     Return true if the name looks like a URL.
     """
     scheme = get_url_scheme(name)
     if scheme is None:
         return False
-    return scheme in ['http', 'https', 'file', 'ftp'] + vcs.all_schemes
+    return scheme in ["http", "https", "file", "ftp"] + vcs.all_schemes
 
 
-def make_vcs_requirement_url(repo_url, rev, project_name, subdir=None):
-    # type: (str, str, str, Optional[str]) -> str
+def make_vcs_requirement_url(
+    repo_url: str, rev: str, project_name: str, subdir: Optional[str] = None
+) -> str:
     """
     Return the URL for a VCS requirement.
 
     Args:
       repo_url: the remote VCS url, with any needed VCS prefix (e.g. "git+").
       project_name: the (unescaped) project name.
     """
     egg_project_name = project_name.replace("-", "_")
-    req = f'{repo_url}@{rev}#egg={egg_project_name}'
+    req = f"{repo_url}@{rev}#egg={egg_project_name}"
     if subdir:
-        req += f'&subdirectory={subdir}'
+        req += f"&subdirectory={subdir}"
 
     return req
 
 
-def find_path_to_project_root_from_repo_root(location, repo_root):
-    # type: (str, str) -> Optional[str]
+def find_path_to_project_root_from_repo_root(
+    location: str, repo_root: str
+) -> Optional[str]:
     """
     Find the the Python project's root by searching up the filesystem from
     `location`. Return the path to project root relative to `repo_root`.
     Return None if the project root is `repo_root`, or cannot be found.
     """
     # find project root.
     orig_location = location
@@ -114,282 +123,259 @@
     install options.
 
     Instances of this class should be treated as if immutable.
     """
 
     def __init__(
         self,
-        vc_class,  # type: Type[VersionControl]
-        rev=None,  # type: Optional[str]
-        extra_args=None,  # type: Optional[CommandArgs]
-    ):
-        # type: (...) -> None
+        vc_class: Type["VersionControl"],
+        rev: Optional[str] = None,
+        extra_args: Optional[CommandArgs] = None,
+    ) -> None:
         """
         Args:
           vc_class: a VersionControl subclass.
           rev: the name of the revision to install.
           extra_args: a list of extra options.
         """
         if extra_args is None:
             extra_args = []
 
         self.extra_args = extra_args
         self.rev = rev
         self.vc_class = vc_class
-        self.branch_name = None  # type: Optional[str]
+        self.branch_name: Optional[str] = None
 
-    def __repr__(self):
-        # type: () -> str
-        return f'<RevOptions {self.vc_class.name}: rev={self.rev!r}>'
+    def __repr__(self) -> str:
+        return f"<RevOptions {self.vc_class.name}: rev={self.rev!r}>"
 
     @property
-    def arg_rev(self):
-        # type: () -> Optional[str]
+    def arg_rev(self) -> Optional[str]:
         if self.rev is None:
             return self.vc_class.default_arg_rev
 
         return self.rev
 
-    def to_args(self):
-        # type: () -> CommandArgs
+    def to_args(self) -> CommandArgs:
         """
         Return the VCS-specific command arguments.
         """
-        args = []  # type: CommandArgs
+        args: CommandArgs = []
         rev = self.arg_rev
         if rev is not None:
             args += self.vc_class.get_base_rev_args(rev)
         args += self.extra_args
 
         return args
 
-    def to_display(self):
-        # type: () -> str
+    def to_display(self) -> str:
         if not self.rev:
-            return ''
+            return ""
 
-        return f' (to revision {self.rev})'
+        return f" (to revision {self.rev})"
 
-    def make_new(self, rev):
-        # type: (str) -> RevOptions
+    def make_new(self, rev: str) -> "RevOptions":
         """
         Make a copy of the current instance, but with a new rev.
 
         Args:
           rev: the name of the revision for the new object.
         """
         return self.vc_class.make_rev_options(rev, extra_args=self.extra_args)
 
 
 class VcsSupport:
-    _registry = {}  # type: Dict[str, VersionControl]
-    schemes = ['ssh', 'git', 'hg', 'bzr', 'sftp', 'svn']
+    _registry: Dict[str, "VersionControl"] = {}
+    schemes = ["ssh", "git", "hg", "bzr", "sftp", "svn"]
 
-    def __init__(self):
-        # type: () -> None
+    def __init__(self) -> None:
         # Register more schemes with urlparse for various version control
         # systems
         urllib.parse.uses_netloc.extend(self.schemes)
         super().__init__()
 
-    def __iter__(self):
-        # type: () -> Iterator[str]
+    def __iter__(self) -> Iterator[str]:
         return self._registry.__iter__()
 
     @property
-    def backends(self):
-        # type: () -> List[VersionControl]
+    def backends(self) -> List["VersionControl"]:
         return list(self._registry.values())
 
     @property
-    def dirnames(self):
-        # type: () -> List[str]
+    def dirnames(self) -> List[str]:
         return [backend.dirname for backend in self.backends]
 
     @property
-    def all_schemes(self):
-        # type: () -> List[str]
-        schemes = []  # type: List[str]
+    def all_schemes(self) -> List[str]:
+        schemes: List[str] = []
         for backend in self.backends:
             schemes.extend(backend.schemes)
         return schemes
 
-    def register(self, cls):
-        # type: (Type[VersionControl]) -> None
-        if not hasattr(cls, 'name'):
-            logger.warning('Cannot register VCS %s', cls.__name__)
+    def register(self, cls: Type["VersionControl"]) -> None:
+        if not hasattr(cls, "name"):
+            logger.warning("Cannot register VCS %s", cls.__name__)
             return
         if cls.name not in self._registry:
             self._registry[cls.name] = cls()
-            logger.debug('Registered VCS backend: %s', cls.name)
+            logger.debug("Registered VCS backend: %s", cls.name)
 
-    def unregister(self, name):
-        # type: (str) -> None
+    def unregister(self, name: str) -> None:
         if name in self._registry:
             del self._registry[name]
 
-    def get_backend_for_dir(self, location):
-        # type: (str) -> Optional[VersionControl]
+    def get_backend_for_dir(self, location: str) -> Optional["VersionControl"]:
         """
         Return a VersionControl object if a repository of that type is found
         at the given directory.
         """
         vcs_backends = {}
         for vcs_backend in self._registry.values():
             repo_path = vcs_backend.get_repository_root(location)
             if not repo_path:
                 continue
-            logger.debug('Determine that %s uses VCS: %s',
-                         location, vcs_backend.name)
+            logger.debug("Determine that %s uses VCS: %s", location, vcs_backend.name)
             vcs_backends[repo_path] = vcs_backend
 
         if not vcs_backends:
             return None
 
         # Choose the VCS in the inner-most directory. Since all repository
         # roots found here would be either `location` or one of its
         # parents, the longest path should have the most path components,
         # i.e. the backend representing the inner-most repository.
         inner_most_repo_path = max(vcs_backends, key=len)
         return vcs_backends[inner_most_repo_path]
 
-    def get_backend_for_scheme(self, scheme):
-        # type: (str) -> Optional[VersionControl]
+    def get_backend_for_scheme(self, scheme: str) -> Optional["VersionControl"]:
         """
         Return a VersionControl object or None.
         """
         for vcs_backend in self._registry.values():
             if scheme in vcs_backend.schemes:
                 return vcs_backend
         return None
 
-    def get_backend(self, name):
-        # type: (str) -> Optional[VersionControl]
+    def get_backend(self, name: str) -> Optional["VersionControl"]:
         """
         Return a VersionControl object or None.
         """
         name = name.lower()
         return self._registry.get(name)
 
 
 vcs = VcsSupport()
 
 
 class VersionControl:
-    name = ''
-    dirname = ''
-    repo_name = ''
+    name = ""
+    dirname = ""
+    repo_name = ""
     # List of supported schemes for this Version Control
-    schemes = ()  # type: Tuple[str, ...]
+    schemes: Tuple[str, ...] = ()
     # Iterable of environment variable names to pass to call_subprocess().
-    unset_environ = ()  # type: Tuple[str, ...]
-    default_arg_rev = None  # type: Optional[str]
+    unset_environ: Tuple[str, ...] = ()
+    default_arg_rev: Optional[str] = None
 
     @classmethod
-    def should_add_vcs_url_prefix(cls, remote_url):
-        # type: (str) -> bool
+    def should_add_vcs_url_prefix(cls, remote_url: str) -> bool:
         """
         Return whether the vcs prefix (e.g. "git+") should be added to a
         repository's remote url when used in a requirement.
         """
-        return not remote_url.lower().startswith(f'{cls.name}:')
+        return not remote_url.lower().startswith(f"{cls.name}:")
 
     @classmethod
-    def get_subdirectory(cls, location):
-        # type: (str) -> Optional[str]
+    def get_subdirectory(cls, location: str) -> Optional[str]:
         """
         Return the path to Python project root, relative to the repo root.
         Return None if the project root is in the repo root.
         """
         return None
 
     @classmethod
-    def get_requirement_revision(cls, repo_dir):
-        # type: (str) -> str
+    def get_requirement_revision(cls, repo_dir: str) -> str:
         """
         Return the revision string that should be used in a requirement.
         """
         return cls.get_revision(repo_dir)
 
     @classmethod
-    def get_src_requirement(cls, repo_dir, project_name):
-        # type: (str, str) -> str
+    def get_src_requirement(cls, repo_dir: str, project_name: str) -> str:
         """
         Return the requirement string to use to redownload the files
         currently at the given repository directory.
 
         Args:
           project_name: the (unescaped) project name.
 
         The return value has a form similar to the following:
 
             {repository_url}@{revision}#egg={project_name}
         """
         repo_url = cls.get_remote_url(repo_dir)
 
         if cls.should_add_vcs_url_prefix(repo_url):
-            repo_url = f'{cls.name}+{repo_url}'
+            repo_url = f"{cls.name}+{repo_url}"
 
         revision = cls.get_requirement_revision(repo_dir)
         subdir = cls.get_subdirectory(repo_dir)
-        req = make_vcs_requirement_url(repo_url, revision, project_name,
-                                       subdir=subdir)
+        req = make_vcs_requirement_url(repo_url, revision, project_name, subdir=subdir)
 
         return req
 
     @staticmethod
-    def get_base_rev_args(rev):
-        # type: (str) -> List[str]
+    def get_base_rev_args(rev: str) -> List[str]:
         """
         Return the base revision arguments for a vcs command.
 
         Args:
           rev: the name of a revision to install.  Cannot be None.
         """
         raise NotImplementedError
 
-    def is_immutable_rev_checkout(self, url, dest):
-        # type: (str, str) -> bool
+    def is_immutable_rev_checkout(self, url: str, dest: str) -> bool:
         """
         Return true if the commit hash checked out at dest matches
         the revision in url.
 
         Always return False, if the VCS does not support immutable commit
         hashes.
 
         This method does not check if there are local uncommitted changes
         in dest after checkout, as pip currently has no use case for that.
         """
         return False
 
     @classmethod
-    def make_rev_options(cls, rev=None, extra_args=None):
-        # type: (Optional[str], Optional[CommandArgs]) -> RevOptions
+    def make_rev_options(
+        cls, rev: Optional[str] = None, extra_args: Optional[CommandArgs] = None
+    ) -> RevOptions:
         """
         Return a RevOptions object.
 
         Args:
           rev: the name of a revision to install.
           extra_args: a list of extra options.
         """
         return RevOptions(cls, rev, extra_args=extra_args)
 
     @classmethod
-    def _is_local_repository(cls, repo):
-        # type: (str) -> bool
+    def _is_local_repository(cls, repo: str) -> bool:
         """
-           posix absolute paths start with os.path.sep,
-           win32 ones start with drive (like c:\\folder)
+        posix absolute paths start with os.path.sep,
+        win32 ones start with drive (like c:\\folder)
         """
         drive, tail = os.path.splitdrive(repo)
         return repo.startswith(os.path.sep) or bool(drive)
 
     @classmethod
-    def get_netloc_and_auth(cls, netloc, scheme):
-        # type: (str, str) -> Tuple[str, Tuple[Optional[str], Optional[str]]]
+    def get_netloc_and_auth(
+        cls, netloc: str, scheme: str
+    ) -> Tuple[str, Tuple[Optional[str], Optional[str]]]:
         """
         Parse the repository URL's netloc, and return the new netloc to use
         along with auth information.
 
         Args:
           netloc: the original repository URL netloc.
           scheme: the repository URL's scheme without the vcs prefix.
@@ -400,131 +386,123 @@
         such an option, auth information must stay in the URL.
 
         Returns: (netloc, (username, password)).
         """
         return netloc, (None, None)
 
     @classmethod
-    def get_url_rev_and_auth(cls, url):
-        # type: (str) -> Tuple[str, Optional[str], AuthInfo]
+    def get_url_rev_and_auth(cls, url: str) -> Tuple[str, Optional[str], AuthInfo]:
         """
         Parse the repository URL to use, and return the URL, revision,
         and auth info to use.
 
         Returns: (url, rev, (username, password)).
         """
         scheme, netloc, path, query, frag = urllib.parse.urlsplit(url)
-        if '+' not in scheme:
+        if "+" not in scheme:
             raise ValueError(
                 "Sorry, {!r} is a malformed VCS url. "
                 "The format is <vcs>+<protocol>://<url>, "
                 "e.g. svn+http://myrepo/svn/MyApp#egg=MyApp".format(url)
             )
         # Remove the vcs prefix.
-        scheme = scheme.split('+', 1)[1]
+        scheme = scheme.split("+", 1)[1]
         netloc, user_pass = cls.get_netloc_and_auth(netloc, scheme)
         rev = None
-        if '@' in path:
-            path, rev = path.rsplit('@', 1)
+        if "@" in path:
+            path, rev = path.rsplit("@", 1)
             if not rev:
                 raise InstallationError(
                     "The URL {!r} has an empty revision (after @) "
                     "which is not supported. Include a revision after @ "
                     "or remove @ from the URL.".format(url)
                 )
-        url = urllib.parse.urlunsplit((scheme, netloc, path, query, ''))
+        url = urllib.parse.urlunsplit((scheme, netloc, path, query, ""))
         return url, rev, user_pass
 
     @staticmethod
-    def make_rev_args(username, password):
-        # type: (Optional[str], Optional[HiddenText]) -> CommandArgs
+    def make_rev_args(
+        username: Optional[str], password: Optional[HiddenText]
+    ) -> CommandArgs:
         """
         Return the RevOptions "extra arguments" to use in obtain().
         """
         return []
 
-    def get_url_rev_options(self, url):
-        # type: (HiddenText) -> Tuple[HiddenText, RevOptions]
+    def get_url_rev_options(self, url: HiddenText) -> Tuple[HiddenText, RevOptions]:
         """
         Return the URL and RevOptions object to use in obtain(),
         as a tuple (url, rev_options).
         """
         secret_url, rev, user_pass = self.get_url_rev_and_auth(url.secret)
         username, secret_password = user_pass
-        password = None  # type: Optional[HiddenText]
+        password: Optional[HiddenText] = None
         if secret_password is not None:
             password = hide_value(secret_password)
         extra_args = self.make_rev_args(username, password)
         rev_options = self.make_rev_options(rev, extra_args=extra_args)
 
         return hide_url(secret_url), rev_options
 
     @staticmethod
-    def normalize_url(url):
-        # type: (str) -> str
+    def normalize_url(url: str) -> str:
         """
         Normalize a URL for comparison by unquoting it and removing any
         trailing slash.
         """
-        return urllib.parse.unquote(url).rstrip('/')
+        return urllib.parse.unquote(url).rstrip("/")
 
     @classmethod
-    def compare_urls(cls, url1, url2):
-        # type: (str, str) -> bool
+    def compare_urls(cls, url1: str, url2: str) -> bool:
         """
         Compare two repo URLs for identity, ignoring incidental differences.
         """
-        return (cls.normalize_url(url1) == cls.normalize_url(url2))
+        return cls.normalize_url(url1) == cls.normalize_url(url2)
 
-    def fetch_new(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def fetch_new(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         """
         Fetch a revision from a repository, in the case that this is the
         first fetch from the repository.
 
         Args:
           dest: the directory to fetch the repository to.
           rev_options: a RevOptions object.
         """
         raise NotImplementedError
 
-    def switch(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def switch(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         """
         Switch the repo at ``dest`` to point to ``URL``.
 
         Args:
           rev_options: a RevOptions object.
         """
         raise NotImplementedError
 
-    def update(self, dest, url, rev_options):
-        # type: (str, HiddenText, RevOptions) -> None
+    def update(self, dest: str, url: HiddenText, rev_options: RevOptions) -> None:
         """
         Update an already-existing repo to the given ``rev_options``.
 
         Args:
           rev_options: a RevOptions object.
         """
         raise NotImplementedError
 
     @classmethod
-    def is_commit_id_equal(cls, dest, name):
-        # type: (str, Optional[str]) -> bool
+    def is_commit_id_equal(cls, dest: str, name: Optional[str]) -> bool:
         """
         Return whether the id of the current commit equals the given name.
 
         Args:
           dest: the repository directory.
           name: a string name.
         """
         raise NotImplementedError
 
-    def obtain(self, dest, url):
-        # type: (str, HiddenText) -> None
+    def obtain(self, dest: str, url: HiddenText) -> None:
         """
         Install or update in editable mode the package represented by this
         VersionControl object.
 
         :param dest: the repository directory in which to install or update.
         :param url: the repository URL starting with a vcs prefix.
         """
@@ -535,182 +513,175 @@
             return
 
         rev_display = rev_options.to_display()
         if self.is_repository_directory(dest):
             existing_url = self.get_remote_url(dest)
             if self.compare_urls(existing_url, url.secret):
                 logger.debug(
-                    '%s in %s exists, and has correct URL (%s)',
+                    "%s in %s exists, and has correct URL (%s)",
                     self.repo_name.title(),
                     display_path(dest),
                     url,
                 )
                 if not self.is_commit_id_equal(dest, rev_options.rev):
                     logger.info(
-                        'Updating %s %s%s',
+                        "Updating %s %s%s",
                         display_path(dest),
                         self.repo_name,
                         rev_display,
                     )
                     self.update(dest, url, rev_options)
                 else:
-                    logger.info('Skipping because already up-to-date.')
+                    logger.info("Skipping because already up-to-date.")
                 return
 
             logger.warning(
-                '%s %s in %s exists with URL %s',
+                "%s %s in %s exists with URL %s",
                 self.name,
                 self.repo_name,
                 display_path(dest),
                 existing_url,
             )
-            prompt = ('(s)witch, (i)gnore, (w)ipe, (b)ackup ',
-                      ('s', 'i', 'w', 'b'))
+            prompt = ("(s)witch, (i)gnore, (w)ipe, (b)ackup ", ("s", "i", "w", "b"))
         else:
             logger.warning(
-                'Directory %s already exists, and is not a %s %s.',
+                "Directory %s already exists, and is not a %s %s.",
                 dest,
                 self.name,
                 self.repo_name,
             )
             # https://github.com/python/mypy/issues/1174
-            prompt = ('(i)gnore, (w)ipe, (b)ackup ',  # type: ignore
-                      ('i', 'w', 'b'))
+            prompt = ("(i)gnore, (w)ipe, (b)ackup ", ("i", "w", "b"))  # type: ignore
 
         logger.warning(
-            'The plan is to install the %s repository %s',
+            "The plan is to install the %s repository %s",
             self.name,
             url,
         )
-        response = ask_path_exists('What to do?  {}'.format(
-            prompt[0]), prompt[1])
+        response = ask_path_exists("What to do?  {}".format(prompt[0]), prompt[1])
 
-        if response == 'a':
+        if response == "a":
             sys.exit(-1)
 
-        if response == 'w':
-            logger.warning('Deleting %s', display_path(dest))
+        if response == "w":
+            logger.warning("Deleting %s", display_path(dest))
             rmtree(dest)
             self.fetch_new(dest, url, rev_options)
             return
 
-        if response == 'b':
+        if response == "b":
             dest_dir = backup_dir(dest)
-            logger.warning(
-                'Backing up %s to %s', display_path(dest), dest_dir,
-            )
+            logger.warning("Backing up %s to %s", display_path(dest), dest_dir)
             shutil.move(dest, dest_dir)
             self.fetch_new(dest, url, rev_options)
             return
 
         # Do nothing if the response is "i".
-        if response == 's':
+        if response == "s":
             logger.info(
-                'Switching %s %s to %s%s',
+                "Switching %s %s to %s%s",
                 self.repo_name,
                 display_path(dest),
                 url,
                 rev_display,
             )
             self.switch(dest, url, rev_options)
 
-    def unpack(self, location, url):
-        # type: (str, HiddenText) -> None
+    def unpack(self, location: str, url: HiddenText) -> None:
         """
         Clean up current location and download the url repository
         (and vcs infos) into location
 
         :param url: the repository URL starting with a vcs prefix.
         """
         if os.path.exists(location):
             rmtree(location)
         self.obtain(location, url=url)
 
     @classmethod
-    def get_remote_url(cls, location):
-        # type: (str) -> str
+    def get_remote_url(cls, location: str) -> str:
         """
         Return the url used at location
 
         Raises RemoteNotFoundError if the repository does not have a remote
         url configured.
         """
         raise NotImplementedError
 
     @classmethod
-    def get_revision(cls, location):
-        # type: (str) -> str
+    def get_revision(cls, location: str) -> str:
         """
         Return the current commit id of the files at the given location.
         """
         raise NotImplementedError
 
     @classmethod
     def run_command(
         cls,
-        cmd,  # type: Union[List[str], CommandArgs]
-        show_stdout=True,  # type: bool
-        cwd=None,  # type: Optional[str]
-        on_returncode='raise',  # type: str
-        extra_ok_returncodes=None,  # type: Optional[Iterable[int]]
-        command_desc=None,  # type: Optional[str]
-        extra_environ=None,  # type: Optional[Mapping[str, Any]]
-        spinner=None,  # type: Optional[SpinnerInterface]
-        log_failed_cmd=True,  # type: bool
-        stdout_only=False,  # type: bool
-    ):
-        # type: (...) -> str
+        cmd: Union[List[str], CommandArgs],
+        show_stdout: bool = True,
+        cwd: Optional[str] = None,
+        on_returncode: 'Literal["raise", "warn", "ignore"]' = "raise",
+        extra_ok_returncodes: Optional[Iterable[int]] = None,
+        command_desc: Optional[str] = None,
+        extra_environ: Optional[Mapping[str, Any]] = None,
+        spinner: Optional[SpinnerInterface] = None,
+        log_failed_cmd: bool = True,
+        stdout_only: bool = False,
+    ) -> str:
         """
         Run a VCS subcommand
         This is simply a wrapper around call_subprocess that adds the VCS
         command name, and checks that the VCS is available
         """
         cmd = make_command(cls.name, *cmd)
         try:
-            return call_subprocess(cmd, show_stdout, cwd,
-                                   on_returncode=on_returncode,
-                                   extra_ok_returncodes=extra_ok_returncodes,
-                                   command_desc=command_desc,
-                                   extra_environ=extra_environ,
-                                   unset_environ=cls.unset_environ,
-                                   spinner=spinner,
-                                   log_failed_cmd=log_failed_cmd,
-                                   stdout_only=stdout_only)
+            return call_subprocess(
+                cmd,
+                show_stdout,
+                cwd,
+                on_returncode=on_returncode,
+                extra_ok_returncodes=extra_ok_returncodes,
+                command_desc=command_desc,
+                extra_environ=extra_environ,
+                unset_environ=cls.unset_environ,
+                spinner=spinner,
+                log_failed_cmd=log_failed_cmd,
+                stdout_only=stdout_only,
+            )
         except FileNotFoundError:
             # errno.ENOENT = no such file or directory
             # In other words, the VCS executable isn't available
             raise BadCommand(
-                f'Cannot find command {cls.name!r} - do you have '
-                f'{cls.name!r} installed and in your PATH?')
+                f"Cannot find command {cls.name!r} - do you have "
+                f"{cls.name!r} installed and in your PATH?"
+            )
         except PermissionError:
             # errno.EACCES = Permission denied
             # This error occurs, for instance, when the command is installed
             # only for another user. So, the current user don't have
             # permission to call the other user command.
             raise BadCommand(
                 f"No permission to execute {cls.name!r} - install it "
                 f"locally, globally (ask admin), or check your PATH. "
                 f"See possible solutions at "
                 f"https://pip.pypa.io/en/latest/reference/pip_freeze/"
                 f"#fixing-permission-denied."
             )
 
     @classmethod
-    def is_repository_directory(cls, path):
-        # type: (str) -> bool
+    def is_repository_directory(cls, path: str) -> bool:
         """
         Return whether a directory path is a repository directory.
         """
-        logger.debug('Checking in %s for %s (%s)...',
-                     path, cls.dirname, cls.name)
+        logger.debug("Checking in %s for %s (%s)...", path, cls.dirname, cls.name)
         return os.path.exists(os.path.join(path, cls.dirname))
 
     @classmethod
-    def get_repository_root(cls, location):
-        # type: (str) -> Optional[str]
+    def get_repository_root(cls, location: str) -> Optional[str]:
         """
         Return the "root" (top-level) directory controlled by the vcs,
         or `None` if the directory is not in any.
 
         It is meant to be overridden to implement smarter detection
         mechanisms for specific vcs.
```

#### pip/_vendor/__init__.py

```diff
@@ -54,15 +54,14 @@
 # all platforms.
 if DEBUNDLED:
     # Actually look inside of WHEEL_DIR to find .whl files and add them to the
     # front of our sys.path.
     sys.path[:] = glob.glob(os.path.join(WHEEL_DIR, "*.whl")) + sys.path
 
     # Actually alias all of our vendored dependencies.
-    vendored("appdirs")
     vendored("cachecontrol")
     vendored("certifi")
     vendored("colorama")
     vendored("distlib")
     vendored("distro")
     vendored("html5lib")
     vendored("six")
@@ -70,14 +69,15 @@
     vendored("six.moves.urllib")
     vendored("six.moves.urllib.parse")
     vendored("packaging")
     vendored("packaging.version")
     vendored("packaging.specifiers")
     vendored("pep517")
     vendored("pkg_resources")
+    vendored("platformdirs")
     vendored("progress")
     vendored("requests")
     vendored("requests.exceptions")
     vendored("requests.packages")
     vendored("requests.packages.urllib3")
     vendored("requests.packages.urllib3._collections")
     vendored("requests.packages.urllib3.connection")
```

#### pip/_vendor/distro.py

```diff
@@ -16,93 +16,137 @@
 The ``distro`` package (``distro`` stands for Linux Distribution) provides
 information about the Linux distribution it runs on, such as a reliable
 machine-readable distro ID, or version information.
 
 It is the recommended replacement for Python's original
 :py:func:`platform.linux_distribution` function, but it provides much more
 functionality. An alternative implementation became necessary because Python
-3.5 deprecated this function, and Python 3.8 will remove it altogether.
-Its predecessor function :py:func:`platform.dist` was already
-deprecated since Python 2.6 and will also be removed in Python 3.8.
-Still, there are many cases in which access to OS distribution information
-is needed. See `Python issue 1322 <https://bugs.python.org/issue1322>`_ for
-more information.
+3.5 deprecated this function, and Python 3.8 removed it altogether. Its
+predecessor function :py:func:`platform.dist` was already deprecated since
+Python 2.6 and removed in Python 3.8. Still, there are many cases in which
+access to OS distribution information is needed. See `Python issue 1322
+<https://bugs.python.org/issue1322>`_ for more information.
 """
 
+import argparse
+import json
+import logging
 import os
 import re
-import sys
-import json
 import shlex
-import logging
-import argparse
 import subprocess
+import sys
+import warnings
 
+__version__ = "1.6.0"
 
-_UNIXCONFDIR = os.environ.get('UNIXCONFDIR', '/etc')
-_OS_RELEASE_BASENAME = 'os-release'
+# Use `if False` to avoid an ImportError on Python 2. After dropping Python 2
+# support, can use typing.TYPE_CHECKING instead. See:
+# https://docs.python.org/3/library/typing.html#typing.TYPE_CHECKING
+if False:  # pragma: nocover
+    from typing import (
+        Any,
+        Callable,
+        Dict,
+        Iterable,
+        Optional,
+        Sequence,
+        TextIO,
+        Tuple,
+        Type,
+        TypedDict,
+        Union,
+    )
+
+    VersionDict = TypedDict(
+        "VersionDict", {"major": str, "minor": str, "build_number": str}
+    )
+    InfoDict = TypedDict(
+        "InfoDict",
+        {
+            "id": str,
+            "version": str,
+            "version_parts": VersionDict,
+            "like": str,
+            "codename": str,
+        },
+    )
+
+
+_UNIXCONFDIR = os.environ.get("UNIXCONFDIR", "/etc")
+_UNIXUSRLIBDIR = os.environ.get("UNIXUSRLIBDIR", "/usr/lib")
+_OS_RELEASE_BASENAME = "os-release"
 
 #: Translation table for normalizing the "ID" attribute defined in os-release
 #: files, for use by the :func:`distro.id` method.
 #:
 #: * Key: Value as defined in the os-release file, translated to lower case,
 #:   with blanks translated to underscores.
 #:
 #: * Value: Normalized value.
 NORMALIZED_OS_ID = {
-    'ol': 'oracle',  # Oracle Linux
+    "ol": "oracle",  # Oracle Linux
 }
 
 #: Translation table for normalizing the "Distributor ID" attribute returned by
 #: the lsb_release command, for use by the :func:`distro.id` method.
 #:
 #: * Key: Value as returned by the lsb_release command, translated to lower
 #:   case, with blanks translated to underscores.
 #:
 #: * Value: Normalized value.
 NORMALIZED_LSB_ID = {
-    'enterpriseenterpriseas': 'oracle',  # Oracle Enterprise Linux 4
-    'enterpriseenterpriseserver': 'oracle',  # Oracle Linux 5
-    'redhatenterpriseworkstation': 'rhel',  # RHEL 6, 7 Workstation
-    'redhatenterpriseserver': 'rhel',  # RHEL 6, 7 Server
-    'redhatenterprisecomputenode': 'rhel',  # RHEL 6 ComputeNode
+    "enterpriseenterpriseas": "oracle",  # Oracle Enterprise Linux 4
+    "enterpriseenterpriseserver": "oracle",  # Oracle Linux 5
+    "redhatenterpriseworkstation": "rhel",  # RHEL 6, 7 Workstation
+    "redhatenterpriseserver": "rhel",  # RHEL 6, 7 Server
+    "redhatenterprisecomputenode": "rhel",  # RHEL 6 ComputeNode
 }
 
 #: Translation table for normalizing the distro ID derived from the file name
 #: of distro release files, for use by the :func:`distro.id` method.
 #:
 #: * Key: Value as derived from the file name of a distro release file,
 #:   translated to lower case, with blanks translated to underscores.
 #:
 #: * Value: Normalized value.
 NORMALIZED_DISTRO_ID = {
-    'redhat': 'rhel',  # RHEL 6.x, 7.x
+    "redhat": "rhel",  # RHEL 6.x, 7.x
 }
 
 # Pattern for content of distro release file (reversed)
 _DISTRO_RELEASE_CONTENT_REVERSED_PATTERN = re.compile(
-    r'(?:[^)]*\)(.*)\()? *(?:STL )?([\d.+\-a-z]*\d) *(?:esaeler *)?(.+)')
+    r"(?:[^)]*\)(.*)\()? *(?:STL )?([\d.+\-a-z]*\d) *(?:esaeler *)?(.+)"
+)
 
 # Pattern for base file name of distro release file
-_DISTRO_RELEASE_BASENAME_PATTERN = re.compile(
-    r'(\w+)[-_](release|version)$')
+_DISTRO_RELEASE_BASENAME_PATTERN = re.compile(r"(\w+)[-_](release|version)$")
 
 # Base file names to be ignored when searching for distro release file
 _DISTRO_RELEASE_IGNORE_BASENAMES = (
-    'debian_version',
-    'lsb-release',
-    'oem-release',
+    "debian_version",
+    "lsb-release",
+    "oem-release",
     _OS_RELEASE_BASENAME,
-    'system-release',
-    'plesk-release',
+    "system-release",
+    "plesk-release",
+    "iredmail-release",
 )
 
 
 def linux_distribution(full_distribution_name=True):
+    # type: (bool) -> Tuple[str, str, str]
     """
+    .. deprecated:: 1.6.0
+
+        :func:`distro.linux_distribution()` is deprecated. It should only be
+        used as a compatibility shim with Python's
+        :py:func:`platform.linux_distribution()`. Please use :func:`distro.id`,
+        :func:`distro.version` and :func:`distro.name` instead.
+
     Return information about the current OS distribution as a tuple
     ``(id_name, version, codename)`` with items as follows:
 
     * ``id_name``:  If *full_distribution_name* is false, the result of
       :func:`distro.id`. Otherwise, the result of :func:`distro.name`.
 
     * ``version``:  The result of :func:`distro.version`.
@@ -118,18 +162,26 @@
     the OS distribution is not consistent across multiple data sources it
     provides (there are indeed such distributions ...).
 
     Another reason for differences is the fact that the :func:`distro.id`
     method normalizes the distro ID string to a reliable machine-readable value
     for a number of popular OS distributions.
     """
+    warnings.warn(
+        "distro.linux_distribution() is deprecated. It should only be used as a "
+        "compatibility shim with Python's platform.linux_distribution(). Please use "
+        "distro.id(), distro.version() and distro.name() instead.",
+        DeprecationWarning,
+        stacklevel=2,
+    )
     return _distro.linux_distribution(full_distribution_name)
 
 
 def id():
+    # type: () -> str
     """
     Return the distro ID of the current distribution, as a
     machine-readable string.
 
     For a number of OS distributions, the returned distro ID value is
     *reliable*, in the sense that it is documented and that it does not change
     across releases of the distribution.
@@ -201,14 +253,15 @@
       command, with ID values that differ from what was previously determined
       from the distro release file name.
     """
     return _distro.id()
 
 
 def name(pretty=False):
+    # type: (bool) -> str
     """
     Return the name of the current OS distribution, as a human-readable
     string.
 
     If *pretty* is false, the name is returned without version or codename.
     (e.g. "CentOS Linux")
 
@@ -240,14 +293,15 @@
         with the value of the pretty version ("<version_id>" and "<codename>"
         fields) of the distro release file, if available.
     """
     return _distro.name(pretty)
 
 
 def version(pretty=False, best=False):
+    # type: (bool, bool) -> str
     """
     Return the version of the current OS distribution, as a human-readable
     string.
 
     If *pretty* is false, the version is returned without codename (e.g.
     "7.0").
 
@@ -284,14 +338,15 @@
       the lsb_release command, if it follows the format of the distro release
       files.
     """
     return _distro.version(pretty, best)
 
 
 def version_parts(best=False):
+    # type: (bool) -> Tuple[str, str, str]
     """
     Return the version of the current OS distribution as a tuple
     ``(major, minor, build_number)`` with items as follows:
 
     * ``major``:  The result of :func:`distro.major_version`.
 
     * ``minor``:  The result of :func:`distro.minor_version`.
@@ -301,53 +356,57 @@
     For a description of the *best* parameter, see the :func:`distro.version`
     method.
     """
     return _distro.version_parts(best)
 
 
 def major_version(best=False):
+    # type: (bool) -> str
     """
     Return the major version of the current OS distribution, as a string,
     if provided.
     Otherwise, the empty string is returned. The major version is the first
     part of the dot-separated version string.
 
     For a description of the *best* parameter, see the :func:`distro.version`
     method.
     """
     return _distro.major_version(best)
 
 
 def minor_version(best=False):
+    # type: (bool) -> str
     """
     Return the minor version of the current OS distribution, as a string,
     if provided.
     Otherwise, the empty string is returned. The minor version is the second
     part of the dot-separated version string.
 
     For a description of the *best* parameter, see the :func:`distro.version`
     method.
     """
     return _distro.minor_version(best)
 
 
 def build_number(best=False):
+    # type: (bool) -> str
     """
     Return the build number of the current OS distribution, as a string,
     if provided.
     Otherwise, the empty string is returned. The build number is the third part
     of the dot-separated version string.
 
     For a description of the *best* parameter, see the :func:`distro.version`
     method.
     """
     return _distro.build_number(best)
 
 
 def like():
+    # type: () -> str
     """
     Return a space-separated list of distro IDs of distributions that are
     closely related to the current OS distribution in regards to packaging
     and programming interfaces, for example distributions the current
     distribution is a derivative from.
 
     **Lookup hierarchy:**
@@ -357,14 +416,15 @@
     `os-release man page
     <http://www.freedesktop.org/software/systemd/man/os-release.html>`_.
     """
     return _distro.like()
 
 
 def codename():
+    # type: () -> str
     """
     Return the codename for the release of the current OS distribution,
     as a string.
 
     If the distribution does not have a codename, an empty string is returned.
 
     Note that the returned codename is not always really a codename. For
@@ -381,14 +441,15 @@
 
     * the value of the "<codename>" field of the distro release file.
     """
     return _distro.codename()
 
 
 def info(pretty=False, best=False):
+    # type: (bool, bool) -> InfoDict
     """
     Return certain machine-readable information items about the current OS
     distribution in a dictionary, as shown in the following example:
 
     .. sourcecode:: python
 
         {
@@ -425,53 +486,58 @@
     For a description of the *pretty* and *best* parameters, see the
     :func:`distro.version` method.
     """
     return _distro.info(pretty, best)
 
 
 def os_release_info():
+    # type: () -> Dict[str, str]
     """
     Return a dictionary containing key-value pairs for the information items
     from the os-release file data source of the current OS distribution.
 
     See `os-release file`_ for details about these information items.
     """
     return _distro.os_release_info()
 
 
 def lsb_release_info():
+    # type: () -> Dict[str, str]
     """
     Return a dictionary containing key-value pairs for the information items
     from the lsb_release command data source of the current OS distribution.
 
     See `lsb_release command output`_ for details about these information
     items.
     """
     return _distro.lsb_release_info()
 
 
 def distro_release_info():
+    # type: () -> Dict[str, str]
     """
     Return a dictionary containing key-value pairs for the information items
     from the distro release file data source of the current OS distribution.
 
     See `distro release file`_ for details about these information items.
     """
     return _distro.distro_release_info()
 
 
 def uname_info():
+    # type: () -> Dict[str, str]
     """
     Return a dictionary containing key-value pairs for the information items
     from the distro release file data source of the current OS distribution.
     """
     return _distro.uname_info()
 
 
 def os_release_attr(attribute):
+    # type: (str) -> str
     """
     Return a single named information item from the os-release file data source
     of the current OS distribution.
 
     Parameters:
 
     * ``attribute`` (string): Key of the information item.
@@ -483,14 +549,15 @@
 
     See `os-release file`_ for details about these information items.
     """
     return _distro.os_release_attr(attribute)
 
 
 def lsb_release_attr(attribute):
+    # type: (str) -> str
     """
     Return a single named information item from the lsb_release command output
     data source of the current OS distribution.
 
     Parameters:
 
     * ``attribute`` (string): Key of the information item.
@@ -503,14 +570,15 @@
     See `lsb_release command output`_ for details about these information
     items.
     """
     return _distro.lsb_release_attr(attribute)
 
 
 def distro_release_attr(attribute):
+    # type: (str) -> str
     """
     Return a single named information item from the distro release file
     data source of the current OS distribution.
 
     Parameters:
 
     * ``attribute`` (string): Key of the information item.
@@ -522,14 +590,15 @@
 
     See `distro release file`_ for details about these information items.
     """
     return _distro.distro_release_attr(attribute)
 
 
 def uname_attr(attribute):
+    # type: (str) -> str
     """
     Return a single named information item from the distro release file
     data source of the current OS distribution.
 
     Parameters:
 
     * ``attribute`` (string): Key of the information item.
@@ -538,27 +607,34 @@
 
     * (string): Value of the information item, if the item exists.
                 The empty string, if the item does not exist.
     """
     return _distro.uname_attr(attribute)
 
 
-class cached_property(object):
-    """A version of @property which caches the value.  On access, it calls the
-    underlying function and sets the value in `__dict__` so future accesses
-    will not re-call the property.
-    """
-    def __init__(self, f):
-        self._fname = f.__name__
-        self._f = f
-
-    def __get__(self, obj, owner):
-        assert obj is not None, 'call {} on an instance'.format(self._fname)
-        ret = obj.__dict__[self._fname] = self._f(obj)
-        return ret
+try:
+    from functools import cached_property
+except ImportError:
+    # Python < 3.8
+    class cached_property(object):  # type: ignore
+        """A version of @property which caches the value.  On access, it calls the
+        underlying function and sets the value in `__dict__` so future accesses
+        will not re-call the property.
+        """
+
+        def __init__(self, f):
+            # type: (Callable[[Any], Any]) -> None
+            self._fname = f.__name__
+            self._f = f
+
+        def __get__(self, obj, owner):
+            # type: (Any, Type[Any]) -> Any
+            assert obj is not None, "call {} on an instance".format(self._fname)
+            ret = obj.__dict__[self._fname] = self._f(obj)
+            return ret
 
 
 class LinuxDistribution(object):
     """
     Provides information about a OS distribution.
 
     This package creates a private module-global instance of this class with
@@ -571,19 +647,23 @@
     Normally, it is not necessary to create additional instances of this class.
     However, in situations where control is needed over the exact data sources
     that are used, instances of this class can be created with a specific
     distro release file, or a specific os-release file, or without invoking the
     lsb_release command.
     """
 
-    def __init__(self,
-                 include_lsb=True,
-                 os_release_file='',
-                 distro_release_file='',
-                 include_uname=True):
+    def __init__(
+        self,
+        include_lsb=True,
+        os_release_file="",
+        distro_release_file="",
+        include_uname=True,
+        root_dir=None,
+    ):
+        # type: (bool, str, str, bool, Optional[str]) -> None
         """
         The initialization method of this class gathers information from the
         available data sources, and stores that in private instance attributes.
         Subsequent access to the information items uses these private instance
         attributes, so that the data sources are read only once.
 
         Parameters:
@@ -614,14 +694,17 @@
           release file will be empty.
 
         * ``include_uname`` (bool): Controls whether uname command output is
           included as a data source. If the uname command is not available in
           the program execution path the data source for the uname command will
           be empty.
 
+        * ``root_dir`` (string): The absolute path to the root directory to use
+          to find distro-related information files.
+
         Public instance attributes:
 
         * ``os_release_file`` (string): The path name of the
           `os-release file`_ that is actually used as a data source. The
           empty string if no distro release file is used as a data source.
 
         * ``distro_release_file`` (string): The path name of the
@@ -643,302 +726,352 @@
         * :py:exc:`subprocess.CalledProcessError`: The lsb_release command had
           some issue (other than not being available in the program execution
           path).
 
         * :py:exc:`UnicodeError`: A data source has unexpected characters or
           uses an unexpected encoding.
         """
-        self.os_release_file = os_release_file or \
-            os.path.join(_UNIXCONFDIR, _OS_RELEASE_BASENAME)
-        self.distro_release_file = distro_release_file or ''  # updated later
+        self.root_dir = root_dir
+        self.etc_dir = os.path.join(root_dir, "etc") if root_dir else _UNIXCONFDIR
+        self.usr_lib_dir = (
+            os.path.join(root_dir, "usr/lib") if root_dir else _UNIXUSRLIBDIR
+        )
+
+        if os_release_file:
+            self.os_release_file = os_release_file
+        else:
+            etc_dir_os_release_file = os.path.join(self.etc_dir, _OS_RELEASE_BASENAME)
+            usr_lib_os_release_file = os.path.join(
+                self.usr_lib_dir, _OS_RELEASE_BASENAME
+            )
+
+            # NOTE: The idea is to respect order **and** have it set
+            #       at all times for API backwards compatibility.
+            if os.path.isfile(etc_dir_os_release_file) or not os.path.isfile(
+                usr_lib_os_release_file
+            ):
+                self.os_release_file = etc_dir_os_release_file
+            else:
+                self.os_release_file = usr_lib_os_release_file
+
+        self.distro_release_file = distro_release_file or ""  # updated later
         self.include_lsb = include_lsb
         self.include_uname = include_uname
 
     def __repr__(self):
-        """Return repr of all info
-        """
-        return \
-            "LinuxDistribution(" \
-            "os_release_file={self.os_release_file!r}, " \
-            "distro_release_file={self.distro_release_file!r}, " \
-            "include_lsb={self.include_lsb!r}, " \
-            "include_uname={self.include_uname!r}, " \
-            "_os_release_info={self._os_release_info!r}, " \
-            "_lsb_release_info={self._lsb_release_info!r}, " \
-            "_distro_release_info={self._distro_release_info!r}, " \
-            "_uname_info={self._uname_info!r})".format(
-                self=self)
+        # type: () -> str
+        """Return repr of all info"""
+        return (
+            "LinuxDistribution("
+            "os_release_file={self.os_release_file!r}, "
+            "distro_release_file={self.distro_release_file!r}, "
+            "include_lsb={self.include_lsb!r}, "
+            "include_uname={self.include_uname!r}, "
+            "_os_release_info={self._os_release_info!r}, "
+            "_lsb_release_info={self._lsb_release_info!r}, "
+            "_distro_release_info={self._distro_release_info!r}, "
+            "_uname_info={self._uname_info!r})".format(self=self)
+        )
 
     def linux_distribution(self, full_distribution_name=True):
+        # type: (bool) -> Tuple[str, str, str]
         """
         Return information about the OS distribution that is compatible
         with Python's :func:`platform.linux_distribution`, supporting a subset
         of its parameters.
 
         For details, see :func:`distro.linux_distribution`.
         """
         return (
             self.name() if full_distribution_name else self.id(),
             self.version(),
-            self.codename()
+            self.codename(),
         )
 
     def id(self):
+        # type: () -> str
         """Return the distro ID of the OS distribution, as a string.
 
         For details, see :func:`distro.id`.
         """
+
         def normalize(distro_id, table):
-            distro_id = distro_id.lower().replace(' ', '_')
+            # type: (str, Dict[str, str]) -> str
+            distro_id = distro_id.lower().replace(" ", "_")
             return table.get(distro_id, distro_id)
 
-        distro_id = self.os_release_attr('id')
+        distro_id = self.os_release_attr("id")
         if distro_id:
             return normalize(distro_id, NORMALIZED_OS_ID)
 
-        distro_id = self.lsb_release_attr('distributor_id')
+        distro_id = self.lsb_release_attr("distributor_id")
         if distro_id:
             return normalize(distro_id, NORMALIZED_LSB_ID)
 
-        distro_id = self.distro_release_attr('id')
+        distro_id = self.distro_release_attr("id")
         if distro_id:
             return normalize(distro_id, NORMALIZED_DISTRO_ID)
 
-        distro_id = self.uname_attr('id')
+        distro_id = self.uname_attr("id")
         if distro_id:
             return normalize(distro_id, NORMALIZED_DISTRO_ID)
 
-        return ''
+        return ""
 
     def name(self, pretty=False):
+        # type: (bool) -> str
         """
         Return the name of the OS distribution, as a string.
 
         For details, see :func:`distro.name`.
         """
-        name = self.os_release_attr('name') \
-            or self.lsb_release_attr('distributor_id') \
-            or self.distro_release_attr('name') \
-            or self.uname_attr('name')
+        name = (
+            self.os_release_attr("name")
+            or self.lsb_release_attr("distributor_id")
+            or self.distro_release_attr("name")
+            or self.uname_attr("name")
+        )
         if pretty:
-            name = self.os_release_attr('pretty_name') \
-                or self.lsb_release_attr('description')
+            name = self.os_release_attr("pretty_name") or self.lsb_release_attr(
+                "description"
+            )
             if not name:
-                name = self.distro_release_attr('name') \
-                       or self.uname_attr('name')
+                name = self.distro_release_attr("name") or self.uname_attr("name")
                 version = self.version(pretty=True)
                 if version:
-                    name = name + ' ' + version
-        return name or ''
+                    name = name + " " + version
+        return name or ""
 
     def version(self, pretty=False, best=False):
+        # type: (bool, bool) -> str
         """
         Return the version of the OS distribution, as a string.
 
         For details, see :func:`distro.version`.
         """
         versions = [
-            self.os_release_attr('version_id'),
-            self.lsb_release_attr('release'),
-            self.distro_release_attr('version_id'),
-            self._parse_distro_release_content(
-                self.os_release_attr('pretty_name')).get('version_id', ''),
+            self.os_release_attr("version_id"),
+            self.lsb_release_attr("release"),
+            self.distro_release_attr("version_id"),
+            self._parse_distro_release_content(self.os_release_attr("pretty_name")).get(
+                "version_id", ""
+            ),
             self._parse_distro_release_content(
-                self.lsb_release_attr('description')).get('version_id', ''),
-            self.uname_attr('release')
+                self.lsb_release_attr("description")
+            ).get("version_id", ""),
+            self.uname_attr("release"),
         ]
-        version = ''
+        version = ""
         if best:
             # This algorithm uses the last version in priority order that has
             # the best precision. If the versions are not in conflict, that
             # does not matter; otherwise, using the last one instead of the
             # first one might be considered a surprise.
             for v in versions:
-                if v.count(".") > version.count(".") or version == '':
+                if v.count(".") > version.count(".") or version == "":
                     version = v
         else:
             for v in versions:
-                if v != '':
+                if v != "":
                     version = v
                     break
         if pretty and version and self.codename():
-            version = '{0} ({1})'.format(version, self.codename())
+            version = "{0} ({1})".format(version, self.codename())
         return version
 
     def version_parts(self, best=False):
+        # type: (bool) -> Tuple[str, str, str]
         """
         Return the version of the OS distribution, as a tuple of version
         numbers.
 
         For details, see :func:`distro.version_parts`.
         """
         version_str = self.version(best=best)
         if version_str:
-            version_regex = re.compile(r'(\d+)\.?(\d+)?\.?(\d+)?')
+            version_regex = re.compile(r"(\d+)\.?(\d+)?\.?(\d+)?")
             matches = version_regex.match(version_str)
             if matches:
                 major, minor, build_number = matches.groups()
-                return major, minor or '', build_number or ''
-        return '', '', ''
+                return major, minor or "", build_number or ""
+        return "", "", ""
 
     def major_version(self, best=False):
+        # type: (bool) -> str
         """
         Return the major version number of the current distribution.
 
         For details, see :func:`distro.major_version`.
         """
         return self.version_parts(best)[0]
 
     def minor_version(self, best=False):
+        # type: (bool) -> str
         """
         Return the minor version number of the current distribution.
 
         For details, see :func:`distro.minor_version`.
         """
         return self.version_parts(best)[1]
 
     def build_number(self, best=False):
+        # type: (bool) -> str
         """
         Return the build number of the current distribution.
 
         For details, see :func:`distro.build_number`.
         """
         return self.version_parts(best)[2]
 
     def like(self):
+        # type: () -> str
         """
         Return the IDs of distributions that are like the OS distribution.
 
         For details, see :func:`distro.like`.
         """
-        return self.os_release_attr('id_like') or ''
+        return self.os_release_attr("id_like") or ""
 
     def codename(self):
+        # type: () -> str
         """
         Return the codename of the OS distribution.
 
         For details, see :func:`distro.codename`.
         """
         try:
             # Handle os_release specially since distros might purposefully set
             # this to empty string to have no codename
-            return self._os_release_info['codename']
+            return self._os_release_info["codename"]
         except KeyError:
-            return self.lsb_release_attr('codename') \
-                or self.distro_release_attr('codename') \
-                or ''
+            return (
+                self.lsb_release_attr("codename")
+                or self.distro_release_attr("codename")
+                or ""
+            )
 
     def info(self, pretty=False, best=False):
+        # type: (bool, bool) -> InfoDict
         """
         Return certain machine-readable information about the OS
         distribution.
 
         For details, see :func:`distro.info`.
         """
         return dict(
             id=self.id(),
             version=self.version(pretty, best),
             version_parts=dict(
                 major=self.major_version(best),
                 minor=self.minor_version(best),
-                build_number=self.build_number(best)
+                build_number=self.build_number(best),
             ),
             like=self.like(),
             codename=self.codename(),
         )
 
     def os_release_info(self):
+        # type: () -> Dict[str, str]
         """
         Return a dictionary containing key-value pairs for the information
         items from the os-release file data source of the OS distribution.
 
         For details, see :func:`distro.os_release_info`.
         """
         return self._os_release_info
 
     def lsb_release_info(self):
+        # type: () -> Dict[str, str]
         """
         Return a dictionary containing key-value pairs for the information
         items from the lsb_release command data source of the OS
         distribution.
 
         For details, see :func:`distro.lsb_release_info`.
         """
         return self._lsb_release_info
 
     def distro_release_info(self):
+        # type: () -> Dict[str, str]
         """
         Return a dictionary containing key-value pairs for the information
         items from the distro release file data source of the OS
         distribution.
 
         For details, see :func:`distro.distro_release_info`.
         """
         return self._distro_release_info
 
     def uname_info(self):
+        # type: () -> Dict[str, str]
         """
         Return a dictionary containing key-value pairs for the information
         items from the uname command data source of the OS distribution.
 
         For details, see :func:`distro.uname_info`.
         """
         return self._uname_info
 
     def os_release_attr(self, attribute):
+        # type: (str) -> str
         """
         Return a single named information item from the os-release file data
         source of the OS distribution.
 
         For details, see :func:`distro.os_release_attr`.
         """
-        return self._os_release_info.get(attribute, '')
+        return self._os_release_info.get(attribute, "")
 
     def lsb_release_attr(self, attribute):
+        # type: (str) -> str
         """
         Return a single named information item from the lsb_release command
         output data source of the OS distribution.
 
         For details, see :func:`distro.lsb_release_attr`.
         """
-        return self._lsb_release_info.get(attribute, '')
+        return self._lsb_release_info.get(attribute, "")
 
     def distro_release_attr(self, attribute):
+        # type: (str) -> str
         """
         Return a single named information item from the distro release file
         data source of the OS distribution.
 
         For details, see :func:`distro.distro_release_attr`.
         """
-        return self._distro_release_info.get(attribute, '')
+        return self._distro_release_info.get(attribute, "")
 
     def uname_attr(self, attribute):
+        # type: (str) -> str
         """
         Return a single named information item from the uname command
         output data source of the OS distribution.
 
-        For details, see :func:`distro.uname_release_attr`.
+        For details, see :func:`distro.uname_attr`.
         """
-        return self._uname_info.get(attribute, '')
+        return self._uname_info.get(attribute, "")
 
     @cached_property
     def _os_release_info(self):
+        # type: () -> Dict[str, str]
         """
         Get the information items from the specified os-release file.
 
         Returns:
             A dictionary containing all information items.
         """
         if os.path.isfile(self.os_release_file):
             with open(self.os_release_file) as release_file:
                 return self._parse_os_release_content(release_file)
         return {}
 
     @staticmethod
     def _parse_os_release_content(lines):
+        # type: (TextIO) -> Dict[str, str]
         """
         Parse the lines of an os-release file.
 
         Parameters:
 
         * lines: Iterable through the lines in the os-release file.
                  Each line must be a unicode string or a UTF-8 encoded byte
@@ -955,207 +1088,215 @@
         # making it dependent on the encoding of the Python source file.
         # In Python 2.6 and 2.7, the shlex source file is encoded in
         # 'iso-8859-1', and the `wordchars` variable is defined as a byte
         # string. This causes a UnicodeDecodeError to be raised when the
         # parsed content is a unicode object. The following fix resolves that
         # (... but it should be fixed in shlex...):
         if sys.version_info[0] == 2 and isinstance(lexer.wordchars, bytes):
-            lexer.wordchars = lexer.wordchars.decode('iso-8859-1')
+            lexer.wordchars = lexer.wordchars.decode("iso-8859-1")
 
         tokens = list(lexer)
         for token in tokens:
             # At this point, all shell-like parsing has been done (i.e.
             # comments processed, quotes and backslash escape sequences
             # processed, multi-line values assembled, trailing newlines
             # stripped, etc.), so the tokens are now either:
             # * variable assignments: var=value
             # * commands or their arguments (not allowed in os-release)
-            if '=' in token:
-                k, v = token.split('=', 1)
+            if "=" in token:
+                k, v = token.split("=", 1)
                 props[k.lower()] = v
             else:
                 # Ignore any tokens that are not variable assignments
                 pass
 
-        if 'version_codename' in props:
+        if "version_codename" in props:
             # os-release added a version_codename field.  Use that in
             # preference to anything else Note that some distros purposefully
             # do not have code names.  They should be setting
             # version_codename=""
-            props['codename'] = props['version_codename']
-        elif 'ubuntu_codename' in props:
+            props["codename"] = props["version_codename"]
+        elif "ubuntu_codename" in props:
             # Same as above but a non-standard field name used on older Ubuntus
-            props['codename'] = props['ubuntu_codename']
-        elif 'version' in props:
+            props["codename"] = props["ubuntu_codename"]
+        elif "version" in props:
             # If there is no version_codename, parse it from the version
-            codename = re.search(r'(\(\D+\))|,(\s+)?\D+', props['version'])
-            if codename:
-                codename = codename.group()
-                codename = codename.strip('()')
-                codename = codename.strip(',')
+            match = re.search(r"(\(\D+\))|,(\s+)?\D+", props["version"])
+            if match:
+                codename = match.group()
+                codename = codename.strip("()")
+                codename = codename.strip(",")
                 codename = codename.strip()
                 # codename appears within paranthese.
-                props['codename'] = codename
+                props["codename"] = codename
 
         return props
 
     @cached_property
     def _lsb_release_info(self):
+        # type: () -> Dict[str, str]
         """
         Get the information items from the lsb_release command output.
 
         Returns:
             A dictionary containing all information items.
         """
         if not self.include_lsb:
             return {}
-        with open(os.devnull, 'w') as devnull:
+        with open(os.devnull, "wb") as devnull:
             try:
-                cmd = ('lsb_release', '-a')
+                cmd = ("lsb_release", "-a")
                 stdout = subprocess.check_output(cmd, stderr=devnull)
-            except OSError:  # Command not found
+            # Command not found or lsb_release returned error
+            except (OSError, subprocess.CalledProcessError):
                 return {}
         content = self._to_str(stdout).splitlines()
         return self._parse_lsb_release_content(content)
 
     @staticmethod
     def _parse_lsb_release_content(lines):
+        # type: (Iterable[str]) -> Dict[str, str]
         """
         Parse the output of the lsb_release command.
 
         Parameters:
 
         * lines: Iterable through the lines of the lsb_release output.
                  Each line must be a unicode string or a UTF-8 encoded byte
                  string.
 
         Returns:
             A dictionary containing all information items.
         """
         props = {}
         for line in lines:
-            kv = line.strip('\n').split(':', 1)
+            kv = line.strip("\n").split(":", 1)
             if len(kv) != 2:
                 # Ignore lines without colon.
                 continue
             k, v = kv
-            props.update({k.replace(' ', '_').lower(): v.strip()})
+            props.update({k.replace(" ", "_").lower(): v.strip()})
         return props
 
     @cached_property
     def _uname_info(self):
-        with open(os.devnull, 'w') as devnull:
+        # type: () -> Dict[str, str]
+        with open(os.devnull, "wb") as devnull:
             try:
-                cmd = ('uname', '-rs')
+                cmd = ("uname", "-rs")
                 stdout = subprocess.check_output(cmd, stderr=devnull)
             except OSError:
                 return {}
         content = self._to_str(stdout).splitlines()
         return self._parse_uname_content(content)
 
     @staticmethod
     def _parse_uname_content(lines):
+        # type: (Sequence[str]) -> Dict[str, str]
         props = {}
-        match = re.search(r'^([^\s]+)\s+([\d\.]+)', lines[0].strip())
+        match = re.search(r"^([^\s]+)\s+([\d\.]+)", lines[0].strip())
         if match:
             name, version = match.groups()
 
             # This is to prevent the Linux kernel version from
             # appearing as the 'best' version on otherwise
             # identifiable distributions.
-            if name == 'Linux':
+            if name == "Linux":
                 return {}
-            props['id'] = name.lower()
-            props['name'] = name
-            props['release'] = version
+            props["id"] = name.lower()
+            props["name"] = name
+            props["release"] = version
         return props
 
     @staticmethod
     def _to_str(text):
+        # type: (Union[bytes, str]) -> str
         encoding = sys.getfilesystemencoding()
-        encoding = 'utf-8' if encoding == 'ascii' else encoding
+        encoding = "utf-8" if encoding == "ascii" else encoding
 
         if sys.version_info[0] >= 3:
             if isinstance(text, bytes):
                 return text.decode(encoding)
         else:
             if isinstance(text, unicode):  # noqa
                 return text.encode(encoding)
 
         return text
 
     @cached_property
     def _distro_release_info(self):
+        # type: () -> Dict[str, str]
         """
         Get the information items from the specified distro release file.
 
         Returns:
             A dictionary containing all information items.
         """
         if self.distro_release_file:
             # If it was specified, we use it and parse what we can, even if
             # its file name or content does not match the expected pattern.
-            distro_info = self._parse_distro_release_file(
-                self.distro_release_file)
+            distro_info = self._parse_distro_release_file(self.distro_release_file)
             basename = os.path.basename(self.distro_release_file)
             # The file name pattern for user-specified distro release files
             # is somewhat more tolerant (compared to when searching for the
             # file), because we want to use what was specified as best as
             # possible.
             match = _DISTRO_RELEASE_BASENAME_PATTERN.match(basename)
-            if 'name' in distro_info \
-               and 'cloudlinux' in distro_info['name'].lower():
-                distro_info['id'] = 'cloudlinux'
+            if "name" in distro_info and "cloudlinux" in distro_info["name"].lower():
+                distro_info["id"] = "cloudlinux"
             elif match:
-                distro_info['id'] = match.group(1)
+                distro_info["id"] = match.group(1)
             return distro_info
         else:
             try:
-                basenames = os.listdir(_UNIXCONFDIR)
+                basenames = os.listdir(self.etc_dir)
                 # We sort for repeatability in cases where there are multiple
                 # distro specific files; e.g. CentOS, Oracle, Enterprise all
                 # containing `redhat-release` on top of their own.
                 basenames.sort()
             except OSError:
                 # This may occur when /etc is not readable but we can't be
                 # sure about the *-release files. Check common entries of
                 # /etc for information. If they turn out to not be there the
                 # error is handled in `_parse_distro_release_file()`.
-                basenames = ['SuSE-release',
-                             'arch-release',
-                             'base-release',
-                             'centos-release',
-                             'fedora-release',
-                             'gentoo-release',
-                             'mageia-release',
-                             'mandrake-release',
-                             'mandriva-release',
-                             'mandrivalinux-release',
-                             'manjaro-release',
-                             'oracle-release',
-                             'redhat-release',
-                             'sl-release',
-                             'slackware-version']
+                basenames = [
+                    "SuSE-release",
+                    "arch-release",
+                    "base-release",
+                    "centos-release",
+                    "fedora-release",
+                    "gentoo-release",
+                    "mageia-release",
+                    "mandrake-release",
+                    "mandriva-release",
+                    "mandrivalinux-release",
+                    "manjaro-release",
+                    "oracle-release",
+                    "redhat-release",
+                    "sl-release",
+                    "slackware-version",
+                ]
             for basename in basenames:
                 if basename in _DISTRO_RELEASE_IGNORE_BASENAMES:
                     continue
                 match = _DISTRO_RELEASE_BASENAME_PATTERN.match(basename)
                 if match:
-                    filepath = os.path.join(_UNIXCONFDIR, basename)
+                    filepath = os.path.join(self.etc_dir, basename)
                     distro_info = self._parse_distro_release_file(filepath)
-                    if 'name' in distro_info:
+                    if "name" in distro_info:
                         # The name is always present if the pattern matches
                         self.distro_release_file = filepath
-                        distro_info['id'] = match.group(1)
-                        if 'cloudlinux' in distro_info['name'].lower():
-                            distro_info['id'] = 'cloudlinux'
+                        distro_info["id"] = match.group(1)
+                        if "cloudlinux" in distro_info["name"].lower():
+                            distro_info["id"] = "cloudlinux"
                         return distro_info
             return {}
 
     def _parse_distro_release_file(self, filepath):
+        # type: (str) -> Dict[str, str]
         """
         Parse a distro release file.
 
         Parameters:
 
         * filepath: Path name of the distro release file.
 
@@ -1166,65 +1307,80 @@
             with open(filepath) as fp:
                 # Only parse the first line. For instance, on SLES there
                 # are multiple lines. We don't want them...
                 return self._parse_distro_release_content(fp.readline())
         except (OSError, IOError):
             # Ignore not being able to read a specific, seemingly version
             # related file.
-            # See https://github.com/nir0s/distro/issues/162
+            # See https://github.com/python-distro/distro/issues/162
             return {}
 
     @staticmethod
     def _parse_distro_release_content(line):
+        # type: (str) -> Dict[str, str]
         """
         Parse a line from a distro release file.
 
         Parameters:
         * line: Line from the distro release file. Must be a unicode string
                 or a UTF-8 encoded byte string.
 
         Returns:
             A dictionary containing all information items.
         """
-        matches = _DISTRO_RELEASE_CONTENT_REVERSED_PATTERN.match(
-            line.strip()[::-1])
+        matches = _DISTRO_RELEASE_CONTENT_REVERSED_PATTERN.match(line.strip()[::-1])
         distro_info = {}
         if matches:
             # regexp ensures non-None
-            distro_info['name'] = matches.group(3)[::-1]
+            distro_info["name"] = matches.group(3)[::-1]
             if matches.group(2):
-                distro_info['version_id'] = matches.group(2)[::-1]
+                distro_info["version_id"] = matches.group(2)[::-1]
             if matches.group(1):
-                distro_info['codename'] = matches.group(1)[::-1]
+                distro_info["codename"] = matches.group(1)[::-1]
         elif line:
-            distro_info['name'] = line.strip()
+            distro_info["name"] = line.strip()
         return distro_info
 
 
 _distro = LinuxDistribution()
 
 
 def main():
+    # type: () -> None
     logger = logging.getLogger(__name__)
     logger.setLevel(logging.DEBUG)
     logger.addHandler(logging.StreamHandler(sys.stdout))
 
     parser = argparse.ArgumentParser(description="OS distro info tool")
     parser.add_argument(
-        '--json',
-        '-j',
-        help="Output in machine readable format",
-        action="store_true")
+        "--json", "-j", help="Output in machine readable format", action="store_true"
+    )
+
+    parser.add_argument(
+        "--root-dir",
+        "-r",
+        type=str,
+        dest="root_dir",
+        help="Path to the root filesystem directory (defaults to /)",
+    )
+
     args = parser.parse_args()
 
+    if args.root_dir:
+        dist = LinuxDistribution(
+            include_lsb=False, include_uname=False, root_dir=args.root_dir
+        )
+    else:
+        dist = _distro
+
     if args.json:
-        logger.info(json.dumps(info(), indent=4, sort_keys=True))
+        logger.info(json.dumps(dist.info(), indent=4, sort_keys=True))
     else:
-        logger.info('Name: %s', name(pretty=True))
-        distribution_version = version(pretty=True)
-        logger.info('Version: %s', distribution_version)
-        distribution_codename = codename()
-        logger.info('Codename: %s', distribution_codename)
+        logger.info("Name: %s", dist.name(pretty=True))
+        distribution_version = dist.version(pretty=True)
+        logger.info("Version: %s", distribution_version)
+        distribution_codename = dist.codename()
+        logger.info("Codename: %s", distribution_codename)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     main()
```

#### pip/_vendor/vendor.txt

```diff
@@ -1,22 +1,22 @@
-appdirs==1.4.4
-CacheControl==0.12.6
+CacheControl==0.12.6  # Make sure to update the license in pyproject.toml for this.
 colorama==0.4.4
-distlib==0.3.2
-distro==1.5.0
+distlib==0.3.3
+distro==1.6.0
 html5lib==1.1
 msgpack==1.0.2
 packaging==21.0
-pep517==0.11.0
-progress==1.5
+pep517==0.12.0
+platformdirs==2.4.0
+progress==1.6
 pyparsing==2.4.7
 requests==2.26.0
     certifi==2021.05.30
     chardet==4.0.0
     idna==3.2
-    urllib3==1.26.6
-resolvelib==0.7.1
+    urllib3==1.26.7
+resolvelib==0.8.0
 setuptools==44.0.0
 six==1.16.0
 tenacity==8.0.1
 tomli==1.0.3
 webencodings==0.5.1
```

#### pip/_vendor/distlib/__init__.py

```diff
@@ -2,15 +2,15 @@
 #
 # Copyright (C) 2012-2019 Vinay Sajip.
 # Licensed to the Python Software Foundation under a contributor agreement.
 # See LICENSE.txt and CONTRIBUTORS.txt.
 #
 import logging
 
-__version__ = '0.3.2'
+__version__ = '0.3.3'
 
 class DistlibException(Exception):
     pass
 
 try:
     from logging import NullHandler
 except ImportError: # pragma: no cover
```

#### pip/_vendor/distlib/compat.py

```diff
@@ -44,35 +44,36 @@
     import Queue as queue
     from HTMLParser import HTMLParser
     import htmlentitydefs
     raw_input = raw_input
     from itertools import ifilter as filter
     from itertools import ifilterfalse as filterfalse
 
-    _userprog = None
-    def splituser(host):
-        """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
-        global _userprog
-        if _userprog is None:
-            import re
-            _userprog = re.compile('^(.*)@(.*)$')
-
-        match = _userprog.match(host)
-        if match: return match.group(1, 2)
-        return None, host
+    # Leaving this around for now, in case it needs resurrecting in some way
+    # _userprog = None
+    # def splituser(host):
+        # """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
+        # global _userprog
+        # if _userprog is None:
+            # import re
+            # _userprog = re.compile('^(.*)@(.*)$')
+
+        # match = _userprog.match(host)
+        # if match: return match.group(1, 2)
+        # return None, host
 
 else:  # pragma: no cover
     from io import StringIO
     string_types = str,
     text_type = str
     from io import TextIOWrapper as file_type
     import builtins
     import configparser
     import shutil
-    from urllib.parse import (urlparse, urlunparse, urljoin, splituser, quote,
+    from urllib.parse import (urlparse, urlunparse, urljoin, quote,
                               unquote, urlsplit, urlunsplit, splittype)
     from urllib.request import (urlopen, urlretrieve, Request, url2pathname,
                                 pathname2url,
                                 HTTPBasicAuthHandler, HTTPPasswordMgr,
                                 HTTPHandler, HTTPRedirectHandler,
                                 build_opener)
     if ssl:
@@ -84,14 +85,15 @@
     import queue
     from html.parser import HTMLParser
     import html.entities as htmlentitydefs
     raw_input = input
     from itertools import filterfalse
     filter = filter
 
+
 try:
     from ssl import match_hostname, CertificateError
 except ImportError: # pragma: no cover
     class CertificateError(ValueError):
         pass
```

#### pip/_vendor/distlib/markers.py

```diff
@@ -9,27 +9,37 @@
 """
 
 # Note: In PEP 345, the micro-language was Python compatible, so the ast
 # module could be used to parse it. However, PEP 508 introduced operators such
 # as ~= and === which aren't in Python, necessitating a different approach.
 
 import os
+import re
 import sys
 import platform
 
 from .compat import string_types
 from .util import in_venv, parse_marker
+from .version import NormalizedVersion as NV
 
 __all__ = ['interpret']
 
+_VERSION_PATTERN = re.compile(r'((\d+(\.\d+)*\w*)|\'(\d+(\.\d+)*\w*)\'|\"(\d+(\.\d+)*\w*)\")')
+
 def _is_literal(o):
     if not isinstance(o, string_types) or not o:
         return False
     return o[0] in '\'"'
 
+def _get_versions(s):
+    result = []
+    for m in _VERSION_PATTERN.finditer(s):
+        result.append(NV(m.groups()[0]))
+    return set(result)
+
 class Evaluator(object):
     """
     This class is used to evaluate marker expessions.
     """
 
     operations = {
         '==': lambda x, y: x == y,
@@ -66,14 +76,21 @@
             elhs = expr['lhs']
             erhs = expr['rhs']
             if _is_literal(expr['lhs']) and _is_literal(expr['rhs']):
                 raise SyntaxError('invalid comparison: %s %s %s' % (elhs, op, erhs))
 
             lhs = self.evaluate(elhs, context)
             rhs = self.evaluate(erhs, context)
+            if ((elhs == 'python_version' or erhs == 'python_version') and
+                op in ('<', '<=', '>', '>=', '===', '==', '!=', '~=')):
+                lhs = NV(lhs)
+                rhs = NV(rhs)
+            elif elhs == 'python_version' and op in ('in', 'not in'):
+                lhs = NV(lhs)
+                rhs = _get_versions(rhs)
             result = self.operations[op](lhs, rhs)
         return result
 
 def default_context():
     def format_full_version(info):
         version = '%s.%s.%s' % (info.major, info.minor, info.micro)
         kind = info.releaselevel
```

#### pip/_vendor/distlib/scripts.py

```diff
@@ -10,15 +10,15 @@
 import re
 import struct
 import sys
 
 from .compat import sysconfig, detect_encoding, ZipFile
 from .resources import finder
 from .util import (FileOperator, get_export_entry, convert_path,
-                   get_executable, in_venv)
+                   get_executable, get_platform, in_venv)
 
 logger = logging.getLogger(__name__)
 
 _DEFAULT_MANIFEST = '''
 <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
 <assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0">
  <assemblyIdentity version="1.0.0.0"
@@ -166,14 +166,19 @@
             executable = os.path.join(sysconfig.get_path('scripts'),
                             'python%s' % sysconfig.get_config_var('EXE'))
         else:  # pragma: no cover
             executable = os.path.join(
                 sysconfig.get_config_var('BINDIR'),
                'python%s%s' % (sysconfig.get_config_var('VERSION'),
                                sysconfig.get_config_var('EXE')))
+            if not os.path.isfile(executable):
+                # for Python builds from source on Windows, no Python executables with
+                # a version suffix are created, so we use python.exe
+                executable = os.path.join(sysconfig.get_config_var('BINDIR'),
+                                'python%s' % (sysconfig.get_config_var('EXE')))
         if options:
             executable = self._get_alternate_executable(executable, options)
 
         if sys.platform.startswith('java'):  # pragma: no cover
             executable = self._fix_jython_executable(executable)
 
         # Normalise case for Windows - COMMENTED OUT
@@ -375,15 +380,16 @@
         # Launchers are from https://bitbucket.org/vinay.sajip/simple_launcher/
 
         def _get_launcher(self, kind):
             if struct.calcsize('P') == 8:   # 64-bit
                 bits = '64'
             else:
                 bits = '32'
-            name = '%s%s.exe' % (kind, bits)
+            platform_suffix = '-arm' if get_platform() == 'win-arm64' else ''
+            name = '%s%s%s.exe' % (kind, bits, platform_suffix)
             # Issue 31: don't hardcode an absolute package name, but
             # determine it relative to the current package
             distlib_package = __name__.rsplit('.', 1)[0]
             resource = finder(distlib_package).find(name)
             if not resource:
                 msg = ('Unable to find resource %s in package %s' % (name,
                        distlib_package))
```

#### pip/_vendor/distlib/util.py

```diff
@@ -211,14 +211,18 @@
                             raise SyntaxError('invalid version: %s' % ver_remaining)
                         v = m.groups()[0]
                         versions.append((op, v))
                         ver_remaining = ver_remaining[m.end():]
                         if not ver_remaining or ver_remaining[0] != ',':
                             break
                         ver_remaining = ver_remaining[1:].lstrip()
+                        # Some packages have a trailing comma which would break things
+                        # See issue #148
+                        if not ver_remaining:
+                            break
                         m = COMPARE_OP.match(ver_remaining)
                         if not m:
                             raise SyntaxError('invalid constraint: %s' % ver_remaining)
                     if not versions:
                         versions = None
                 return versions, ver_remaining
```

#### pip/_vendor/distlib/version.py

```diff
@@ -190,15 +190,15 @@
     nums = tuple(int(v) for v in groups[1].split('.'))
     while len(nums) > 1 and nums[-1] == 0:
         nums = nums[:-1]
 
     if not groups[0]:
         epoch = 0
     else:
-        epoch = int(groups[0])
+        epoch = int(groups[0][:-1])
     pre = groups[4:6]
     post = groups[7:9]
     dev = groups[10:12]
     local = groups[13]
     if pre == (None, None):
         pre = ()
     else:
```

#### pip/_vendor/distlib/wheel.py

```diff
@@ -43,18 +43,15 @@
 elif sys.platform == 'cli':  # pragma: no cover
     IMP_PREFIX = 'ip'
 else:
     IMP_PREFIX = 'cp'
 
 VER_SUFFIX = sysconfig.get_config_var('py_version_nodot')
 if not VER_SUFFIX:   # pragma: no cover
-    if sys.version_info[1] >= 10:
-        VER_SUFFIX = '%s_%s' % sys.version_info[:2]  # PEP 641 (draft)
-    else:
-        VER_SUFFIX = '%s%s' % sys.version_info[:2]
+    VER_SUFFIX = '%s%s' % sys.version_info[:2]
 PYVER = 'py' + VER_SUFFIX
 IMPVER = IMP_PREFIX + VER_SUFFIX
 
 ARCH = get_platform().replace('-', '_').replace('.', '_')
 
 ABI = sysconfig.get_config_var('SOABI')
 if ABI and ABI.startswith('cpython-'):
```

#### pip/_vendor/pep517/__init__.py

```diff
@@ -1,6 +1,6 @@
 """Wrappers to build Python packages using PEP 517 hooks
 """
 
-__version__ = '0.11.0'
+__version__ = '0.12.0'
 
 from .wrappers import *  # noqa: F401, F403
```

#### pip/_vendor/pep517/build.py

```diff
@@ -27,15 +27,15 @@
 
 
 def load_system(source_dir):
     """
     Load the build system from a source dir (pyproject.toml).
     """
     pyproject = os.path.join(source_dir, 'pyproject.toml')
-    with io.open(pyproject, encoding="utf-8") as f:
+    with io.open(pyproject, 'rb') as f:
         pyproject_data = toml_load(f)
     return pyproject_data['build-system']
 
 
 def compat_system(source_dir):
     """
     Given a source dir, attempt to get a build system backend
```

#### pip/_vendor/pep517/check.py

```diff
@@ -138,15 +138,15 @@
     if isfile(pyproject):
         log.info('Found pyproject.toml')
     else:
         log.error('Missing pyproject.toml')
         return False
 
     try:
-        with io.open(pyproject, encoding="utf-8") as f:
+        with io.open(pyproject, 'rb') as f:
             pyproject_data = toml_load(f)
         # Ensure the mandatory data can be loaded
         buildsys = pyproject_data['build-system']
         requires = buildsys['requires']
         backend = buildsys['build-backend']
         backend_path = buildsys.get('backend-path')
         log.info('Loaded pyproject.toml')
```

#### pip/_vendor/pep517/compat.py

```diff
@@ -1,8 +1,9 @@
 """Python 2/3 compatibility"""
+import io
 import json
 import sys
 
 
 # Handle reading and writing JSON in UTF-8, on Python 3 and 2.
 
 if sys.version_info[0] >= 3:
@@ -31,12 +32,20 @@
 try:
     FileNotFoundError = FileNotFoundError
 except NameError:
     FileNotFoundError = IOError
 
 
 if sys.version_info < (3, 6):
-    from toml import load as toml_load  # noqa: F401
+    from toml import load as _toml_load  # noqa: F401
+
+    def toml_load(f):
+        w = io.TextIOWrapper(f, encoding="utf8", newline="")
+        try:
+            return _toml_load(w)
+        finally:
+            w.detach()
+
     from toml import TomlDecodeError as TOMLDecodeError  # noqa: F401
 else:
     from pip._vendor.tomli import load as toml_load  # noqa: F401
     from pip._vendor.tomli import TOMLDecodeError  # noqa: F401
```

#### pip/_vendor/pep517/envbuild.py

```diff
@@ -15,15 +15,15 @@
 
 log = logging.getLogger(__name__)
 
 
 def _load_pyproject(source_dir):
     with io.open(
             os.path.join(source_dir, 'pyproject.toml'),
-            encoding="utf-8",
+            'rb',
             ) as f:
         pyproject_data = toml_load(f)
     buildsys = pyproject_data['build-system']
     return (
         buildsys['requires'],
         buildsys['build-backend'],
         buildsys.get('backend-path'),
```

#### pip/_vendor/pep517/wrappers.py

```diff
@@ -150,14 +150,18 @@
         prev = self._subprocess_runner
         self._subprocess_runner = runner
         try:
             yield
         finally:
             self._subprocess_runner = prev
 
+    def _supported_features(self):
+        """Return the list of optional features supported by the backend."""
+        return self._call_hook('_supported_features', {})
+
     def get_requires_for_build_wheel(self, config_settings=None):
         """Identify packages required for building a wheel
 
         Returns a list of dependency specifications, e.g.::
 
             ["wheel >= 0.25", "setuptools"]
```

#### pip/_vendor/pep517/in_process/_in_process.py

```diff
@@ -99,14 +99,27 @@
 
     if obj_path:
         for path_part in obj_path.split('.'):
             obj = getattr(obj, path_part)
     return obj
 
 
+def _supported_features():
+    """Return the list of options features supported by the backend.
+
+    Returns a list of strings.
+    The only possible value is 'build_editable'.
+    """
+    backend = _build_backend()
+    features = []
+    if hasattr(backend, "build_editable"):
+        features.append("build_editable")
+    return features
+
+
 def get_requires_for_build_wheel(config_settings):
     """Invoke the optional get_requires_for_build_wheel hook
 
     Returns [] if the hook is not defined.
     """
     backend = _build_backend()
     try:
@@ -308,14 +321,15 @@
     'prepare_metadata_for_build_wheel',
     'build_wheel',
     'get_requires_for_build_editable',
     'prepare_metadata_for_build_editable',
     'build_editable',
     'get_requires_for_build_sdist',
     'build_sdist',
+    '_supported_features',
 }
 
 
 def main():
     if len(sys.argv) < 3:
         sys.exit("Needs args: hook_name, control_dir")
     hook_name = sys.argv[1]
```

#### pip/_vendor/pkg_resources/__init__.py

```diff
@@ -73,15 +73,15 @@
     import importlib.machinery as importlib_machinery
     # access attribute to force import under delayed import mechanisms.
     importlib_machinery.__name__
 except ImportError:
     importlib_machinery = None
 
 from . import py31compat
-from pip._vendor import appdirs
+from pip._vendor import platformdirs
 from pip._vendor import packaging
 __import__('pip._vendor.packaging.version')
 __import__('pip._vendor.packaging.specifiers')
 __import__('pip._vendor.packaging.requirements')
 __import__('pip._vendor.packaging.markers')
 
 
@@ -1306,15 +1306,15 @@
     """
     Return the ``PYTHON_EGG_CACHE`` environment variable
     or a platform-relevant user cache dir for an app
     named "Python-Eggs".
     """
     return (
         os.environ.get('PYTHON_EGG_CACHE')
-        or appdirs.user_cache_dir(appname='Python-Eggs')
+        or platformdirs.user_cache_dir(appname='Python-Eggs')
     )
 
 
 def safe_name(name):
     """Convert an arbitrary string to a standard distribution name
 
     Any runs of non-alphanumeric/. characters are replaced with a single '-'.
```

#### pip/_vendor/progress/__init__.py

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2012 Giorgos Verigakis <verigak@gmail.com>
+# Copyright (c) 2012 Georgios Verigakis <verigak@gmail.com>
 #
 # Permission to use, copy, modify, and distribute this software for any
 # purpose with or without fee is hereby granted, provided that the above
 # copyright notice and this permission notice appear in all copies.
 #
 # THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 # WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
@@ -20,15 +20,15 @@
 from sys import stderr
 try:
     from time import monotonic
 except ImportError:
     from time import time as monotonic
 
 
-__version__ = '1.5'
+__version__ = '1.6'
 
 HIDE_CURSOR = '\x1b[?25l'
 SHOW_CURSOR = '\x1b[?25h'
 
 
 class Infinite(object):
     file = stderr
@@ -42,22 +42,27 @@
         self.avg = 0
         self._avg_update_ts = self.start_ts
         self._ts = self.start_ts
         self._xput = deque(maxlen=self.sma_window)
         for key, val in kwargs.items():
             setattr(self, key, val)
 
-        self._width = 0
+        self._max_width = 0
+        self._hidden_cursor = False
         self.message = message
 
         if self.file and self.is_tty():
             if self.hide_cursor:
                 print(HIDE_CURSOR, end='', file=self.file)
-            print(self.message, end='', file=self.file)
-            self.file.flush()
+                self._hidden_cursor = True
+        self.writeln('')
+
+    def __del__(self):
+        if self._hidden_cursor:
+            print(SHOW_CURSOR, end='', file=self.file)
 
     def __getitem__(self, key):
         if key.startswith('_'):
             return None
         return getattr(self, key, None)
 
     @property
@@ -81,53 +86,55 @@
 
     def update(self):
         pass
 
     def start(self):
         pass
 
-    def clearln(self):
-        if self.file and self.is_tty():
-            print('\r\x1b[K', end='', file=self.file)
-
-    def write(self, s):
-        if self.file and self.is_tty():
-            line = self.message + s.ljust(self._width)
-            print('\r' + line, end='', file=self.file)
-            self._width = max(self._width, len(s))
-            self.file.flush()
-
     def writeln(self, line):
         if self.file and self.is_tty():
-            self.clearln()
-            print(line, end='', file=self.file)
+            width = len(line)
+            if width < self._max_width:
+                # Add padding to cover previous contents
+                line += ' ' * (self._max_width - width)
+            else:
+                self._max_width = width
+            print('\r' + line, end='', file=self.file)
             self.file.flush()
 
     def finish(self):
         if self.file and self.is_tty():
             print(file=self.file)
-            if self.hide_cursor:
+            if self._hidden_cursor:
                 print(SHOW_CURSOR, end='', file=self.file)
+                self._hidden_cursor = False
 
     def is_tty(self):
-        return self.file.isatty() if self.check_tty else True
+        try:
+            return self.file.isatty() if self.check_tty else True
+        except AttributeError:
+            msg = "%s has no attribute 'isatty'. Try setting check_tty=False." % self
+            raise AttributeError(msg)
 
     def next(self, n=1):
         now = monotonic()
         dt = now - self._ts
         self.update_avg(n, dt)
         self._ts = now
         self.index = self.index + n
         self.update()
 
     def iter(self, it):
+        self.iter_value = None
         with self:
             for x in it:
+                self.iter_value = x
                 yield x
                 self.next()
+        del self.iter_value
 
     def __enter__(self):
         self.start()
         return self
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         self.finish()
@@ -148,14 +155,16 @@
 
     @property
     def percent(self):
         return self.progress * 100
 
     @property
     def progress(self):
+        if self.max == 0:
+            return 0
         return min(1, self.index / self.max)
 
     @property
     def remaining(self):
         return max(self.max - self.index, 0)
 
     def start(self):
@@ -167,11 +176,14 @@
 
     def iter(self, it):
         try:
             self.max = len(it)
         except TypeError:
             pass
 
+        self.iter_value = None
         with self:
             for x in it:
+                self.iter_value = x
                 yield x
                 self.next()
+        del self.iter_value
```

#### pip/_vendor/progress/bar.py

```diff
@@ -1,10 +1,10 @@
 # -*- coding: utf-8 -*-
 
-# Copyright (c) 2012 Giorgos Verigakis <verigak@gmail.com>
+# Copyright (c) 2012 Georgios Verigakis <verigak@gmail.com>
 #
 # Permission to use, copy, modify, and distribute this software for any
 # purpose with or without fee is hereby granted, provided that the above
 # copyright notice and this permission notice appear in all copies.
 #
 # THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 # WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
@@ -15,30 +15,32 @@
 # OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 
 from __future__ import unicode_literals
 
 import sys
 
 from . import Progress
+from .colors import color
 
 
 class Bar(Progress):
     width = 32
     suffix = '%(index)d/%(max)d'
     bar_prefix = ' |'
     bar_suffix = '| '
     empty_fill = ' '
     fill = '#'
+    color = None
 
     def update(self):
         filled_length = int(self.width * self.progress)
         empty_length = self.width - filled_length
 
         message = self.message % self
-        bar = self.fill * filled_length
+        bar = color(self.fill * filled_length, fg=self.color)
         empty = self.empty_fill * empty_length
         suffix = self.suffix % self
         line = ''.join([message, self.bar_prefix, bar, empty, self.bar_suffix,
                         suffix])
         self.writeln(line)
 
 
@@ -70,15 +72,15 @@
         nphases = len(self.phases)
         filled_len = self.width * self.progress
         nfull = int(filled_len)                      # Number of full chars
         phase = int((filled_len - nfull) * nphases)  # Phase of last char
         nempty = self.width - nfull                  # Number of empty chars
 
         message = self.message % self
-        bar = self.phases[-1] * nfull
+        bar = color(self.phases[-1] * nfull, fg=self.color)
         current = self.phases[phase] if phase > 0 else ''
         empty = self.empty_fill * max(0, nempty - len(current))
         suffix = self.suffix % self
         line = ''.join([message, self.bar_prefix, bar, current, empty,
                         self.bar_suffix, suffix])
         self.writeln(line)
```

#### pip/_vendor/progress/counter.py

```diff
@@ -1,10 +1,10 @@
 # -*- coding: utf-8 -*-
 
-# Copyright (c) 2012 Giorgos Verigakis <verigak@gmail.com>
+# Copyright (c) 2012 Georgios Verigakis <verigak@gmail.com>
 #
 # Permission to use, copy, modify, and distribute this software for any
 # purpose with or without fee is hereby granted, provided that the above
 # copyright notice and this permission notice appear in all copies.
 #
 # THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 # WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
@@ -16,26 +16,32 @@
 
 from __future__ import unicode_literals
 from . import Infinite, Progress
 
 
 class Counter(Infinite):
     def update(self):
-        self.write(str(self.index))
+        message = self.message % self
+        line = ''.join([message, str(self.index)])
+        self.writeln(line)
 
 
 class Countdown(Progress):
     def update(self):
-        self.write(str(self.remaining))
+        message = self.message % self
+        line = ''.join([message, str(self.remaining)])
+        self.writeln(line)
 
 
 class Stack(Progress):
     phases = (' ', '▁', '▂', '▃', '▄', '▅', '▆', '▇', '█')
 
     def update(self):
         nphases = len(self.phases)
         i = min(nphases - 1, int(self.progress * nphases))
-        self.write(self.phases[i])
+        message = self.message % self
+        line = ''.join([message, self.phases[i]])
+        self.writeln(line)
 
 
 class Pie(Stack):
     phases = ('○', '◔', '◑', '◕', '●')
```

#### pip/_vendor/progress/spinner.py

```diff
@@ -1,10 +1,10 @@
 # -*- coding: utf-8 -*-
 
-# Copyright (c) 2012 Giorgos Verigakis <verigak@gmail.com>
+# Copyright (c) 2012 Georgios Verigakis <verigak@gmail.com>
 #
 # Permission to use, copy, modify, and distribute this software for any
 # purpose with or without fee is hereby granted, provided that the above
 # copyright notice and this permission notice appear in all copies.
 #
 # THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 # WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
@@ -20,15 +20,17 @@
 
 class Spinner(Infinite):
     phases = ('-', '\\', '|', '/')
     hide_cursor = True
 
     def update(self):
         i = self.index % len(self.phases)
-        self.write(self.phases[i])
+        message = self.message % self
+        line = ''.join([message, self.phases[i]])
+        self.writeln(line)
 
 
 class PieSpinner(Spinner):
     phases = ['◷', '◶', '◵', '◴']
 
 
 class MoonSpinner(Spinner):
```

#### pip/_vendor/resolvelib/__init__.py

```diff
@@ -7,15 +7,15 @@
     "Resolver",
     "RequirementsConflicted",
     "ResolutionError",
     "ResolutionImpossible",
     "ResolutionTooDeep",
 ]
 
-__version__ = "0.7.1"
+__version__ = "0.8.0"
 
 
 from .providers import AbstractProvider, AbstractResolver
 from .reporters import BaseReporter
 from .resolvers import (
     InconsistentCandidate,
     RequirementsConflicted,
```

#### pip/_vendor/resolvelib/providers.py

```diff
@@ -5,15 +5,22 @@
         """Given a requirement, return an identifier for it.
 
         This is used to identify a requirement, e.g. whether two requirements
         should have their specifier parts merged.
         """
         raise NotImplementedError
 
-    def get_preference(self, identifier, resolutions, candidates, information):
+    def get_preference(
+        self,
+        identifier,
+        resolutions,
+        candidates,
+        information,
+        backtrack_causes,
+    ):
         """Produce a sort key for given requirement based on preference.
 
         The preference is defined as "I think this requirement should be
         resolved first". The lower the return value is, the more preferred
         this group of arguments is.
 
         :param identifier: An identifier as returned by ``identify()``. This
@@ -21,14 +28,16 @@
         :param resolutions: Mapping of candidates currently pinned by the
             resolver. Each key is an identifier, and the value a candidate.
             The candidate may conflict with requirements from ``information``.
         :param candidates: Mapping of each dependency's possible candidates.
             Each value is an iterator of candidates.
         :param information: Mapping of requirement information of each package.
             Each value is an iterator of *requirement information*.
+        :param backtrack_causes: Sequence of requirement information that were
+            the requirements that caused the resolver to most recently backtrack.
 
         A *requirement information* instance is a named tuple with two members:
 
         * ``requirement`` specifies a requirement contributing to the current
           list of candidates.
         * ``parent`` specifies the candidate that provides (dependend on) the
           requirement, or ``None`` to indicate a root requirement.
```

#### pip/_vendor/resolvelib/resolvers.py

```diff
@@ -95,15 +95,15 @@
 class ResolutionTooDeep(ResolutionError):
     def __init__(self, round_count):
         super(ResolutionTooDeep, self).__init__(round_count)
         self.round_count = round_count
 
 
 # Resolution state in a round.
-State = collections.namedtuple("State", "mapping criteria")
+State = collections.namedtuple("State", "mapping criteria backtrack_causes")
 
 
 class Resolution(object):
     """Stateful resolution object.
 
     This is designed as a one-off object that holds information to kick start
     the resolution process, and holds the results afterwards.
@@ -127,14 +127,15 @@
         This new state will be used to hold resolution results of the next
         coming round.
         """
         base = self._states[-1]
         state = State(
             mapping=base.mapping.copy(),
             criteria=base.criteria.copy(),
+            backtrack_causes=base.backtrack_causes[:],
         )
         self._states.append(state)
 
     def _add_to_criteria(self, criteria, requirement, parent):
         self._r.adding_requirement(requirement=requirement, parent=parent)
 
         identifier = self._p.identify(requirement_or_candidate=requirement)
@@ -181,14 +182,15 @@
                 self.state.criteria,
                 operator.attrgetter("candidates"),
             ),
             information=IteratorMapping(
                 self.state.criteria,
                 operator.attrgetter("information"),
             ),
+            backtrack_causes=self.state.backtrack_causes,
         )
 
     def _is_current_pin_satisfying(self, name, criterion):
         try:
             current_pin = self.state.mapping[name]
         except KeyError:
             return False
@@ -331,15 +333,21 @@
     def resolve(self, requirements, max_rounds):
         if self._states:
             raise RuntimeError("already resolved")
 
         self._r.starting()
 
         # Initialize the root state.
-        self._states = [State(mapping=collections.OrderedDict(), criteria={})]
+        self._states = [
+            State(
+                mapping=collections.OrderedDict(),
+                criteria={},
+                backtrack_causes=[],
+            )
+        ]
         for r in requirements:
             try:
                 self._add_to_criteria(self.state.criteria, r, parent=None)
             except RequirementsConflicted as e:
                 raise ResolutionImpossible(e.criterion.information)
 
         # The root state is saved as a sentinel so the first ever pin can have
@@ -365,19 +373,21 @@
             name = min(unsatisfied_names, key=self._get_preference)
             failure_causes = self._attempt_to_pin_criterion(name)
 
             if failure_causes:
                 # Backtrack if pinning fails. The backtrack process puts us in
                 # an unpinned state, so we can work on it in the next round.
                 success = self._backtrack()
+                self.state.backtrack_causes[:] = [
+                    i for c in failure_causes for i in c.information
+                ]
 
                 # Dead ends everywhere. Give up.
                 if not success:
-                    causes = [i for c in failure_causes for i in c.information]
-                    raise ResolutionImpossible(causes)
+                    raise ResolutionImpossible(self.state.backtrack_causes)
             else:
                 # Pinning was successful. Push a new state to do another pin.
                 self._push_new_state()
 
             self._r.ending_round(index=round_index, state=self.state)
 
         raise ResolutionTooDeep(max_rounds)
```

#### pip/_vendor/urllib3/_version.py

```diff
@@ -1,2 +1,2 @@
 # This file is protected via CODEOWNERS
-__version__ = "1.26.6"
+__version__ = "1.26.7"
```

#### pip/_vendor/urllib3/connection.py

```diff
@@ -52,14 +52,15 @@
     SystemTimeWarning,
 )
 from .packages.ssl_match_hostname import CertificateError, match_hostname
 from .util import SKIP_HEADER, SKIPPABLE_HEADERS, connection
 from .util.ssl_ import (
     assert_fingerprint,
     create_urllib3_context,
+    is_ipaddress,
     resolve_cert_reqs,
     resolve_ssl_version,
     ssl_wrap_socket,
 )
 
 log = logging.getLogger(__name__)
 
@@ -103,14 +104,18 @@
     #: Disable Nagle's algorithm by default.
     #: ``[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]``
     default_socket_options = [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]
 
     #: Whether this connection verifies the host's certificate.
     is_verified = False
 
+    #: Whether this proxy connection (if used) verifies the proxy host's
+    #: certificate.
+    proxy_is_verified = None
+
     def __init__(self, *args, **kw):
         if not six.PY2:
             kw.pop("strict", None)
 
         # Pre-set source_address.
         self.source_address = kw.get("source_address")
 
@@ -486,32 +491,57 @@
         ssl_context = create_proxy_ssl_context(
             self.ssl_version,
             self.cert_reqs,
             self.ca_certs,
             self.ca_cert_dir,
             self.ca_cert_data,
         )
-        # By default urllib3's SSLContext disables `check_hostname` and uses
-        # a custom check. For proxies we're good with relying on the default
-        # verification.
-        ssl_context.check_hostname = True
 
         # If no cert was provided, use only the default options for server
         # certificate validation
-        return ssl_wrap_socket(
+        socket = ssl_wrap_socket(
             sock=conn,
             ca_certs=self.ca_certs,
             ca_cert_dir=self.ca_cert_dir,
             ca_cert_data=self.ca_cert_data,
             server_hostname=hostname,
             ssl_context=ssl_context,
         )
 
+        if ssl_context.verify_mode != ssl.CERT_NONE and not getattr(
+            ssl_context, "check_hostname", False
+        ):
+            # While urllib3 attempts to always turn off hostname matching from
+            # the TLS library, this cannot always be done. So we check whether
+            # the TLS Library still thinks it's matching hostnames.
+            cert = socket.getpeercert()
+            if not cert.get("subjectAltName", ()):
+                warnings.warn(
+                    (
+                        "Certificate for {0} has no `subjectAltName`, falling back to check for a "
+                        "`commonName` for now. This feature is being removed by major browsers and "
+                        "deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 "
+                        "for details.)".format(hostname)
+                    ),
+                    SubjectAltNameWarning,
+                )
+            _match_hostname(cert, hostname)
+
+        self.proxy_is_verified = ssl_context.verify_mode == ssl.CERT_REQUIRED
+        return socket
+
 
 def _match_hostname(cert, asserted_hostname):
+    # Our upstream implementation of ssl.match_hostname()
+    # only applies this normalization to IP addresses so it doesn't
+    # match DNS SANs so we do the same thing!
+    stripped_hostname = asserted_hostname.strip("u[]")
+    if is_ipaddress(stripped_hostname):
+        asserted_hostname = stripped_hostname
+
     try:
         match_hostname(cert, asserted_hostname)
     except CertificateError as e:
         log.warning(
             "Certificate did not match expected hostname: %s. Certificate: %s",
             asserted_hostname,
             cert,
```

#### pip/_vendor/urllib3/connectionpool.py

```diff
@@ -1016,14 +1016,25 @@
                     "Adding certificate verification is strongly advised. See: "
                     "https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html"
                     "#ssl-warnings" % conn.host
                 ),
                 InsecureRequestWarning,
             )
 
+        if getattr(conn, "proxy_is_verified", None) is False:
+            warnings.warn(
+                (
+                    "Unverified HTTPS connection done to an HTTPS proxy. "
+                    "Adding certificate verification is strongly advised. See: "
+                    "https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html"
+                    "#ssl-warnings"
+                ),
+                InsecureRequestWarning,
+            )
+
 
 def connection_from_url(url, **kw):
     """
     Given a url, return an :class:`.ConnectionPool` instance of its host.
 
     This is a shortcut for not having to parse out the scheme, host, and port
     of the url before creating an :class:`.ConnectionPool` instance.
```

#### pip/_vendor/urllib3/contrib/pyopenssl.py

```diff
@@ -24,16 +24,16 @@
 before you begin making HTTP requests. This can be done in a ``sitecustomize``
 module, or at any other time before your application begins using ``urllib3``,
 like this:
 
 .. code-block:: python
 
     try:
-        import urllib3.contrib.pyopenssl
-        urllib3.contrib.pyopenssl.inject_into_urllib3()
+        import pip._vendor.urllib3.contrib.pyopenssl as pyopenssl
+        pyopenssl.inject_into_urllib3()
     except ImportError:
         pass
 
 Now you can use :mod:`urllib3` as you normally would, and it will support SNI
 when the required modules are installed.
 
 Activating this module also has the positive side effect of disabling SSL/TLS
```

#### pip/_vendor/urllib3/contrib/securetransport.py

```diff
@@ -15,16 +15,16 @@
 The hope is that PEP 543 will eventually solve this issue for us, at which
 point we can retire this contrib module. But in the short term, we need to
 solve the impending tire fire that is Python on Mac without this kind of
 contrib module. So...here we are.
 
 To use this module, simply import and inject it::
 
-    import urllib3.contrib.securetransport
-    urllib3.contrib.securetransport.inject_into_urllib3()
+    import pip._vendor.urllib3.contrib.securetransport as securetransport
+    securetransport.inject_into_urllib3()
 
 Happy TLSing!
 
 This code is a bastardised version of the code found in Will Bond's oscrypto
 library. An enormous debt is owed to him for blazing this trail for us. For
 that reason, this code should be considered to be covered both by urllib3's
 license and by oscrypto's:
```

#### pip/_vendor/urllib3/contrib/_securetransport/low_level.py

```diff
@@ -184,14 +184,15 @@
             CoreFoundation.CFArrayAppendValue(cert_array, cert)
             CoreFoundation.CFRelease(cert)
     except Exception:
         # We need to free the array before the exception bubbles further.
         # We only want to do that if an error occurs: otherwise, the caller
         # should free.
         CoreFoundation.CFRelease(cert_array)
+        raise
 
     return cert_array
 
 
 def _is_cert(item):
     """
     Returns True if a given CFTypeRef is a certificate.
```

#### pip/_vendor/urllib3/util/proxy.py

```diff
@@ -41,14 +41,15 @@
     Generates a default proxy ssl context if one hasn't been provided by the
     user.
     """
     ssl_context = create_urllib3_context(
         ssl_version=resolve_ssl_version(ssl_version),
         cert_reqs=resolve_cert_reqs(cert_reqs),
     )
+
     if (
         not ca_certs
         and not ca_cert_dir
         and not ca_cert_data
         and hasattr(ssl_context, "load_default_certs")
     ):
         ssl_context.load_default_certs()
```

#### Comparing `pip-21.2.4.dist-info/LICENSE.txt` & `pip-21.3.1.dist-info/LICENSE.txt`

 * *Files identical despite different names*

#### Comparing `pip-21.2.4.dist-info/METADATA` & `pip-21.3.1.dist-info/METADATA`

 * *Files 3% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: pip
-Version: 21.2.4
+Version: 21.3.1
 Summary: The PyPA recommended tool for installing Python packages.
 Home-page: https://pip.pypa.io/
 Author: The pip developers
 Author-email: distutils-sig@python.org
 License: MIT
 Project-URL: Documentation, https://pip.pypa.io
 Project-URL: Source, https://github.com/pypa/pip
@@ -17,14 +17,15 @@
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: Programming Language :: Python :: 3.6
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Programming Language :: Python :: Implementation :: PyPy
 Requires-Python: >=3.6
 License-File: LICENSE.txt
 
 pip - The Python Package Installer
 ==================================
```

#### Comparing `pip-21.2.4.dist-info/RECORD` & `pip-21.3.1.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,157 +1,159 @@
-pip/__init__.py,sha256=EkjFYKiNdO5r1TZT1K-GxPs3Bl2IdRXw75e7IVsKrmc,357
+pip/__init__.py,sha256=798yhPIf6eMHi7R5Ogb3BJ5ALJ0Id8IwEuOSU2DFlp0,357
 pip/__main__.py,sha256=mXwWDftNLMKfwVqKFWGE_uuBZvGSIiUELhLkeysIuZc,1198
 pip/py.typed,sha256=EBVvvPRTn_eIpz5e5QztSCdrMX7Qwd7VP93RSoIlZ2I,286
 pip/_internal/__init__.py,sha256=nnFCuxrPMgALrIDxSoy-H6Zj4W4UY60D-uL1aJyq0pc,573
-pip/_internal/build_env.py,sha256=uqtt1F0185ctzme5UX43I6bFHVeORY7q-dyhpkk5NDE,10121
-pip/_internal/cache.py,sha256=6VONtoReGZbBd7sqY1n6hwkdWC4iz3tmXwXwZjpjZKw,9958
-pip/_internal/configuration.py,sha256=QBLfhv-sbP-oR08NFxSYnv_mLB-SgtNOsWXAF9tDEcM,13725
-pip/_internal/exceptions.py,sha256=2JQJSS68oggR_ZIOA-h1U2DRADURbkQn9Nf4EZWZ834,13170
-pip/_internal/main.py,sha256=BZ0vkdqgpoteTo1A1Q8ovFe8EzgKFJWOUjPmIUQfGCY,351
-pip/_internal/pyproject.py,sha256=Sl1dOQYazG9AsrE0TXWK2zVcDR_FROshCTwjKBRQsPE,7063
-pip/_internal/self_outdated_check.py,sha256=ivoUYaGuq-Ra_DvlZvPtHhgbY97NKHYuPGzrgN2G1A8,6484
-pip/_internal/wheel_builder.py,sha256=hW63ZmABr65rOiSRBHXu1jBUdEZw5LZiw0LaQBbz0lI,11740
+pip/_internal/build_env.py,sha256=uIg4HJDgZK542FXVTl3jkPDNbklNgb8Rj6DeZef_oS8,9950
+pip/_internal/cache.py,sha256=71eaYwrls34HJ6gzbmmYiotiKhPNFTM_tqYJXD5nf3s,9441
+pip/_internal/configuration.py,sha256=dKHBEl8aXnqVuRB0NW7Nz7lyYMwr7XCfkMZvUORaSRo,13153
+pip/_internal/exceptions.py,sha256=XyfiRZn2X8WR61X-JF50BU72TdmVkneWPy9cnuKv2Rg,12762
+pip/_internal/main.py,sha256=r-UnUe8HLo5XFJz8inTcOOTiu_sxNhgHb6VwlGUllOI,340
+pip/_internal/pyproject.py,sha256=YgcyleTgyuh7NwGH9j8_21htqnF_VxgKiPc4ecLBWKk,7215
+pip/_internal/self_outdated_check.py,sha256=nVLSc0nl4JZ9VI7GsZvblE-zzT-T5ofmMgplned8s_s,6393
+pip/_internal/wheel_builder.py,sha256=ZakEA7CEJyp70yHoX0QLE8TAwM7vxF9PYPtjBxT3F1I,12247
 pip/_internal/cli/__init__.py,sha256=FkHBgpxxb-_gd6r1FjnNhfMOzAUYyXoXKJ6abijfcFU,132
 pip/_internal/cli/autocompletion.py,sha256=NK5yqe49SgExZOCFVEUT5Bf0QV2CuITGK27WSo2MWg8,6399
-pip/_internal/cli/base_command.py,sha256=Dq5oXBXYd24GaHs1vPt6CfYgCl22V_4tLEJqfQyBrdE,7596
-pip/_internal/cli/cmdoptions.py,sha256=xOqvgDNfpkMXVjy0mH3hI0HyczVD6wMuP8K44qsvbew,28283
+pip/_internal/cli/base_command.py,sha256=oFuvjLsYE17V67L1dHeTo-YePZN97RKpOuGEXwCKwLc,7790
+pip/_internal/cli/cmdoptions.py,sha256=o6hueHSc3VWZ-_do9eeoZKEaxqh18zlXKAzVZ00Kg-o,28391
 pip/_internal/cli/command_context.py,sha256=a1pBBvvGLDiZ1Kw64_4tT6HmRTwYDoYy8JFgG5Czn7s,760
 pip/_internal/cli/main.py,sha256=ioJ8IVlb2K1qLOxR-tXkee9lURhYV89CDM71MKag7YY,2472
 pip/_internal/cli/main_parser.py,sha256=Q9TnytfuC5Z2JSjBFWVGtEdYLFy7rukNIb04movHdAo,2614
 pip/_internal/cli/parser.py,sha256=CDXTuFr2UD8ozOlZYf1KDziQdo9-X_IaYOiUcyJQwrA,10788
 pip/_internal/cli/progress_bars.py,sha256=ha8wowclY8_PaoM0cz4G6qK37zjnzuxQ-ydOtzx4EMI,8300
-pip/_internal/cli/req_command.py,sha256=ZlxKFS9LtEbE1IRB6JyeUeYMe7lvKxVIzpdvag-BHok,16548
+pip/_internal/cli/req_command.py,sha256=La6J8YonTxoPtJ8HMPN4RTKyzg0VS_R4vxfVf_HmFZw,17097
 pip/_internal/cli/spinners.py,sha256=TFhjxtOnLeNJ5YmRvQm4eKPgPbJNkZiqO8jOXuxRaYU,5076
 pip/_internal/cli/status_codes.py,sha256=sEFHUaUJbqv8iArL3HAtcztWZmGOFX01hTesSytDEh0,116
-pip/_internal/commands/__init__.py,sha256=3f1ZVidEDfgmzAH7aypZLKOZUvUy7qxv4X1CiIZEN30,3776
-pip/_internal/commands/cache.py,sha256=O1grQjTg6IRFs_8DxMH00583tmCR0ujqTMv_gZ0h0uU,7237
-pip/_internal/commands/check.py,sha256=gPC6GTp7S9aK73IeZAW7Z6yxlMnWdMyDTq9er9nXpIY,1570
-pip/_internal/commands/completion.py,sha256=4Uh_cg04qDmtmgLji-J4VJKZ8BaIBZy2_uTWLi8tiVk,2914
-pip/_internal/commands/configuration.py,sha256=TK9VTXNJ5haVH0Dc_ylhqo6A9Q_GcNoNsAOMJff4MYY,8962
-pip/_internal/commands/debug.py,sha256=f943fbrAUufQ7flAR2zHfI0oi_uqhJEEW7Fj_EiwB1Y,6647
-pip/_internal/commands/download.py,sha256=VGyQ6TDLiqJqJXfJwr_D6ZuHnYfhmzZPQk1mRSQp3tQ,4949
-pip/_internal/commands/freeze.py,sha256=x0-ia-MFrVvfYqe5p6yAWqzaK5AIi3SqqcXBJNvxXkg,2785
-pip/_internal/commands/hash.py,sha256=Y5FQ_WgbuEFnJxyLZdNYP928BGWNyNm9ljIUr90R6tI,1664
-pip/_internal/commands/help.py,sha256=F_IJkERv9gGfGC6YpBNYm_qs8xmBphUCfOuguNRSqLs,1132
-pip/_internal/commands/index.py,sha256=xA5LSVy1kv-IAvsjIX6Wnk5ZHA0Y_m6AP9T5ZoUGs9o,4781
-pip/_internal/commands/install.py,sha256=FV-qBbQ56TUEmLDtuWTMeNpD4aQtOpjBEi7ePqlEtSM,27493
-pip/_internal/commands/list.py,sha256=fpG6_KYqtAEBV8uSlt_lfF7o1GTuS4UdobsZjVqZspQ,11753
-pip/_internal/commands/search.py,sha256=P8GY077JmUwy7FiOgYJ1CPDsBPgmo7it-b14luquJN4,5543
-pip/_internal/commands/show.py,sha256=2TxWaJ2saCDSVUVBoRYueijLiueid2DNOhZuM-jhGf0,7974
-pip/_internal/commands/uninstall.py,sha256=0VQQMfPBTGSlWJn1RRgvYtJhSj7tQFYc3H1kOjrstRE,3480
-pip/_internal/commands/wheel.py,sha256=UiH15NXfrJ9piFNg3oHm4n2Jyk9Ojv5q0MvrWbHB3Ac,6189
+pip/_internal/commands/__init__.py,sha256=Vc1HjsLEtyCh7506OozPHPKXe2Hk-z9cFkFF3BMj1lM,3736
+pip/_internal/commands/cache.py,sha256=p9gvc6W_xgxE2zO0o8NXqO1gGJEinEK42qEC-a7Cnuk,7524
+pip/_internal/commands/check.py,sha256=0gjXR7j36xJT5cs2heYU_dfOfpnFfzX8OoPNNoKhqdM,1685
+pip/_internal/commands/completion.py,sha256=kTG_I1VR3N5kGC4Ma9pQTSoY9Q1URCrNyseHSQ-rCL4,2958
+pip/_internal/commands/configuration.py,sha256=arE8vLstjBg-Ar1krXF-bBmT1qBtnL7Fpk-NVh38a0U,8944
+pip/_internal/commands/debug.py,sha256=krET-y45CnQzXwKR1qA3M_tJE4LE2vnQtm3yfGyDSnE,6629
+pip/_internal/commands/download.py,sha256=p4lmYDgawRrwDFUpde_-1Gld45FnsMNHUFtOWFUCcSE,4904
+pip/_internal/commands/freeze.py,sha256=gCjoD6foBZPBAAYx5t8zZLkJhsF_ZRtnb3dPuD7beO8,2951
+pip/_internal/commands/hash.py,sha256=EVVOuvGtoPEdFi8SNnmdqlCQrhCxV-kJsdwtdcCnXGQ,1703
+pip/_internal/commands/help.py,sha256=gcc6QDkcgHMOuAn5UxaZwAStsRBrnGSn_yxjS57JIoM,1132
+pip/_internal/commands/index.py,sha256=1VVXXj5MsI2qH-N7uniQQyVkg-KCn_RdjiyiUmkUS5U,4762
+pip/_internal/commands/install.py,sha256=HTWdTb72Bcrm2tA_d55_hX6yQbchnr_XRdA2Xs8uApU,27851
+pip/_internal/commands/list.py,sha256=SnCh19e5zQKonNP7j25c_xru0Wm7wWWF8j49f-Dy9Bw,12203
+pip/_internal/commands/search.py,sha256=sbBZiARRc050QquOKcCvOr2K3XLsoYebLKZGRi__iUI,5697
+pip/_internal/commands/show.py,sha256=OREbPHF6UzvQiGLC1UIjG52Kc_jYDgcXZMYzgKXMbBI,8064
+pip/_internal/commands/uninstall.py,sha256=DNTYAGJNljMO_YYBxrpcwj0FEl7lo_P55_98O6g2TNk,3526
+pip/_internal/commands/wheel.py,sha256=xGSwLPYUM7jP_McD-wnM4D3zsP0n-NSkHFp4d0mAWIg,6168
 pip/_internal/distributions/__init__.py,sha256=Hq6kt6gXBgjNit5hTTWLAzeCNOKoB-N0pGYSqehrli8,858
-pip/_internal/distributions/base.py,sha256=GynlnVE3QLvNu4JvnxPO6D8IQSs_GAlFUabA6U-G-eU,1206
-pip/_internal/distributions/installed.py,sha256=gT20WSniecOvKGMA-nCyq-4DcJlrIjv8jT-JEWyEOnA,645
-pip/_internal/distributions/sdist.py,sha256=VBme1UNlCuH_wIoUHTZq9ngo2NpFWQXmJqnwUb3ZpTk,3862
-pip/_internal/distributions/wheel.py,sha256=J7DNQvKS50pXfwXtetKZtLNgYzkEc8SAbaKQ5v6JHtA,1183
+pip/_internal/distributions/base.py,sha256=3FUYD8Gb4YuSu3pggC_FRctZBDbpm5ZK89tPksIUjoE,1172
+pip/_internal/distributions/installed.py,sha256=QObf6KALGtwGx-Ap3Ua5FfcfaRMXWOk_wcrm7n5gYII,767
+pip/_internal/distributions/sdist.py,sha256=3fsErGhAWdGzuO7Wea0F_8b9fKyUL1PoYet273OoAoM,5598
+pip/_internal/distributions/wheel.py,sha256=-NgzdIs-w_hcer_U81yzgpVTljJRg5m79xufqvbjv0s,1115
 pip/_internal/index/__init__.py,sha256=vpt-JeTZefh8a-FC22ZeBSXFVbuBcXSGiILhQZJaNpQ,30
-pip/_internal/index/collector.py,sha256=oH4XlYHvGMXePbjNhKZPpLI-NLBTXxpHRRZgQ85meNk,17645
-pip/_internal/index/package_finder.py,sha256=Zzto_P1YPeTlBjJTlPgU8wjocQDJnLYZxUSR8JxVf1E,36138
+pip/_internal/index/collector.py,sha256=7rhUeH0IU_dUMk13-lBAN9czRuJ6dbG76Un7xuQ36Ck,17534
+pip/_internal/index/package_finder.py,sha256=_N9LIcwAXbGDN3BUDlikSB93WI9PHv3MvkJ4YapfrPY,36344
 pip/_internal/index/sources.py,sha256=SVyPitv08-Qalh2_Bk5diAJ9GAA_d-a93koouQodAG0,6557
-pip/_internal/locations/__init__.py,sha256=8HvAnPCRi2Ln5yimpHRq8NVtsImh1KEvqsPhi4H56y0,13292
+pip/_internal/locations/__init__.py,sha256=CpH6Cz9HSZ0csN_KPtOcvS9TGYLb7ZNGtCAAmVtjXW0,14444
 pip/_internal/locations/_distutils.py,sha256=Sk7tw8ZP1DWMYJ8MibABsa8IME2Ejv1PKeGlYQCBTZc,5871
 pip/_internal/locations/_sysconfig.py,sha256=LQNKTJKyjVqxXaPntlBwdUqTG1xwYf6GVCKMbyRJx5M,7918
 pip/_internal/locations/base.py,sha256=x5D1ONktmPJd8nnUTh-ELsAJ7fiXA-k-0a_vhfi2_Us,1579
-pip/_internal/metadata/__init__.py,sha256=0XQDTWweYOV7kcMuzwoiCggu3wJearBNcK8JV9LXA6Y,1576
-pip/_internal/metadata/base.py,sha256=oRj58fKGutZKZCslfQlKfrzuXI_0M4w1xVOluT3-6TQ,7928
-pip/_internal/metadata/pkg_resources.py,sha256=xOYt6IluIDvVMgYX-QoZA3SFbToJlZDOVPRHVPJ2Uk4,5200
+pip/_internal/metadata/__init__.py,sha256=HzTS3lRukzn-MJaEZkUQhAFe6ulxvNe7nNoBvUzy-DU,1660
+pip/_internal/metadata/base.py,sha256=gbNbb9blWO5hejmror-2n4_wLuYVrTyqwUluY9OmnMg,11103
+pip/_internal/metadata/pkg_resources.py,sha256=-LiuojtAfl3yhNx8rnUKYN3ECBVCVcDWszCupithXAw,5089
 pip/_internal/models/__init__.py,sha256=3DHUd_qxpPozfzouoqa9g9ts1Czr5qaHfFxbnxriepM,63
-pip/_internal/models/candidate.py,sha256=b2aiufhD5jZEI0zhEaMn_o1VRldVE2J-MPsqPpcY2Ds,946
-pip/_internal/models/direct_url.py,sha256=x2-kAnrP18XAdOftYBStDNt3Zfd8sipef5h0h_efGvY,6262
-pip/_internal/models/format_control.py,sha256=t5nmFD43huIFj0VchV6FuvlaRHfaMTotbBOTOPBsKeY,2557
-pip/_internal/models/index.py,sha256=_U2imEWggevvcI7rhQCFZK0djsE-It13BJmvW9Ejmig,1058
-pip/_internal/models/link.py,sha256=chRRuGqeE5w1XqidCrw6j-j8O-eeCmw-HUdYCR18HmQ,9809
-pip/_internal/models/scheme.py,sha256=i2QGt5J96gMKC_Wm7xO587kibhhChUQoULhAFgPRxkE,738
-pip/_internal/models/search_scope.py,sha256=mykEee0wDNCx9xZmQBtkgVaDiQVcDNqbjAZGqI1nm78,4474
-pip/_internal/models/selection_prefs.py,sha256=OEoiP83Wpm7cUwjH7fnbRo7TzHl5D4y23W0JnZLXk_4,1877
-pip/_internal/models/target_python.py,sha256=7iT4lbRtoNRkwsmLndysJ4Ic7Iwp_YyIII3doXeLD8c,3870
-pip/_internal/models/wheel.py,sha256=Ec8fvPoSYeBX9cvBvffLM7gNRx23CrVud1dN3zJmBjc,3541
+pip/_internal/models/candidate.py,sha256=6pcABsaR7CfIHlbJbr2_kMkVJFL_yrYjTx6SVWUnCPQ,990
+pip/_internal/models/direct_url.py,sha256=7XtGQSLLDQb5ZywI2EMnnLcddtf5CJLx44lMtTHPxFw,6350
+pip/_internal/models/format_control.py,sha256=DJpMYjxeYKKQdwNcML2_F0vtAh-qnKTYe-CpTxQe-4g,2520
+pip/_internal/models/index.py,sha256=tYnL8oxGi4aSNWur0mG8DAP7rC6yuha_MwJO8xw0crI,1030
+pip/_internal/models/link.py,sha256=hoT_qsOBAgLBm9GKqpBrNF_mrEXeGXQE-aH_RX2cGgg,9817
+pip/_internal/models/scheme.py,sha256=3EFQp_ICu_shH1-TBqhl0QAusKCPDFOlgHFeN4XowWs,738
+pip/_internal/models/search_scope.py,sha256=LwloG0PJAmtI1hFXIypsD95kWE9xfR5hf_a2v1Vw7sk,4520
+pip/_internal/models/selection_prefs.py,sha256=KZdi66gsR-_RUXUr9uejssk3rmTHrQVJWeNA2sV-VSY,1907
+pip/_internal/models/target_python.py,sha256=qKpZox7J8NAaPmDs5C_aniwfPDxzvpkrCKqfwndG87k,3858
+pip/_internal/models/wheel.py,sha256=hN9Ub-m-cAJCajCcQHyQNsqpcDCbPPDlEzBDwaBMc14,3500
 pip/_internal/network/__init__.py,sha256=jf6Tt5nV_7zkARBrKojIXItgejvoegVJVKUbhAa5Ioc,50
-pip/_internal/network/auth.py,sha256=zq-fu-eK_EwiqjT0SVmMxuzyvhBlCdBGJi_fnOmcar8,11645
+pip/_internal/network/auth.py,sha256=a3C7Xaa8kTJjXkdi_wrUjqaySc8Z9Yz7U6QIbXfzMyc,12190
 pip/_internal/network/cache.py,sha256=HoprMCecwd4IS2wDZowc9B_OpaBlFjJYJl4xOxvtuwU,2100
 pip/_internal/network/download.py,sha256=VmiR-KKIBugShZS4JlD7N8mq3hErx-0fK-D8aTYU3Og,6016
-pip/_internal/network/lazy_wheel.py,sha256=4szChUW2I9quggvjEoIhALezmiVVteescGh6TDUslaQ,7615
-pip/_internal/network/session.py,sha256=3tJHNQCooM7bjLK1WP-q6tiJ84jtqkyrIdrYY84WR1A,16582
+pip/_internal/network/lazy_wheel.py,sha256=1b8ZJ1w4bSBzpGzGwJR_CL2yQ6AFIwWQkS1vbPPw2XU,7627
+pip/_internal/network/session.py,sha256=38IKGKC64MTVUIH5XOR1hr2pOCzp39RccykdmGAvqRU,16729
 pip/_internal/network/utils.py,sha256=igLlTu_-q0LmL8FdJKq-Uj7AT_owrQ-T9FfyarkhK5U,4059
 pip/_internal/network/xmlrpc.py,sha256=AzQgG4GgS152_cqmGr_Oz2MIXsCal-xfsis7fA7nmU0,1791
 pip/_internal/operations/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pip/_internal/operations/check.py,sha256=zEIdxyRL3vc7CQ1p8qkLFG-mjs-LjnaJDxOr1WI5Yp0,5295
-pip/_internal/operations/freeze.py,sha256=TyLvXT4ZqpIi8x8X_TTsgBJ76IG54CidJlxGIHBbmBM,10556
-pip/_internal/operations/prepare.py,sha256=jgnH7CIdoAhwnYOSpkESvhrJ1yr5TL2ZY5ojjSzRMZo,24848
+pip/_internal/operations/check.py,sha256=ca4O9CkPt9Em9sLCf3H0iVt1GIcW7M8C0U5XooaBuT4,5109
+pip/_internal/operations/freeze.py,sha256=ZiYw5GlUpLVx4VJHz4S1AP2JFNyvH0iq5kpcYj2ovyw,9770
+pip/_internal/operations/prepare.py,sha256=Dg-lFYsFhYeib8NuQvGOxd0wxcmTqXfe_c5zYb3ep64,23838
 pip/_internal/operations/build/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pip/_internal/operations/build/metadata.py,sha256=jJp05Rrp0AMsQb7izDXbNGC1LtPNwOhHQj7cRM5324c,1165
-pip/_internal/operations/build/metadata_legacy.py,sha256=ECMBhLEPEQv6PUUCpPCXW-wN9QRXdY45PNXJv7BZKTU,1917
-pip/_internal/operations/build/wheel.py,sha256=WYLMxuxqN3ahJTQk2MI9hdmZKBpFyxHeNpUdO0PybxU,1106
-pip/_internal/operations/build/wheel_legacy.py,sha256=NOJhTYMYljdbizFo_WjkaKGWG1SEZ6aByrBdCrrsZB8,3227
+pip/_internal/operations/build/metadata.py,sha256=KEsyrRFOBs2jhR-AcjyJyeV5GlsK1ubQqAB1j-b0Zu4,1119
+pip/_internal/operations/build/metadata_editable.py,sha256=RnA8UgQqZwtBjBdqi1DW1gI3xaZ7qhKp1Xd-0YTktSk,1177
+pip/_internal/operations/build/metadata_legacy.py,sha256=hjAJ75iKuJfKQYALZD0U6wJ7ElJ_BAEvjDxF8b9_l5k,1945
+pip/_internal/operations/build/wheel.py,sha256=AO9XnTGhTgHtZmU8Dkbfo1OGr41rBuSDjIgAa4zUKgE,1063
+pip/_internal/operations/build/wheel_editable.py,sha256=TVETY-L_M_dSEKBhTIcQOP75zKVXw8tuq1U354Mm30A,1405
+pip/_internal/operations/build/wheel_legacy.py,sha256=aFMVOvyG-_CAIuXEVxuPJkz5UfCppSeu9FBPzn2tWvI,3047
 pip/_internal/operations/install/__init__.py,sha256=mX7hyD2GNBO2mFGokDQ30r_GXv7Y_PLdtxcUv144e-s,51
-pip/_internal/operations/install/editable_legacy.py,sha256=bjBObfE6sz3UmGI7y4-GCgKa2WmTgnWlFFU7b-i0sQs,1396
-pip/_internal/operations/install/legacy.py,sha256=Wk_46sR7zDsh7vp4j63Hka4NTevQ617WdqJKt8_TuUQ,4405
-pip/_internal/operations/install/wheel.py,sha256=4Y6rtOpPnjlvGkzYXP8HXzqJu1KHEuA6ExgHBdZnD6s,29466
-pip/_internal/req/__init__.py,sha256=lz4GFfzm5gsm0e8H98Wi6IPI14R2JdDMBc61-4F-0CY,2831
-pip/_internal/req/constructors.py,sha256=35LRb-iaL01AlKBOO_2vrbKil6KI5Tl450NJwUvUnhk,15826
-pip/_internal/req/req_file.py,sha256=TsBSr0LMVIYF7AqkwslyJxHPLstN0SMqKeVxciI2In4,17408
-pip/_internal/req/req_install.py,sha256=jPfSPt-s3RoRCj6tYqvvHaxxIW1yr8KbiPRGbAyF3pU,31671
-pip/_internal/req/req_set.py,sha256=NoPQztL1Z5HZEB3n2Wtst6KV51hMDAPe9AfdAUWmJLs,7572
-pip/_internal/req/req_tracker.py,sha256=dJ3ql2C3VyaKUQN9kwbFvOPMxAvbTdblB0hKQ2f6Lns,4182
-pip/_internal/req/req_uninstall.py,sha256=wBcGKaweIyi5RGPPpBqrrn62t8uP3frZmrUJ-qDeO0Y,23821
+pip/_internal/operations/install/editable_legacy.py,sha256=J4VCOHvk_BgA_wG02WmlDtSWLwZJ5S_g9SXBkjYojaw,1298
+pip/_internal/operations/install/legacy.py,sha256=YKrZvH894Iqf2oEkYqF9O7CK1DjTgfZCP3R9Azpjeqo,4158
+pip/_internal/operations/install/wheel.py,sha256=QuQyCZE-XjuJjDYRixo40oUt2ucFhNmSrCbcXY7A9aE,27412
+pip/_internal/req/__init__.py,sha256=A7mUvT1KAcCYP3H7gUOTx2GRMlgoDur3H68Q0OJqM5A,2793
+pip/_internal/req/constructors.py,sha256=FVWkWeGt3fK0DTC3Gurd2jglp_Z10CK-abd6yM3HD-A,15285
+pip/_internal/req/req_file.py,sha256=5N8OTouPCof-305StC2YK9HBxQMw-xO46skRoBPbkZo,17421
+pip/_internal/req/req_install.py,sha256=N8xohvY6CIaVt6D1sU9VWv2muO9oPjixIDisqBXUr0E,33804
+pip/_internal/req/req_set.py,sha256=kHYiLvkKRx21WaLTwOI-54Ng0SSzZZ9SE7FD0PsfvYA,7584
+pip/_internal/req/req_tracker.py,sha256=jK7JDu-Wt73X-gqozrFtgJVlUlnQo0P4IQ4x4_gPlfM,4117
+pip/_internal/req/req_uninstall.py,sha256=Uf8Kx-PgoQIudFq9Y7sFP-uz_I6x1gEfPpJJxujOf14,23748
 pip/_internal/resolution/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pip/_internal/resolution/base.py,sha256=yATwIW1VbJkwkFJIgG3JQafndFDSZ50smc-Ao9-SoxI,557
+pip/_internal/resolution/base.py,sha256=qlmh325SBVfvG6Me9gc5Nsh5sdwHBwzHBq6aEXtKsLA,583
 pip/_internal/resolution/legacy/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pip/_internal/resolution/legacy/resolver.py,sha256=TZnGUay9WM2Uk0W3D48OA70U9cLYYGHxles1h9ELqSg,17552
+pip/_internal/resolution/legacy/resolver.py,sha256=Fr7bfTaKqXoaIfSte7mvFRLMb8pAaiozgydoHeIyiHI,18312
 pip/_internal/resolution/resolvelib/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pip/_internal/resolution/resolvelib/base.py,sha256=Yvgb2jf0l6S4C2rXAbjbpURYF6yjUgCdwDSrnpiZA8U,5290
-pip/_internal/resolution/resolvelib/candidates.py,sha256=RgCvLf1meDecmw9lfhG_AU5tN9ufaC0EDrcVOR2hgiA,18842
-pip/_internal/resolution/resolvelib/factory.py,sha256=N9telNB1arFV-4TqdGdh9KML8zfAWdMbqUSNip6HeEc,26859
-pip/_internal/resolution/resolvelib/found_candidates.py,sha256=ES3PNACh3ONwGAghPip2Vbgyy_e4baKmeEEHVQiq47g,5285
-pip/_internal/resolution/resolvelib/provider.py,sha256=fy139RDxPrsPmNLn6YrrjqhBOmeLY0aHEEdzZqS35aU,8420
-pip/_internal/resolution/resolvelib/reporter.py,sha256=Z06Xa4d9dTWbHNvXIBtBxDn4DHeQmlyW9MJAojkC_iU,2600
+pip/_internal/resolution/resolvelib/base.py,sha256=u1O4fkvCO4mhmu5i32xrDv9AX5NgUci_eYVyBDQhTIM,5220
+pip/_internal/resolution/resolvelib/candidates.py,sha256=5q66J90AoMKKwy1HsdXvEeleOJG8QkAbo8OidFekee0,18210
+pip/_internal/resolution/resolvelib/factory.py,sha256=GnjXkaWRbfjdtQJcjcmkXUyPIgjckCHTu6wkneDMck8,26806
+pip/_internal/resolution/resolvelib/found_candidates.py,sha256=hvL3Hoa9VaYo-qEOZkBi2Iqw251UDxPz-uMHVaWmLpE,5705
+pip/_internal/resolution/resolvelib/provider.py,sha256=HUMHvkU001rtlqvs11NPmMtlyMMLlVQfAl6qXdsLxZQ,9205
+pip/_internal/resolution/resolvelib/reporter.py,sha256=3ZVVYrs5PqvLFJkGLcuXoMK5mTInFzl31xjUpDBpZZk,2526
 pip/_internal/resolution/resolvelib/requirements.py,sha256=pcsnwz7txyDNZUEOWJOZEfivy3COWHPf_DIU7fwZ-Kk,5455
-pip/_internal/resolution/resolvelib/resolver.py,sha256=Rry36d0uCKobfBnSPYMw8WStyNYtjAEFz3j6ZtBsbGQ,10523
+pip/_internal/resolution/resolvelib/resolver.py,sha256=bkrMZs_jJHP_KFAbg36-lcN4Ums7ESgllup8piHXOz0,9580
 pip/_internal/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pip/_internal/utils/_log.py,sha256=-jHLOE_THaZz5BFcCnoSL9EYAtJ0nXem49s9of4jvKw,1015
-pip/_internal/utils/appdirs.py,sha256=CyH0arjhfR4kaeybXs5B1hxe66KeeCfssJhiRFxpFJk,1185
+pip/_internal/utils/appdirs.py,sha256=swgcTKOm3daLeXTW6v5BUS2Ti2RvEnGRQYH_yDXklAo,1665
 pip/_internal/utils/compat.py,sha256=ACyBfLgj3_XG-iA5omEDrXqDM0cQKzi8h8HRBInzG6Q,1884
-pip/_internal/utils/compatibility_tags.py,sha256=h2P4U0ZCkWHwPYveBzFZA79it6agElRhm6yci7S8MCo,5454
+pip/_internal/utils/compatibility_tags.py,sha256=ydin8QG8BHqYRsPY4OL6cmb44CbqXl1T0xxS97VhHkk,5377
 pip/_internal/utils/datetime.py,sha256=m21Y3wAtQc-ji6Veb6k_M5g6A0ZyFI4egchTdnwh-pQ,242
-pip/_internal/utils/deprecation.py,sha256=0bdiuvnAcAZMp1dDrwxK7uDgmJQDHVfb1790_ypO9U4,3200
-pip/_internal/utils/direct_url_helpers.py,sha256=5ffB9GHoqalUvSU6C53lEFdUgYcWAbXJGfyCwGyIlrY,2994
+pip/_internal/utils/deprecation.py,sha256=NKo8VqLioJ4nnXXGmW4KdasxF90EFHkZaHeX1fT08C8,3627
+pip/_internal/utils/direct_url_helpers.py,sha256=6F1tc2rcKaCZmgfVwsE6ObIe_Pux23mUVYA-2D9wCFc,3206
 pip/_internal/utils/distutils_args.py,sha256=mcAscyp80vTt3xAGTipnpgc83V-_wCvydNELVXLq7JI,1249
+pip/_internal/utils/egg_link.py,sha256=5MVlpz5LirT4iLQq86OYzjXaYF0D4Qk1dprEI7ThST4,2203
 pip/_internal/utils/encoding.py,sha256=bdZ3YgUpaOEBI5MP4-DEXiQarCW3V0rxw1kRz-TaU1Q,1169
 pip/_internal/utils/entrypoints.py,sha256=aPvCnQVi9Hdk35Kloww_D5ibjUpqxgqcJP8O9VuMZek,1055
 pip/_internal/utils/filesystem.py,sha256=rrl-rY1w8TYyKYndUyZlE9ffkQyA4-jI9x_59zXkn5s,5893
-pip/_internal/utils/filetypes.py,sha256=weviVbapHWVQ_8-K-PTQ_TnYL66kZi4SrVBTmRYZXLc,761
-pip/_internal/utils/glibc.py,sha256=GM1Y2hWkOf_tumySGFg-iNbc7oilBQQrjczb_705CF8,3170
-pip/_internal/utils/hashes.py,sha256=o1qQEkqe2AqsRm_JhLoM4hkxmVtewH0ZZpQ6EBObHuU,5167
-pip/_internal/utils/inject_securetransport.py,sha256=tGl9Bgyt2IHKtB3b0B-6r3W2yYF3Og-PBe0647S3lZs,810
-pip/_internal/utils/logging.py,sha256=E5VE1n-pqgdd5DajPQPKpmu7VpJVd7dAhhdjPZNsYjE,12344
-pip/_internal/utils/misc.py,sha256=WhWMKbtoBWvGrqVMaPekKML-orsLnD2e0N83arjpYQw,23644
-pip/_internal/utils/models.py,sha256=qCgYyUw2mIH1pombsJ3YQsMtONZgyJ4BGwO5MJnSC4c,1329
-pip/_internal/utils/packaging.py,sha256=I1938AB7FprcVJJd6C0vSiMuCVajmrxZF55vX5j0bMo,2900
-pip/_internal/utils/parallel.py,sha256=RZF4JddPEWVbkkPCknfvpqaLfm3Pmqd_ABoCHmV4lXs,3224
-pip/_internal/utils/pkg_resources.py,sha256=jwH5JViPe-JlXLvLC0-ASfTTCRYvm0u9CwQGcWjxStI,1106
-pip/_internal/utils/setuptools_build.py,sha256=xk9sRBjUyNTHs_TvEWebVWs1GfLPN208MzpSXr9Ok_A,5047
-pip/_internal/utils/subprocess.py,sha256=7QOQPJj6ezIVsypJJrcyyq4-mJM9qUsOdOLq0_wUiAA,10043
-pip/_internal/utils/temp_dir.py,sha256=9gs3N9GQeVXRVWjJIalSpH1uj8yQXPTzarb5n1_HMVo,7950
-pip/_internal/utils/unpacking.py,sha256=_qYZgmq8b0rRAN2swXsf9VfPogrjShlsTvhRI2heBYI,9050
-pip/_internal/utils/urls.py,sha256=O5f4VeKJ9cWt_CKqqKmiDTW48uOzo0UNb1QWPQ0n2TI,1798
-pip/_internal/utils/virtualenv.py,sha256=iRTK-sD6bWpHqXcZ0ECfdpFLWatMOHFUVCIRa0L6Gu0,3564
-pip/_internal/utils/wheel.py,sha256=DOIVZaXN7bMOAeMEqzIOZHGl4OFO-KGrEqBUB848DPo,6290
+pip/_internal/utils/filetypes.py,sha256=i8XAQ0eFCog26Fw9yV0Yb1ygAqKYB1w9Cz9n0fj8gZU,716
+pip/_internal/utils/glibc.py,sha256=tDfwVYnJCOC0BNVpItpy8CGLP9BjkxFHdl0mTS0J7fc,3110
+pip/_internal/utils/hashes.py,sha256=anpZfFGIT6HcIj2td9NHtE8AWg6GeAIhwpP8GPvZE0E,4811
+pip/_internal/utils/inject_securetransport.py,sha256=o-QRVMGiENrTJxw3fAhA7uxpdEdw6M41TjHYtSVRrcg,795
+pip/_internal/utils/logging.py,sha256=oEkBvjj2A6NtVo75_Q-sL7qqH0bMFuY0pK4d8t40SKg,11532
+pip/_internal/utils/misc.py,sha256=HfMsfc9LQbjNlf_EdYm79Ggxb63Nd9WOfoZSW3H4wmo,20432
+pip/_internal/utils/models.py,sha256=5GoYU586SrxURMvDn_jBMJInitviJg4O5-iOU-6I0WY,1193
+pip/_internal/utils/packaging.py,sha256=wA29RPW_KkorI2PIfkm9cWCytpcVbk-wubwUE8YTmbQ,2952
+pip/_internal/utils/parallel.py,sha256=Z-vNgYsyiAx8JfZYbD6ZSzkkPfpk0ANQI_YpCBE0Pxo,3196
+pip/_internal/utils/pkg_resources.py,sha256=A7HUm5lSk7n1_7qypyI4QkXErXgb5iXDlKPXo8r_1Hk,987
+pip/_internal/utils/setuptools_build.py,sha256=yDrfmxUgd0A9SDKV-7UuSTA3YLmVav5J86G9Fym-2FE,4697
+pip/_internal/utils/subprocess.py,sha256=cy2c6XRuYkX3XJF_lIjY5nQL2XygBHLJr6WXwTsjfnc,10058
+pip/_internal/utils/temp_dir.py,sha256=zob3PYMVevONkheOMUp_4jDofrEY3HIu5DHK78cSspI,7662
+pip/_internal/utils/unpacking.py,sha256=HUFlMEyCa9dPwdLh6sWeh95DeKytV8rsOyKShEw9y6g,8906
+pip/_internal/utils/urls.py,sha256=AhaesUGl-9it6uvG6fsFPOr9ynFpGaTMk4t5XTX7Z_Q,1759
+pip/_internal/utils/virtualenv.py,sha256=4_48qMzCwB_F5jIK5BC_ua7uiAMVifmQWU9NdaGUoVA,3459
+pip/_internal/utils/wheel.py,sha256=YwsLfuDzPJhFLuGotZ69i0bxJVGSweGuIHG2SxZvZtM,6163
 pip/_internal/vcs/__init__.py,sha256=UAqvzpbi0VbZo3Ub6skEeZAw-ooIZR-zX_WpCbxyCoU,596
-pip/_internal/vcs/bazaar.py,sha256=Ay_vN-87vYSEzBqXT3RVwl40vlk56j3jy_AfQbMj4uo,2962
-pip/_internal/vcs/git.py,sha256=VDSzQlkh1390xw6PMh6fneJAZyc1s9qHZgum3wO3DOU,17347
-pip/_internal/vcs/mercurial.py,sha256=WwoTWZQdQN9FcUTINvIeb0Vt46UJ_lLdf2BAdea9Tic,5076
-pip/_internal/vcs/subversion.py,sha256=FRMYx7q-b6skWuv6IU7tJyC8Jm8PPblMnH7WN_ucXWU,11866
-pip/_internal/vcs/versioncontrol.py,sha256=jMKitwE4bQ45jOKKomBxgBypm2TcuDGWWdTUmPa-MUQ,23276
-pip/_vendor/__init__.py,sha256=eE_yoHELq6Kw--WqhAEcKkvHLKbmTR1-JX_Th1wcNZc,4703
-pip/_vendor/appdirs.py,sha256=M6IYRJtdZgmSPCXCSMBRB0VT3P8MdFbWCDbSLrB2Ebg,25907
-pip/_vendor/distro.py,sha256=xxMIh2a3KmippeWEHzynTdHT3_jZM0o-pos0dAWJROM,43628
+pip/_internal/vcs/bazaar.py,sha256=pNMHrCLx1jSJzu1t1ycDVwhXQ23XI4Q483cvewaTUDs,2857
+pip/_internal/vcs/git.py,sha256=Ph_hThbfTG040GpJRz1z0ByiNkj5eHgF_shCCbNnCw0,17804
+pip/_internal/vcs/mercurial.py,sha256=Mtk-Bqjnp3wlaOdHfNSxq86vgCwNc3-df6UqgIXvMjE,4945
+pip/_internal/vcs/subversion.py,sha256=h4_nYmYN9kcfeTPp9wjkHhIeTpFZwoCp1UVm4hbBq90,11596
+pip/_internal/vcs/versioncontrol.py,sha256=W1zLW32PeuYiCV1I_dhqlk_n74B_GFTjNC5xdxs-1Ek,22414
+pip/_vendor/__init__.py,sha256=xjcBX0EP50pkaMdCssrsBXoZgo2hTtYxlcH1CIyA3T4,4708
+pip/_vendor/distro.py,sha256=O1EeHMq1-xAO373JI2_6pYEtd09yEkxtmrYkdY-9S-w,48414
 pip/_vendor/pyparsing.py,sha256=J1b4z3S_KwyJW7hKGnoN-hXW9pgMIzIP6QThyY5yJq4,273394
 pip/_vendor/six.py,sha256=TOOfQi7nFGfMrIvtdr6wX4wyHH8M7aknmuLfo2cBBrM,34549
-pip/_vendor/vendor.txt,sha256=GuFhR0DHZazrSYZyoY7j3X3T_mGJh-ky2opcZ-A7ezo,364
+pip/_vendor/vendor.txt,sha256=vux9Tgc3pSRZZnXz9TNDdn514NdkDdnb-QPC0LCHkK4,432
 pip/_vendor/cachecontrol/__init__.py,sha256=pJtAaUxOsMPnytI1A3juAJkXYDr8krdSnsg4Yg3OBEg,302
 pip/_vendor/cachecontrol/_cmd.py,sha256=URGE0KrA87QekCG3SGPatlSPT571dZTDjNa-ZXX3pDc,1295
 pip/_vendor/cachecontrol/adapter.py,sha256=sSwaSYd93IIfCFU4tOMgSo6b2LCt_gBSaQUj8ktJFOA,4882
 pip/_vendor/cachecontrol/cache.py,sha256=1fc4wJP8HYt1ycnJXeEw5pCpeBL2Cqxx6g9Fb0AYDWQ,805
 pip/_vendor/cachecontrol/compat.py,sha256=kHNvMRdt6s_Xwqq_9qJmr9ou3wYMOMUMxPPcwNxT8Mc,695
 pip/_vendor/cachecontrol/controller.py,sha256=CWEX3pedIM9s60suf4zZPtm_JvVgnvogMGK_OiBG5F8,14149
 pip/_vendor/cachecontrol/filewrapper.py,sha256=vACKO8Llzu_ZWyjV1Fxn1MA4TGU60N5N3GSrAFdAY2Q,2533
@@ -210,31 +212,33 @@
 pip/_vendor/chardet/metadata/languages.py,sha256=41tLq3eLSrBEbEVVQpVGFq9K7o1ln9b1HpY1l0hCUQo,19474
 pip/_vendor/colorama/__init__.py,sha256=pCdErryzLSzDW5P-rRPBlPLqbBtIRNJB6cMgoeJns5k,239
 pip/_vendor/colorama/ansi.py,sha256=Top4EeEuaQdBWdteKMEcGOTeKeF19Q-Wo_6_Cj5kOzQ,2522
 pip/_vendor/colorama/ansitowin32.py,sha256=yV7CEmCb19MjnJKODZEEvMH_fnbJhwnpzo4sxZuGXmA,10517
 pip/_vendor/colorama/initialise.py,sha256=PprovDNxMTrvoNHFcL2NZjpH2XzDc8BLxLxiErfUl4k,1915
 pip/_vendor/colorama/win32.py,sha256=bJ8Il9jwaBN5BJ8bmN6FoYZ1QYuMKv2j8fGrXh7TJjw,5404
 pip/_vendor/colorama/winterm.py,sha256=2y_2b7Zsv34feAsP67mLOVc-Bgq51mdYGo571VprlrM,6438
-pip/_vendor/distlib/__init__.py,sha256=bHNWOvZsLE4ES9S4FEA8CyP-rDYzatVgp9GHbpTnb2I,581
-pip/_vendor/distlib/compat.py,sha256=ADA56xiAxar3mU6qemlBhNbsrFPosXRhO44RzsbJPqk,41408
+pip/_vendor/distlib/__init__.py,sha256=HTGLP7dnTRTQCbEZNGUxBq-0sobr0KQUMn3yd6uEObA,581
+pip/_vendor/distlib/compat.py,sha256=fbsxc5PfJ2wBx1K4k6mQ2goAYs-GZW0tcOPIlE_vf0I,41495
 pip/_vendor/distlib/database.py,sha256=Kl0YvPQKc4OcpVi7k5cFziydM1xOK8iqdxLGXgbZHV4,51059
 pip/_vendor/distlib/index.py,sha256=UfcimNW19AB7IKWam4VaJbXuCBvArKfSxhV16EwavzE,20739
 pip/_vendor/distlib/locators.py,sha256=AKlB3oZvfOTg4E0CtfwOzujFL19X5V4XUA4eHdKOu44,51965
 pip/_vendor/distlib/manifest.py,sha256=nQEhYmgoreaBZzyFzwYsXxJARu3fo4EkunU163U16iE,14811
-pip/_vendor/distlib/markers.py,sha256=OunMSH1SIbvLLt4z2VEERCll4WNlz2tDrg1mSXCNUj4,4344
+pip/_vendor/distlib/markers.py,sha256=9c70ISEKwBjmUOHuIdOygVnRVESOKdNYp9a2TVn4qrI,4989
 pip/_vendor/distlib/metadata.py,sha256=vatoxFdmBr6ie-sTVXVNPOPG3uwMDWJTnEECnm7xDCw,39109
 pip/_vendor/distlib/resources.py,sha256=LwbPksc0A1JMbi6XnuPdMBUn83X7BPuFNWqPGEKI698,10820
-pip/_vendor/distlib/scripts.py,sha256=YD5_kioPD-qybYwQ4Gxyu-FR4ffxczy2gdBuU4II9qA,17248
+pip/_vendor/distlib/scripts.py,sha256=tjSwENINeV91ROZxec5zTSMRg2jEeKc4enyCHDzNvEE,17720
 pip/_vendor/distlib/t32.exe,sha256=NS3xBCVAld35JVFNmb-1QRyVtThukMrwZVeXn4LhaEQ,96768
+pip/_vendor/distlib/t64-arm.exe,sha256=8WGDh6aI8WJAjngRNQpyJpB21Sv20PCYYFSNW1fWd6w,180736
 pip/_vendor/distlib/t64.exe,sha256=oAqHes78rUWVM0OtVqIhUvequl_PKhAhXYQWnUf7zR0,105984
-pip/_vendor/distlib/util.py,sha256=eIKKJ5Mp4unHMOVzixRIRxGq4ty5-h_PoFmZ_lpvkkM,67558
-pip/_vendor/distlib/version.py,sha256=_geOv-cHoV-G8dQzKI8g6z8F0XeFeUqdJ_1G1K6iyrQ,23508
+pip/_vendor/distlib/util.py,sha256=0Uq_qa63FCLtdyNdWvMnmPbiSvVa-ykHM2E8HT7LSIU,67766
+pip/_vendor/distlib/version.py,sha256=WG__LyAa2GwmA6qSoEJtvJE8REA1LZpbSizy8WvhJLk,23513
 pip/_vendor/distlib/w32.exe,sha256=lJtnZdeUxTZWya_EW5DZos_K5rswRECGspIl8ZJCIXs,90112
+pip/_vendor/distlib/w64-arm.exe,sha256=Q_HdzVu9zxYdaBa3m0iJ5_ddLOEqtPe8x30WADoXza8,166400
 pip/_vendor/distlib/w64.exe,sha256=0aRzoN2BO9NWW4ENy4_4vHkHR4qZTFZNVSAJJYlODTI,99840
-pip/_vendor/distlib/wheel.py,sha256=W6aQQo2Si0CzWiCaqlS-Nu8CoHnDbmcGMqRxCHJmg_Q,43062
+pip/_vendor/distlib/wheel.py,sha256=pj5VVCjqZMcHvgizORWwAFPS7hOk61CZ59dxP8laQ4E,42943
 pip/_vendor/distlib/_backport/__init__.py,sha256=bqS_dTOH6uW9iGgd0uzfpPjo6vZ4xpPZ7kyfZJ2vNaw,274
 pip/_vendor/distlib/_backport/misc.py,sha256=KWecINdbFNOxSOP1fGF680CJnaC6S4fBRgEtaYTw0ig,971
 pip/_vendor/distlib/_backport/shutil.py,sha256=IX_G2NPqwecJibkIDje04bqu0xpHkfSQ2GaGdEVqM5Y,25707
 pip/_vendor/distlib/_backport/sysconfig.cfg,sha256=swZKxq9RY5e9r3PXCrlvQPMsvOdiWZBTHLEbqS8LJLU,2617
 pip/_vendor/distlib/_backport/sysconfig.py,sha256=BQHFlb6pubCl_dvT1NjtzIthylofjKisox239stDg0U,26854
 pip/_vendor/distlib/_backport/tarfile.py,sha256=Ihp7rXRcjbIKw8COm9wSePV9ARGXbSF9gGXAMn2Q-KU,92628
 pip/_vendor/html5lib/__init__.py,sha256=BYzcKCqeEii52xDrqBFruhnmtmkiuHXFyFh-cglQ8mk,1160
@@ -290,31 +294,40 @@
 pip/_vendor/packaging/_structures.py,sha256=TMiAgFbdUOPmIfDIfiHc3KFhSJ8kMjof2QS5I-2NyQ8,1629
 pip/_vendor/packaging/markers.py,sha256=AJBOcY8Oq0kYc570KuuPTkvuqjAlhufaE2c9sCUbm64,8487
 pip/_vendor/packaging/requirements.py,sha256=NtDlPBtojpn1IUC85iMjPNsUmufjpSlwnNA-Xb4m5NA,4676
 pip/_vendor/packaging/specifiers.py,sha256=MZ-fYcNL3u7pNrt-6g2EQO7AbRXkjc-SPEYwXMQbLmc,30964
 pip/_vendor/packaging/tags.py,sha256=akIerYw8W0sz4OW9HHozgawWnbt2GGOPm3sviW0jowY,15714
 pip/_vendor/packaging/utils.py,sha256=dJjeat3BS-TYn1RrUFVwufUMasbtzLfYRoy_HXENeFQ,4200
 pip/_vendor/packaging/version.py,sha256=_fLRNrFrxYcHVfyo8vk9j8s6JM8N_xsSxVFr6RJyco8,14665
-pip/_vendor/pep517/__init__.py,sha256=qDgVbDWpBYpTvtxA2tilifXlxwzOzRqIodLZdbyahyQ,130
-pip/_vendor/pep517/build.py,sha256=MqN_W6o5a9oauTC0u6W5cILGFjf9x2BV9BdMLeY60hc,3469
-pip/_vendor/pep517/check.py,sha256=AYG2yvpzmtsL810c75Z5-nhaXa7SxgK8APyw-_x53Ok,6096
+pip/_vendor/pep517/__init__.py,sha256=Y1bATL2qbFNN6M_DQa4yyrwqjpIiL-j9T6kBmR0DS14,130
+pip/_vendor/pep517/build.py,sha256=2bar6EdjwIz2Dlfy94qdxn3oA9mVnnny40mfoT5f-qI,3457
+pip/_vendor/pep517/check.py,sha256=bCORq1WrHjhpTONa-zpAqG0EB9rHNuhO1ORu6DsDuL8,6084
 pip/_vendor/pep517/colorlog.py,sha256=Tk9AuYm_cLF3BKTBoSTJt9bRryn0aFojIQOwbfVUTxQ,4098
-pip/_vendor/pep517/compat.py,sha256=fw2Py6lqLwJLfp6MKmXvt1m4sbbgoU1D-_gcScvz8OU,1071
+pip/_vendor/pep517/compat.py,sha256=NmLImE5oiDT3gbEhJ4w7xeoMFcpAPrGu_NltBytSJUY,1253
 pip/_vendor/pep517/dirtools.py,sha256=2mkAkAL0mRz_elYFjRKuekTJVipH1zTn4tbf1EDev84,1129
-pip/_vendor/pep517/envbuild.py,sha256=LcST0MASmcQNLOFqDPxDoS1kjkglx8F6eEhoBJ-DWkg,6112
+pip/_vendor/pep517/envbuild.py,sha256=zFde--rmzjXMLXcm7SA_3hDtgk5VCTA8hjpk88RbF6E,6100
 pip/_vendor/pep517/meta.py,sha256=8mnM5lDnT4zXQpBTliJbRGfesH7iioHwozbDxALPS9Y,2463
-pip/_vendor/pep517/wrappers.py,sha256=qCWfEUnbE5387PyQl7cT8xv4dDca4uNgro_0bnAO4Rk,13258
+pip/_vendor/pep517/wrappers.py,sha256=impq7Cz_LL1iDF1iiOzYWB4MaEu6O6Gps7TJ5qsJz1Q,13429
 pip/_vendor/pep517/in_process/__init__.py,sha256=MyWoAi8JHdcBv7yXuWpUSVADbx6LSB9rZh7kTIgdA8Y,563
-pip/_vendor/pep517/in_process/_in_process.py,sha256=YJJf-qaL7BBVdgCHuMhTpx-LtwG1EIGVfly4rtusdiI,10833
-pip/_vendor/pkg_resources/__init__.py,sha256=XpGBfvS9fafA6bm5rx7vnxdxs7yqyoc_NnpzKApkJ64,108277
+pip/_vendor/pep517/in_process/_in_process.py,sha256=D3waguyNSGcwosociD5USfcycYr2RCzCjYtxX5UHQmQ,11201
+pip/_vendor/pkg_resources/__init__.py,sha256=NnpQ3g6BCHzpMgOR_OLBmYtniY4oOzdKpwqghfq_6ug,108287
 pip/_vendor/pkg_resources/py31compat.py,sha256=CRk8fkiPRDLsbi5pZcKsHI__Pbmh_94L8mr9Qy9Ab2U,562
-pip/_vendor/progress/__init__.py,sha256=fcbQQXo5np2CoQyhSH5XprkicwLZNLePR3uIahznSO0,4857
-pip/_vendor/progress/bar.py,sha256=QuDuVNcmXgpxtNtxO0Fq72xKigxABaVmxYGBw4J3Z_E,2854
-pip/_vendor/progress/counter.py,sha256=MznyBrvPWrOlGe4MZAlGUb9q3aODe6_aNYeAE_VNoYA,1372
-pip/_vendor/progress/spinner.py,sha256=k8JbDW94T0-WXuXfxZIFhdoNPYp3jfnpXqBnfRv5fGs,1380
+pip/_vendor/platformdirs/__init__.py,sha256=3iz938Grn-6IRg8gSuMxJtgiBfH0xqRqAlMBo-vPGUw,12859
+pip/_vendor/platformdirs/__main__.py,sha256=SzGvNkYWuosrWXs2yL2VqcXEh-kivWq3-53-BpTco0o,1140
+pip/_vendor/platformdirs/android.py,sha256=dadYfG2oc900YVi5AONQWw2WEvk-kmgkZs5iiNSiWiE,3994
+pip/_vendor/platformdirs/api.py,sha256=yhRR6RkcZzPBfJD4Sn90vCHZbRMQ9nwtnRaa93X1wR8,4922
+pip/_vendor/platformdirs/macos.py,sha256=vIowPYKkHksJcWVjqHQoa-oI1i2D0S7gsSdyFzZDJEA,2619
+pip/_vendor/platformdirs/unix.py,sha256=7JdDnsyTFn2IHC8IFdiNYH7_R8VS-rPx8ivh4_dT1DU,6905
+pip/_vendor/platformdirs/version.py,sha256=uUssQTtUqVP-PxbOSNBzNGRW27X5u1GvOllg--kzyuw,80
+pip/_vendor/platformdirs/windows.py,sha256=91nNccR0CSxX_myMppSvUT1qtQao6kaO96e6ior8-Xw,6416
+pip/_vendor/progress/__init__.py,sha256=1HejNZtv2ouUNQeStUDAtZrtwkz_3FmYKQ476hJ7zOs,5294
+pip/_vendor/progress/bar.py,sha256=GbedY0oZ-Q1duXjmvVLO0tSf-uTSH7hJ3zzyI91Esws,2942
+pip/_vendor/progress/colors.py,sha256=cCYXQnYFYVmQKKmYEbQ_lj6SPSFzdw4FN98F2x2kR-U,2655
+pip/_vendor/progress/counter.py,sha256=zYt9DWH0_05s8Q9TrJwHVud-WwsyyaR3PwYtk5hxwwQ,1613
+pip/_vendor/progress/spinner.py,sha256=u5ElzW94XEiLGH-aAlr54VJtKfeK745xr6UfGvvflzU,1461
 pip/_vendor/requests/__init__.py,sha256=g4Bh1QYh6JKjMS4YLobx0uOLq-41sINaXjvbhX2VI8g,5113
 pip/_vendor/requests/__version__.py,sha256=PZEyPTSIN_jRIAIB51wV7pw81m3qAw0InSR7OrKZUnE,441
 pip/_vendor/requests/_internal_utils.py,sha256=Zx3PnEUccyfsB-ie11nZVAW8qClJy0gx1qNME7rgT18,1096
 pip/_vendor/requests/adapters.py,sha256=e-bmKEApNVqFdylxuMJJfiaHdlmS_zhWhIMEzlHvGuc,21548
 pip/_vendor/requests/api.py,sha256=hjuoP79IAEmX6Dysrw8t032cLfwLHxbI_wM4gC5G9t0,6402
 pip/_vendor/requests/auth.py,sha256=OMoJIVKyRLy9THr91y8rxysZuclwPB-K1Xg1zBomUhQ,10207
 pip/_vendor/requests/certs.py,sha256=nXRVq9DtGmv_1AYbwjTu9UrgAcdJv05ZvkNeaoLOZxY,465
@@ -325,18 +338,18 @@
 pip/_vendor/requests/hooks.py,sha256=QReGyy0bRcr5rkwCuObNakbYsc7EkiKeBwG4qHekr2Q,757
 pip/_vendor/requests/models.py,sha256=9_LS_t1t6HbbaWFE3ZkxGmmHN2V8BgxziiOU84rrQ50,34924
 pip/_vendor/requests/packages.py,sha256=njJmVifY4aSctuW3PP5EFRCxjEwMRDO6J_feG2dKWsI,695
 pip/_vendor/requests/sessions.py,sha256=57O4ud9yRL6eLYh-dtFbqC1kO4d_EwZcCgYXEkujlfs,30168
 pip/_vendor/requests/status_codes.py,sha256=gT79Pbs_cQjBgp-fvrUgg1dn2DQO32bDj4TInjnMPSc,4188
 pip/_vendor/requests/structures.py,sha256=msAtr9mq1JxHd-JRyiILfdFlpbJwvvFuP3rfUQT_QxE,3005
 pip/_vendor/requests/utils.py,sha256=U_-i6WxLw-67KEij43xHbcvL0DdeQ5Jbd4hfifWJzQY,31394
-pip/_vendor/resolvelib/__init__.py,sha256=uoW0dgWCDwApX59mRffoPISkZGGk_UZ1It_PY4o_PaE,537
-pip/_vendor/resolvelib/providers.py,sha256=bfzFDZd7UqkkAS7lUM_HeYbA-HzjKfDlle_pn_79vio,5638
+pip/_vendor/resolvelib/__init__.py,sha256=fzWkeoLV8ol6l2fvBVRZZLylOePc9w9tKRvUb8RJsCY,537
+pip/_vendor/resolvelib/providers.py,sha256=roVmFBItQJ0TkhNua65h8LdNny7rmeqVEXZu90QiP4o,5872
 pip/_vendor/resolvelib/reporters.py,sha256=hQvvXuuEBOyEWO8KDfLsWKVjX55UFMAUwO0YZMNpzAw,1364
-pip/_vendor/resolvelib/resolvers.py,sha256=wT83PHiBWRCklL-nLJ1-8sk2B3yBI06Rse1H11crOsI,17225
+pip/_vendor/resolvelib/resolvers.py,sha256=UjFUEVrUa1hCzfEEakmjHEjYAL9J5ACJmwZyHFdmzvE,17540
 pip/_vendor/resolvelib/structs.py,sha256=IVIYof6sA_N4ZEiE1C1UhzTX495brCNnyCdgq6CYq28,4794
 pip/_vendor/resolvelib/compat/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pip/_vendor/resolvelib/compat/collections_abc.py,sha256=uy8xUZ-NDEw916tugUXm8HgwCGiMO0f-RcdnpkfXfOs,156
 pip/_vendor/tenacity/__init__.py,sha256=GLLsTFD4Bd5VDgTR6mU_FxyOsrxc48qONorVaRebeD4,18257
 pip/_vendor/tenacity/_asyncio.py,sha256=HEb0BVJEeBJE9P-m9XBxh1KcaF96BwoeqkJCL5sbVcQ,3314
 pip/_vendor/tenacity/_utils.py,sha256=-y68scDcyoqvTJuJJ0GTfjdSCljEYlbCYvgk7nM4NdM,1944
 pip/_vendor/tenacity/after.py,sha256=dlmyxxFy2uqpLXDr838DiEd7jgv2AGthsWHGYcGYsaI,1496
@@ -348,55 +361,55 @@
 pip/_vendor/tenacity/tornadoweb.py,sha256=E8lWO2nwe6dJgoB-N2HhQprYLDLB_UdSgFnv-EN6wKE,2145
 pip/_vendor/tenacity/wait.py,sha256=e_Saa6I2tsNLpCL1t9897wN2fGb0XQMQlE4bU2t9V2w,6691
 pip/_vendor/tomli/__init__.py,sha256=z1Elt0nLAqU5Y0DOn9p__8QnLWavlEOpRyQikdYgKro,230
 pip/_vendor/tomli/_parser.py,sha256=50BD4o9YbzFAGAYyZLqZC8F81DQ7iWWyJnrHNwBKa6A,22415
 pip/_vendor/tomli/_re.py,sha256=5GPfgXKteg7wRFCF-DzlkAPI2ilHbkMK2-JC49F-AJQ,2681
 pip/_vendor/urllib3/__init__.py,sha256=j3yzHIbmW7CS-IKQJ9-PPQf_YKO8EOAey_rMW0UR7us,2763
 pip/_vendor/urllib3/_collections.py,sha256=Rp1mVyBgc_UlAcp6M3at1skJBXR5J43NawRTvW2g_XY,10811
-pip/_vendor/urllib3/_version.py,sha256=6fJAIPnJkT0m9wzVjHrFcq5wYt65dStDpaRcjj5ugoo,63
-pip/_vendor/urllib3/connection.py,sha256=kAlubwsW33FUSUroPSVHMF_Zzv-uzX_BwUFMXX9Pt8c,18754
-pip/_vendor/urllib3/connectionpool.py,sha256=jXNmm4y3LJWYgteNeGcYJx8-0k7bzKRU__AVTXzaIak,37131
+pip/_vendor/urllib3/_version.py,sha256=CA4bKbKLwUBfKitbVR-44Whe53HWyInIVElDQQniAJU,63
+pip/_vendor/urllib3/connection.py,sha256=8TiEbQrJMgySqOllKNeX5tMv8nluKRjNj5j9hyzS6x0,20080
+pip/_vendor/urllib3/connectionpool.py,sha256=FQoodlNAP1KeUi4htGdl5TJEvKL5LWisCbmFNewxRpg,37587
 pip/_vendor/urllib3/exceptions.py,sha256=0Mnno3KHTNfXRfY7638NufOPkUb6mXOm-Lqj-4x2w8A,8217
 pip/_vendor/urllib3/fields.py,sha256=kvLDCg_JmH1lLjUUEY_FLS8UhY7hBvDPuVETbY8mdrM,8579
 pip/_vendor/urllib3/filepost.py,sha256=5b_qqgRHVlL7uLtdAYBzBh-GHmU5AfJVt_2N0XS3PeY,2440
 pip/_vendor/urllib3/poolmanager.py,sha256=whzlX6UTEgODMOCy0ZDMUONRBCz5wyIM8Z9opXAY-Lk,19763
 pip/_vendor/urllib3/request.py,sha256=ZFSIqX0C6WizixecChZ3_okyu7BEv0lZu1VT0s6h4SM,5985
 pip/_vendor/urllib3/response.py,sha256=hGhGBh7TkEkh_IQg5C1W_xuPNrgIKv5BUXPyE-q0LuE,28203
 pip/_vendor/urllib3/contrib/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pip/_vendor/urllib3/contrib/_appengine_environ.py,sha256=bDbyOEhW2CKLJcQqAKAyrEHN-aklsyHFKq6vF8ZFsmk,957
 pip/_vendor/urllib3/contrib/appengine.py,sha256=lfzpHFmJiO82shClLEm3QB62SYgHWnjpZOH_2JhU5Tc,11034
 pip/_vendor/urllib3/contrib/ntlmpool.py,sha256=ej9gGvfAb2Gt00lafFp45SIoRz-QwrQ4WChm6gQmAlM,4538
-pip/_vendor/urllib3/contrib/pyopenssl.py,sha256=lYIxGFWTosqbfLnkZXOBg7igY71iRvM3NUOaD0stUQ8,16891
-pip/_vendor/urllib3/contrib/securetransport.py,sha256=TN5q9dKZ0Sd5_vW9baRzEAEItdJ-4VlHWmAUrlcJNfo,34434
+pip/_vendor/urllib3/contrib/pyopenssl.py,sha256=DD4pInv_3OEEGffEFynBoirc8ldR789sLmGSKukzA0E,16900
+pip/_vendor/urllib3/contrib/securetransport.py,sha256=4qUKo7PUV-vVIqXmr2BD-sH7qplB918jiD5eNsRI9vU,34449
 pip/_vendor/urllib3/contrib/socks.py,sha256=aRi9eWXo9ZEb95XUxef4Z21CFlnnjbEiAo9HOseoMt4,7097
 pip/_vendor/urllib3/contrib/_securetransport/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pip/_vendor/urllib3/contrib/_securetransport/bindings.py,sha256=eRy1Mj-wpg7sR6-OSvnSV4jUbjMT464dLN_CWxbIRVw,17649
-pip/_vendor/urllib3/contrib/_securetransport/low_level.py,sha256=lgIdsSycqfB0Xm5BiJzXGeIKT7ybCQMFPJAgkcwPa1s,13908
+pip/_vendor/urllib3/contrib/_securetransport/low_level.py,sha256=B2JBB2_NRP02xK6DCa1Pa9IuxrPwxzDzZbixQkb7U9M,13922
 pip/_vendor/urllib3/packages/__init__.py,sha256=h4BLhD4tLaBx1adaDtKXfupsgqY0wWLXb_f1_yVlV6A,108
 pip/_vendor/urllib3/packages/six.py,sha256=1LVW7ljqRirFlfExjwl-v1B7vSAUNTmzGMs-qays2zg,34666
 pip/_vendor/urllib3/packages/backports/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pip/_vendor/urllib3/packages/backports/makefile.py,sha256=nbzt3i0agPVP07jqqgjhaYjMmuAi_W5E0EywZivVO8E,1417
 pip/_vendor/urllib3/packages/ssl_match_hostname/__init__.py,sha256=ZVMwCkHx-py8ERsxxM3Il-MiREZktV-8iLBmCfRRHI4,927
 pip/_vendor/urllib3/packages/ssl_match_hostname/_implementation.py,sha256=6dZ-q074g7XhsJ27MFCgkct8iVNZB3sMZvKhf-KUVy0,5679
 pip/_vendor/urllib3/util/__init__.py,sha256=JEmSmmqqLyaw8P51gUImZh8Gwg9i1zSe-DoqAitn2nc,1155
 pip/_vendor/urllib3/util/connection.py,sha256=KykjNIXzUZEzeKEOpl5xvKs6IsESXP9o9eTrjE0W_Ys,4920
-pip/_vendor/urllib3/util/proxy.py,sha256=FGipAEnvZteyldXNjce4DEB7YzwU-a5lep8y5S0qHQg,1604
+pip/_vendor/urllib3/util/proxy.py,sha256=zUvPPCJrp6dOF0N4GAVbOcl6o-4uXKSrGiTkkr5vUS4,1605
 pip/_vendor/urllib3/util/queue.py,sha256=nRgX8_eX-_VkvxoX096QWoz8Ps0QHUAExILCY_7PncM,498
 pip/_vendor/urllib3/util/request.py,sha256=NnzaEKQ1Pauw5MFMV6HmgEMHITf0Aua9fQuzi2uZzGc,4123
 pip/_vendor/urllib3/util/response.py,sha256=GJpg3Egi9qaJXRwBh5wv-MNuRWan5BIu40oReoxWP28,3510
 pip/_vendor/urllib3/util/retry.py,sha256=tOWfZpLsuc7Vbk5nWpMwkHdMoXCp90IAvH4xtjSDRqQ,21391
 pip/_vendor/urllib3/util/ssl_.py,sha256=X4-AqW91aYPhPx6-xbf66yHFQKbqqfC_5Zt4WkLX1Hc,17177
 pip/_vendor/urllib3/util/ssltransport.py,sha256=F_UncOXGcc-MgeWFTA1H4QCt_RRNQXRbF6onje3SyHY,6931
 pip/_vendor/urllib3/util/timeout.py,sha256=QSbBUNOB9yh6AnDn61SrLQ0hg5oz0I9-uXEG91AJuIg,10003
 pip/_vendor/urllib3/util/url.py,sha256=QVEzcbHipbXyCWwH6R4K4TR-N8T4LM55WEMwNUTBmLE,14047
 pip/_vendor/urllib3/util/wait.py,sha256=3MUKRSAUJDB2tgco7qRUskW0zXGAWYvRRE4Q1_6xlLs,5404
 pip/_vendor/webencodings/__init__.py,sha256=qOBJIuPy_4ByYH6W_bNgJF-qYQ2DoU-dKsDu5yRWCXg,10579
 pip/_vendor/webencodings/labels.py,sha256=4AO_KxTddqGtrL9ns7kAPjb0CcN6xsCIxbK37HY9r3E,8979
 pip/_vendor/webencodings/mklabels.py,sha256=GYIeywnpaLnP0GSic8LFWgd0UVvO_l1Nc6YoF-87R_4,1305
 pip/_vendor/webencodings/tests.py,sha256=OtGLyjhNY1fvkW1GvLJ_FV9ZoqC9Anyjr7q3kxTbzNs,6563
 pip/_vendor/webencodings/x_user_defined.py,sha256=yOqWSdmpytGfUgh_Z6JYgDNhoc-BAHyyeeT15Fr42tM,4307
-pip-21.2.4.dist-info/LICENSE.txt,sha256=I6c2HCsVgQKLxiO52ivSSZeryqR4Gs5q1ESjeUT42uE,1090
-pip-21.2.4.dist-info/METADATA,sha256=PGCimuD-VsKv664Ne_9navMt6I9Ym_rm5p_u6Ykgfd4,4165
-pip-21.2.4.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
-pip-21.2.4.dist-info/entry_points.txt,sha256=5ExSa1s54zSPNA_1epJn5SX06786S8k5YHwskMvVYzw,125
-pip-21.2.4.dist-info/top_level.txt,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
-pip-21.2.4.dist-info/RECORD,,
+pip-21.3.1.dist-info/LICENSE.txt,sha256=I6c2HCsVgQKLxiO52ivSSZeryqR4Gs5q1ESjeUT42uE,1090
+pip-21.3.1.dist-info/METADATA,sha256=PjWcvFEqJd4gOfiQam8il34_wPNKxf8ubyYI2wYm7tc,4216
+pip-21.3.1.dist-info/WHEEL,sha256=ewwEueio1C2XeHTvT17n8dZUJgOvyCWCt0WVNLClP9o,92
+pip-21.3.1.dist-info/entry_points.txt,sha256=5ExSa1s54zSPNA_1epJn5SX06786S8k5YHwskMvVYzw,125
+pip-21.3.1.dist-info/top_level.txt,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+pip-21.3.1.dist-info/RECORD,,
```

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/setuptools-44.1.1-py2.py3-none-any.whl` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/setuptools-44.1.1-py2.py3-none-any.whl`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/setuptools-50.3.2-py3-none-any.whl` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/setuptools-50.3.2-py3-none-any.whl`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/setuptools-58.1.0-py3-none-any.whl` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/setuptools-58.3.0-py3-none-any.whl`

 * *Files 12% similar despite different names*

#### zipinfo {}

```diff
@@ -1,157 +1,159 @@
-Zip file size: 816725 bytes, number of entries: 155
--rw-r--r--  2.0 unx      152 b- defN 21-Sep-22 02:01 distutils-precedence.pth
--rw-r--r--  2.0 unx     3688 b- defN 21-Sep-22 02:00 _distutils_hack/__init__.py
--rw-r--r--  2.0 unx       44 b- defN 21-Sep-22 02:00 _distutils_hack/override.py
--rw-r--r--  2.0 unx   108202 b- defN 21-Sep-22 02:00 pkg_resources/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/__init__.py
--rw-r--r--  2.0 unx    24701 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/appdirs.py
--rw-r--r--  2.0 unx   232056 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/pyparsing.py
--rw-r--r--  2.0 unx      736 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/__about__.py
--rw-r--r--  2.0 unx      562 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/__init__.py
--rw-r--r--  2.0 unx     1128 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/_compat.py
--rw-r--r--  2.0 unx     2022 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/_structures.py
--rw-r--r--  2.0 unx     1812 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/_typing.py
--rw-r--r--  2.0 unx     9518 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/markers.py
--rw-r--r--  2.0 unx     4929 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/requirements.py
--rw-r--r--  2.0 unx    31944 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/specifiers.py
--rw-r--r--  2.0 unx    24067 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/tags.py
--rw-r--r--  2.0 unx     1811 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/utils.py
--rw-r--r--  2.0 unx    15470 b- defN 21-Sep-22 02:00 pkg_resources/_vendor/packaging/version.py
--rw-r--r--  2.0 unx     2362 b- defN 21-Sep-22 02:00 pkg_resources/extern/__init__.py
--rw-r--r--  2.0 unx      104 b- defN 21-Sep-22 02:00 pkg_resources/tests/data/my-test-package-source/setup.py
--rw-r--r--  2.0 unx     7448 b- defN 21-Sep-22 02:00 setuptools/__init__.py
--rw-r--r--  2.0 unx      218 b- defN 21-Sep-22 02:00 setuptools/_deprecation_warning.py
--rw-r--r--  2.0 unx     2392 b- defN 21-Sep-22 02:00 setuptools/_imp.py
--rw-r--r--  2.0 unx     7077 b- defN 21-Sep-22 02:00 setuptools/archive_util.py
--rw-r--r--  2.0 unx    10280 b- defN 21-Sep-22 02:00 setuptools/build_meta.py
--rw-r--r--  2.0 unx    65536 b- defN 21-Sep-22 02:00 setuptools/cli-32.exe
--rw-r--r--  2.0 unx    74752 b- defN 21-Sep-22 02:00 setuptools/cli-64.exe
--rw-r--r--  2.0 unx    65536 b- defN 21-Sep-22 02:00 setuptools/cli.exe
--rw-r--r--  2.0 unx    23123 b- defN 21-Sep-22 02:00 setuptools/config.py
--rw-r--r--  2.0 unx      949 b- defN 21-Sep-22 02:00 setuptools/dep_util.py
--rw-r--r--  2.0 unx     5474 b- defN 21-Sep-22 02:00 setuptools/depends.py
--rw-r--r--  2.0 unx    43087 b- defN 21-Sep-22 02:00 setuptools/dist.py
--rw-r--r--  2.0 unx      524 b- defN 21-Sep-22 02:00 setuptools/errors.py
--rw-r--r--  2.0 unx     1684 b- defN 21-Sep-22 02:00 setuptools/extension.py
--rw-r--r--  2.0 unx     4873 b- defN 21-Sep-22 02:00 setuptools/glob.py
--rw-r--r--  2.0 unx    65536 b- defN 21-Sep-22 02:00 setuptools/gui-32.exe
--rw-r--r--  2.0 unx    75264 b- defN 21-Sep-22 02:00 setuptools/gui-64.exe
--rw-r--r--  2.0 unx    65536 b- defN 21-Sep-22 02:00 setuptools/gui.exe
--rw-r--r--  2.0 unx     3567 b- defN 21-Sep-22 02:00 setuptools/installer.py
--rw-r--r--  2.0 unx      812 b- defN 21-Sep-22 02:00 setuptools/launch.py
--rw-r--r--  2.0 unx     5217 b- defN 21-Sep-22 02:00 setuptools/monkey.py
--rw-r--r--  2.0 unx    50561 b- defN 21-Sep-22 02:00 setuptools/msvc.py
--rw-r--r--  2.0 unx     3093 b- defN 21-Sep-22 02:00 setuptools/namespaces.py
--rw-r--r--  2.0 unx    39886 b- defN 21-Sep-22 02:00 setuptools/package_index.py
--rw-r--r--  2.0 unx      245 b- defN 21-Sep-22 02:00 setuptools/py34compat.py
--rw-r--r--  2.0 unx    14348 b- defN 21-Sep-22 02:00 setuptools/sandbox.py
--rw-r--r--  2.0 unx      218 b- defN 21-Sep-22 02:00 setuptools/script (dev).tmpl
--rw-r--r--  2.0 unx      138 b- defN 21-Sep-22 02:00 setuptools/script.tmpl
--rw-r--r--  2.0 unx      941 b- defN 21-Sep-22 02:00 setuptools/unicode_utils.py
--rw-r--r--  2.0 unx      144 b- defN 21-Sep-22 02:00 setuptools/version.py
--rw-r--r--  2.0 unx     8288 b- defN 21-Sep-22 02:00 setuptools/wheel.py
--rw-r--r--  2.0 unx      714 b- defN 21-Sep-22 02:00 setuptools/windows_support.py
--rw-r--r--  2.0 unx      250 b- defN 21-Sep-22 02:00 setuptools/_distutils/__init__.py
--rw-r--r--  2.0 unx    20813 b- defN 21-Sep-22 02:00 setuptools/_distutils/_msvccompiler.py
--rw-r--r--  2.0 unx     8572 b- defN 21-Sep-22 02:00 setuptools/_distutils/archive_util.py
--rw-r--r--  2.0 unx    14894 b- defN 21-Sep-22 02:00 setuptools/_distutils/bcppcompiler.py
--rw-r--r--  2.0 unx    47607 b- defN 21-Sep-22 02:00 setuptools/_distutils/ccompiler.py
--rw-r--r--  2.0 unx    18079 b- defN 21-Sep-22 02:00 setuptools/_distutils/cmd.py
--rw-r--r--  2.0 unx     4827 b- defN 21-Sep-22 02:00 setuptools/_distutils/config.py
--rw-r--r--  2.0 unx     8876 b- defN 21-Sep-22 02:00 setuptools/_distutils/core.py
--rw-r--r--  2.0 unx    16938 b- defN 21-Sep-22 02:00 setuptools/_distutils/cygwinccompiler.py
--rw-r--r--  2.0 unx      139 b- defN 21-Sep-22 02:00 setuptools/_distutils/debug.py
--rw-r--r--  2.0 unx     3491 b- defN 21-Sep-22 02:00 setuptools/_distutils/dep_util.py
--rw-r--r--  2.0 unx     7778 b- defN 21-Sep-22 02:00 setuptools/_distutils/dir_util.py
--rw-r--r--  2.0 unx    50421 b- defN 21-Sep-22 02:00 setuptools/_distutils/dist.py
--rw-r--r--  2.0 unx     3577 b- defN 21-Sep-22 02:00 setuptools/_distutils/errors.py
--rw-r--r--  2.0 unx    10515 b- defN 21-Sep-22 02:00 setuptools/_distutils/extension.py
--rw-r--r--  2.0 unx    17784 b- defN 21-Sep-22 02:00 setuptools/_distutils/fancy_getopt.py
--rw-r--r--  2.0 unx     8148 b- defN 21-Sep-22 02:00 setuptools/_distutils/file_util.py
--rw-r--r--  2.0 unx    13407 b- defN 21-Sep-22 02:00 setuptools/_distutils/filelist.py
--rw-r--r--  2.0 unx     1969 b- defN 21-Sep-22 02:00 setuptools/_distutils/log.py
--rw-r--r--  2.0 unx    30453 b- defN 21-Sep-22 02:00 setuptools/_distutils/msvc9compiler.py
--rw-r--r--  2.0 unx    23540 b- defN 21-Sep-22 02:00 setuptools/_distutils/msvccompiler.py
--rw-r--r--  2.0 unx      455 b- defN 21-Sep-22 02:00 setuptools/_distutils/py35compat.py
--rw-r--r--  2.0 unx      212 b- defN 21-Sep-22 02:00 setuptools/_distutils/py38compat.py
--rw-r--r--  2.0 unx     3498 b- defN 21-Sep-22 02:00 setuptools/_distutils/spawn.py
--rw-r--r--  2.0 unx    21630 b- defN 21-Sep-22 02:00 setuptools/_distutils/sysconfig.py
--rw-r--r--  2.0 unx    12483 b- defN 21-Sep-22 02:00 setuptools/_distutils/text_file.py
--rw-r--r--  2.0 unx    14980 b- defN 21-Sep-22 02:00 setuptools/_distutils/unixccompiler.py
--rw-r--r--  2.0 unx    20373 b- defN 21-Sep-22 02:00 setuptools/_distutils/util.py
--rw-r--r--  2.0 unx    12514 b- defN 21-Sep-22 02:00 setuptools/_distutils/version.py
--rw-r--r--  2.0 unx     5133 b- defN 21-Sep-22 02:00 setuptools/_distutils/versionpredicate.py
--rw-r--r--  2.0 unx      799 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/__init__.py
--rw-r--r--  2.0 unx     5562 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/bdist.py
--rw-r--r--  2.0 unx     4913 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/bdist_dumb.py
--rw-r--r--  2.0 unx    35579 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/bdist_msi.py
--rw-r--r--  2.0 unx    21537 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/bdist_rpm.py
--rw-r--r--  2.0 unx    16030 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/bdist_wininst.py
--rw-r--r--  2.0 unx     5773 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/build.py
--rw-r--r--  2.0 unx     8022 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/build_clib.py
--rw-r--r--  2.0 unx    31683 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/build_ext.py
--rw-r--r--  2.0 unx    16495 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/build_py.py
--rw-r--r--  2.0 unx     5963 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/build_scripts.py
--rw-r--r--  2.0 unx     5637 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/check.py
--rw-r--r--  2.0 unx     2776 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/clean.py
--rw-r--r--  2.0 unx    13117 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/config.py
--rw-r--r--  2.0 unx    27534 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/install.py
--rw-r--r--  2.0 unx     2822 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/install_data.py
--rw-r--r--  2.0 unx     2603 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/install_egg_info.py
--rw-r--r--  2.0 unx     1298 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/install_headers.py
--rw-r--r--  2.0 unx     8397 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/install_lib.py
--rw-r--r--  2.0 unx     2017 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/install_scripts.py
--rw-r--r--  2.0 unx      671 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/py37compat.py
--rw-r--r--  2.0 unx    11712 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/register.py
--rw-r--r--  2.0 unx    19005 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/sdist.py
--rw-r--r--  2.0 unx     7597 b- defN 21-Sep-22 02:00 setuptools/_distutils/command/upload.py
--rw-r--r--  2.0 unx        0 b- defN 21-Sep-22 02:00 setuptools/_vendor/__init__.py
--rw-r--r--  2.0 unx    15130 b- defN 21-Sep-22 02:00 setuptools/_vendor/ordered_set.py
--rw-r--r--  2.0 unx   232056 b- defN 21-Sep-22 02:00 setuptools/_vendor/pyparsing.py
--rw-r--r--  2.0 unx       82 b- defN 21-Sep-22 02:00 setuptools/_vendor/more_itertools/__init__.py
--rw-r--r--  2.0 unx   117968 b- defN 21-Sep-22 02:00 setuptools/_vendor/more_itertools/more.py
--rw-r--r--  2.0 unx    16256 b- defN 21-Sep-22 02:00 setuptools/_vendor/more_itertools/recipes.py
--rw-r--r--  2.0 unx      736 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/__about__.py
--rw-r--r--  2.0 unx      562 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/__init__.py
--rw-r--r--  2.0 unx     1128 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/_compat.py
--rw-r--r--  2.0 unx     2022 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/_structures.py
--rw-r--r--  2.0 unx     1812 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/_typing.py
--rw-r--r--  2.0 unx     9509 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/markers.py
--rw-r--r--  2.0 unx     4917 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/requirements.py
--rw-r--r--  2.0 unx    31944 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/specifiers.py
--rw-r--r--  2.0 unx    24067 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/tags.py
--rw-r--r--  2.0 unx     1811 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/utils.py
--rw-r--r--  2.0 unx    15470 b- defN 21-Sep-22 02:00 setuptools/_vendor/packaging/version.py
--rw-r--r--  2.0 unx      217 b- defN 21-Sep-22 02:00 setuptools/command/__init__.py
--rw-r--r--  2.0 unx     2381 b- defN 21-Sep-22 02:00 setuptools/command/alias.py
--rw-r--r--  2.0 unx    16604 b- defN 21-Sep-22 02:00 setuptools/command/bdist_egg.py
--rw-r--r--  2.0 unx     1182 b- defN 21-Sep-22 02:00 setuptools/command/bdist_rpm.py
--rw-r--r--  2.0 unx     4415 b- defN 21-Sep-22 02:00 setuptools/command/build_clib.py
--rw-r--r--  2.0 unx    13212 b- defN 21-Sep-22 02:00 setuptools/command/build_ext.py
--rw-r--r--  2.0 unx     8276 b- defN 21-Sep-22 02:00 setuptools/command/build_py.py
--rw-r--r--  2.0 unx     7012 b- defN 21-Sep-22 02:00 setuptools/command/develop.py
--rw-r--r--  2.0 unx      960 b- defN 21-Sep-22 02:00 setuptools/command/dist_info.py
--rw-r--r--  2.0 unx    85344 b- defN 21-Sep-22 02:00 setuptools/command/easy_install.py
--rw-r--r--  2.0 unx    25335 b- defN 21-Sep-22 02:00 setuptools/command/egg_info.py
--rw-r--r--  2.0 unx     4705 b- defN 21-Sep-22 02:00 setuptools/command/install.py
--rw-r--r--  2.0 unx     2203 b- defN 21-Sep-22 02:00 setuptools/command/install_egg_info.py
--rw-r--r--  2.0 unx     3875 b- defN 21-Sep-22 02:00 setuptools/command/install_lib.py
--rw-r--r--  2.0 unx     2593 b- defN 21-Sep-22 02:00 setuptools/command/install_scripts.py
--rw-r--r--  2.0 unx      628 b- defN 21-Sep-22 02:00 setuptools/command/launcher manifest.xml
--rw-r--r--  2.0 unx     4946 b- defN 21-Sep-22 02:00 setuptools/command/py36compat.py
--rw-r--r--  2.0 unx      468 b- defN 21-Sep-22 02:00 setuptools/command/register.py
--rw-r--r--  2.0 unx     2128 b- defN 21-Sep-22 02:00 setuptools/command/rotate.py
--rw-r--r--  2.0 unx      658 b- defN 21-Sep-22 02:00 setuptools/command/saveopts.py
--rw-r--r--  2.0 unx     5967 b- defN 21-Sep-22 02:00 setuptools/command/sdist.py
--rw-r--r--  2.0 unx     5086 b- defN 21-Sep-22 02:00 setuptools/command/setopt.py
--rw-r--r--  2.0 unx     8088 b- defN 21-Sep-22 02:00 setuptools/command/test.py
--rw-r--r--  2.0 unx      462 b- defN 21-Sep-22 02:00 setuptools/command/upload.py
--rw-r--r--  2.0 unx     7218 b- defN 21-Sep-22 02:00 setuptools/command/upload_docs.py
--rw-r--r--  2.0 unx     2407 b- defN 21-Sep-22 02:00 setuptools/extern/__init__.py
--rw-r--r--  2.0 unx     1050 b- defN 21-Sep-22 02:01 setuptools-58.1.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     4852 b- defN 21-Sep-22 02:01 setuptools-58.1.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 21-Sep-22 02:01 setuptools-58.1.0.dist-info/WHEEL
--rw-r--r--  2.0 unx     2636 b- defN 21-Sep-22 02:01 setuptools-58.1.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       41 b- defN 21-Sep-22 02:01 setuptools-58.1.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    13982 b- defN 21-Sep-22 02:01 setuptools-58.1.0.dist-info/RECORD
-155 files, 2488160 bytes uncompressed, 794553 bytes compressed:  68.1%
+Zip file size: 946220 bytes, number of entries: 157
+-rw-r--r--  2.0 unx      152 b- defN 21-Oct-22 20:56 distutils-precedence.pth
+-rw-r--r--  2.0 unx     3688 b- defN 21-Oct-22 20:55 _distutils_hack/__init__.py
+-rw-r--r--  2.0 unx       44 b- defN 21-Oct-22 20:55 _distutils_hack/override.py
+-rw-r--r--  2.0 unx   108202 b- defN 21-Oct-22 20:55 pkg_resources/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/__init__.py
+-rw-r--r--  2.0 unx    24701 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/appdirs.py
+-rw-r--r--  2.0 unx   232056 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/pyparsing.py
+-rw-r--r--  2.0 unx      736 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/__about__.py
+-rw-r--r--  2.0 unx      562 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/__init__.py
+-rw-r--r--  2.0 unx     1128 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/_compat.py
+-rw-r--r--  2.0 unx     2022 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/_structures.py
+-rw-r--r--  2.0 unx     1812 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/_typing.py
+-rw-r--r--  2.0 unx     9518 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/markers.py
+-rw-r--r--  2.0 unx     4929 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/requirements.py
+-rw-r--r--  2.0 unx    31944 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/specifiers.py
+-rw-r--r--  2.0 unx    24067 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/tags.py
+-rw-r--r--  2.0 unx     1811 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/utils.py
+-rw-r--r--  2.0 unx    15470 b- defN 21-Oct-22 20:55 pkg_resources/_vendor/packaging/version.py
+-rw-r--r--  2.0 unx     2362 b- defN 21-Oct-22 20:55 pkg_resources/extern/__init__.py
+-rw-r--r--  2.0 unx      104 b- defN 21-Oct-22 20:55 pkg_resources/tests/data/my-test-package-source/setup.py
+-rw-r--r--  2.0 unx     7670 b- defN 21-Oct-22 20:55 setuptools/__init__.py
+-rw-r--r--  2.0 unx      218 b- defN 21-Oct-22 20:55 setuptools/_deprecation_warning.py
+-rw-r--r--  2.0 unx     2392 b- defN 21-Oct-22 20:55 setuptools/_imp.py
+-rw-r--r--  2.0 unx     7077 b- defN 21-Oct-22 20:55 setuptools/archive_util.py
+-rw-r--r--  2.0 unx    10280 b- defN 21-Oct-22 20:55 setuptools/build_meta.py
+-rw-r--r--  2.0 unx    65536 b- defN 21-Oct-22 20:55 setuptools/cli-32.exe
+-rw-r--r--  2.0 unx    74752 b- defN 21-Oct-22 20:55 setuptools/cli-64.exe
+-rw-r--r--  2.0 unx   137216 b- defN 21-Oct-22 20:55 setuptools/cli-arm64.exe
+-rw-r--r--  2.0 unx    65536 b- defN 21-Oct-22 20:55 setuptools/cli.exe
+-rw-r--r--  2.0 unx    23123 b- defN 21-Oct-22 20:55 setuptools/config.py
+-rw-r--r--  2.0 unx      949 b- defN 21-Oct-22 20:55 setuptools/dep_util.py
+-rw-r--r--  2.0 unx     5474 b- defN 21-Oct-22 20:55 setuptools/depends.py
+-rw-r--r--  2.0 unx    43087 b- defN 21-Oct-22 20:55 setuptools/dist.py
+-rw-r--r--  2.0 unx      524 b- defN 21-Oct-22 20:55 setuptools/errors.py
+-rw-r--r--  2.0 unx     1684 b- defN 21-Oct-22 20:55 setuptools/extension.py
+-rw-r--r--  2.0 unx     4873 b- defN 21-Oct-22 20:55 setuptools/glob.py
+-rw-r--r--  2.0 unx    65536 b- defN 21-Oct-22 20:55 setuptools/gui-32.exe
+-rw-r--r--  2.0 unx    75264 b- defN 21-Oct-22 20:55 setuptools/gui-64.exe
+-rw-r--r--  2.0 unx   137728 b- defN 21-Oct-22 20:55 setuptools/gui-arm64.exe
+-rw-r--r--  2.0 unx    65536 b- defN 21-Oct-22 20:55 setuptools/gui.exe
+-rw-r--r--  2.0 unx     3567 b- defN 21-Oct-22 20:55 setuptools/installer.py
+-rw-r--r--  2.0 unx      812 b- defN 21-Oct-22 20:55 setuptools/launch.py
+-rw-r--r--  2.0 unx     5217 b- defN 21-Oct-22 20:55 setuptools/monkey.py
+-rw-r--r--  2.0 unx    50561 b- defN 21-Oct-22 20:55 setuptools/msvc.py
+-rw-r--r--  2.0 unx     3093 b- defN 21-Oct-22 20:55 setuptools/namespaces.py
+-rw-r--r--  2.0 unx    39886 b- defN 21-Oct-22 20:55 setuptools/package_index.py
+-rw-r--r--  2.0 unx      245 b- defN 21-Oct-22 20:55 setuptools/py34compat.py
+-rw-r--r--  2.0 unx    14348 b- defN 21-Oct-22 20:55 setuptools/sandbox.py
+-rw-r--r--  2.0 unx      218 b- defN 21-Oct-22 20:55 setuptools/script (dev).tmpl
+-rw-r--r--  2.0 unx      138 b- defN 21-Oct-22 20:55 setuptools/script.tmpl
+-rw-r--r--  2.0 unx      941 b- defN 21-Oct-22 20:55 setuptools/unicode_utils.py
+-rw-r--r--  2.0 unx      144 b- defN 21-Oct-22 20:55 setuptools/version.py
+-rw-r--r--  2.0 unx     8288 b- defN 21-Oct-22 20:55 setuptools/wheel.py
+-rw-r--r--  2.0 unx      714 b- defN 21-Oct-22 20:55 setuptools/windows_support.py
+-rw-r--r--  2.0 unx      250 b- defN 21-Oct-22 20:55 setuptools/_distutils/__init__.py
+-rw-r--r--  2.0 unx    20813 b- defN 21-Oct-22 20:55 setuptools/_distutils/_msvccompiler.py
+-rw-r--r--  2.0 unx     8572 b- defN 21-Oct-22 20:55 setuptools/_distutils/archive_util.py
+-rw-r--r--  2.0 unx    14894 b- defN 21-Oct-22 20:55 setuptools/_distutils/bcppcompiler.py
+-rw-r--r--  2.0 unx    47607 b- defN 21-Oct-22 20:55 setuptools/_distutils/ccompiler.py
+-rw-r--r--  2.0 unx    18079 b- defN 21-Oct-22 20:55 setuptools/_distutils/cmd.py
+-rw-r--r--  2.0 unx     4827 b- defN 21-Oct-22 20:55 setuptools/_distutils/config.py
+-rw-r--r--  2.0 unx     8876 b- defN 21-Oct-22 20:55 setuptools/_distutils/core.py
+-rw-r--r--  2.0 unx    16938 b- defN 21-Oct-22 20:55 setuptools/_distutils/cygwinccompiler.py
+-rw-r--r--  2.0 unx      139 b- defN 21-Oct-22 20:55 setuptools/_distutils/debug.py
+-rw-r--r--  2.0 unx     3491 b- defN 21-Oct-22 20:55 setuptools/_distutils/dep_util.py
+-rw-r--r--  2.0 unx     7778 b- defN 21-Oct-22 20:55 setuptools/_distutils/dir_util.py
+-rw-r--r--  2.0 unx    50421 b- defN 21-Oct-22 20:55 setuptools/_distutils/dist.py
+-rw-r--r--  2.0 unx     3577 b- defN 21-Oct-22 20:55 setuptools/_distutils/errors.py
+-rw-r--r--  2.0 unx    10515 b- defN 21-Oct-22 20:55 setuptools/_distutils/extension.py
+-rw-r--r--  2.0 unx    17784 b- defN 21-Oct-22 20:55 setuptools/_distutils/fancy_getopt.py
+-rw-r--r--  2.0 unx     8148 b- defN 21-Oct-22 20:55 setuptools/_distutils/file_util.py
+-rw-r--r--  2.0 unx    13407 b- defN 21-Oct-22 20:55 setuptools/_distutils/filelist.py
+-rw-r--r--  2.0 unx     1969 b- defN 21-Oct-22 20:55 setuptools/_distutils/log.py
+-rw-r--r--  2.0 unx    30453 b- defN 21-Oct-22 20:55 setuptools/_distutils/msvc9compiler.py
+-rw-r--r--  2.0 unx    23540 b- defN 21-Oct-22 20:55 setuptools/_distutils/msvccompiler.py
+-rw-r--r--  2.0 unx      455 b- defN 21-Oct-22 20:55 setuptools/_distutils/py35compat.py
+-rw-r--r--  2.0 unx      212 b- defN 21-Oct-22 20:55 setuptools/_distutils/py38compat.py
+-rw-r--r--  2.0 unx     3498 b- defN 21-Oct-22 20:55 setuptools/_distutils/spawn.py
+-rw-r--r--  2.0 unx    21630 b- defN 21-Oct-22 20:55 setuptools/_distutils/sysconfig.py
+-rw-r--r--  2.0 unx    12483 b- defN 21-Oct-22 20:55 setuptools/_distutils/text_file.py
+-rw-r--r--  2.0 unx    14538 b- defN 21-Oct-22 20:55 setuptools/_distutils/unixccompiler.py
+-rw-r--r--  2.0 unx    20375 b- defN 21-Oct-22 20:55 setuptools/_distutils/util.py
+-rw-r--r--  2.0 unx    12514 b- defN 21-Oct-22 20:55 setuptools/_distutils/version.py
+-rw-r--r--  2.0 unx     5133 b- defN 21-Oct-22 20:55 setuptools/_distutils/versionpredicate.py
+-rw-r--r--  2.0 unx      799 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/__init__.py
+-rw-r--r--  2.0 unx     5562 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/bdist.py
+-rw-r--r--  2.0 unx     4913 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/bdist_dumb.py
+-rw-r--r--  2.0 unx    35579 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/bdist_msi.py
+-rw-r--r--  2.0 unx    21537 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/bdist_rpm.py
+-rw-r--r--  2.0 unx    16030 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/bdist_wininst.py
+-rw-r--r--  2.0 unx     5773 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/build.py
+-rw-r--r--  2.0 unx     8022 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/build_clib.py
+-rw-r--r--  2.0 unx    31683 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/build_ext.py
+-rw-r--r--  2.0 unx    16495 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/build_py.py
+-rw-r--r--  2.0 unx     5963 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/build_scripts.py
+-rw-r--r--  2.0 unx     5637 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/check.py
+-rw-r--r--  2.0 unx     2776 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/clean.py
+-rw-r--r--  2.0 unx    13117 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/config.py
+-rw-r--r--  2.0 unx    27534 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/install.py
+-rw-r--r--  2.0 unx     2822 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/install_data.py
+-rw-r--r--  2.0 unx     2603 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/install_egg_info.py
+-rw-r--r--  2.0 unx     1298 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/install_headers.py
+-rw-r--r--  2.0 unx     8397 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/install_lib.py
+-rw-r--r--  2.0 unx     2017 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/install_scripts.py
+-rw-r--r--  2.0 unx      671 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/py37compat.py
+-rw-r--r--  2.0 unx    11712 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/register.py
+-rw-r--r--  2.0 unx    19005 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/sdist.py
+-rw-r--r--  2.0 unx     7597 b- defN 21-Oct-22 20:55 setuptools/_distutils/command/upload.py
+-rw-r--r--  2.0 unx        0 b- defN 21-Oct-22 20:55 setuptools/_vendor/__init__.py
+-rw-r--r--  2.0 unx    15130 b- defN 21-Oct-22 20:55 setuptools/_vendor/ordered_set.py
+-rw-r--r--  2.0 unx   232056 b- defN 21-Oct-22 20:55 setuptools/_vendor/pyparsing.py
+-rw-r--r--  2.0 unx       82 b- defN 21-Oct-22 20:55 setuptools/_vendor/more_itertools/__init__.py
+-rw-r--r--  2.0 unx   117968 b- defN 21-Oct-22 20:55 setuptools/_vendor/more_itertools/more.py
+-rw-r--r--  2.0 unx    16256 b- defN 21-Oct-22 20:55 setuptools/_vendor/more_itertools/recipes.py
+-rw-r--r--  2.0 unx      736 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/__about__.py
+-rw-r--r--  2.0 unx      562 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/__init__.py
+-rw-r--r--  2.0 unx     1128 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/_compat.py
+-rw-r--r--  2.0 unx     2022 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/_structures.py
+-rw-r--r--  2.0 unx     1812 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/_typing.py
+-rw-r--r--  2.0 unx     9509 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/markers.py
+-rw-r--r--  2.0 unx     4917 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/requirements.py
+-rw-r--r--  2.0 unx    31944 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/specifiers.py
+-rw-r--r--  2.0 unx    24067 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/tags.py
+-rw-r--r--  2.0 unx     1811 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/utils.py
+-rw-r--r--  2.0 unx    15470 b- defN 21-Oct-22 20:55 setuptools/_vendor/packaging/version.py
+-rw-r--r--  2.0 unx      217 b- defN 21-Oct-22 20:55 setuptools/command/__init__.py
+-rw-r--r--  2.0 unx     2381 b- defN 21-Oct-22 20:55 setuptools/command/alias.py
+-rw-r--r--  2.0 unx    16604 b- defN 21-Oct-22 20:55 setuptools/command/bdist_egg.py
+-rw-r--r--  2.0 unx     1182 b- defN 21-Oct-22 20:55 setuptools/command/bdist_rpm.py
+-rw-r--r--  2.0 unx     4415 b- defN 21-Oct-22 20:55 setuptools/command/build_clib.py
+-rw-r--r--  2.0 unx    13212 b- defN 21-Oct-22 20:55 setuptools/command/build_ext.py
+-rw-r--r--  2.0 unx     8276 b- defN 21-Oct-22 20:55 setuptools/command/build_py.py
+-rw-r--r--  2.0 unx     7012 b- defN 21-Oct-22 20:55 setuptools/command/develop.py
+-rw-r--r--  2.0 unx      960 b- defN 21-Oct-22 20:55 setuptools/command/dist_info.py
+-rw-r--r--  2.0 unx    85660 b- defN 21-Oct-22 20:55 setuptools/command/easy_install.py
+-rw-r--r--  2.0 unx    25335 b- defN 21-Oct-22 20:55 setuptools/command/egg_info.py
+-rw-r--r--  2.0 unx     4906 b- defN 21-Oct-22 20:55 setuptools/command/install.py
+-rw-r--r--  2.0 unx     2203 b- defN 21-Oct-22 20:55 setuptools/command/install_egg_info.py
+-rw-r--r--  2.0 unx     3875 b- defN 21-Oct-22 20:55 setuptools/command/install_lib.py
+-rw-r--r--  2.0 unx     2593 b- defN 21-Oct-22 20:55 setuptools/command/install_scripts.py
+-rw-r--r--  2.0 unx      628 b- defN 21-Oct-22 20:55 setuptools/command/launcher manifest.xml
+-rw-r--r--  2.0 unx     4946 b- defN 21-Oct-22 20:55 setuptools/command/py36compat.py
+-rw-r--r--  2.0 unx      468 b- defN 21-Oct-22 20:55 setuptools/command/register.py
+-rw-r--r--  2.0 unx     2128 b- defN 21-Oct-22 20:55 setuptools/command/rotate.py
+-rw-r--r--  2.0 unx      658 b- defN 21-Oct-22 20:55 setuptools/command/saveopts.py
+-rw-r--r--  2.0 unx     6172 b- defN 21-Oct-22 20:55 setuptools/command/sdist.py
+-rw-r--r--  2.0 unx     5086 b- defN 21-Oct-22 20:55 setuptools/command/setopt.py
+-rw-r--r--  2.0 unx     8088 b- defN 21-Oct-22 20:55 setuptools/command/test.py
+-rw-r--r--  2.0 unx      462 b- defN 21-Oct-22 20:55 setuptools/command/upload.py
+-rw-r--r--  2.0 unx     7218 b- defN 21-Oct-22 20:55 setuptools/command/upload_docs.py
+-rw-r--r--  2.0 unx     2407 b- defN 21-Oct-22 20:55 setuptools/extern/__init__.py
+-rw-r--r--  2.0 unx     1050 b- defN 21-Oct-22 20:56 setuptools-58.3.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     4852 b- defN 21-Oct-22 20:56 setuptools-58.3.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 21-Oct-22 20:56 setuptools-58.3.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx     2636 b- defN 21-Oct-22 20:56 setuptools-58.3.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       41 b- defN 21-Oct-22 20:56 setuptools-58.3.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    14148 b- defN 21-Oct-22 20:56 setuptools-58.3.0.dist-info/RECORD
+157 files, 2763774 bytes uncompressed, 923800 bytes compressed:  66.6%
```

#### zipnote «TEMP»/diffoscope_2t9ypn17_/tmp9y65vyq1_.zip

```diff
@@ -75,14 +75,17 @@
 
 Filename: setuptools/cli-32.exe
 Comment: 
 
 Filename: setuptools/cli-64.exe
 Comment: 
 
+Filename: setuptools/cli-arm64.exe
+Comment: 
+
 Filename: setuptools/cli.exe
 Comment: 
 
 Filename: setuptools/config.py
 Comment: 
 
 Filename: setuptools/dep_util.py
@@ -105,14 +108,17 @@
 
 Filename: setuptools/gui-32.exe
 Comment: 
 
 Filename: setuptools/gui-64.exe
 Comment: 
 
+Filename: setuptools/gui-arm64.exe
+Comment: 
+
 Filename: setuptools/gui.exe
 Comment: 
 
 Filename: setuptools/installer.py
 Comment: 
 
 Filename: setuptools/launch.py
@@ -441,26 +447,26 @@
 
 Filename: setuptools/command/upload_docs.py
 Comment: 
 
 Filename: setuptools/extern/__init__.py
 Comment: 
 
-Filename: setuptools-58.1.0.dist-info/LICENSE
+Filename: setuptools-58.3.0.dist-info/LICENSE
 Comment: 
 
-Filename: setuptools-58.1.0.dist-info/METADATA
+Filename: setuptools-58.3.0.dist-info/METADATA
 Comment: 
 
-Filename: setuptools-58.1.0.dist-info/WHEEL
+Filename: setuptools-58.3.0.dist-info/WHEEL
 Comment: 
 
-Filename: setuptools-58.1.0.dist-info/entry_points.txt
+Filename: setuptools-58.3.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: setuptools-58.1.0.dist-info/top_level.txt
+Filename: setuptools-58.3.0.dist-info/top_level.txt
 Comment: 
 
-Filename: setuptools-58.1.0.dist-info/RECORD
+Filename: setuptools-58.3.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

#### setuptools/__init__.py

```diff
@@ -1,13 +1,14 @@
 """Extensions to the 'distutils' for large or complex distributions"""
 
 from fnmatch import fnmatchcase
 import functools
 import os
 import re
+import warnings
 
 import _distutils_hack.override  # noqa: F401
 
 import distutils.core
 from distutils.errors import DistutilsOptionError
 from distutils.util import convert_path
 
@@ -140,14 +141,19 @@
             """
 
     dist = MinimalDistribution(attrs)
 
     # Honor setup.cfg's options.
     dist.parse_config_files(ignore_option_errors=True)
     if dist.setup_requires:
+        warnings.warn(
+            "setup_requires is deprecated. Supply build "
+            "dependencies using PEP 517 pyproject.toml build-requires.",
+            SetuptoolsDeprecationWarning,
+        )
         dist.fetch_build_eggs(dist.setup_requires)
 
 
 def setup(**attrs):
     # Make sure we have any requirements needed to interpret 'attrs'.
     _install_setup_requires(attrs)
     return distutils.core.setup(**attrs)
```

#### setuptools/_distutils/unixccompiler.py

```diff
@@ -241,31 +241,24 @@
                 return "-L" + dir
         elif sys.platform[:7] == "freebsd":
             return "-Wl,-rpath=" + dir
         elif sys.platform[:5] == "hp-ux":
             if self._is_gcc(compiler):
                 return ["-Wl,+s", "-L" + dir]
             return ["+s", "-L" + dir]
+
+        # For all compilers, `-Wl` is the presumed way to
+        # pass a compiler option to the linker and `-R` is
+        # the way to pass an RPATH.
+        if sysconfig.get_config_var("GNULD") == "yes":
+            # GNU ld needs an extra option to get a RUNPATH
+            # instead of just an RPATH.
+            return "-Wl,--enable-new-dtags,-R" + dir
         else:
-            if self._is_gcc(compiler):
-                # gcc on non-GNU systems does not need -Wl, but can
-                # use it anyway.  Since distutils has always passed in
-                # -Wl whenever gcc was used in the past it is probably
-                # safest to keep doing so.
-                if sysconfig.get_config_var("GNULD") == "yes":
-                    # GNU ld needs an extra option to get a RUNPATH
-                    # instead of just an RPATH.
-                    return "-Wl,--enable-new-dtags,-R" + dir
-                else:
-                    return "-Wl,-R" + dir
-            else:
-                # No idea how --enable-new-dtags would be passed on to
-                # ld if this system was using GNU ld.  Don't know if a
-                # system like this even exists.
-                return "-R" + dir
+            return "-Wl,-R" + dir
 
     def library_option(self, lib):
         return "-l" + lib
 
     def find_library_file(self, dirs, lib, debug=0):
         shared_f = self.library_filename(lib, lib_type='shared')
         dylib_f = self.library_filename(lib, lib_type='dylib')
```

#### setuptools/_distutils/util.py

```diff
@@ -130,22 +130,22 @@
             _syscfg_macosx_ver = ver
     return _syscfg_macosx_ver
 
 def get_macosx_target_ver():
     """Return the version of macOS for which we are building.
 
     The target version defaults to the version in sysconfig latched at time
-    the Python interpreter was built, unless overriden by an environment
+    the Python interpreter was built, unless overridden by an environment
     variable. If neither source has a value, then None is returned"""
 
     syscfg_ver = get_macosx_target_ver_from_syscfg()
     env_ver = os.environ.get(MACOSX_VERSION_VAR)
 
     if env_ver:
-        # Validate overriden version against sysconfig version, if have both.
+        # Validate overridden version against sysconfig version, if have both.
         # Ensure that the deployment target of the build process is not less
         # than 10.3 if the interpreter was built for 10.3 or later.  This
         # ensures extension modules are built with correct compatibility
         # values, specifically LDSHARED which can use
         # '-undefined dynamic_lookup' which only works on >= 10.3.
         if syscfg_ver and split_version(syscfg_ver) >= [10, 3] and \
             split_version(env_ver) < [10, 3]:
```

#### setuptools/command/easy_install.py

```diff
@@ -149,14 +149,20 @@
         'user'
     ]
 
     negative_opt = {'always-unzip': 'zip-ok'}
     create_index = PackageIndex
 
     def initialize_options(self):
+        warnings.warn(
+            "easy_install command is deprecated. "
+            "Use build and pip and other standards-based tools.",
+            EasyInstallDeprecationWarning,
+        )
+
         # the --user option seems to be an opt-in one,
         # so the default should be False.
         self.user = 0
         self.zip_ok = self.local_snapshots_ok = None
         self.install_dir = self.script_dir = self.exclude_scripts = None
         self.index_url = None
         self.find_links = None
@@ -2259,15 +2265,18 @@
 
     `type` should be either 'cli' or 'gui'
 
     Returns the executable as a byte string.
     """
     launcher_fn = '%s.exe' % type
     if is_64bit():
-        launcher_fn = launcher_fn.replace(".", "-64.")
+        if get_platform() == "win-arm64":
+            launcher_fn = launcher_fn.replace(".", "-arm64.")
+        else:
+            launcher_fn = launcher_fn.replace(".", "-64.")
     else:
         launcher_fn = launcher_fn.replace(".", "-32.")
     return resource_string('setuptools', launcher_fn)
 
 
 def load_launcher_manifest(name):
     manifest = pkg_resources.resource_string(__name__, 'launcher manifest.xml')
```

#### setuptools/command/install.py

```diff
@@ -26,14 +26,21 @@
     new_commands = [
         ('install_egg_info', lambda self: True),
         ('install_scripts', lambda self: True),
     ]
     _nc = dict(new_commands)
 
     def initialize_options(self):
+
+        warnings.warn(
+            "setup.py install is deprecated. "
+            "Use build and pip and other standards-based tools.",
+            setuptools.SetuptoolsDeprecationWarning,
+        )
+
         orig.install.initialize_options(self)
         self.old_and_unmanageable = None
         self.single_version_externally_managed = None
 
     def finalize_options(self):
         orig.install.finalize_options(self)
         if self.root:
```

#### setuptools/command/sdist.py

```diff
@@ -27,14 +27,18 @@
          "formats for source distribution (comma-separated list)"),
         ('keep-temp', 'k',
          "keep the distribution tree around after creating " +
          "archive file(s)"),
         ('dist-dir=', 'd',
          "directory to put the source distribution archive(s) in "
          "[default: dist]"),
+        ('owner=', 'u',
+         "Owner name used when creating a tar file [default: current user]"),
+        ('group=', 'g',
+         "Group name used when creating a tar file [default: current group]"),
     ]
 
     negative_opt = {}
 
     README_EXTENSIONS = ['', '.rst', '.txt', '.md']
     READMES = tuple('README{0}'.format(ext) for ext in README_EXTENSIONS)
```

#### Comparing `setuptools-58.1.0.dist-info/LICENSE` & `setuptools-58.3.0.dist-info/LICENSE`

 * *Files identical despite different names*

#### Comparing `setuptools-58.1.0.dist-info/METADATA` & `setuptools-58.3.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: setuptools
-Version: 58.1.0
+Version: 58.3.0
 Summary: Easily download, build, install, upgrade, and uninstall Python packages
 Home-page: https://github.com/pypa/setuptools
 Author: Python Packaging Authority
 Author-email: distutils-sig@python.org
 License: UNKNOWN
 Project-URL: Documentation, https://setuptools.readthedocs.io/
 Keywords: CPAN PyPI distutils eggs package management
```

#### Comparing `setuptools-58.1.0.dist-info/entry_points.txt` & `setuptools-58.3.0.dist-info/entry_points.txt`

 * *Files identical despite different names*

#### Comparing `setuptools-58.1.0.dist-info/RECORD` & `setuptools-58.3.0.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -14,31 +14,33 @@
 pkg_resources/_vendor/packaging/requirements.py,sha256=R8K4H4xX_iD4LvpGw1U3ouuPbGN-wzsFgD7brhAM71Y,4929
 pkg_resources/_vendor/packaging/specifiers.py,sha256=uYp9l13F0LcknS6d4N60ytiBgFmIhKideOq9AnsxTco,31944
 pkg_resources/_vendor/packaging/tags.py,sha256=NKMS37Zo_nWrZxgsD6zbXsXgc9edn9m160cBiLmHJdE,24067
 pkg_resources/_vendor/packaging/utils.py,sha256=RShlvnjO2CtYSD8uri32frMMFMTmB-3ihsq1-ghzLEw,1811
 pkg_resources/_vendor/packaging/version.py,sha256=Cnbm-OO9D_qd8ZTFxzFcjSavexSYFZmyeaoPvMsjgPc,15470
 pkg_resources/extern/__init__.py,sha256=3PixaT9Tzzd4NoyV6CVhGd7S_9Z-U5yvMWAftZKvC6k,2362
 pkg_resources/tests/data/my-test-package-source/setup.py,sha256=Mrezl3nqxkYkjCYpIxmjhhg4AR8hgi4QZdEYmk-I7R8,104
-setuptools/__init__.py,sha256=l7ULo8jGk-4-8jbacmJ58cYpSRX4swS1ccbJaJVAGdM,7448
+setuptools/__init__.py,sha256=h06afcaxHUhFjHFiEIoJhv6Sr0bTy9Aku4Rd8_82iys,7670
 setuptools/_deprecation_warning.py,sha256=jU9-dtfv6cKmtQJOXN8nP1mm7gONw5kKEtiPtbwnZyI,218
 setuptools/_imp.py,sha256=HmF91IbitRfsD5z-g4_wmcuH-RahyIONbPgiCOFgtzA,2392
 setuptools/archive_util.py,sha256=maJDbozRbDeSPw53VT0cb_IS3W0Ap73lJR8tX8RZDx0,7077
 setuptools/build_meta.py,sha256=x7FI1UPKCKxBBSopXocfGDnJa98rQO8atKXSwJtdid8,10280
 setuptools/cli-32.exe,sha256=dfEuovMNnA2HLa3jRfMPVi5tk4R7alCbpTvuxtCyw0Y,65536
 setuptools/cli-64.exe,sha256=KLABu5pyrnokJCv6skjXZ6GsXeyYHGcqOUT3oHI3Xpo,74752
+setuptools/cli-arm64.exe,sha256=o9amxowudZ98NvNWh_a2DRY8LhoIRqTAekxABqltiMc,137216
 setuptools/cli.exe,sha256=dfEuovMNnA2HLa3jRfMPVi5tk4R7alCbpTvuxtCyw0Y,65536
 setuptools/config.py,sha256=sm9ZbziX9DlOugcVlIbhqttMJwxwznGEsk82D8MVaDM,23123
 setuptools/dep_util.py,sha256=BDx1BkzNQntvAB4alypHbW5UVBzjqths000PrUL4Zqc,949
 setuptools/depends.py,sha256=iHfZdLdlCu2BllSF9bRg7NU0oqbPWMH8ljm4BuwQDY0,5474
 setuptools/dist.py,sha256=cZtPPzGEhSomPH_vXH_DeCFetjJ9B8Hv8VUCG0KbZh8,43087
 setuptools/errors.py,sha256=MVOcv381HNSajDgEUWzOQ4J6B5BHCBMSjHfaWcEwA1o,524
 setuptools/extension.py,sha256=NMM46XjNdVelWemc0x8CyVKA5Ks6Zm3xTWSA2SS6xZM,1684
 setuptools/glob.py,sha256=1oZjbfjAHSXbgdhSuR6YGU8jKob9L8NtEmBYqcPTLYk,4873
 setuptools/gui-32.exe,sha256=XBr0bHMA6Hpz2s9s9Bzjl-PwXfa9nH4ie0rFn4V2kWA,65536
 setuptools/gui-64.exe,sha256=aYKMhX1IJLn4ULHgWX0sE0yREUt6B3TEHf_jOw6yNyE,75264
+setuptools/gui-arm64.exe,sha256=TEFnOKDi-mq3ZszxqbCoCXTnM_lhUWjdIqBpr6fVs40,137728
 setuptools/gui.exe,sha256=XBr0bHMA6Hpz2s9s9Bzjl-PwXfa9nH4ie0rFn4V2kWA,65536
 setuptools/installer.py,sha256=jbhb7ZVkNV_bSUMgfnLcZw0IHr6REFnKF4o7_1Jqxm0,3567
 setuptools/launch.py,sha256=TyPT-Ic1T2EnYvGO26gfNRP4ysBlrhpbRjQxWsiO414,812
 setuptools/monkey.py,sha256=0e3HdVKXHL415O7np-AUqhEFXPPuDdJKbI47chQ_DE4,5217
 setuptools/msvc.py,sha256=3LLt938e6OR7wWPzIvCQu7LCWZSIKqoKV6w3r8jV3kY,50561
 setuptools/namespaces.py,sha256=PMqGVPXPYQgjUTvEg9bGccRAkIODrQ6NmsDg_fwErwI,3093
 setuptools/package_index.py,sha256=2A1O7fpTXcfeD5IV4HWrIoEXXkgq5k8t9aWrjx90Vnw,39886
@@ -72,16 +74,16 @@
 setuptools/_distutils/msvc9compiler.py,sha256=X623B92g0v8A3BEM9qpRf396AEd_hfjkfDUVTKu0hcE,30453
 setuptools/_distutils/msvccompiler.py,sha256=qruALeGRq8-CjtjE2tLQ8W26QnchcYedWzFme8AxZ4Q,23540
 setuptools/_distutils/py35compat.py,sha256=-sk1vBIsOgH-AobjIYbK_OEjdJF_54Ul_D1EiE9XM_c,455
 setuptools/_distutils/py38compat.py,sha256=II7ddBxOijC7uNN4z_46HYUjwYTJYMNiLJoGTormZm0,212
 setuptools/_distutils/spawn.py,sha256=4uE9k3VZWijxy7E_Rlcmh1MoamaPJ8rajdNBagKxjgU,3498
 setuptools/_distutils/sysconfig.py,sha256=mrtbAa9QXYXrNEe2HGKFyes2oJTNqImcgJGWiXnxOtQ,21630
 setuptools/_distutils/text_file.py,sha256=PsuAJeWdKJoLSV_6N6IpB5-0Pa84KzLUucJMFRazw3I,12483
-setuptools/_distutils/unixccompiler.py,sha256=VmkjwPXyVI8_nbHLqrGgS7xgf12JNeWXkWHcx1iRIj0,14980
-setuptools/_distutils/util.py,sha256=6UsgxxG3pzfimk2JHa5LBIHHddmBT-YdxoocXLlL6g4,20373
+setuptools/_distutils/unixccompiler.py,sha256=u2Sfs6LRmqQux4nZW08GwDtoFMded6wYnkiaO2TvKC4,14538
+setuptools/_distutils/util.py,sha256=QJLa8Xkzuw_7-o7fK5TnVc_zp_UHBXbTjiGmrY8nQ_4,20375
 setuptools/_distutils/version.py,sha256=8NogP6NPPQpp3EUMZcT9czEHia-ehqPo8spo_e7AgUU,12514
 setuptools/_distutils/versionpredicate.py,sha256=ZxpEA-TQv88mUWc6hetUO4qSqA2sa7ipjZ3QEK5evDk,5133
 setuptools/_distutils/command/__init__.py,sha256=2TA-rlNDlzeI-csbWHXFjGD8uOYqALMfyWOhT49nC6g,799
 setuptools/_distutils/command/bdist.py,sha256=2z4eudRl_n7m3lG9leL0IYqes4bsm8c0fxfZuiafjMg,5562
 setuptools/_distutils/command/bdist_dumb.py,sha256=BTur9jcIppyP7Piavjfsk7YjElqvxeYO2npUyPPOekc,4913
 setuptools/_distutils/command/bdist_msi.py,sha256=EVFQYN_X-ExeeP8gmdV9JcINsuUGsLJUz9afMU0Rt8c,35579
 setuptools/_distutils/command/bdist_rpm.py,sha256=gjOw22GhDSbcq0bdq25cTb-n6HWWm0bShLQad_mkJ4k,21537
@@ -126,30 +128,30 @@
 setuptools/command/bdist_egg.py,sha256=-upiB6fFtm8cQSQj1LRDVpG1-T143DsXCvV0fh03u7U,16604
 setuptools/command/bdist_rpm.py,sha256=PxrgoHPNaw2Pw2qNjjHDPC-Ay_IaDbCqP3d_5N-cj2A,1182
 setuptools/command/build_clib.py,sha256=fWHSFGkk10VCddBWCszvNhowbG9Z9CZXVjQ2uSInoOs,4415
 setuptools/command/build_ext.py,sha256=SNK042HfB2ezlDQbSVRGFqI1IM5A4AsjU1wpV3fgskE,13212
 setuptools/command/build_py.py,sha256=UydjclXl6FSyrPjXOOwZD-gHby0tIKoP-qu5itvyP0g,8276
 setuptools/command/develop.py,sha256=5_Ss7ENd1_B_jVMY1tF5UV_y1Xu6jbVzAPG8oKeluGA,7012
 setuptools/command/dist_info.py,sha256=5t6kOfrdgALT-P3ogss6PF9k-Leyesueycuk3dUyZnI,960
-setuptools/command/easy_install.py,sha256=uK0hIXMflGuefmQuA8c6lwwT7Np0uVXRWhxPiextgb4,85344
+setuptools/command/easy_install.py,sha256=C8Ppz7A2js_6Mv0KO8rqy_YPWCZzJX34e0KtVZRJxNo,85660
 setuptools/command/egg_info.py,sha256=se-FhYI1sZMzKd6lndV_-vNkJ31hX4HY4ZcMUu71l9k,25335
-setuptools/command/install.py,sha256=8doMxeQEDoK4Eco0mO2WlXXzzp9QnsGJQ7Z7yWkZPG8,4705
+setuptools/command/install.py,sha256=UynjFBgRyyHrDZRVAmXrXG0vChJAMx-sxnOO3JoAzVo,4906
 setuptools/command/install_egg_info.py,sha256=bMgeIeRiXzQ4DAGPV1328kcjwQjHjOWU4FngAWLV78Q,2203
 setuptools/command/install_lib.py,sha256=Uz42McsyHZAjrB6cw9E7Bz0xsaTbzxnM1PI9CBhiPtE,3875
 setuptools/command/install_scripts.py,sha256=o0jN_ex7yYYk8W5clymTFOXwkFMKzW9q_zd9Npcex7M,2593
 setuptools/command/launcher manifest.xml,sha256=xlLbjWrB01tKC0-hlVkOKkiSPbzMml2eOPtJ_ucCnbE,628
 setuptools/command/py36compat.py,sha256=7yLWzQj179Enx3pJ8V1cDDCzeLMFMd9XJXlK-iZTq5Y,4946
 setuptools/command/register.py,sha256=kk3DxXCb5lXTvqnhfwx2g6q7iwbUmgTyXUCaBooBOUk,468
 setuptools/command/rotate.py,sha256=SvsQPasezIojPjvMnfkqzh8P0U0tCj0daczF8uc3NQM,2128
 setuptools/command/saveopts.py,sha256=za7QCBcQimKKriWcoCcbhxPjUz30gSB74zuTL47xpP4,658
-setuptools/command/sdist.py,sha256=pEMF0GMVuaznNK6GFamK4GSXG9_qef0ic8z7jEsPmKo,5967
+setuptools/command/sdist.py,sha256=2wJds5JaCDpDZmxyN3vo4BqqrTkL-wRmDDLZPeYEGGE,6172
 setuptools/command/setopt.py,sha256=okxhqD1NM1nQlbSVDCNv6P7Y7g680sc2r-tUW7wPH1Y,5086
 setuptools/command/test.py,sha256=qGY-Hx1RPCndlVh2rsrEs5479CgmxRsrEflVLr98jVA,8088
 setuptools/command/upload.py,sha256=XT3YFVfYPAmA5qhGg0euluU98ftxRUW-PzKcODMLxUs,462
 setuptools/command/upload_docs.py,sha256=ba5kOyedD_u62weinrxqqnvpuQvBIuamXehJG6tAvO0,7218
 setuptools/extern/__init__.py,sha256=Hhf9W73WAitw9TdRJfDIb6YFjmK56CF61afds1Mg0HY,2407
-setuptools-58.1.0.dist-info/LICENSE,sha256=2z8CRrH5J48VhFuZ_sR4uLUG63ZIeZNyL4xuJUKF-vg,1050
-setuptools-58.1.0.dist-info/METADATA,sha256=jjOLGyArpWjlz4JTmU_TEhFruOOTABRjZYqBzJXus5A,4852
-setuptools-58.1.0.dist-info/WHEEL,sha256=ewwEueio1C2XeHTvT17n8dZUJgOvyCWCt0WVNLClP9o,92
-setuptools-58.1.0.dist-info/entry_points.txt,sha256=wpnhLrbtyk4hZ1qCCw48cCSxoQPzULMhIuaFqsB7GxQ,2636
-setuptools-58.1.0.dist-info/top_level.txt,sha256=d9yL39v_W7qmKDDSH6sT4bE0j_Ls1M3P161OGgdsm4g,41
-setuptools-58.1.0.dist-info/RECORD,,
+setuptools-58.3.0.dist-info/LICENSE,sha256=2z8CRrH5J48VhFuZ_sR4uLUG63ZIeZNyL4xuJUKF-vg,1050
+setuptools-58.3.0.dist-info/METADATA,sha256=uI89jlY7w7UjYJQzF3Bc4W3jK7VofkekiCtuLgOnNQY,4852
+setuptools-58.3.0.dist-info/WHEEL,sha256=ewwEueio1C2XeHTvT17n8dZUJgOvyCWCt0WVNLClP9o,92
+setuptools-58.3.0.dist-info/entry_points.txt,sha256=wpnhLrbtyk4hZ1qCCw48cCSxoQPzULMhIuaFqsB7GxQ,2636
+setuptools-58.3.0.dist-info/top_level.txt,sha256=d9yL39v_W7qmKDDSH6sT4bE0j_Ls1M3P161OGgdsm4g,41
+setuptools-58.3.0.dist-info/RECORD,,
```

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/embed/wheel-0.37.0-py2.py3-none-any.whl` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/embed/wheel-0.37.0-py2.py3-none-any.whl`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/periodic_update.py` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/periodic_update.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/seed/wheels/util.py` & `virtualenv-20.9.0/src/virtualenv/seed/wheels/util.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/util/lock.py` & `virtualenv-20.9.0/src/virtualenv/util/lock.py`

 * *Files 4% similar despite different names*

```diff
@@ -86,29 +86,31 @@
         with _store_lock:
             if lock_file not in _lock_store:
                 _lock_store[lock_file] = _CountedFileLock(lock_file)
             return _lock_store[lock_file]
 
     @staticmethod
     def _del_lock(lock):
-        with _store_lock:
-            if lock is not None:
+        if lock is not None:
+            with _store_lock:
                 with lock.thread_safe:
                     if lock.count == 0:
                         _lock_store.pop(lock.lock_file, None)
 
     def __del__(self):
         self._del_lock(self._lock)
 
     def __enter__(self):
         self._lock = self._create_lock()
         self._lock_file(self._lock)
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         self._release(self._lock)
+        self._del_lock(self._lock)
+        self._lock = None
 
     def _lock_file(self, lock, no_block=False):
         # multiple processes might be trying to get a first lock... so we cannot check if this directory exist without
         # a lock, but that lock might then become expensive, and it's not clear where that lock should live.
         # Instead here we just ignore if we fail to create the directory.
         try:
             os.makedirs(str(self.path))
@@ -134,14 +136,15 @@
             try:
                 self._lock_file(lock, no_block)
                 yield
             finally:
                 self._release(lock)
         finally:
             self._del_lock(lock)
+            lock = None
 
     @contextmanager
     def non_reentrant_lock_for_key(self, name):
         with _CountedFileLock(str(self.path / "{}.lock".format(name))):
             yield
```

### Comparing `virtualenv-20.8.1/src/virtualenv/util/path/_pathlib/via_os_path.py` & `virtualenv-20.9.0/src/virtualenv/util/path/_pathlib/via_os_path.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/util/path/_permission.py` & `virtualenv-20.9.0/src/virtualenv/util/path/_permission.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/util/path/_sync.py` & `virtualenv-20.9.0/src/virtualenv/util/path/_sync.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/util/path/_win.py` & `virtualenv-20.9.0/src/virtualenv/util/path/_win.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/util/six.py` & `virtualenv-20.9.0/src/virtualenv/util/six.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/util/subprocess/__init__.py` & `virtualenv-20.9.0/src/virtualenv/util/subprocess/__init__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/util/subprocess/_win_subprocess.py` & `virtualenv-20.9.0/src/virtualenv/util/subprocess/_win_subprocess.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv/util/zipapp.py` & `virtualenv-20.9.0/src/virtualenv/util/zipapp.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv.egg-info/PKG-INFO` & `virtualenv-20.9.0/src/virtualenv.egg-info/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: virtualenv
-Version: 20.8.1
+Version: 20.9.0
 Summary: Virtual Python Environment builder
 Home-page: https://virtualenv.pypa.io/
 Author: Bernat Gabor
 Author-email: gaborjbernat@gmail.com
 Maintainer: Bernat Gabor
 Maintainer-email: gaborjbernat@gmail.com
 License: MIT
```

### Comparing `virtualenv-20.8.1/src/virtualenv.egg-info/SOURCES.txt` & `virtualenv-20.9.0/src/virtualenv.egg-info/SOURCES.txt`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 .coveragerc
 .dockerignore
 .pre-commit-config.yaml
 .readthedocs.yml
 LICENSE
 README.md
-codecov.yaml
+codecov.yml
 pyproject.toml
 setup.cfg
 setup.py
 tox.ini
 .github/ISSUE_TEMPLATE/bug-report.md
 .github/ISSUE_TEMPLATE/bug_report.md
 .github/ISSUE_TEMPLATE/config.yml
@@ -20,14 +20,19 @@
 docs/development.rst
 docs/extend.rst
 docs/index.rst
 docs/installation.rst
 docs/render_cli.py
 docs/user_guide.rst
 docs/_static/custom.css
+docs/changelog/2182.bugfix.txt
+docs/changelog/2205.bugfix.rst
+docs/changelog/2218.misc.rst
+docs/changelog/2220.feature.rst
+docs/changelog/2221.bugfix.rst
 docs/changelog/examples.rst
 docs/changelog/template.jinja2
 src/virtualenv/__init__.py
 src/virtualenv/__main__.py
 src/virtualenv/info.py
 src/virtualenv/report.py
 src/virtualenv/version.py
@@ -126,18 +131,18 @@
 src/virtualenv/seed/wheels/__init__.py
 src/virtualenv/seed/wheels/acquire.py
 src/virtualenv/seed/wheels/bundle.py
 src/virtualenv/seed/wheels/periodic_update.py
 src/virtualenv/seed/wheels/util.py
 src/virtualenv/seed/wheels/embed/__init__.py
 src/virtualenv/seed/wheels/embed/pip-20.3.4-py2.py3-none-any.whl
-src/virtualenv/seed/wheels/embed/pip-21.2.4-py3-none-any.whl
+src/virtualenv/seed/wheels/embed/pip-21.3.1-py3-none-any.whl
 src/virtualenv/seed/wheels/embed/setuptools-44.1.1-py2.py3-none-any.whl
 src/virtualenv/seed/wheels/embed/setuptools-50.3.2-py3-none-any.whl
-src/virtualenv/seed/wheels/embed/setuptools-58.1.0-py3-none-any.whl
+src/virtualenv/seed/wheels/embed/setuptools-58.3.0-py3-none-any.whl
 src/virtualenv/seed/wheels/embed/wheel-0.37.0-py2.py3-none-any.whl
 src/virtualenv/util/__init__.py
 src/virtualenv/util/error.py
 src/virtualenv/util/lock.py
 src/virtualenv/util/six.py
 src/virtualenv/util/zipapp.py
 src/virtualenv/util/path/__init__.py
@@ -155,14 +160,15 @@
 tests/integration/test_run_int.py
 tests/integration/test_zipapp.py
 tests/unit/test_run.py
 tests/unit/test_util.py
 tests/unit/activation/conftest.py
 tests/unit/activation/test_activate_this.py
 tests/unit/activation/test_activation_support.py
+tests/unit/activation/test_activator.py
 tests/unit/activation/test_bash.py
 tests/unit/activation/test_batch.py
 tests/unit/activation/test_csh.py
 tests/unit/activation/test_fish.py
 tests/unit/activation/test_nushell.py
 tests/unit/activation/test_powershell.py
 tests/unit/activation/test_python_activator.py
```

### Comparing `virtualenv-20.8.1/src/virtualenv.egg-info/entry_points.txt` & `virtualenv-20.9.0/src/virtualenv.egg-info/entry_points.txt`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/src/virtualenv.egg-info/requires.txt` & `virtualenv-20.9.0/src/virtualenv.egg-info/requires.txt`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 backports.entry_points_selectable>=1.0.4
 distlib<1,>=0.3.1
-filelock<4,>=3.0.0
+filelock<4,>=3.2
 platformdirs<3,>=2
 six<2,>=1.9.0
 
 [:python_version < "3.4" and sys_platform != "win32"]
 pathlib2<3,>=2.3.3
 
 [:python_version < "3.7"]
```

### Comparing `virtualenv-20.8.1/tasks/__main__zipapp.py` & `virtualenv-20.9.0/tasks/__main__zipapp.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tasks/make_zipapp.py` & `virtualenv-20.9.0/tasks/make_zipapp.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tasks/update_embedded.py` & `virtualenv-20.9.0/tasks/update_embedded.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/conftest.py` & `virtualenv-20.9.0/tests/conftest.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/integration/test_run_int.py` & `virtualenv-20.9.0/tests/integration/test_run_int.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/integration/test_zipapp.py` & `virtualenv-20.9.0/tests/integration/test_zipapp.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/conftest.py` & `virtualenv-20.9.0/tests/unit/activation/conftest.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/test_activate_this.py` & `virtualenv-20.9.0/tests/unit/activation/test_activate_this.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/test_activation_support.py` & `virtualenv-20.9.0/tests/unit/activation/test_activation_support.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/test_bash.py` & `virtualenv-20.9.0/tests/unit/activation/test_bash.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/test_batch.py` & `virtualenv-20.9.0/tests/unit/activation/test_batch.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/test_fish.py` & `virtualenv-20.9.0/tests/unit/activation/test_fish.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/test_nushell.py` & `virtualenv-20.9.0/tests/unit/activation/test_nushell.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/test_powershell.py` & `virtualenv-20.9.0/tests/unit/activation/test_powershell.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/activation/test_python_activator.py` & `virtualenv-20.9.0/tests/unit/activation/test_python_activator.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/config/cli/test_parser.py` & `virtualenv-20.9.0/tests/unit/config/cli/test_parser.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/config/test___main__.py` & `virtualenv-20.9.0/tests/unit/config/test___main__.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/config/test_env_var.py` & `virtualenv-20.9.0/tests/unit/config/test_env_var.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/config/test_ini.py` & `virtualenv-20.9.0/tests/unit/config/test_ini.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/create/conftest.py` & `virtualenv-20.9.0/tests/unit/create/conftest.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/create/test_creator.py` & `virtualenv-20.9.0/tests/unit/create/test_creator.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/create/test_interpreters.py` & `virtualenv-20.9.0/tests/unit/create/test_interpreters.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/create/via_global_ref/greet/greet3.c` & `virtualenv-20.9.0/tests/unit/create/via_global_ref/greet/greet3.c`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/create/via_global_ref/test_build_c_ext.py` & `virtualenv-20.9.0/tests/unit/create/via_global_ref/test_build_c_ext.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/create/virtualenv-16.7.9-py2.py3-none-any.whl` & `virtualenv-20.9.0/tests/unit/create/virtualenv-16.7.9-py2.py3-none-any.whl`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/discovery/py_info/test_py_info.py` & `virtualenv-20.9.0/tests/unit/discovery/py_info/test_py_info.py`

 * *Files 0% similar despite different names*

```diff
@@ -39,15 +39,15 @@
 def test_bad_exe_py_info_no_raise(tmp_path, caplog, capsys, session_app_data):
     caplog.set_level(logging.NOTSET)
     exe = str(tmp_path)
     result = PythonInfo.from_exe(exe, session_app_data, raise_on_error=False)
     assert result is None
     out, _ = capsys.readouterr()
     assert not out
-    messages = [r.message for r in caplog.records if r.filename != "filelock.py"]
+    messages = [r.message for r in caplog.records if r.name != "filelock"]
     assert len(messages) == 2
     msg = messages[0]
     assert "get interpreter info via cmd: " in msg
     msg = messages[1]
     assert str(exe) in msg
     assert "code" in msg
```

### Comparing `virtualenv-20.8.1/tests/unit/discovery/py_info/test_py_info_exe_based_of.py` & `virtualenv-20.9.0/tests/unit/discovery/py_info/test_py_info_exe_based_of.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/discovery/test_discovery.py` & `virtualenv-20.9.0/tests/unit/discovery/test_discovery.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/discovery/test_py_spec.py` & `virtualenv-20.9.0/tests/unit/discovery/test_py_spec.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/discovery/windows/test_windows_pep514.py` & `virtualenv-20.9.0/tests/unit/discovery/windows/test_windows_pep514.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/discovery/windows/winreg-mock-values.py` & `virtualenv-20.9.0/tests/unit/discovery/windows/winreg-mock-values.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/seed/embed/test_bootstrap_link_via_app_data.py` & `virtualenv-20.9.0/tests/unit/seed/embed/test_bootstrap_link_via_app_data.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/seed/embed/test_pip_invoke.py` & `virtualenv-20.9.0/tests/unit/seed/embed/test_pip_invoke.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/seed/wheels/test_acquire.py` & `virtualenv-20.9.0/tests/unit/seed/wheels/test_acquire.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/seed/wheels/test_acquire_find_wheel.py` & `virtualenv-20.9.0/tests/unit/seed/wheels/test_acquire_find_wheel.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/seed/wheels/test_periodic_update.py` & `virtualenv-20.9.0/tests/unit/seed/wheels/test_periodic_update.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/seed/wheels/test_wheels_util.py` & `virtualenv-20.9.0/tests/unit/seed/wheels/test_wheels_util.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/test_run.py` & `virtualenv-20.9.0/tests/unit/test_run.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tests/unit/test_util.py` & `virtualenv-20.9.0/tests/unit/test_util.py`

 * *Files identical despite different names*

### Comparing `virtualenv-20.8.1/tox.ini` & `virtualenv-20.9.0/tox.ini`

 * *Files identical despite different names*

